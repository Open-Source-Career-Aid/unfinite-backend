,id,title,categories,abstract,doi,created,updated,authors,pdf_url
0,1703.10049,autonomous recharging and flight mission planning for battery-operated   autonomous drones,cs.ro cs.ds,"unmanned aerial vehicles (uavs), commonly known as drones, are being increasingly deployed throughout the globe as a means to streamline monitoring, inspection, mapping, and logistic routines. when dispatched on autonomous missions, drones require an intelligent decision-making system for trajectory planning and tour optimization. given the limited capacity of their onboard batteries, a key design challenge is to ensure the underlying algorithms can efficiently optimize the mission objectives along with recharging operations during long-haul flights. with this in view, the present work undertakes a comprehensive study on automated tour management systems for an energy-constrained drone: (1) we construct a machine learning model that estimates the energy expenditure of typical multi-rotor drones while accounting for real-world aspects and extrinsic meteorological factors. (2) leveraging this model, the joint program of flight mission planning and recharging optimization is formulated as a multi-criteria asymmetric traveling salesman problem (atsp), wherein a drone seeks for the time-optimal energy-feasible tour that visits all the target sites and refuels whenever necessary. (3) we devise an efficient approximation algorithm with provable worst-case performance guarantees and implement it in a drone management system, which supports real-time flight path tracking and re-computation in dynamic environments. (4) the effectiveness and practicality of the proposed approach are validated through extensive numerical simulations as well as real-world experiments.",10.1109/tase.2022.3175565,2017-03-29,2022-04-19,"['rashid alyassi', 'majid khonji', 'areg karapetyan', 'sid chi-kin chau', 'khaled elbassioni', 'chien-ming tseng']",https://arxiv.org/pdf/1703.10049.pdf
1,1807.07889,"submodular maximization with nearly optimal approximation, adaptivity   and query complexity",cs.ds,"submodular optimization generalizes many classic problems in combinatorial optimization and has recently found a wide range of applications in machine learning (e.g., feature engineering and active learning). for many large-scale optimization problems, we are often concerned with the adaptivity complexity of an algorithm, which quantifies the number of sequential rounds where polynomially-many independent function evaluations can be executed in parallel. while low adaptivity is ideal, it is not sufficient for a distributed algorithm to be efficient, since in many practical applications of submodular optimization the number of function evaluations becomes prohibitively expensive. motivated by these applications, we study the adaptivity and query complexity of adaptive submodular optimization.   our main result is a distributed algorithm for maximizing a monotone submodular function with cardinality constraint $k$ that achieves a $(1-1/e-\varepsilon)$-approximation in expectation. this algorithm runs in $o(\log(n))$ adaptive rounds and makes $o(n)$ calls to the function evaluation oracle in expectation. the approximation guarantee and query complexity are optimal, and the adaptivity is nearly optimal. moreover, the number of queries is substantially less than in previous works. last, we extend our results to the submodular cover problem to demonstrate the generality of our algorithm and techniques.",10.1137/1.9781611975482.17,2018-07-20,2023-04-07,"['matthew fahrbach', 'vahab mirrokni', 'morteza zadimoghaddam']",https://arxiv.org/pdf/1807.07889.pdf
2,1808.06932,non-monotone submodular maximization with nearly optimal adaptivity and   query complexity,cs.ds,"submodular maximization is a general optimization problem with a wide range of applications in machine learning (e.g., active learning, clustering, and feature selection). in large-scale optimization, the parallel running time of an algorithm is governed by its adaptivity, which measures the number of sequential rounds needed if the algorithm can execute polynomially-many independent oracle queries in parallel. while low adaptivity is ideal, it is not sufficient for an algorithm to be efficient in practice -- there are many applications of distributed submodular optimization where the number of function evaluations becomes prohibitively expensive. motivated by these applications, we study the adaptivity and query complexity of submodular maximization. in this paper, we give the first constant-factor approximation algorithm for maximizing a non-monotone submodular function subject to a cardinality constraint $k$ that runs in $o(\log(n))$ adaptive rounds and makes $o(n \log(k))$ oracle queries in expectation. in our empirical study, we use three real-world applications to compare our algorithm with several benchmarks for non-monotone submodular maximization. the results demonstrate that our algorithm finds competitive solutions using significantly fewer rounds and queries.",,2018-08-19,2023-04-07,"['matthew fahrbach', 'vahab mirrokni', 'morteza zadimoghaddam']",https://arxiv.org/pdf/1808.06932.pdf
3,1811.00915,convolutional neural networks for epileptic seizure prediction,cs.lg q-bio.nc stat.ml,"epilepsy is the most common neurological disorder and an accurate forecast of seizures would help to overcome the patient's uncertainty and helplessness. in this contribution, we present and discuss a novel methodology for the classification of intracranial electroencephalography (ieeg) for seizure prediction. contrary to previous approaches, we categorically refrain from an extraction of hand-crafted features and use a convolutional neural network (cnn) topology instead for both the determination of suitable signal characteristics and the binary classification of preictal and interictal segments. three different models have been evaluated on public datasets with long-term recordings from four dogs and three patients. overall, our findings demonstrate the general applicability. in this work we discuss the strengths and limitations of our methodology.",10.1109/bibm.2018.8621225,2018-11-02,2023-04-11,"['matthias eberlein', 'raphael hildebrand', 'ronald tetzlaff', 'nico hoffmann', 'levin kuhlmann', 'benjamin brinkmann', 'jens m√ºller']",https://arxiv.org/pdf/1811.00915.pdf
4,1911.09660,estimating uncertainty of earthquake rupture using bayesian neural   network,stat.ml cs.lg physics.geo-ph,"bayesian neural networks (bnn) are the probabilistic model that combines the strengths of both neural network (nn) and stochastic processes. as a result, bnn can combat overfitting and perform well in applications where data is limited. earthquake rupture study is such a problem where data is insufficient, and scientists have to rely on many trial and error numerical or physical models. lack of resources and computational expenses, often, it becomes hard to determine the reasons behind the earthquake rupture. in this work, a bnn has been used (1) to combat the small data problem and (2) to find out the parameter combinations responsible for earthquake rupture and (3) to estimate the uncertainty associated with earthquake rupture. two thousand rupture simulations are used to train and test the model. a simple 2d rupture geometry is considered where the fault has a gaussian geometric heterogeneity at the center, and eight parameters vary in each simulation. the test f1-score of bnn (0.8334), which is 2.34% higher than plain nn score. results show that the parameters of rupture propagation have higher uncertainty than the rupture arrest. normal stresses play a vital role in determining rupture propagation and are also the highest source of uncertainty, followed by the dynamic friction coefficient. shear stress has a moderate role, whereas the geometric features such as the width and height of the fault are least significant and uncertain.",,2019-11-21,2023-04-11,"['sabber ahamed', 'md mesbah uddin']",https://arxiv.org/pdf/1911.09660.pdf
5,2002.07920,block switching: a stochastic approach for deep learning security,cs.lg cs.cv,"recent study of adversarial attacks has revealed the vulnerability of modern deep learning models. that is, subtly crafted perturbations of the input can make a trained network with high accuracy produce arbitrary incorrect predictions, while maintain imperceptible to human vision system. in this paper, we introduce block switching (bs), a defense strategy against adversarial attacks based on stochasticity. bs replaces a block of model layers with multiple parallel channels, and the active channel is randomly assigned in the run time hence unpredictable to the adversary. we show empirically that bs leads to a more dispersed input gradient distribution and superior defense effectiveness compared with other stochastic defenses such as stochastic activation pruning (sap). compared to other defenses, bs is also characterized by the following features: (i) bs causes less test accuracy drop; (ii) bs is attack-independent and (iii) bs is compatible with other defenses and can be used jointly with others.",10.47852/bonviewjcce2202320,2020-02-18,,"['xiao wang', 'siyue wang', 'pin-yu chen', 'xue lin', 'peter chin']",https://arxiv.org/pdf/2002.07920.pdf
6,2003.00120,improving certified robustness via statistical learning with logical   reasoning,cs.lg cs.cr stat.ml,"intensive algorithmic efforts have been made to enable the rapid improvements of certificated robustness for complex ml models recently. however, current robustness certification methods are only able to certify under a limited perturbation radius. given that existing pure data-driven statistical approaches have reached a bottleneck, in this paper, we propose to integrate statistical ml models with knowledge (expressed as logical rules) as a reasoning component using markov logic networks (mln, so as to further improve the overall certified robustness. this opens new research questions about certifying the robustness of such a paradigm, especially the reasoning component (e.g., mln). as the first step towards understanding these questions, we first prove that the computational complexity of certifying the robustness of mln is #p-hard. guided by this hardness result, we then derive the first certified robustness bound for mln by carefully analyzing different model regimes. finally, we conduct extensive experiments on five datasets including both high-dimensional images and natural language texts, and we show that the certified robustness with knowledge-based logical reasoning indeed significantly outperforms that of the state-of-the-arts.",,2020-02-28,2023-04-12,"['zhuolin yang', 'zhikuan zhao', 'boxin wang', 'jiawei zhang', 'linyi li', 'hengzhi pei', 'bojan karlas', 'ji liu', 'heng guo', 'ce zhang', 'bo li']",https://arxiv.org/pdf/2003.00120.pdf
7,2003.14105,learning cross-domain semantic-visual relationships for transductive   zero-shot learning,cs.cv,"zero-shot learning (zsl) learns models for recognizing new classes. one of the main challenges in zsl is the domain discrepancy caused by the category inconsistency between training and testing data. domain adaptation is the most intuitive way to address this challenge. however, existing domain adaptation techniques cannot be directly applied into zsl due to the disjoint label space between source and target domains. this work proposes the transferrable semantic-visual relation (tsvr) approach towards transductive zsl. tsvr redefines image recognition as predicting the similarity/dissimilarity labels for semantic-visual fusions consisting of class attributes and visual features. after the above transformation, the source and target domains can have the same label space, which hence enables to quantify domain discrepancy. for the redefined problem, the number of similar semantic-visual pairs is significantly smaller than that of dissimilar ones. to this end, we further propose to use domain-specific batch normalization to align the domain discrepancy.",,2020-03-31,2023-04-08,"['fengmao lv', 'jianyang zhang', 'guowu yang', 'lei feng', 'yufeng yu', 'lixin duan']",https://arxiv.org/pdf/2003.14105.pdf
8,2005.04843,semi-supervised hypergraph node classification on hypergraph line   expansion,cs.lg cs.si stat.ml,"previous hypergraph expansions are solely carried out on either vertex level or hyperedge level, thereby missing the symmetric nature of data co-occurrence, and resulting in information loss. to address the problem, this paper treats vertices and hyperedges equally and proposes a new hypergraph formulation named the \emph{line expansion (le)} for hypergraphs learning. the new expansion bijectively induces a homogeneous structure from the hypergraph by treating vertex-hyperedge pairs as ""line nodes"". by reducing the hypergraph to a simple graph, the proposed \emph{line expansion} makes existing graph learning algorithms compatible with the higher-order structure and has been proven as a unifying framework for various hypergraph expansions. we evaluate the proposed line expansion on five hypergraph datasets, the results show that our method beats sota baselines by a significant margin.",,2020-05-10,2023-04-13,"['chaoqi yang', 'ruijie wang', 'shuochao yao', 'tarek abdelzaher']",https://arxiv.org/pdf/2005.04843.pdf
9,2006.01244,the power of factorial powers: new parameter settings for (stochastic)   optimization,cs.lg math.oc stat.ml,"the convergence rates for convex and non-convex optimization methods depend on the choice of a host of constants, including step sizes, lyapunov function constants and momentum constants. in this work we propose the use of factorial powers as a flexible tool for defining constants that appear in convergence proofs. we list a number of remarkable properties that these sequences enjoy, and show how they can be applied to convergence proofs to simplify or improve the convergence rates of the momentum method, accelerated gradient and the stochastic variance reduced method (svrg).",,2020-06-01,2023-04-11,"['aaron defazio', 'robert m. gower']",https://arxiv.org/pdf/2006.01244.pdf
10,2007.02519,fluid: a unified evaluation framework for flexible sequential data,cs.cv cs.lg,"modern ml methods excel when training data is iid, large-scale, and well labeled. learning in less ideal conditions remains an open challenge. the sub-fields of few-shot, continual, transfer, and representation learning have made substantial strides in learning under adverse conditions; each affording distinct advantages through methods and insights. these methods address different challenges such as data arriving sequentially or scarce training examples, however often the difficult conditions an ml system will face over its lifetime cannot be anticipated prior to deployment. therefore, general ml systems which can handle the many challenges of learning in practical settings are needed. to foster research towards the goal of general ml methods, we introduce a new unified evaluation framework - fluid (flexible sequential data). fluid integrates the objectives of few-shot, continual, transfer, and representation learning while enabling comparison and integration of techniques across these subfields. in fluid, a learner faces a stream of data and must make sequential predictions while choosing how to update itself, adapt quickly to novel classes, and deal with changing data distributions; while accounting for the total amount of compute. we conduct experiments on a broad set of methods which shed new insight on the advantages and limitations of current solutions and indicate new research problems to solve. as a starting point towards more general methods, we present two new baselines which outperform other evaluated methods on fluid. project page: https://raivn.cs.washington.edu/projects/fluid/.",,2020-07-06,2023-04-10,"['matthew wallingford', 'aditya kusupati', 'keivan alizadeh-vahid', 'aaron walsman', 'aniruddha kembhavi', 'ali farhadi']",https://arxiv.org/pdf/2007.02519.pdf
11,2008.01468,on feature relevance uncertainty: a monte carlo dropout sampling   approach,cs.lg stat.ml,"understanding decisions made by neural networks is key for the deployment of intelligent systems in real world applications. however, the opaque decision making process of these systems is a disadvantage where interpretability is essential. many feature-based explanation techniques have been introduced over the last few years in the field of machine learning to better understand decisions made by neural networks and have become an important component to verify their reasoning capabilities. however, existing methods do not allow statements to be made about the uncertainty regarding a feature's relevance for the prediction. in this paper, we introduce monte carlo relevance propagation (mcrp) for feature relevance uncertainty estimation. a simple but powerful method based on monte carlo estimation of the feature relevance distribution to compute feature relevance uncertainty scores that allow a deeper understanding of a neural network's perception and reasoning.",10.5281/zenodo.3970396,2020-08-04,2023-04-11,"['kai fischer', 'jonas schneider']",https://arxiv.org/pdf/2008.01468.pdf
12,2009.04131,sok: certified robustness for deep neural networks,cs.lg cs.cr stat.ml,"great advances in deep neural networks (dnns) have led to state-of-the-art performance on a wide range of tasks. however, recent studies have shown that dnns are vulnerable to adversarial attacks, which have brought great concerns when deploying these models to safety-critical applications such as autonomous driving. different defense approaches have been proposed against adversarial attacks, including: a) empirical defenses, which can usually be adaptively attacked again without providing robustness certification; and b) certifiably robust approaches, which consist of robustness verification providing the lower bound of robust accuracy against any attacks under certain conditions and corresponding robust training approaches. in this paper, we systematize certifiably robust approaches and related practical and theoretical implications and findings. we also provide the first comprehensive benchmark on existing robustness verification and training approaches on different datasets. in particular, we 1) provide a taxonomy for the robustness verification and training approaches, as well as summarize the methodologies for representative algorithms, 2) reveal the characteristics, strengths, limitations, and fundamental connections among these approaches, 3) discuss current research progresses, theoretical barriers, main challenges, and future directions for certifiably robust approaches for dnns, and 4) provide an open-sourced unified platform to evaluate 20+ representative certifiably robust approaches.",,2020-09-09,2023-04-12,"['linyi li', 'tao xie', 'bo li']",https://arxiv.org/pdf/2009.04131.pdf
13,2010.11642,the role of mutual information in variational classifiers,stat.ml cs.lg,"overfitting data is a well-known phenomenon related with the generation of a model that mimics too closely (or exactly) a particular instance of data, and may therefore fail to predict future observations reliably. in practice, this behaviour is controlled by various--sometimes heuristics--regularization techniques, which are motivated by developing upper bounds to the generalization error. in this work, we study the generalization error of classifiers relying on stochastic encodings trained on the cross-entropy loss, which is often used in deep learning for classification problems. we derive bounds to the generalization error showing that there exists a regime where the generalization error is bounded by the mutual information between input features and the corresponding representations in the latent space, which are randomly generated according to the encoding distribution. our bounds provide an information-theoretic understanding of generalization in the so-called class of variational classifiers, which are regularized by a kullback-leibler (kl) divergence term. these results give theoretical grounds for the highly popular kl term in variational inference methods that was already recognized to act effectively as a regularization penalty. we further observe connections with well studied notions such as variational autoencoders, information dropout, information bottleneck and boltzmann machines. finally, we perform numerical experiments on mnist and cifar datasets and show that mutual information is indeed highly representative of the behaviour of the generalization error.",,2020-10-22,2023-04-13,"['matias vera', 'leonardo rey vega', 'pablo piantanida']",https://arxiv.org/pdf/2010.11642.pdf
14,2011.05001,mmd-regularized unbalanced optimal transport,cs.lg math.oc,"we study the unbalanced optimal transport (uot) problem, where the marginal constraints are enforced using maximum mean discrepancy (mmd) regularization. our study is motivated by the observation that existing works on uot have mainly focused on regularization based on $\phi$-divergence (e.g., kl). the role of mmd, which belongs to the complementary family of integral probability metrics (ipms), as a regularizer in the context of uot seems to be less understood. our main result is based on fenchel duality, using which we are able to study the properties of mmd-regularized uot (mmd-uot). one interesting outcome of this duality result is that mmd-uot induces a novel metric over measures, which again belongs to the ipm family. further, we present finite-sample-based convex programs for estimating mmd-uot and the corresponding barycenter. under mild conditions, we prove that our convex-program-based estimators are consistent, and the estimation error decays at a rate $\mathcal{o}\left(m^{-\frac{1}{2}}\right)$, where $m$ is the number of samples from the source/target measures. finally, we discuss how these convex programs can be solved efficiently using (accelerated) projected gradient descent. we conduct diverse experiments to show that mmd-uot is a promising alternative to $\phi$-divergence-regularized uot in machine learning applications.",,2020-11-10,2023-04-11,"['piyushi manupriya', 'j. saketha nath', 'pratik jawanpuria']",https://arxiv.org/pdf/2011.05001.pdf
15,2012.08443,strong overall error analysis for the training of artificial neural   networks via random initializations,cs.lg cs.na math.na math.st stat.th,"although deep learning based approximation algorithms have been applied very successfully to numerous problems, at the moment the reasons for their performance are not entirely understood from a mathematical point of view. recently, estimates for the convergence of the overall error have been obtained in the situation of deep supervised learning, but with an extremely slow rate of convergence. in this note we partially improve on these estimates. more specifically, we show that the depth of the neural network only needs to increase much slower in order to obtain the same rate of approximation. the results hold in the case of an arbitrary stochastic optimization algorithm with i.i.d.\ random initializations.",10.1007/s40304-022-00292-9,2020-12-15,,"['arnulf jentzen', 'adrian riekert']",https://arxiv.org/pdf/2012.08443.pdf
16,2012.14331,a method to integrate and classify normal distributions,stat.ml cs.cv cs.lg,"univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. we demonstrate these tools with vision research applications of detecting occluding objects in natural scenes, and detecting camouflage.",,2020-12-23,2023-04-12,"['abhranil das', 'wilson s geisler']",https://arxiv.org/pdf/2012.14331.pdf
17,2101.11156,fundamental limits and algorithms for sparse linear regression with   sublinear sparsity,cs.it cs.lg math.it stat.ml,"we establish exact asymptotic expressions for the normalized mutual information and minimum mean-square-error (mmse) of sparse linear regression in the sub-linear sparsity regime. our result is achieved by a generalization of the adaptive interpolation method in bayesian inference for linear regimes to sub-linear ones. a modification of the well-known approximate message passing algorithm to approach the mmse fundamental limit is also proposed, and its state evolution is rigorously analyzed. our results show that the traditional linear assumption between the signal dimension and number of observations in the replica and adaptive interpolation methods is not necessary for sparse signals. they also show how to modify the existing well-known amp algorithms for linear regimes to sub-linear ones.",,2021-01-26,2023-04-08,['lan v. truong'],https://arxiv.org/pdf/2101.11156.pdf
18,2102.10205,cknet: a convolutional neural network based on koopman operator for   modeling latent dynamics from pixels,eess.sy cs.lg cs.sy,"with the development of end-to-end control based on deep learning, it is important to study new system modeling techniques to realize dynamics modeling with high-dimensional inputs. in this paper, a novel koopman-based deep convolutional network, called cknet, is proposed to identify latent dynamics from raw pixels. cknet learns an encoder and decoder to play the role of the koopman eigenfunctions and modes, respectively. the koopman eigenvalues can be approximated by eigenvalues of the learned state transition matrix. the deterministic convolutional koopman network (dcknet) and the variational convolutional koopman network (vcknet) are proposed to span some subspace for approximating the koopman operator respectively. because cknet is trained under the constraints of the koopman theory, the identified latent dynamics is in a linear form and has good interpretability. besides, the state transition and control matrices are trained as trainable tensors so that the identified dynamics is also time-invariant. we also design an auxiliary weight term for reducing multi-step linearity and prediction losses. experiments were conducted on two offline trained and four online trained nonlinear forced dynamical systems with continuous action spaces in gym and mujoco environment respectively, and the results show that identified dynamics are adequate for approximating the latent dynamics and generating clear images. especially for offline trained cases, this work confirms cknet from a novel perspective that we visualize the evolutionary processes of the latent states and the koopman eigenfunctions with dcknet and vcknet separately to each task based on the same episode and results demonstrate that different approaches learn similar features in shapes.",10.1049/cit2.12149,2021-02-19,2021-07-27,"['yongqian xiao', 'xin xu', 'qianli lin']",https://arxiv.org/pdf/2102.10205.pdf
19,2102.12736,time-series imputation with wasserstein interpolation for optimal   look-ahead-bias and variance tradeoff,stat.ml cs.lg,"missing time-series data is a prevalent practical problem. imputation methods in time-series data often are applied to the full panel data with the purpose of training a model for a downstream out-of-sample task. for example, in finance, imputation of missing returns may be applied prior to training a portfolio optimization model. unfortunately, this practice may result in a look-ahead-bias in the future performance on the downstream task. there is an inherent trade-off between the look-ahead-bias of using the full data set for imputation and the larger variance in the imputation from using only the training data. by connecting layers of information revealed in time, we propose a bayesian posterior consensus distribution which optimally controls the variance and look-ahead-bias trade-off in the imputation. we demonstrate the benefit of our methodology both in synthetic and real financial data.",,2021-02-25,2023-04-11,"['jose blanchet', 'fernando hernandez', 'viet anh nguyen', 'markus pelger', 'xuhui zhang']",https://arxiv.org/pdf/2102.12736.pdf
20,2102.13008,gaze regularized imitation learning: learning continuous control from   human gaze,cs.lg cs.hc cs.ro,"approaches for teaching learning agents via human demonstrations have been widely studied and successfully applied to multiple domains. however, the majority of imitation learning work utilizes only behavioral information from the demonstrator, i.e. which actions were taken, and ignores other useful information. in particular, eye gaze information can give valuable insight towards where the demonstrator is allocating visual attention, and holds the potential to improve agent performance and generalization. in this work, we propose gaze regularized imitation learning (gril), a novel context-aware, imitation learning architecture that learns concurrently from both human demonstrations and eye gaze to solve tasks where visual attention provides important context. we apply gril to a visual navigation task, in which an unmanned quadrotor is trained to search for and navigate to a target vehicle in a photorealistic simulated environment. we show that gril outperforms several state-of-the-art gaze-based imitation learning algorithms, simultaneously learns to predict human visual attention, and generalizes to scenarios not present in the training data. supplemental videos can be found at project https://sites.google.com/view/gaze-regularized-il/ and code at https://github.com/ravikt/gril.",,2021-02-25,2023-04-07,"['ravi kumar thakur', 'md-nazmus samin sunbeam', 'vinicius g. goecks', 'ellen novoseller', 'ritwik bera', 'vernon j. lawhern', 'gregory m. gremillion', 'john valasek', 'nicholas r. waytowich']",https://arxiv.org/pdf/2102.13008.pdf
21,2104.03408,nanosecond machine learning event classification with boosted decision   trees in fpga for high energy physics,hep-ex cs.lg physics.ins-det,"we present a novel implementation of classification using the machine learning / artificial intelligence method called boosted decision trees (bdt) on field programmable gate arrays (fpga). the firmware implementation of binary classification requiring 100 training trees with a maximum depth of 4 using four input variables gives a latency value of about 10 ns, independent of the clock speed from 100 to 320 mhz in our setup. the low timing values are achieved by restructuring the bdt layout and reconfiguring its parameters. the fpga resource utilization is also kept low at a range from 0.01% to 0.2% in our setup. a software package called fwxmachina achieves this implementation. our intended user is an expert of custom electronics-based trigger systems in high energy physics experiments or anyone that needs decisions at the lowest latency values for real-time event classification. two problems from high energy physics are considered, in the separation of electrons vs. photons and in the selection of vector boson fusion-produced higgs bosons vs. the rejection of the multijet processes.",10.1088/1748-0221/16/08/p08016,2021-04-07,2021-08-17,"['tae min hong', 'benjamin carlson', 'brandon eubanks', 'stephen racz', 'stephen roche', 'joerg stelzer', 'daniel stumpp']",https://arxiv.org/pdf/2104.03408.pdf
22,2104.08736,stochastic optimization of areas under precision-recall curves with   provable convergence,cs.lg cs.ai cs.cv math.oc,"areas under roc (auroc) and precision-recall curves (auprc) are common metrics for evaluating classification performance for imbalanced problems. compared with auroc, auprc is a more appropriate metric for highly imbalanced datasets. while stochastic optimization of auroc has been studied extensively, principled stochastic optimization of auprc has been rarely explored. in this work, we propose a principled technical method to optimize auprc for deep learning. our approach is based on maximizing the averaged precision (ap), which is an unbiased point estimator of auprc. we cast the objective into a sum of {\it dependent compositional functions} with inner functions dependent on random variables of the outer level. we propose efficient adaptive and non-adaptive stochastic algorithms named soap with {\it provable convergence guarantee under mild conditions} by leveraging recent advances in stochastic compositional optimization. extensive experimental results on image and graph datasets demonstrate that our proposed method outperforms prior methods on imbalanced problems in terms of auprc. to the best of our knowledge, our work represents the first attempt to optimize auprc with provable convergence. the soap has been implemented in the libauc library at~\url{https://libauc.org/}.",,2021-04-18,2023-04-12,"['qi qi', 'youzhi luo', 'zhao xu', 'shuiwang ji', 'tianbao yang']",https://arxiv.org/pdf/2104.08736.pdf
23,2104.09439,vec2gc -- a graph based clustering method for text representations,cs.ir cs.lg,"nlp pipelines with limited or no labeled data, rely on unsupervised methods for document processing. unsupervised approaches typically depend on clustering of terms or documents. in this paper, we introduce a novel clustering algorithm, vec2gc (vector to graph communities), an end-to-end pipeline to cluster terms or documents for any given text corpus. our method uses community detection on a weighted graph of the terms or documents, created using text representation learning. vec2gc clustering algorithm is a density based approach, that supports hierarchical clustering as well.",,2021-04-15,2023-04-12,"['rajesh n rao', 'manojit chakraborty']",https://arxiv.org/pdf/2104.09439.pdf
24,2104.13094,detection of fake users in smps using nlp and graph embeddings,cs.lg,"social media platforms (smps) like facebook, twitter, instagram etc. have large user base all around the world that generates huge amount of data every second. this includes a lot of posts by fake and spam users, typically used by many organisations around the globe to have competitive edge over others. in this work, we aim at detecting such user accounts in twitter using a novel approach. we show how to distinguish between genuine and spam accounts in twitter using a combination of graph representation learning and natural language processing techniques.",10.1109/comsnets53615.2022.9668371,2021-04-27,,"['manojit chakraborty', 'shubham das', 'radhika mamidi']",https://arxiv.org/pdf/2104.13094.pdf
25,2104.14839,the factual inconsistency problem in abstractive text summarization: a   survey,cs.cl,"recently, various neural encoder-decoder models pioneered by seq2seq framework have been proposed to achieve the goal of generating more abstractive summaries by learning to map input text to output text. at a high level, such neural models can freely generate summaries without any constraint on the words or phrases used. moreover, their format is closer to human-edited summaries and output is more readable and fluent. however, the neural model's abstraction ability is a double-edged sword. a commonly observed problem with the generated summaries is the distortion or fabrication of factual information in the article. this inconsistency between the original text and the summary has caused various concerns over its applicability, and the previous evaluation methods of text summarization are not suitable for this issue. in response to the above problems, the current research direction is predominantly divided into two categories, one is to design fact-aware evaluation metrics to select outputs without factual inconsistency errors, and the other is to develop new summarization systems towards factual consistency. in this survey, we focus on presenting a comprehensive review of these fact-specific evaluation methods and text summarization models.",,2021-04-30,2023-04-10,"['yichong huang', 'xiachong feng', 'xiaocheng feng', 'bing qin']",https://arxiv.org/pdf/2104.14839.pdf
26,2105.01244,regret-optimal lqr control,math.oc cs.lg cs.sy eess.sy,"we consider the infinite-horizon lqr control problem. motivated by competitive analysis in online learning, as a criterion for controller design we introduce the dynamic regret, defined as the difference between the lqr cost of a causal controller (that has only access to past disturbances) and the lqr cost of the \emph{unique} clairvoyant one (that has also access to future disturbances) that is known to dominate all other controllers. the regret itself is a function of the disturbances, and we propose to find a causal controller that minimizes the worst-case regret over all bounded energy disturbances. the resulting controller has the interpretation of guaranteeing the smallest regret compared to the best non-causal controller that can see the future. we derive explicit formulas for the optimal regret and for the regret-optimal controller for the state-space setting. these explicit solutions are obtained by showing that the regret-optimal control problem can be reduced to a nehari extension problem that can be solved explicitly. the regret-optimal controller is shown to be linear and can be expressed as the sum of the classical $h_2$ state-feedback law and an $n$-th order controller ($n$ is the state dimension), and its construction simply requires a solution to the standard lqr riccati equation and two lyapunov equations. simulations over a range of plants demonstrate that the regret-optimal controller interpolates nicely between the $h_2$ and the $h_\infty$ optimal controllers, and generally has $h_2$ and $h_\infty$ costs that are simultaneously close to their optimal values. the regret-optimal controller thus presents itself as a viable option for control systems design.",,2021-05-03,2023-04-13,"['oron sabag', 'gautam goel', 'sahin lale', 'babak hassibi']",https://arxiv.org/pdf/2105.01244.pdf
27,2105.13431,an offline risk-aware policy selection method for bayesian markov   decision processes,cs.lg cs.ai cs.sy eess.sy,"in offline model learning for planning and in offline reinforcement learning, the limited data set hinders the estimate of the value function of the relative markov decision process (mdp). consequently, the performance of the obtained policy in the real world is bounded and possibly risky, especially when the deployment of a wrong policy can lead to catastrophic consequences. for this reason, several pathways are being followed with the scope of reducing the model error (or the distributional shift between the learned model and the true one) and, more broadly, obtaining risk-aware solutions with respect to model uncertainty. but when it comes to the final application which baseline should a practitioner choose? in an offline context where computational time is not an issue and robustness is the priority we propose exploitation vs caution (evc), a paradigm that (1) elegantly incorporates model uncertainty abiding by the bayesian formalism, and (2) selects the policy that maximizes a risk-aware objective over the bayesian posterior between a fixed set of candidate policies provided, for instance, by the current baselines. we validate evc with state-of-the-art approaches in different discrete, yet simple, environments offering a fair variety of mdp classes. in the tested scenarios evc manages to select robust policies and hence stands out as a useful tool for practitioners that aim to apply offline planning and reinforcement learning solvers in the real world.",,2021-05-27,2023-04-11,"['giorgio angelotti', 'nicolas drougard', 'caroline ponzoni carvalho chanel']",https://arxiv.org/pdf/2105.13431.pdf
28,2106.03931,entropy regularized reinforcement learning using large deviation theory,cs.lg cond-mat.stat-mech cs.ai stat.ml,"reinforcement learning (rl) is an important field of research in machine learning that is increasingly being applied to complex optimization problems in physics. in parallel, concepts from physics have contributed to important advances in rl with developments such as entropy-regularized rl. while these developments have led to advances in both fields, obtaining analytical solutions for optimization in entropy-regularized rl is currently an open problem. in this paper, we establish a mapping between entropy-regularized rl and research in non-equilibrium statistical mechanics focusing on markovian processes conditioned on rare events. in the long-time limit, we apply approaches from large deviation theory to derive exact analytical results for the optimal policy and optimal dynamics in markov decision process (mdp) models of reinforcement learning. the results obtained lead to a novel analytical and computational framework for entropy-regularized rl which is validated by simulations. the mapping established in this work connects current research in reinforcement learning and non-equilibrium statistical mechanics, thereby opening new avenues for the application of analytical and computational approaches from one field to cutting-edge problems in the other.",,2021-06-07,2023-04-10,"['argenis arriojas', 'jacob adamczyk', 'stas tiomkin', 'rahul v. kulkarni']",https://arxiv.org/pdf/2106.03931.pdf
29,2106.05847,unfolding the multiscale structure of networks with dynamical   ollivier-ricci curvature,physics.soc-ph cs.dm physics.data-an,"describing networks geometrically through low-dimensional latent metric spaces has helped design efficient learning algorithms, unveil network symmetries and study dynamical network processes. however, latent space embeddings are limited to specific classes of networks because incompatible metric spaces generally result in information loss. here, we study arbitrary networks geometrically by defining a dynamic edge curvature measuring the similarity between pairs of dynamical network processes seeded at nearby nodes. we show that the evolution of the curvature distribution exhibits gaps at characteristic timescales indicating bottleneck-edges that limit information spreading. importantly, curvature gaps are robust to large fluctuations in node degrees, encoding communities until the phase transition of detectability, where spectral and node-clustering methods fail. using this insight, we derive geometric modularity to find multiscale communities based on deviations from constant network curvature in generative and real-world networks, significantly outperforming most previous methods. our work suggests using network geometry for studying and controlling the structure of and information spreading on networks.",10.1038/s41467-021-24884-1,2021-01-30,2021-07-14,"['adam gosztolai', 'alexis arnaudon']",https://arxiv.org/pdf/2106.05847.pdf
30,2106.06965,contrastive attention for automatic chest x-ray report generation,cs.cv cs.cl,"recently, chest x-ray report generation, which aims to automatically generate descriptions of given chest x-ray images, has received growing research interests. the key challenge of chest x-ray report generation is to accurately capture and describe the abnormal regions. in most cases, the normal regions dominate the entire chest x-ray image, and the corresponding descriptions of these normal regions dominate the final report. due to such data bias, learning-based models may fail to attend to abnormal regions. in this work, to effectively capture and describe abnormal regions, we propose the contrastive attention (ca) model. instead of solely focusing on the current input image, the ca model compares the current input image with normal images to distill the contrastive information. the acquired contrastive information can better represent the visual features of abnormal regions. according to the experiments on the public iu-x-ray and mimic-cxr datasets, incorporating our ca into several existing models can boost their performance across most metrics. in addition, according to the analysis, the ca model can help existing models better attend to the abnormal regions and provide more accurate descriptions which are crucial for an interpretable diagnosis. specifically, we achieve the state-of-the-art results on the two public datasets.",,2021-06-13,2023-04-11,"['fenglin liu', 'changchang yin', 'xian wu', 'shen ge', 'yuexian zou', 'ping zhang', 'yuexian zou', 'xu sun']",https://arxiv.org/pdf/2106.06965.pdf
31,2106.07258,gittables: a large-scale corpus of relational tables,cs.db cs.lg,"the success of deep learning has sparked interest in improving relational table tasks, like data preparation and search, with table representation models trained on large table corpora. existing table corpora primarily contain tables extracted from html pages, limiting the capability to represent offline database tables. to train and evaluate high-capacity models for applications beyond the web, we need resources with tables that resemble relational database tables. here we introduce gittables, a corpus of 1m relational tables extracted from github. our continuing curation aims at growing the corpus to at least 10m tables. analyses of gittables show that its structure, content, and topical coverage differ significantly from existing table corpora. we annotate table columns in gittables with semantic types, hierarchical relations and descriptions from schema.org and dbpedia. the evaluation of our annotation pipeline on the t2dv2 benchmark illustrates that our approach provides results on par with human annotations. we present three applications of gittables, demonstrating its value for learned semantic type detection models, schema completion methods, and benchmarks for table-to-kg matching, data search, and preparation. we make the corpus and code available at https://gittables.github.io.",10.1145/3588710,2021-06-14,2023-04-12,"['madelon hulsebos', '√ßaƒüatay demiralp', 'paul groth']",https://arxiv.org/pdf/2106.07258.pdf
32,2107.03433,in-network learning: distributed training and inference in networks,cs.lg cs.it math.it stat.ml,"it is widely perceived that leveraging the success of modern machine learning techniques to mobile devices and wireless networks has the potential of enabling important new services. this, however, poses significant challenges, essentially due to that both data and processing power are highly distributed in a wireless network. in this paper, we develop a learning algorithm and an architecture that make use of multiple data streams and processing units, not only during the training phase but also during the inference phase. in particular, the analysis reveals how inference propagates and fuses across a network. we study the design criterion of our proposed method and its bandwidth requirements. also, we discuss implementation aspects using neural networks in typical wireless radio access; and provide experiments that illustrate benefits over state-of-the-art techniques.",,2021-07-07,2023-04-12,"['matei moldoveanu', 'abdellatif zaidi']",https://arxiv.org/pdf/2107.03433.pdf
33,2107.03920,likelihood-free frequentist inference: confidence sets with correct   conditional coverage,stat.ml cs.lg,"many areas of science make extensive use of computer simulators that implicitly encode likelihood functions of complex systems. classical statistical methods are poorly suited for these so-called likelihood-free inference (lfi) settings, particularly outside asymptotic and low-dimensional regimes. although new machine learning methods, such as normalizing flows, have revolutionized the sample efficiency and capacity of lfi methods, it remains an open question whether they produce confidence sets with correct conditional coverage for small sample sizes. this paper unifies classical statistics with modern machine learning to present (i) a practical procedure for the neyman construction of confidence sets with finite-sample guarantees of nominal coverage, and (ii) diagnostics that estimate conditional coverage over the entire parameter space. we refer to our framework as likelihood-free frequentist inference (lf2i). any method that defines a test statistic, like the likelihood ratio, can leverage the lf2i machinery to create valid confidence sets and diagnostics without costly monte carlo samples at fixed parameter settings. we study the power of two test statistics (acore and bff), which, respectively, maximize versus integrate an odds function over the parameter space. our paper discusses the benefits and challenges of lf2i, with a breakdown of the sources of errors in lf2i confidence sets.",,2021-07-08,2023-04-06,"['niccol√≤ dalmasso', 'luca masserano', 'david zhao', 'rafael izbicki', 'ann b. lee']",https://arxiv.org/pdf/2107.03920.pdf
34,2107.08574,a modulation layer to increase neural network robustness against data   quality issues,cs.lg cs.ai,"data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. developers often train machine learning models on carefully curated datasets using only high quality data; however, this reduces the utility of such models in production environments. we propose a novel neural network modification to mitigate the impacts of low quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of an additional input. this is inspired from neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. in testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against degradation of data quality, including additional missingness. these models are superior to imputation as they save on training time by completely skipping the imputation process and further allow the introduction of other data quality measures that imputation cannot handle. our results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time applications.",,2021-07-18,2022-10-10,"['mohamed abdelhack', 'jiaming zhang', 'sandhya tripathi', 'bradley a fritz', 'daniel felsky', 'michael s avidan', 'yixin chen', 'christopher r king']",https://arxiv.org/pdf/2107.08574.pdf
35,2108.00682,asymptotic bias of inexact markov chain monte carlo methods in high   dimension,math.pr cs.na math.na stat.co stat.ml,"inexact markov chain monte carlo methods rely on markov chains that do not exactly preserve the target distribution. examples include the unadjusted langevin algorithm (ula) and unadjusted hamiltonian monte carlo (uhmc). this paper establishes bounds on wasserstein distances between the invariant probability measures of inexact mcmc methods and their target distributions with a focus on understanding the precise dependence of this asymptotic bias on both dimension and discretization step size. assuming wasserstein bounds on the convergence to equilibrium of either the exact or the approximate dynamics, we show that for both ula and uhmc, the asymptotic bias depends on key quantities related to the target distribution or the stationary probability measure of the scheme. as a corollary, we conclude that for models with a limited amount of interactions such as mean-field models, finite range graphical models, and perturbations thereof, the asymptotic bias has a similar dependence on the step size and the dimension as for product measures.",,2021-08-02,2023-04-12,"['alain oliviero durmus', 'andreas eberle']",https://arxiv.org/pdf/2108.00682.pdf
36,2108.08106,"existence, uniqueness, and convergence rates for gradient flows in the   training of artificial neural networks with relu activation",cs.lg cs.na math.ds math.na,"the training of artificial neural networks (anns) with rectified linear unit (relu) activation via gradient descent (gd) type optimization schemes is nowadays a common industrially relevant procedure. till this day in the scientific literature there is in general no mathematical convergence analysis which explains the numerical success of gd type optimization schemes in the training of anns with relu activation. gd type optimization schemes can be regarded as temporal discretization methods for the gradient flow (gf) differential equations associated to the considered optimization problem and, in view of this, it seems to be a natural direction of research to first aim to develop a mathematical convergence theory for time-continuous gf differential equations and, thereafter, to aim to extend such a time-continuous convergence theory to implementable time-discrete gd type optimization methods. in this article we establish two basic results for gf differential equations in the training of fully-connected feedforward anns with one hidden layer and relu activation. in the first main result of this article we establish in the training of such anns under the assumption that the probability distribution of the input data of the considered supervised learning problem is absolutely continuous with a bounded density function that every gf differential equation admits for every initial value a solution which is also unique among a suitable class of solutions. in the second main result of this article we prove in the training of such anns under the assumption that the target function and the density function of the probability distribution of the input data are piecewise polynomial that every non-divergent gf trajectory converges with an appropriate rate of convergence to a critical point and that the risk of the non-divergent gf trajectory converges with rate 1 to the risk of the critical point.",10.3934/era.2023128,2021-08-18,,"['simon eberle', 'arnulf jentzen', 'adrian riekert', 'georg s. weiss']",https://arxiv.org/pdf/2108.08106.pdf
37,2108.08481,neural operator: learning maps between function spaces,cs.lg cs.na math.na,"the classical development of neural networks has primarily focused on learning mappings between finite dimensional euclidean spaces or finite sets. we propose a generalization of neural networks to learn operators, termed neural operators, that map between infinite dimensional function spaces. we formulate the neural operator as a composition of linear integral operators and nonlinear activation functions. we prove a universal approximation theorem for our proposed neural operator, showing that it can approximate any given nonlinear continuous operator. the proposed neural operators are also discretization-invariant, i.e., they share the same model parameters among different discretization of the underlying function spaces. furthermore, we introduce four classes of efficient parameterization, viz., graph neural operators, multi-pole graph neural operators, low-rank neural operators, and fourier neural operators. an important application for neural operators is learning surrogate maps for the solution operators of partial differential equations (pdes). we consider standard pdes such as the burgers, darcy subsurface flow, and the navier-stokes equations, and show that the proposed neural operators have superior performance compared to existing machine learning based methodologies, while being several orders of magnitude faster than conventional pde solvers.",,2021-08-18,2023-04-07,"['nikola kovachki', 'zongyi li', 'burigede liu', 'kamyar azizzadenesheli', 'kaushik bhattacharya', 'andrew stuart', 'anima anandkumar']",https://arxiv.org/pdf/2108.08481.pdf
38,2108.11580,learning partial differential equations in reproducing kernel hilbert   spaces,math.st cs.na math.na stat.th,"we propose a new data-driven approach for learning the fundamental solutions (green's functions) of various linear partial differential equations (pdes) given sample pairs of input-output functions. building off the theory of functional linear regression (flr), we estimate the best-fit green's function and bias term of the fundamental solution in a reproducing kernel hilbert space (rkhs) which allows us to regularize their smoothness and impose various structural constraints. we derive a general representer theorem for operator rkhss to approximate the original infinite-dimensional regression problem by a finite-dimensional one, reducing the search space to a parametric class of green's functions. in order to study the prediction error of our green's function estimator, we extend prior results on flr with scalar outputs to the case with functional outputs. finally, we demonstrate our method on several linear pdes including the poisson, helmholtz, schr\""{o}dinger, fokker-planck, and heat equation. we highlight its robustness to noise as well as its ability to generalize to new data with varying degrees of smoothness and mesh discretization without any additional training.",,2021-08-26,2023-04-10,['george stepaniants'],https://arxiv.org/pdf/2108.11580.pdf
39,2109.13391,curvature-aware derivative-free optimization,math.oc cs.lg,"the paper discusses derivative-free optimization (dfo), which involves minimizing a function without access to gradients or directional derivatives, only function evaluations. classical dfo methods, which mimic gradient-based methods, such as nelder-mead and direct search have limited scalability for high-dimensional problems. zeroth-order methods have been gaining popularity due to the demands of large-scale machine learning applications, and the paper focuses on the selection of the step size $\alpha_k$ in these methods. the proposed approach, called curvature-aware random search (cars), uses first- and second-order finite difference approximations to compute a candidate $\alpha_{+}$. we prove that for strongly convex objective functions, cars converges linearly provided that the search direction is drawn from a distribution satisfying very mild conditions. we also present a cubic regularized variant of cars, named cars-cr, which converges in a rate of $\mathcal{o}(k^{-1})$ without the assumption of strong convexity. numerical experiments show that cars and cars-cr match or exceed the state-of-the-arts on benchmark problem sets.",,2021-09-27,2023-04-12,"['bumsu kim', 'hanqin cai', 'daniel mckenzie', 'wotao yin']",https://arxiv.org/pdf/2109.13391.pdf
40,2109.14925,genealogical population-based training for hyperparameter optimization,cs.lg,"hyperparameter optimization (hpo) aims at finding the best hyperparameters (hps) of learning models, such as neural networks, in the fastest and most efficient way possible. most recent hpo algorithms try to optimize hps regardless of the model that obtained them, assuming that for different models, same hps will produce very similar results. we break free from this paradigm and propose a new take on preexisting methods that we called genealogical population based training (gpbt). gpbt, via the shared histories of ""genealogically""-related models, exploit the coupling of hps and models in an efficient way. we experimentally demonstrate that our method cuts down by 2 to 3 times the computational cost required, generally allows a 1% accuracy improvement on computer vision tasks, and reduces the variance of the results by an order of magnitude, compared to the current algorithms. our method is search-algorithm agnostic so that the inner search routine can be any search algorithm like tpe, gp, cma or random search.",,2021-09-30,2023-04-09,"['antoine scardigli', 'paul fournier', 'matteo vilucchio', 'david naccache']",https://arxiv.org/pdf/2109.14925.pdf
41,2110.05740,temporal abstraction in reinforcement learning with the successor   representation,cs.lg cs.ai,"reasoning at multiple levels of temporal abstraction is one of the key attributes of intelligence. in reinforcement learning, this is often modeled through temporally extended courses of actions called options. options allow agents to make predictions and to operate at different levels of abstraction within an environment. nevertheless, approaches based on the options framework often start with the assumption that a reasonable set of options is known beforehand. when this is not the case, there are no definitive answers for which options one should consider. in this paper, we argue that the successor representation (sr), which encodes states based on the pattern of state visitation that follows them, can be seen as a natural substrate for the discovery and use of temporal abstractions. to support our claim, we take a big picture view of recent results, showing how the sr can be used to discover options that facilitate either temporally-extended exploration or planning. we cast these results as instantiations of a general framework for option discovery in which the agent's representation is used to identify useful options, which are then used to further improve its representation. this results in a virtuous, never-ending, cycle in which both the representation and the options are constantly refined based on each other. beyond option discovery itself, we also discuss how the sr allows us to augment a set of options into a combinatorially large counterpart without additional learning. this is achieved through the combination of previously learned options. our empirical evaluation focuses on options discovered for exploration and on the use of the sr to combine them. the results of our experiments shed light on important design decisions involved in the definition of options and demonstrate the synergy of different methods based on the sr, such as eigenoptions and the option keyboard.",,2021-10-12,2023-04-11,"['marlos c. machado', 'andre barreto', 'doina precup', 'michael bowling']",https://arxiv.org/pdf/2110.05740.pdf
42,2110.08693,learning generative models of the geometry and topology of tree-like 3d   objects,cs.lg cs.cg cs.gr stat.ml,"how can one analyze detailed 3d biological objects, such as neurons and botanical trees, that exhibit complex geometrical and topological variation? in this paper, we develop a novel mathematical framework for representing, comparing, and computing geodesic deformations between the shapes of such tree-like 3d objects. a hierarchical organization of subtrees characterizes these objects -- each subtree has the main branch with some side branches attached -- and one needs to match these structures across objects for meaningful comparisons. we propose a novel representation that extends the square-root velocity function (srvf), initially developed for euclidean curves, to tree-shaped 3d objects. we then define a new metric that quantifies the bending, stretching, and branch sliding needed to deform one tree-shaped object into the other. compared to the current metrics, such as the quotient euclidean distance (qed) and the tree edit distance (ted), the proposed representation and metric capture the full elasticity of the branches (i.e., bending and stretching) as well as the topological variations (i.e., branch death/birth and sliding). it completely avoids the shrinkage that results from the edge collapse and node split operations of the qed and ted metrics. we demonstrate the utility of this framework in comparing, matching, and computing geodesics between biological objects such as neurons and botanical trees. the framework is also applied to various shape analysis tasks: (i) symmetry analysis and symmetrization of tree-shaped 3d objects, (ii) computing summary statistics (means and modes of variations) of populations of tree-shaped 3d objects, (iii) fitting parametric probability distributions to such populations, and (iv) finally synthesizing novel tree-shaped 3d objects through random sampling from estimated probability distributions.",,2021-10-16,2023-04-10,"['guan wang', 'hamid laga', 'anuj srivastava']",https://arxiv.org/pdf/2110.08693.pdf
43,2110.10422,priorvae: encoding spatial priors with vaes for small-area estimation,cs.lg stat.ml,"gaussian processes (gps), implemented through multivariate gaussian distributions for a finite collection of data, are the most popular approach in small-area spatial statistical modelling. in this context they are used to encode correlation structures over space and can generalise well in interpolation tasks. despite their flexibility, off-the-shelf gps present serious computational challenges which limit their scalability and practical usefulness in applied settings. here, we propose a novel, deep generative modelling approach to tackle this challenge, termed priorvae: for a particular spatial setting, we approximate a class of gp priors through prior sampling and subsequent fitting of a variational autoencoder (vae). given a trained vae, the resultant decoder allows spatial inference to become incredibly efficient due to the low dimensional, independently distributed latent gaussian space representation of the vae. once trained, inference using the vae decoder replaces the gp within a bayesian sampling framework. this approach provides tractable and easy-to-implement means of approximately encoding spatial priors and facilitates efficient statistical inference. we demonstrate the utility of our vae two stage approach on bayesian, small-area estimation tasks.",10.1098/rsif.2022.0094,2021-10-20,2022-05-16,"['elizaveta semenova', 'yidan xu', 'adam howes', 'theo rashid', 'samir bhatt', 'swapnil mishra', 'seth flaxman']",https://arxiv.org/pdf/2110.10422.pdf
44,2110.11155,delag: using multi-objective optimization to enhance the detection of   latency degradation patterns in service-based systems,cs.se cs.lg cs.pf,"performance debugging in production is a fundamental activity in modern service-based systems. the diagnosis of performance issues is often time-consuming, since it requires thorough inspection of large volumes of traces and performance indices. in this paper we present delag, a novel automated search-based approach for diagnosing performance issues in service-based systems. delag identifies subsets of requests that show, in the combination of their remote procedure call execution times, symptoms of potentially relevant performance issues. we call such symptoms latency degradation patterns. delag simultaneously searches for multiple latency degradation patterns while optimizing precision, recall and latency dissimilarity. experimentation on 700 datasets of requests generated from two microservice-based systems shows that our approach provides better and more stable effectiveness than three state-of-the-art approaches and general purpose machine learning clustering algorithms. delag is more effective than all baseline techniques in at least one case study (with p $\leq$ 0.05 and non-negligible effect size). moreover, delag outperforms in terms of efficiency the second and the third most effective baseline techniques on the largest datasets used in our evaluation (up to 22%).",10.1109/tse.2023.3266041,2021-10-21,2023-04-07,"['luca traini', 'vittorio cortellessa']",https://arxiv.org/pdf/2110.11155.pdf
45,2110.11749,feature learning and signal propagation in deep neural networks,stat.ml cs.lg,"recent work by baratin et al. (2021) sheds light on an intriguing pattern that occurs during the training of deep neural networks: some layers align much more with data compared to other layers (where the alignment is defined as the euclidean product of the tangent features matrix and the data labels matrix). the curve of the alignment as a function of layer index (generally) exhibits an ascent-descent pattern where the maximum is reached for some hidden layer. in this work, we provide the first explanation for this phenomenon. we introduce the equilibrium hypothesis which connects this alignment pattern to signal propagation in deep neural networks. our experiments demonstrate an excellent match with the theoretical predictions.",,2021-10-22,2022-05-22,"['yizhang lou', 'chris mingard', 'yoonsoo nam', 'soufiane hayou']",https://arxiv.org/pdf/2110.11749.pdf
46,2110.12648,review-based domain disentanglement without duplicate users or contexts   for cross-domain recommendation,cs.ir cs.ai,"a cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. to deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. our model (named ser) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-art single and cross-domain recommendation methods.",10.1145/3511808.3557434,2021-10-25,2023-04-12,"['yoonhyuk choi', 'jiho choi', 'taewook ko', 'hyungho byun', 'chong-kwon kim']",https://arxiv.org/pdf/2110.12648.pdf
47,2111.01872,towards fairness-aware federated learning,cs.lg cs.ai cs.dc,"recent advances in federated learning (fl) have brought large-scale collaborative machine learning opportunities for massively distributed clients with performance and data privacy guarantees. however, most current works focus on the interest of the central controller in fl,and overlook the interests of the fl clients. this may result in unfair treatment of clients that discourages them from actively participating in the learning process and damages the sustainability of the fl ecosystem. therefore, the topic of ensuring fairness in fl is attracting a great deal of research interest. in recent years, diverse fairness-aware fl (fafl) approaches have been proposed in an effort to achieve fairness in fl from different perspectives. however, there is no comprehensive survey that helps readers gain insight into this interdisciplinary field. this paper aims to provide such a survey. by examining the fundamental and simplifying assumptions, as well as the notions of fairness adopted by existing literature in this field, we propose a taxonomy of fafl approaches covering major steps in fl, including client selection, optimization, contribution evaluation and incentive distribution. in addition, we discuss the main metrics for experimentally evaluating the performance of fafl approaches, and suggest promising future research directions towards fafl.",10.1109/tnnls.2023.3263594,2021-11-02,2023-04-03,"['yuxin shi', 'han yu', 'cyril leung']",https://arxiv.org/pdf/2111.01872.pdf
48,2111.02571,learning suction graspability considering grasp quality and robot   reachability for bin-picking,cs.ro cs.lg,"deep learning has been widely used for inferring robust grasps. although human-labeled rgb-d datasets were initially used to learn grasp configurations, preparation of this kind of large dataset is expensive. to address this problem, images were generated by a physical simulator, and a physically inspired model (e.g., a contact model between a suction vacuum cup and object) was used as a grasp quality evaluation metric to annotate the synthesized images. however, this kind of contact model is complicated and requires parameter identification by experiments to ensure real world performance. in addition, previous studies have not considered manipulator reachability such as when a grasp configuration with high grasp quality is unable to reach the target due to collisions or the physical limitations of the robot. in this study, we propose an intuitive geometric analytic-based grasp quality evaluation metric. we further incorporate a reachability evaluation metric. we annotate the pixel-wise grasp quality and reachability by the proposed evaluation metric on synthesized images in a simulator to train an auto-encoder--decoder called suction graspability u-net++ (sg-u-net++). experiment results show that our intuitive grasp quality evaluation metric is competitive with a physically-inspired metric. learning the reachability helps to reduce motion planning computation time by removing obviously unreachable candidates. the system achieves an overall picking speed of 560 pph (pieces per hour).",10.3389/fnbot.2022.806898,2021-11-03,,"['ping jiang', 'junji oaki', 'yoshiyuki ishihara', 'junichiro ooga', 'haifeng han', 'atsushi sugahara', 'seiji tokura', 'haruna eto', 'kazuma komoda', 'akihito ogawa']",https://arxiv.org/pdf/2111.02571.pdf
49,2111.08644,ubnormal: new benchmark for supervised open-set video anomaly detection,cs.cv cs.lg,"detecting abnormal events in video is commonly framed as a one-class classification task, where training videos contain only normal events, while test videos encompass both normal and abnormal events. in this scenario, anomaly detection is an open-set problem. however, some studies assimilate anomaly detection to action recognition. this is a closed-set scenario that fails to test the capability of systems at detecting new anomaly types. to this end, we propose ubnormal, a new supervised open-set benchmark composed of multiple virtual scenes for video anomaly detection. unlike existing data sets, we introduce abnormal events annotated at the pixel level at training time, for the first time enabling the use of fully-supervised learning methods for abnormal event detection. to preserve the typical open-set formulation, we make sure to include disjoint sets of anomaly types in our training and test collections of videos. to our knowledge, ubnormal is the first video anomaly detection benchmark to allow a fair head-to-head comparison between one-class open-set models and supervised closed-set models, as shown in our experiments. moreover, we provide empirical evidence showing that ubnormal can enhance the performance of a state-of-the-art anomaly detection framework on two prominent data sets, avenue and shanghaitech. our benchmark is freely available at https://github.com/lilygeorgescu/ubnormal.",,2021-11-16,2023-04-07,"['andra acsintoae', 'andrei florescu', 'mariana-iuliana georgescu', 'tudor mare', 'paul sumedrea', 'radu tudor ionescu', 'fahad shahbaz khan', 'mubarak shah']",https://arxiv.org/pdf/2111.08644.pdf
50,2111.10050,combined scaling for zero-shot transfer learning,cs.lg cs.cl cs.cv,"we present a combined scaling method - named basic - that achieves 85.7% top-1 accuracy on the imagenet ilsvrc-2012 validation set without learning from any labeled imagenet example. this accuracy surpasses best published similar models - clip and align - by 9.3%. our basic model also shows significant improvements in robustness benchmarks. for instance, on 5 test sets with natural distribution shifts such as imagenet-{a,r,v2,sketch} and objectnet, our model achieves 84.3% top-1 average accuracy, only a small drop from its original imagenet accuracy. to achieve these results, we scale up the contrastive learning framework of clip and align in three dimensions: data size, model size, and batch size. our dataset has 6.6b noisy image-text pairs, which is 4x larger than align, and 16x larger than clip. our largest model has 3b weights, which is 3.75x larger in parameters and 8x larger in flops than align and clip. finally, our batch size is 65536 which is 2x more than clip and 4x more than align. we encountered two main challenges with the scaling rules of basic. first, the main challenge with implementing the combined scaling rules of basic is the limited memory of accelerators, such as gpus and tpus. to overcome the memory limit, we propose two simple methods which make use of gradient checkpointing and model parallelism. second, while increasing the dataset size and the model size has been the defacto method to improve the performance of deep learning models like basic, the effect of a large contrastive batch size on such contrastive-trained image-text models is not well-understood. to shed light on the benefits of large contrastive batch sizes, we develop a theoretical framework which shows that larger contrastive batch sizes lead to smaller generalization gaps for image-text models such as basic.",,2021-11-19,2023-04-12,"['hieu pham', 'zihang dai', 'golnaz ghiasi', 'kenji kawaguchi', 'hanxiao liu', 'adams wei yu', 'jiahui yu', 'yi-ting chen', 'minh-thang luong', 'yonghui wu', 'mingxing tan', 'quoc v. le']",https://arxiv.org/pdf/2111.10050.pdf
51,2112.00319,object-aware cropping for self-supervised learning,cs.cv cs.lg,"a core component of the recent success of self-supervised learning is cropping data augmentation, which selects sub-regions of an image to be used as positive views in the self-supervised loss. the underlying assumption is that randomly cropped and resized regions of a given image share information about the objects of interest, which the learned representation will capture. this assumption is mostly satisfied in datasets such as imagenet where there is a large, centered object, which is highly likely to be present in random crops of the full image. however, in other datasets such as openimages or coco, which are more representative of real world uncurated data, there are typically multiple small objects in an image. in this work, we show that self-supervised learning based on the usual random cropping performs poorly on such datasets. we propose replacing one or both of the random crops with crops obtained from an object proposal algorithm. this encourages the model to learn both object and scene level semantic representations. using this approach, which we call object-aware cropping, results in significant improvements over scene cropping on classification and object detection benchmarks. for example, on openimages, our approach achieves an improvement of 8.8% map over random scene-level cropping using moco-v2 based pre-training. we also show significant improvements on coco and pascal-voc object detection and segmentation tasks over the state-of-the-art self-supervised learning approaches. our approach is efficient, simple and general, and can be used in most existing contrastive and non-contrastive self-supervised learning frameworks.",,2021-12-01,2023-04-06,"['shlok mishra', 'anshul shah', 'ankan bansal', 'abhyuday jagannatha', 'janit anjaria', 'abhishek sharma', 'david jacobs', 'dilip krishnan']",https://arxiv.org/pdf/2112.00319.pdf
52,2112.02807,mdpfuzz: testing models solving markov decision processes,cs.se cs.lg,"the markov decision process (mdp) provides a mathematical framework for modeling sequential decision-making problems, many of which are crucial to security and safety, such as autonomous driving and robot control. the rapid development of artificial intelligence research has created efficient methods for solving mdps, such as deep neural networks (dnns), reinforcement learning (rl), and imitation learning (il). however, these popular models solving mdps are neither thoroughly tested nor rigorously reliable.   we present mdpfuzz, the first blackbox fuzz testing framework for models solving mdps. mdpfuzz forms testing oracles by checking whether the target model enters abnormal and dangerous states. during fuzzing, mdpfuzz decides which mutated state to retain by measuring if it can reduce cumulative rewards or form a new state sequence. we design efficient techniques to quantify the ""freshness"" of a state sequence using gaussian mixture models (gmms) and dynamic expectation-maximization (dynem). we also prioritize states with high potential of revealing crashes by estimating the local sensitivity of target models over states.   mdpfuzz is evaluated on five state-of-the-art models for solving mdps, including supervised dnn, rl, il, and multi-agent rl. our evaluation includes scenarios of autonomous driving, aircraft collision avoidance, and two games that are often used to benchmark rl. during a 12-hour run, we find over 80 crash-triggering state sequences on each model. we show inspiring findings that crash-triggering states, though they look normal, induce distinct neuron activation patterns compared with normal states. we further develop an abnormal behavior detector to harden all the evaluated models and repair them with the findings of mdpfuzz to significantly enhance their robustness without sacrificing accuracy.",,2021-12-06,2023-04-11,"['qi pang', 'yuanyuan yuan', 'shuai wang']",https://arxiv.org/pdf/2112.02807.pdf
53,2112.02918,when the curious abandon honesty: federated learning is not private,cs.lg cs.cr cs.dc,"in federated learning (fl), data does not leave personal devices when they are jointly training a machine learning model. instead, these devices share gradients, parameters, or other model updates, with a central party (e.g., a company) coordinating the training. because data never ""leaves"" personal devices, fl is often presented as privacy-preserving. yet, recently it was shown that this protection is but a thin facade, as even a passive, honest-but-curious attacker observing gradients can reconstruct data of individual users contributing to the protocol. in this work, we show a novel data reconstruction attack which allows an active and dishonest central party to efficiently extract user data from the received gradients. while prior work on data reconstruction in fl relies on solving computationally expensive optimization problems or on making easily detectable modifications to the shared model's architecture or parameters, in our attack the central party makes inconspicuous changes to the shared model's weights before sending them out to the users. we call the modified weights of our attack trap weights. our active attacker is able to recover user data perfectly, i.e., with zero error, even when this data stems from the same class. recovery comes with near-zero costs: the attack requires no complex optimization objectives. instead, our attacker exploits inherent data leakage from model gradients and simply amplifies this effect by maliciously altering the weights of the shared model through the trap weights. these specificities enable our attack to scale to fully-connected and convolutional deep neural networks trained with large mini-batches of data. for example, for the high-dimensional vision dataset imagenet, we perfectly reconstruct more than 50% of the training data points from mini-batches as large as 100 data points.",,2021-12-06,2023-04-12,"['franziska boenisch', 'adam dziedzic', 'roei schuster', 'ali shahin shamsabadi', 'ilia shumailov', 'nicolas papernot']",https://arxiv.org/pdf/2112.02918.pdf
54,2112.03975,tailored neural networks for learning optimal value functions in mpc,eess.sy cs.lg cs.sy,"learning-based predictive control is a promising alternative to optimization-based mpc. however, efficiently learning the optimal control policy, the optimal value function, or the q-function requires suitable function approximators. often, artificial neural networks (ann) are considered but choosing a suitable topology is also non-trivial. against this background, it has recently been shown that tailored ann allow, in principle, to exactly describe the optimal control policy in linear mpc by exploiting its piecewise affine structure. in this paper, we provide a similar result for representing the optimal value function and the q-function that are both known to be piecewise quadratic for linear mpc.",10.1109/cdc45484.2021.9683528,2021-12-07,,"['dieter teichrib', 'moritz schulze darup']",https://arxiv.org/pdf/2112.03975.pdf
55,2112.08760,constrained multi-objective optimization of process design parameters in   settings with scarce data: an application to adhesive bonding,cs.ne cs.lg,"adhesive joints are increasingly used in industry for a wide variety of applications because of their favorable characteristics such as high strength-to-weight ratio, design flexibility, limited stress concentrations, planar force transfer, good damage tolerance, and fatigue resistance. finding the optimal process parameters for an adhesive bonding process is challenging: the optimization is inherently multi-objective (aiming to maximize break strength while minimizing cost), constrained (the process should not result in any visual damage to the materials, and stress tests should not result in failures that are adhesion-related), and uncertain (testing the same process parameters several times may lead to different break strengths). real-life physical experiments in the lab are expensive to perform. traditional evolutionary approaches (such as genetic algorithms) are then ill-suited to solve the problem, due to the prohibitive amount of experiments required for evaluation. although bayesian optimization-based algorithms are preferred to solve such expensive problems, few methods consider the optimization of more than one (noisy) objective and several constraints at the same time. in this research, we successfully applied specific machine learning techniques (gaussian process regression) to emulate the objective and constraint functions based on a limited amount of experimental data. the techniques are embedded in a bayesian optimization algorithm, which succeeds in detecting pareto-optimal process settings in a highly efficient way (i.e., requiring a limited number of physical experiments).",,2021-12-16,2023-04-10,"['alejandro morales-hern√°ndez', 'sebastian rojas gonzalez', 'inneke van nieuwenhuyse', 'ivo couckuyt', 'jeroen jordens', 'maarten witters', 'bart van doninck']",https://arxiv.org/pdf/2112.08760.pdf
56,2112.09943,data augmentation through expert-guided symmetry detection to improve   performance in offline reinforcement learning,cs.lg cs.ai,"offline estimation of the dynamical model of a markov decision process (mdp) is a non-trivial task that greatly depends on the data available in the learning phase. sometimes the dynamics of the model is invariant with respect to some transformations of the current state and action. recent works showed that an expert-guided pipeline relying on density estimation methods as deep neural network based normalizing flows effectively detects this structure in deterministic environments, both categorical and continuous-valued. the acquired knowledge can be exploited to augment the original data set, leading eventually to a reduction in the distributional shift between the true and the learned model. such data augmentation technique can be exploited as a preliminary process to be executed before adopting an offline reinforcement learning architecture, increasing its performance. in this work we extend the paradigm to also tackle non-deterministic mdps, in particular, 1) we propose a detection threshold in categorical environments based on statistical distances, and 2) we show that the former results lead to a performance improvement when solving the learned mdp and then applying the optimized policy in the real environment.",10.5220/0011633400003393,2021-12-18,2023-04-12,"['giorgio angelotti', 'nicolas drougard', 'caroline p. c. chanel']",https://arxiv.org/pdf/2112.09943.pdf
57,2112.11602,causal inference despite limited global confounding via mixture models,cs.lg cs.ds eess.sp stat.ml,"a bayesian network is a directed acyclic graph (dag) on a set of $n$ random variables (the vertices); a bayesian network distribution (bnd) is a probability distribution on the random variables that is markovian on the graph. a finite $k$-mixture of such models is graphically represented by a larger graph which has an additional ""hidden"" (or ""latent"") random variable $u$, ranging in $\{1,\ldots,k\}$, and a directed edge from $u$ to every other vertex. models of this type are fundamental to causal inference, where $u$ models an unobserved confounding effect of multiple populations, obscuring the causal relationships in the observable dag. by solving the mixture problem and recovering the joint probability distribution on $u$, traditionally unidentifiable causal relationships become identifiable. using a reduction to the more well-studied ""product"" case on empty graphs, we give the first algorithm to learn mixtures of non-empty dags.",,2021-12-21,2023-04-11,"['spencer l. gordon', 'bijan mazaheri', 'yuval rabani', 'leonard j. schulman']",https://arxiv.org/pdf/2112.11602.pdf
58,2112.14602,modified ddpg car-following model with a real-world human driving   experience with carla simulator,cs.ro cs.ai cs.lg,"in the autonomous driving field, fusion of human knowledge into deep reinforcement learning (drl) is often based on the human demonstration recorded in a simulated environment. this limits the generalization and the feasibility of application in real-world traffic. we propose a two-stage drl method to train a car-following agent, that modifies the policy by leveraging the real-world human driving experience and achieves performance superior to the pure drl agent. training a drl agent is done within carla framework with robot operating system (ros). for evaluation, we designed different driving scenarios to compare the proposed two-stage drl car-following agent with other agents. after extracting the ""good"" behavior from the human driver, the agent becomes more efficient and reasonable, which makes this autonomous agent more suitable for human-robot interaction (hri) traffic.",10.1016/j.trc.2022.103987,2021-12-29,2022-09-19,"['dianzhao li', 'ostap okhrin']",https://arxiv.org/pdf/2112.14602.pdf
59,2201.00785,implicit autoencoder for point cloud self-supervised representation   learning,cs.cv,"this paper advocates the use of implicit surface representation in autoencoder-based self-supervised 3d representation learning. the most popular and accessible 3d representation, i.e., point clouds, involves discrete samples of the underlying continuous 3d surface. this discretization process introduces sampling variations on the 3d shape, making it challenging to develop transferable knowledge of the true 3d geometry. in the standard autoencoding paradigm, the encoder is compelled to encode not only the 3d geometry but also information on the specific discrete sampling of the 3d shape into the latent code. this is because the point cloud reconstructed by the decoder is considered unacceptable unless there is a perfect mapping between the original and the reconstructed point clouds. this paper introduces the implicit autoencoder (iae), a simple yet effective method that addresses the sampling variation issue by replacing the commonly-used point-cloud decoder with an implicit decoder. the implicit decoder reconstructs a continuous representation of the 3d shape, independent of the imperfections in the discrete samples. extensive experiments demonstrate that the proposed iae achieves state-of-the-art performance across various self-supervised learning benchmarks.",,2022-01-03,2023-04-10,"['siming yan', 'zhenpei yang', 'haoxiang li', 'chen song', 'li guan', 'hao kang', 'gang hua', 'qixing huang']",https://arxiv.org/pdf/2201.00785.pdf
60,2201.01140,predicting influenza a viral host using pssm and word embeddings,cs.cl cs.lg,"the rapid mutation of the influenza virus threatens public health. reassortment among viruses with different hosts can lead to a fatal pandemic. however, it is difficult to detect the original host of the virus during or after an outbreak as influenza viruses can circulate between different species. therefore, early and rapid detection of the viral host would help reduce the further spread of the virus. we use various machine learning models with features derived from the position-specific scoring matrix (pssm) and features learned from word embedding and word encoding to infer the origin host of viruses. the results show that the performance of the pssm-based model reaches the mcc around 95%, and the f1 around 96%. the mcc obtained using the model with word embedding is around 96%, and the f1 is around 97%.",10.1109/cibcb49929.2021.9562959,2022-01-04,2023-04-06,"['yanhua xu', 'dominik wojtczak']",https://arxiv.org/pdf/2201.01140.pdf
61,2201.01300,the camels project: public data release,astro-ph.co astro-ph.ga astro-ph.im cs.ai cs.lg,"the cosmology and astrophysics with machine learning simulations (camels) project was developed to combine cosmology with astrophysics through thousands of cosmological hydrodynamic simulations and machine learning. camels contains 4,233 cosmological simulations, 2,049 n-body and 2,184 state-of-the-art hydrodynamic simulations that sample a vast volume in parameter space. in this paper we present the camels public data release, describing the characteristics of the camels simulations and a variety of data products generated from them, including halo, subhalo, galaxy, and void catalogues, power spectra, bispectra, lyman-$\alpha$ spectra, probability distribution functions, halo radial profiles, and x-rays photon lists. we also release over one thousand catalogues that contain billions of galaxies from camels-sam: a large collection of n-body simulations that have been combined with the santa cruz semi-analytic model. we release all the data, comprising more than 350 terabytes and containing 143,922 snapshots, millions of halos, galaxies and summary statistics. we provide further technical details on how to access, download, read, and process the data at \url{https://camels.readthedocs.io}.",10.3847/1538-4365/acbf47,2022-01-04,,"['francisco villaescusa-navarro', 'shy genel', 'daniel angl√©s-alc√°zar', 'lucia a. perez', 'pablo villanueva-domingo', 'digvijay wadekar', 'helen shao', 'faizan g. mohammad', 'sultan hassan', 'emily moser', 'erwin t. lau', 'luis fernando machado poletti valle', 'andrina nicola', 'leander thiele', 'yongseok jo', 'oliver h. e. philcox', 'benjamin d. oppenheimer', 'megan tillman', 'changhoon hahn', 'neerav kaushal', 'alice pisani', 'matthew gebhardt', 'ana maria delgado', 'joyce caliendo', 'christina kreisch', 'kaze w. k. wong', 'william r. coulton', 'michael eickenberg', 'gabriele parimbelli', 'yueying ni', 'ulrich p. steinwandel', 'valentina la torre', 'romeel dave', 'nicholas battaglia', 'daisuke nagai', 'david n. spergel', 'lars hernquist', 'blakesley burkhart', 'desika narayanan', 'benjamin wandelt', 'rachel s. somerville', 'greg l. bryan', 'matteo viel', 'yin li', 'vid irsic', 'katarina kraljic', 'mark vogelsberger']",https://arxiv.org/pdf/2201.01300.pdf
62,2201.02775,adi: adversarial dominating inputs in vertical federated learning   systems,cs.cr cs.dc cs.lg,"vertical federated learning (vfl) system has recently become prominent as a concept to process data distributed across many individual sources without the need to centralize it. multiple participants collaboratively train models based on their local data in a privacy-aware manner. to date, vfl has become a de facto solution to securely learn a model among organizations, allowing knowledge to be shared without compromising privacy of any individuals. despite the prosperous development of vfl systems, we find that certain inputs of a participant, named adversarial dominating inputs (adis), can dominate the joint inference towards the direction of the adversary's will and force other (victim) participants to make negligible contributions, losing rewards that are usually offered regarding the importance of their contributions in federated learning scenarios. we conduct a systematic study on adis by first proving their existence in typical vfl systems. we then propose gradient-based methods to synthesize adis of various formats and exploit common vfl systems. we further launch greybox fuzz testing, guided by the saliency score of ``victim'' participants, to perturb adversary-controlled inputs and systematically explore the vfl attack surface in a privacy-preserving manner. we conduct an in-depth study on the influence of critical parameters and settings in synthesizing adis. our study reveals new vfl attack opportunities, promoting the identification of unknown threats before breaches and building more secure vfl systems.",,2022-01-08,2023-04-11,"['qi pang', 'yuanyuan yuan', 'shuai wang', 'wenting zheng']",https://arxiv.org/pdf/2201.02775.pdf
63,2201.04828,multi-scale adaptive graph neural network for multivariate time series   forecasting,cs.lg,"multivariate time series (mts) forecasting plays an important role in the automation and optimization of intelligent applications. it is a challenging task, as we need to consider both complex intra-variable dependencies and inter-variable dependencies. existing works only learn temporal patterns with the help of single inter-variable dependencies. however, there are multi-scale temporal patterns in many real-world mts. single inter-variable dependencies make the model prefer to learn one type of prominent and shared temporal patterns. in this paper, we propose a multi-scale adaptive graph neural network (magnn) to address the above issue. magnn exploits a multi-scale pyramid network to preserve the underlying temporal dependencies at different time scales. since the inter-variable dependencies may be different under distinct time scales, an adaptive graph learning module is designed to infer the scale-specific inter-variable dependencies without pre-defined priors. given the multi-scale feature representations and scale-specific inter-variable dependencies, a multi-scale temporal graph neural network is introduced to jointly model intra-variable dependencies and inter-variable dependencies. after that, we develop a scale-wise fusion module to effectively promote the collaboration across different time scales, and automatically capture the importance of contributed temporal patterns. experiments on four real-world datasets demonstrate that magnn outperforms the state-of-the-art methods across various settings.",,2022-01-13,2023-04-09,"['ling chen', 'donghui chen', 'zongjiang shang', 'binqing wu', 'cen zheng', 'bo wen', 'wei zhang']",https://arxiv.org/pdf/2201.04828.pdf
64,2201.07211,human-level control through directly-trained deep spiking q-networks,cs.ne cs.lg,"as the third-generation neural networks, spiking neural networks (snns) have great potential on neuromorphic hardware because of their high energy-efficiency. however, deep spiking reinforcement learning (dsrl), i.e., the reinforcement learning (rl) based on snns, is still in its preliminary stage due to the binary output and the non-differentiable property of the spiking function. to address these issues, we propose a deep spiking q-network (dsqn) in this paper. specifically, we propose a directly-trained deep spiking reinforcement learning architecture based on the leaky integrate-and-fire (lif) neurons and deep q-network (dqn). then, we adapt a direct spiking learning algorithm for the deep spiking q-network. we further demonstrate the advantages of using lif neurons in dsqn theoretically. comprehensive experiments have been conducted on 17 top-performing atari games to compare our method with the state-of-the-art conversion method. the experimental results demonstrate the superiority of our method in terms of performance, stability, robustness and energy-efficiency. to the best of our knowledge, our work is the first one to achieve state-of-the-art performance on multiple atari games with the directly-trained snn.",10.1109/tcyb.2022.3198259,2021-12-13,2023-04-10,"['guisong liu', 'wenjie deng', 'xiurui xie', 'li huang', 'huajin tang']",https://arxiv.org/pdf/2201.07211.pdf
65,2201.09562,gosafeopt: scalable safe exploration for global optimization of   dynamical systems,cs.lg cs.sy eess.sy,"learning optimal control policies directly on physical systems is challenging since even a single failure can lead to costly hardware damage. most existing model-free learning methods that guarantee safety, i.e., no failures, during exploration are limited to local optima. a notable exception is the gosafe algorithm, which, unfortunately, cannot handle high-dimensional systems and hence cannot be applied to most real-world dynamical systems. this work proposes gosafeopt as the first algorithm that can safely discover globally optimal policies for high-dimensional systems while giving safety and optimality guarantees. we demonstrate the superiority of gosafeopt over competing model-free safe learning methods on a robot arm that would be prohibitive for gosafe.",,2022-01-24,2023-04-12,"['bhavya sukhija', 'matteo turchetta', 'david lindner', 'andreas krause', 'sebastian trimpe', 'dominik baumann']",https://arxiv.org/pdf/2201.09562.pdf
66,2201.10014,zero-truncated poisson regression for sparse multiway count data   corrupted by false zeros,stat.me cs.ms cs.na math.na math.st stat.ml stat.th,"we propose a novel statistical inference methodology for multiway count data that is corrupted by false zeros that are indistinguishable from true zero counts. our approach consists of zero-truncating the poisson distribution to neglect all zero values. this simple truncated approach dispenses with the need to distinguish between true and false zero counts and reduces the amount of data to be processed. inference is accomplished via tensor completion that imposes low-rank tensor structure on the poisson parameter space.   our main result shows that an $n$-way rank-$r$ parametric tensor $\boldsymbol{\mathscr{m}}\in(0,\infty)^{i\times \cdots\times i}$ generating poisson observations can be accurately estimated by zero-truncated poisson regression from approximately $ir^2\log_2^2(i)$ non-zero counts under the nonnegative canonical polyadic decomposition. our result also quantifies the error made by zero-truncating the poisson distribution when the parameter is uniformly bounded from below. therefore, under a low-rank multiparameter model, we propose an implementable approach guaranteed to achieve accurate regression in under-determined scenarios with substantial corruption by false zeros. several numerical experiments are presented to explore the theoretical results.",,2022-01-24,2023-04-11,"['oscar l√≥pez', 'daniel m. dunlavy', 'richard b. lehoucq']",https://arxiv.org/pdf/2201.10014.pdf
67,2201.10034,self-supervised point cloud registration with deep versatile descriptors,cs.cv,"as a fundamental yet challenging problem in intelligent transportation systems, point cloud registration attracts vast attention and has been attained with various deep learning-based algorithms. the unsupervised registration algorithms take advantage of deep neural network-enabled novel representation learning while requiring no human annotations, making them applicable to industrial applications. however, unsupervised methods mainly depend on global descriptors, which ignore the high-level representations of local geometries. in this paper, we propose to jointly use both global and local descriptors to register point clouds in a self-supervised manner, which is motivated by a critical observation that all local geometries of point clouds are transformed consistently under the same transformation. therefore, local geometries can be employed to enhance the representation ability of the feature extraction module. moreover, the proposed local descriptor is flexible and can be integrated into most existing registration methods and improve their performance. besides, we also utilize point cloud reconstruction and normal estimation to enhance the transformation awareness of global and local descriptors. lastly, extensive experimental results on one synthetic and three real-world datasets demonstrate that our method outperforms existing state-of-art unsupervised registration methods and even surpasses supervised ones in some cases. robustness and computational efficiency evaluations also indicate that the proposed method applies to intelligent vehicles.",,2022-01-24,2023-04-12,"['dongrui liu', 'chuanchuan chen', 'changqing xu', 'robert qiu', 'lei chu']",https://arxiv.org/pdf/2201.10034.pdf
68,2201.10084,revisiting l1 loss in super-resolution: a probabilistic view and beyond,cs.cv,"super-resolution as an ill-posed problem has many high-resolution candidates for a low-resolution input. however, the popular $\ell_1$ loss used to best fit the given hr image fails to consider this fundamental property of non-uniqueness in image restoration. in this work, we fix the missing piece in $\ell_1$ loss by formulating super-resolution with neural networks as a probabilistic model. it shows that $\ell_1$ loss is equivalent to a degraded likelihood function that removes the randomness from the learning process. by introducing a data-adaptive random variable, we present a new objective function that aims at minimizing the expectation of the reconstruction error over all plausible solutions. the experimental results show consistent improvements on mainstream architectures, with no extra parameter or computing cost at inference time.",,2022-01-24,2023-04-08,"['xiangyu he', 'jian cheng']",https://arxiv.org/pdf/2201.10084.pdf
69,2201.10424,improving segmentation of calcified and non-calcified plaques on   ccta-cpr scans via masking of the artery wall,eess.iv cs.cv,"the presence of plaques in the coronary arteries is a major risk to the patients' life. in particular, non-calcified plaques pose a great challenge, as they are harder to detect and more likely to rupture than calcified plaques. while current deep learning techniques allow precise segmentation of real-life images, the performance in medical images is still low. this is caused mostly by blurriness and ambiguous voxel intensities of unrelated parts that fall on the same value range. in this paper, we propose a novel methodology for segmenting calcified and non-calcified plaques in ccta-cpr scans of coronary arteries. the input slices are masked so only the voxels within the wall vessel are considered for segmentation, thus, reducing ambiguity. this mask can be automatically generated via a deep learning-based vessel detector, that provides not only the contour of the outer artery wall, but also the inner contour. for evaluation, we utilized a dataset in which each voxel is carefully annotated as one of five classes: background, lumen, artery wall, calcified plaque, or non-calcified plaque. we also provide an exhaustive evaluation by applying different types of masks, in order to validate the potential of vessel masking for plaque segmentation. our methodology results in a prominent boost in segmentation performance, in both quantitative and qualitative evaluation, achieving accurate plaque shapes even for the challenging non-calcified plaques. furthermore, when using highly accurate masks, difficult cases such as stenosis become segmentable. we believe our findings can lead the future research for high-performance plaque segmentation.",10.1117/12.2652895,2022-01-25,2023-04-10,"['antonio tejero-de-pablos', 'hiroaki yamane', 'yusuke kurose', 'junichi iho', 'youji tokunaga', 'makoto horie', 'keisuke nishizawa', 'yusaku hayashi', 'yasushi koyama', 'tatsuya harada']",https://arxiv.org/pdf/2201.10424.pdf
70,2202.01888,a hybrid physics machine learning approach for macroscopic traffic state   estimation,cs.lg eess.sp,"full-field traffic state information (i.e., flow, speed, and density) is critical for the successful operation of intelligent transportation systems (its) on freeways. however, incomplete traffic information tends to be directly collected from traffic detectors that are insufficiently installed in most areas, which is a major obstacle to the popularization of its. to tackle this issue, this paper introduces an innovative traffic state estimation (tse) framework that hybrid regression machine learning techniques (e.g., artificial neural network (ann), random forest (rf), and support vector machine (svm)) with a traffic physics model (e.g., second-order macroscopic traffic flow model) using limited information from traffic sensors as inputs to construct accurate and full-field estimated traffic state for freeway systems. to examine the effectiveness of the proposed tse framework, this paper conducted empirical studies on a real-world data set collected from a stretch of i-15 freeway in salt lake city, utah. experimental results show that the proposed method has been proved to estimate full-field traffic information accurately. hence, the proposed method could provide accurate and full-field traffic information, thus providing the basis for the popularization of its.",,2022-02-01,2023-04-11,"['zhao zhang', 'ding zhao', 'xianfeng terry yang']",https://arxiv.org/pdf/2202.01888.pdf
71,2202.03527,integrated multiscale domain adaptive yolo,cs.cv,"the area of domain adaptation has been instrumental in addressing the domain shift problem encountered by many applications. this problem arises due to the difference between the distributions of source data used for training in comparison with target data used during realistic testing scenarios. in this paper, we introduce a novel multiscale domain adaptive yolo (ms-dayolo) framework that employs multiple domain adaptation paths and corresponding domain classifiers at different scales of the recently introduced yolov4 object detector. building on our baseline multiscale dayolo framework, we introduce three novel deep learning architectures for a domain adaptation network (dan) that generates domain-invariant features. in particular, we propose a progressive feature reduction (pfr), a unified classifier (uc), and an integrated architecture. we train and test our proposed dan architectures in conjunction with yolov4 using popular datasets. our experiments show significant improvements in object detection performance when training yolov4 using the proposed ms-dayolo architectures and when tested on target data for autonomous driving applications. moreover, ms-dayolo framework achieves an order of magnitude real-time speed improvement relative to faster r-cnn solutions while providing comparable object detection performance.",10.1109/tip.2023.3255106,2022-02-07,2022-07-04,"['mazin hnewa', 'hayder radha']",https://arxiv.org/pdf/2202.03527.pdf
72,2202.03881,robust hybrid learning with expert augmentation,cs.lg stat.ml,"hybrid modelling reduces the misspecification of expert models by combining them with machine learning (ml) components learned from data. similarly to many ml algorithms, hybrid model performance guarantees are limited to the training distribution. leveraging the insight that the expert model is usually valid even outside the training domain, we overcome this limitation by introducing a hybrid data augmentation strategy termed \textit{expert augmentation}. based on a probabilistic formalization of hybrid modelling, we demonstrate that expert augmentation, which can be incorporated into existing hybrid systems, improves generalization. we empirically validate the expert augmentation on three controlled experiments modelling dynamical systems with ordinary and partial differential equations. finally, we assess the potential real-world applicability of expert augmentation on a dataset of a real double pendulum.",,2022-02-08,2023-04-11,"['antoine wehenkel', 'jens behrmann', 'hsiang hsu', 'guillermo sapiro', 'gilles louppe', 'j√∂rn-henrik jacobsen']",https://arxiv.org/pdf/2202.03881.pdf
73,2202.06843,continual learning from demonstration of robotics skills,cs.ro cs.lg,"methods for teaching motion skills to robots focus on training for a single skill at a time. robots capable of learning from demonstration can considerably benefit from the added ability to learn new movement skills without forgetting what was learned in the past. to this end, we propose an approach for continual learning from demonstration using hypernetworks and neural ordinary differential equation solvers. we empirically demonstrate the effectiveness of this approach in remembering long sequences of trajectory learning tasks without the need to store any data from past demonstrations. our results show that hypernetworks outperform other state-of-the-art continual learning approaches for learning from demonstration. in our experiments, we use the popular lasa benchmark, and two new datasets of kinesthetic demonstrations collected with a real robot that we introduce in this paper called the helloworld and robotasks datasets. we evaluate our approach on a physical robot and demonstrate its effectiveness in learning real-world robotic tasks involving changing positions as well as orientations. we report both trajectory error metrics and continual learning metrics, and we propose two new continual learning metrics. our code, along with the newly collected datasets, is available at https://github.com/sayantanauddy/clfd.",,2022-02-14,2023-04-12,"['sayantan auddy', 'jakob hollenstein', 'matteo saveriano', 'antonio rodr√≠guez-s√°nchez', 'justus piater']",https://arxiv.org/pdf/2202.06843.pdf
74,2202.07165,olive: oblivious federated learning on trusted execution environment   against the risk of sparsification,cs.lg cs.cr,"combining federated learning (fl) with a trusted execution environment (tee) is a promising approach for realizing privacy-preserving fl, which has garnered significant academic attention in recent years. implementing the tee on the server side enables each round of fl to proceed without exposing the client's gradient information to untrusted servers. this addresses usability gaps in existing secure aggregation schemes as well as utility gaps in differentially private fl. however, to address the issue using a tee, the vulnerabilities of server-side tees need to be considered -- this has not been sufficiently investigated in the context of fl. the main technical contribution of this study is the analysis of the vulnerabilities of tee in fl and the defense. first, we theoretically analyze the leakage of memory access patterns, revealing the risk of sparsified gradients, which are commonly used in fl to enhance communication efficiency and model accuracy. second, we devise an inference attack to link memory access patterns to sensitive information in the training dataset. finally, we propose an oblivious yet efficient aggregation algorithm to prevent memory access pattern leakage. our experiments on real-world data demonstrate that the proposed method functions efficiently in practical scales.",,2022-02-14,2023-04-11,"['fumiyuki kato', 'yang cao', 'masatoshi yoshikawa']",https://arxiv.org/pdf/2202.07165.pdf
75,2202.10746,cd-rom: complemented deep-reduced order model,physics.flu-dyn cs.lg stat.ml,"model order reduction through the pod-galerkin method can lead to dramatic gains in terms of computational efficiency in solving physical problems. however, the applicability of the method to non linear high-dimensional dynamical systems such as the navier-stokes equations has been shown to be limited, producing inaccurate and sometimes unstable models. this paper proposes a closure modeling approach for classical pod-galerkin reduced order models (rom). we use multi layer perceptrons (mlp) to learn a continuous in time closure model through the recently proposed neural ode method. inspired by taken's theorem as well as the mori-zwanzig formalism, we augment roms with a delay differential equation architecture to model non-markovian effects in reduced models. the proposed model, called cd-rom (complementary deep-reduced order model) is able to retain information from past states of the system and use it to correct the imperfect reduced dynamics. the model can be integrated in time as a system of ordinary differential equations using any classical time marching scheme. we demonstrate the ability of our cd-rom approach to improve the accuracy of pod-galerkin models on two cfd examples, even in configurations unseen during training.",10.1016/j.cma.2023.115985,2022-02-22,2022-11-21,"['emmanuel menier', 'michele alessandro bucci', 'mouadh yagoubi', 'lionel mathelin', 'marc schoenauer']",https://arxiv.org/pdf/2202.10746.pdf
76,2203.02090,bayesian community detection for networks with covariates,stat.me cs.si stat.co stat.ml,"the increasing prevalence of network data in a vast variety of fields and the need to extract useful information out of them have spurred fast developments in related models and algorithms. among the various learning tasks with network data, community detection, the discovery of node clusters or ""communities,"" has arguably received the most attention in the scientific community. in many real-world applications, the network data often come with additional information in the form of node or edge covariates that should ideally be leveraged for inference. in this paper, we add to a limited literature on community detection for networks with covariates by proposing a bayesian stochastic block model with a covariate-dependent random partition prior. under our prior, the covariates are explicitly expressed in specifying the prior distribution on the cluster membership. our model has the flexibility of modeling uncertainties of all the parameter estimates including the community membership. importantly, and unlike the majority of existing methods, our model has the ability to learn the number of the communities via posterior inference without having to assume it to be known. our model can be applied to community detection in both dense and sparse networks, with both categorical and continuous covariates, and our mcmc algorithm is very efficient with good mixing properties. we demonstrate the superior performance of our model over existing models in a comprehensive simulation study and an application to two real datasets.",,2022-03-03,2023-04-06,"['luyi shen', 'arash amini', 'nathaniel josephs', 'lizhen lin']",https://arxiv.org/pdf/2203.02090.pdf
77,2203.04249,evaluating feasibility of batteries for second-life applications using   machine learning,eess.sy cs.lg cs.sy,"this paper presents a combination of machine learning techniques to enable prompt evaluation of retired electric vehicle batteries as to either retain those batteries for a second-life application and extend their operation beyond the original and first intent or send them to recycle facilities. the proposed algorithm generates features from available battery current and voltage measurements with simple statistics, selects and ranks the features using correlation analysis, and employs gaussian process regression enhanced with bagging. this approach is validated over publicly available aging datasets of more than 200 cells with slow and fast charging, with different cathode chemistries, and for diverse operating conditions. promising results are observed based on multiple training-test partitions, wherein the mean of root mean squared percent error and mean percent error performance errors are found to be less than 1.48% and 1.29%, respectively, in the worst-case scenarios.",,2022-03-08,2023-04-07,"['aki takahashi', 'anirudh allam', 'simona onori']",https://arxiv.org/pdf/2203.04249.pdf
78,2203.06993,supervised segmentation of no2 plumes from individual ships using   tropomi satellite data,cs.cv cs.lg,"the shipping industry is one of the strongest anthropogenic emitters of $\text{no}_\text{x}$ -- substance harmful both to human health and the environment. the rapid growth of the industry causes societal pressure on controlling the emission levels produced by ships. all the methods currently used for ship emission monitoring are costly and require proximity to a ship, which makes global and continuous emission monitoring impossible. a promising approach is the application of remote sensing. studies showed that some of the $\text{no}_\text{2}$ plumes from individual ships can visually be distinguished using the tropospheric monitoring instrument on board the copernicus sentinel 5 precursor (tropomi/s5p). to deploy a remote sensing-based global emission monitoring system, an automated procedure for the estimation of $\text{no}_\text{2}$ emissions from individual ships is needed. the extremely low signal-to-noise ratio of the available data as well as the absence of ground truth makes the task very challenging. here, we present a methodology for the automated segmentation of $\text{no}_\text{2}$ plumes produced by seagoing ships using supervised machine learning on tropomi/s5p data. we show that the proposed approach leads to a more than a 20\% increase in the average precision score in comparison to the methods used in previous studies and results in a high correlation of 0.834 with the theoretically derived ship emission proxy. this work is a crucial step toward the development of an automated procedure for global ship emission monitoring using remote sensing data.",10.3390/rs14225809,2022-03-14,2023-04-07,"['solomiia kurchaba', 'jasper van vliet', 'fons j. verbeek', 'jacqueline j. meulman', 'cor j. veenman']",https://arxiv.org/pdf/2203.06993.pdf
79,2203.09829,representative subset selection for efficient fine-tuning in   self-supervised speech recognition,cs.lg cs.sd eess.as,"self-supervised speech recognition models require considerable labeled training data for learning high-fidelity representations for automatic speech recognition (asr) which is computationally demanding and time-consuming. we consider the task of identifying an optimal subset of data for efficient fine-tuning in self-supervised speech models for asr. we discover that the dataset pruning strategies used in vision tasks for sampling the most informative examples do not perform better than random subset selection on fine-tuning self-supervised asr. we then present the cowerage algorithm for representative subset selection in self-supervised asr. cowerage is based on our finding that ensuring the coverage of examples based on training word error rate (wer) in the early training epochs leads to better generalization performance. extensive experiments with the wav2vec 2.0 and hubert model on timit, librispeech, and ljspeech datasets show the effectiveness of cowerage and its transferability across models, with up to 17% relative wer improvement over existing dataset pruning methods and random sampling. we also demonstrate that the coverage of training instances in terms of wer values ensures the inclusion of phonemically diverse examples, leading to better test accuracy in self-supervised speech recognition models.",,2022-03-18,2023-04-11,"['abdul hameed azeemi', 'ihsan ayyub qazi', 'agha ali raza']",https://arxiv.org/pdf/2203.09829.pdf
80,2203.09962,randomized sharpness-aware training for boosting computational   efficiency in deep learning,cs.lg cs.ai,"by driving models to converge to flat minima, sharpness-aware learning algorithms (such as sam) have shown the power to achieve state-of-the-art performances. however, these algorithms will generally incur one extra forward-backward propagation at each training iteration, which largely burdens the computation especially for scalable models. to this end, we propose a simple yet efficient training scheme, called randomized sharpness-aware training (rst). optimizers in rst would perform a bernoulli trial at each iteration to choose randomly from base algorithms (sgd) and sharpness-aware algorithms (sam) with a probability arranged by a predefined scheduling function. due to the mixture of base algorithms, the overall count of propagation pairs could be largely reduced. also, we give theoretical analysis on the convergence of rst. then, we empirically study the computation cost and effect of various types of scheduling functions, and give directions on setting appropriate scheduling functions. further, we extend the rst to a general framework (g-rst), where we can adjust regularization degree on sharpness freely for any scheduling function. we show that g-rst can outperform sam in most cases while saving 50\% extra computation cost.",,2022-03-18,2023-04-10,"['yang zhao', 'hao zhang', 'xiuyuan hu']",https://arxiv.org/pdf/2203.09962.pdf
81,2203.14205,recent few-shot object detection algorithms: a survey with performance   comparison,cs.cv,"the generic object detection (god) task has been successfully tackled by recent deep neural networks, trained by an avalanche of annotated training samples from some common classes. however, it is still non-trivial to generalize these object detectors to the novel long-tailed object classes, which have only few labeled training samples. to this end, the few-shot object detection (fsod) has been topical recently, as it mimics the humans' ability of learning to learn, and intelligently transfers the learned generic object knowledge from the common heavy-tailed, to the novel long-tailed object classes. especially, the research in this emerging field has been flourishing in recent years with various benchmarks, backbones, and methodologies proposed. to review these fsod works, there are several insightful fsod survey articles [58, 59, 74, 78] that systematically study and compare them as the groups of fine-tuning/transfer learning, and meta-learning methods. in contrast, we review the existing fsod algorithms from a new perspective under a new taxonomy based on their contributions, i.e., data-oriented, model-oriented, and algorithm-oriented. thus, a comprehensive survey with performance comparison is conducted on recent achievements of fsod. furthermore, we also analyze the technical challenges, the merits and demerits of these methods, and envision the future directions of fsod. specifically, we give an overview of fsod, including the problem definition, common datasets, and evaluation protocols. the taxonomy is then proposed that groups fsod methods into three types. following this taxonomy, we provide a systematic review of the advances in fsod. finally, further discussions on performance, challenges, and future directions are presented.",,2022-03-27,2023-04-12,"['tianying liu', 'lu zhang', 'yang wang', 'jihong guan', 'yanwei fu', 'jiajia zhao', 'shuigeng zhou']",https://arxiv.org/pdf/2203.14205.pdf
82,2203.16711,analytic theory for the dynamics of wide quantum neural networks,quant-ph cs.ai cs.lg stat.ml,"parameterized quantum circuits can be used as quantum neural networks and have the potential to outperform their classical counterparts when trained for addressing learning problems. to date, much of the results on their performance on practical problems are heuristic in nature. in particular, the convergence rate for the training of quantum neural networks is not fully understood. here, we analyze the dynamics of gradient descent for the training error of a class of variational quantum machine learning models. we define wide quantum neural networks as parameterized quantum circuits in the limit of a large number of qubits and variational parameters. we then find a simple analytic formula that captures the average behavior of their loss function and discuss the consequences of our findings. for example, for random quantum circuits, we predict and characterize an exponential decay of the residual training error as a function of the parameters of the system. we finally validate our analytic results with numerical experiments.",10.1103/physrevlett.130.150601,2022-03-30,2023-04-11,"['junyu liu', 'khadijeh najafi', 'kunal sharma', 'francesco tacchino', 'liang jiang', 'antonio mezzacapo']",https://arxiv.org/pdf/2203.16711.pdf
83,2204.00102,dynamic multimodal fusion,cs.cv cs.ai cs.mm,"deep multimodal learning has achieved great progress in recent years. however, current fusion approaches are static in nature, i.e., they process and fuse multimodal inputs with identical computation, without accounting for diverse computational demands of different multimodal data. in this work, we propose dynamic multimodal fusion (dynmm), a new approach that adaptively fuses multimodal data and generates data-dependent forward paths during inference. to this end, we propose a gating function to provide modality-level or fusion-level decisions on-the-fly based on multimodal features and a resource-aware loss function that encourages computational efficiency. results on various multimodal tasks demonstrate the efficiency and wide applicability of our approach. for instance, dynmm can reduce the computation costs by 46.5% with only a negligible accuracy loss (cmu-mosei sentiment analysis) and improve segmentation performance with over 21% savings in computation (nyu depth v2 semantic segmentation) when compared with static fusion approaches. we believe our approach opens a new direction towards dynamic multimodal network design, with applications to a wide range of multimodal tasks.",,2022-03-31,2023-04-06,"['zihui xue', 'radu marculescu']",https://arxiv.org/pdf/2204.00102.pdf
84,2204.04213,structure-aware protein self-supervised learning,cs.lg cs.ai q-bio.qm,"protein representation learning methods have shown great potential to yield useful representation for many downstream tasks, especially on protein classification. moreover, a few recent studies have shown great promise in addressing insufficient labels of proteins with self-supervised learning methods. however, existing protein language models are usually pretrained on protein sequences without considering the important protein structural information. to this end, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. in particular, a well-designed graph neural network (gnn) model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. specifically, we identify the relation between the sequential information in the protein language model and the structural information in the specially designed gnn model via a novel pseudo bi-level optimization scheme. experiments on several supervised downstream tasks verify the effectiveness of our proposed method.the code of the proposed method is available in \url{https://github.com/ggchen1997/steps_bioinformatics}.",,2022-04-05,2023-04-08,"['can chen', 'jingbo zhou', 'fan wang', 'xue liu', 'dejing dou']",https://arxiv.org/pdf/2204.04213.pdf
85,2204.04746,cholectriplet2021: a benchmark challenge for surgical action triplet   recognition,cs.cv,"context-aware decision support in the operating room can foster surgical safety and efficiency by leveraging real-time feedback from surgical workflow analysis. most existing works recognize surgical activities at a coarse-grained level, such as phases, steps or events, leaving out fine-grained interaction details about the surgical activity; yet those are needed for more helpful ai assistance in the operating room. recognizing surgical actions as triplets of <instrument, verb, target> combination delivers comprehensive details about the activities taking place in surgical videos. this paper presents cholectriplet2021: an endoscopic vision challenge organized at miccai 2021 for the recognition of surgical action triplets in laparoscopic videos. the challenge granted private access to the large-scale cholect50 dataset, which is annotated with action triplet information. in this paper, we present the challenge setup and assessment of the state-of-the-art deep learning methods proposed by the participants during the challenge. a total of 4 baseline methods from the challenge organizers and 19 new deep learning algorithms by competing teams are presented to recognize surgical action triplets directly from surgical videos, achieving mean average precision (map) ranging from 4.2% to 38.1%. this study also analyzes the significance of the results obtained by the presented approaches, performs a thorough methodological comparison between them, in-depth result analysis, and proposes a novel ensemble method for enhanced recognition. our analysis shows that surgical workflow analysis is not yet solved, and also highlights interesting directions for future research on fine-grained surgical activity recognition which is of utmost importance for the development of ai in surgery.",10.1016/j.media.2023.102803,2022-04-10,2022-12-29,"['chinedu innocent nwoye', 'deepak alapatt', 'tong yu', 'armine vardazaryan', 'fangfang xia', 'zixuan zhao', 'tong xia', 'fucang jia', 'yuxuan yang', 'hao wang', 'derong yu', 'guoyan zheng', 'xiaotian duan', 'neil getty', 'ricardo sanchez-matilla', 'maria robu', 'li zhang', 'huabin chen', 'jiacheng wang', 'liansheng wang', 'bokai zhang', 'beerend gerats', 'sista raviteja', 'rachana sathish', 'rong tao', 'satoshi kondo', 'winnie pang', 'hongliang ren', 'julian ronald abbing', 'mohammad hasan sarhan', 'sebastian bodenstedt', 'nithya bhasker', 'bruno oliveira', 'helena r. torres', 'li ling', 'finn gaida', 'tobias czempiel', 'jo√£o l. vila√ßa', 'pedro morais', 'jaime fonseca', 'ruby mae egging', 'inge nicole wijma', 'chen qian', 'guibin bian', 'zhen li', 'velmurugan balasubramanian', 'debdoot sheet', 'imanol luengo', 'yuanbo zhu', 'shuai ding', 'jakob-anton aschenbrenner', 'nicolas elini van der kar', 'mengya xu', 'mobarakol islam', 'lalithkumar seenivasan', 'alexander jenke', 'danail stoyanov', 'didier mutter', 'pietro mascagni', 'barbara seeliger', 'cristians gonzalez', 'nicolas padoy']",https://arxiv.org/pdf/2204.04746.pdf
86,2204.06552,neural vector fields for implicit surface representation and inference,cs.cv,"implicit fields have recently shown increasing success in representing and learning 3d shapes accurately. signed distance fields and occupancy fields are decades old and still the preferred representations, both with well-studied properties, despite their restriction to closed surfaces. with neural networks, several other variations and training principles have been proposed with the goal to represent all classes of shapes. in this paper, we develop a novel and yet a fundamental representation considering unit vectors in 3d space and call it vector field (vf): at each point in $\mathbb{r}^3$, vf is directed at the closest point on the surface. we theoretically demonstrate that vf can be easily transformed to surface density by computing the flux density. unlike other standard representations, vf directly encodes an important physical property of the surface, its normal. we further show the advantages of vf representation, in learning open, closed, or multi-layered as well as piecewise planar surfaces. we compare our method on several datasets including shapenet where the proposed new neural implicit field shows superior accuracy in representing any type of shape, outperforming other standard methods. code is available at https://github.com/edomel/implicitvf.",,2022-04-13,2023-04-07,"['edoardo mello rella', 'ajad chhatkuli', 'ender konukoglu', 'luc van gool']",https://arxiv.org/pdf/2204.06552.pdf
87,2204.07404,divide & conquer imitation learning,cs.ai cs.ro,"when cast into the deep reinforcement learning framework, many robotics tasks require solving a long horizon and sparse reward problem, where learning algorithms struggle. in such context, imitation learning (il) can be a powerful approach to bootstrap the learning process. however, most il methods require several expert demonstrations which can be prohibitively difficult to acquire. only a handful of il algorithms have shown efficiency in the context of an extreme low expert data regime where a single expert demonstration is available. in this paper, we present a novel algorithm designed to imitate complex robotic tasks from the states of an expert trajectory. based on a sequential inductive bias, our method divides the complex task into smaller skills. the skills are learned into a goal-conditioned policy that is able to solve each skill individually and chain skills to solve the entire task. we show that our method imitates a non-holonomic navigation task and scales to a complex simulated robotic manipulation task with very high sample efficiency.",,2022-04-15,2023-04-13,"['alexandre chenu', 'nicolas perrin-gilbert', 'olivier sigaud']",https://arxiv.org/pdf/2204.07404.pdf
88,2204.07471,the importance of credo in multiagent learning,cs.ai,"we propose a model for multi-objective optimization, a credo, for agents in a system that are configured into multiple groups (i.e., teams). our model of credo regulates how agents optimize their behavior for the groups they belong to. we evaluate credo in the context of challenging social dilemmas with reinforcement learning agents. our results indicate that the interests of teammates, or the entire system, are not required to be fully aligned for achieving globally beneficial outcomes. we identify two scenarios without full common interest that achieve high equality and significantly higher mean population rewards compared to when the interests of all agents are aligned.",,2022-04-15,2023-04-12,"['david radke', 'kate larson', 'tim brecht']",https://arxiv.org/pdf/2204.07471.pdf
89,2204.08096,synthetic distracted driving (syndd2) dataset for analyzing distracted   behaviors and various gaze zones of a driver,cs.cv cs.ai,"this article presents a synthetic distracted driving (syndd2 - a continuum of syndd1) dataset for machine learning models to detect and analyze drivers' various distracted behavior and different gaze zones. we collected the data in a stationary vehicle using three in-vehicle cameras positioned at locations: on the dashboard, near the rearview mirror, and on the top right-side window corner. the dataset contains two activity types: distracted activities and gaze zones for each participant, and each activity type has two sets: without appearance blocks and with appearance blocks such as wearing a hat or sunglasses. the order and duration of each activity for each participant are random. in addition, the dataset contains manual annotations for each activity, having its start and end time annotated. researchers could use this dataset to evaluate the performance of machine learning algorithms to classify various distracting activities and gaze zones of drivers.",,2022-04-17,2023-04-10,"['mohammed shaiqur rahman', 'jiyang wang', 'senem velipasalar gursoy', 'david anastasiu', 'shuo wang', 'anuj sharma']",https://arxiv.org/pdf/2204.08096.pdf
90,2204.08358,automlbench: a comprehensive experimental evaluation of automated   machine learning frameworks,cs.lg cs.ai,"with the booming demand for machine learning applications, it has been recognized that the number of knowledgeable data scientists can not scale with the growing data volumes and application needs in our digital world. in response to this demand, several automated machine learning (automl) frameworks have been developed to fill the gap of human expertise by automating the process of building machine learning pipelines. each framework comes with different heuristics-based design decisions. in this study, we present a comprehensive evaluation and comparison of the performance characteristics of six popular automl frameworks, namely, autoweka, autosklearn, tpot, recipe, atm, and smartml, across 100 data sets from established automl benchmark suites. our experimental evaluation considers different aspects for its comparison, including the performance impact of several design decisions, including time budget, size of search space, meta-learning, and ensemble construction. the results of our study reveal various interesting insights that can significantly guide and impact the design of automl frameworks.",,2022-04-18,2023-04-12,"['hassan eldeeb', 'mohamed maher', 'radwa elshawi', 'sherif sakr']",https://arxiv.org/pdf/2204.08358.pdf
91,2204.11351,an empirical study of the effect of background data size on the   stability of shapley additive explanations (shap) for deep learning models,cs.lg cs.ai,"nowadays, the interpretation of why a machine learning (ml) model makes certain inferences is as crucial as the accuracy of such inferences. some ml models like the decision tree possess inherent interpretability that can be directly comprehended by humans. others like artificial neural networks (ann), however, rely on external methods to uncover the deduction mechanism. shapley additive explanations (shap) is one of such external methods, which requires a background dataset when interpreting anns. generally, a background dataset consists of instances randomly sampled from the training dataset. however, the sampling size and its effect on shap remain to be unexplored. in our empirical study on the mimic-iii dataset, we show that the two core explanations - shap values and variable rankings fluctuate when using different background datasets acquired from random sampling, indicating that users cannot unquestioningly trust the one-shot interpretation from shap. luckily, such fluctuation decreases with the increase of the background dataset size. also, we notice an u-shape in the stability assessment of shap variable rankings, demonstrating that shap is more reliable in ranking the most and least important variables compared to moderately important ones. overall, our results suggest that users should take into account how background data affects shap results, with improved shap stability as the background sample size increases.",,2022-04-24,2023-04-09,"['han yuan', 'mingxuan liu', 'lican kang', 'chenkui miao', 'ying wu']",https://arxiv.org/pdf/2204.11351.pdf
92,2204.14211,temporalwiki: a lifelong benchmark for training and evaluating   ever-evolving language models,cs.cl,"language models (lms) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. this is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of lms to frequently-updated knowledge corpus such as wikipedia. to this end, we introduce temporalwiki, a lifelong benchmark for ever-evolving lms that utilizes the difference between consecutive snapshots of english wikipedia and english wikidata for training and evaluation, respectively. the benchmark hence allows researchers to periodically track an lm's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. we also find that training an lm on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less computational cost, which verifies that factual knowledge in lms can be safely updated with minimal training data via continual learning. the dataset and the code are available at https://github.com/joeljang/temporalwiki.",,2022-04-29,2023-04-12,"['joel jang', 'seonghyeon ye', 'changho lee', 'sohee yang', 'joongbo shin', 'janghoon han', 'gyeonghun kim', 'minjoon seo']",https://arxiv.org/pdf/2204.14211.pdf
93,2205.01217,insider stories: analyzing internal sustainability efforts of major us   companies from online reviews,cs.si cs.cy,"it is hard to establish whether a company supports internal sustainability efforts (ises) like gender equality, diversity, and general staff welfare, not least because of lack of methodologies operationalizing these internal sustainability practices, and of data honestly documenting such efforts. we developed and validated a six-dimension framework reflecting internal sustainability efforts (ises), gathered more than 350k employee reviews of 104 major companies across the whole us for the (2008-2020) years, and developed a deep-learning framework scoring these reviews in terms of the six ises. commitment to ises manifested itself at micro-level -- companies scoring high in ises enjoyed high stock growth. this new conceptualization of ises offers both theoretical implications for the literature in corporate sustainability, and practical implications for companies and policymakers. to further explore these implications, researchers need to add potentially missing ises, to do so for more companies, and establish the causal relationship between company success and ises.",,2022-05-02,2023-04-13,"['indira sen', 'daniele quercia', 'licia capra', 'matteo montecchi', 'sanja ≈°ƒáepanoviƒá']",https://arxiv.org/pdf/2205.01217.pdf
94,2205.02089,a new dimensionality reduction method based on hensel's compression for   privacy protection in federated learning,cs.cr cs.ai,"differential privacy (dp) is considered a de-facto standard for protecting users' privacy in data analysis, machine, and deep learning. existing dp-based privacy-preserving training approaches consist of adding noise to the clients' gradients before sharing them with the server. however, implementing dp on the gradient is not efficient as the privacy leakage increases by increasing the synchronization training epochs due to the composition theorem. recently researchers were able to recover images used in the training dataset using generative regression neural network (grnn) even when the gradient was protected by dp. in this paper, we propose two layers of privacy protection approach to overcome the limitations of the existing dp-based approaches. the first layer reduces the dimension of the training dataset based on hensel's lemma. we are the first to use hensel's lemma for reducing the dimension (i.e., compress) of a dataset. the new dimensionality reduction method allows reducing the dimension of a dataset without losing information since hensel's lemma guarantees uniqueness. the second layer applies dp to the compressed dataset generated by the first layer. the proposed approach overcomes the problem of privacy leakage due to composition by applying dp only once before the training; clients train their local model on the privacy-preserving dataset generated by the second layer. experimental results show that the proposed approach ensures strong privacy protection while achieving good accuracy. the new dimensionality reduction method achieves an accuracy of 97%, with only 25 % of the original data size.",10.1109/icnc57223.2023.10074197,2022-05-01,,"['ahmed el ouadrhiri', 'ahmed abdelhadi']",https://arxiv.org/pdf/2205.02089.pdf
95,2205.08419,human emotion classification based on eeg signals using recurrent neural   network and knn,eess.sp cs.ai cs.hc cs.lg,"in human contact, emotion is very crucial. attributes like words, voice intonation, facial expressions, and kinesics can all be used to portray one's feelings. however, brain-computer interface (bci) devices have not yet reached the level required for emotion interpretation. with the rapid development of machine learning algorithms, dry electrode techniques, and different real-world applications of the brain-computer interface for normal individuals, emotion categorization from eeg data has recently gotten a lot of attention. electroencephalogram (eeg) signals are a critical resource for these systems. the primary benefit of employing eeg signals is that they reflect true emotion and are easily resolved by computer systems. in this work, eeg signals associated with good, neutral, and negative emotions were identified using channel selection preprocessing. however, researchers had a limited grasp of the specifics of the link between various emotional states until now. to identify eeg signals, we used discrete wavelet transform and machine learning techniques such as recurrent neural network (rnn) and k-nearest neighbor (knn) algorithm. initially, the classifier methods were utilized for channel selection. as a result, final feature vectors were created by integrating the features of eeg segments from these channels. using the rnn and knn algorithms, the final feature vectors with connected positive, neutral, and negative emotions were categorized independently. the classification performance of both techniques is computed and compared. using rnn and knn, the average overall accuracies were 94.844 % and 93.438 %, respectively.",10.47164/ijngc.v14i2.691,2022-05-10,,"['shashank joshi', 'falak joshi']",https://arxiv.org/pdf/2205.08419.pdf
96,2205.10868,memory-efficient reinforcement learning with value-based knowledge   consolidation,cs.lg cs.ai,"artificial neural networks are promising for general function approximation but challenging to train on non-independent or non-identically distributed data due to catastrophic forgetting. the experience replay buffer, a standard component in deep reinforcement learning, is often used to reduce forgetting and improve sample efficiency by storing experiences in a large buffer and using them for training later. however, a large replay buffer results in a heavy memory burden, especially for onboard and edge devices with limited memory capacities. we propose memory-efficient reinforcement learning algorithms based on the deep q-network algorithm to alleviate this problem. our algorithms reduce forgetting and maintain high sample efficiency by consolidating knowledge from the target q-network to the current q-network. compared to baseline methods, our algorithms achieve comparable or better performance in both feature-based and image-based tasks while easing the burden of large experience replay buffers.",,2022-05-22,2023-04-10,"['qingfeng lan', 'yangchen pan', 'jun luo', 'a. rupam mahmood']",https://arxiv.org/pdf/2205.10868.pdf
97,2205.12718,dpsnn: a differentially private spiking neural network with temporal   enhanced pooling,cs.ne cs.ai cs.lg,"privacy protection is a crucial issue in machine learning algorithms, and the current privacy protection is combined with traditional artificial neural networks based on real values. spiking neural network (snn), the new generation of artificial neural networks, plays a crucial role in many fields. therefore, research on the privacy protection of snn is urgently needed. this paper combines the differential privacy(dp) algorithm with snn and proposes a differentially private spiking neural network (dpsnn). the snn uses discrete spike sequences to transmit information, combined with the gradient noise introduced by dp so that snn maintains strong privacy protection. at the same time, to make snn maintain high performance while obtaining high privacy protection, we propose the temporal enhanced pooling (tep) method. it fully integrates the temporal information of snn into the spatial information transfer, which enables snn to perform better information transfer. we conduct experiments on static and neuromorphic datasets, and the experimental results show that our algorithm still maintains high performance while providing strong privacy protection.",,2022-05-24,2023-04-11,"['jihang wang', 'dongcheng zhao', 'guobin shen', 'qian zhang', 'yi zeng']",https://arxiv.org/pdf/2205.12718.pdf
98,2205.13803,bongard-hoi: benchmarking few-shot visual reasoning for human-object   interactions,cs.cv cs.ai cs.lg,"a significant gap remains between today's visual pattern recognition models and human-level visual cognition especially when it comes to few-shot learning and compositional reasoning of novel concepts. we introduce bongard-hoi, a new visual reasoning benchmark that focuses on compositional learning of human-object interactions (hois) from natural images. it is inspired by two desirable characteristics from the classical bongard problems (bps): 1) few-shot concept learning, and 2) context-dependent reasoning. we carefully curate the few-shot instances with hard negatives, where positive and negative images only disagree on action labels, making mere recognition of object categories insufficient to complete our benchmarks. we also design multiple test sets to systematically study the generalization of visual learning models, where we vary the overlap of the hoi concepts between the training and test sets of few-shot instances, from partial to no overlaps. bongard-hoi presents a substantial challenge to today's visual recognition models. the state-of-the-art hoi detection model achieves only 62% accuracy on few-shot binary prediction while even amateur human testers on mturk have 91% accuracy. with the bongard-hoi benchmark, we hope to further advance research efforts in visual reasoning, especially in holistic perception-reasoning systems and better representation learning.",,2022-05-27,2023-04-13,"['huaizu jiang', 'xiaojian ma', 'weili nie', 'zhiding yu', 'yuke zhu', 'song-chun zhu', 'anima anandkumar']",https://arxiv.org/pdf/2205.13803.pdf
99,2205.15469,gconet+: a stronger group collaborative co-salient object detector,cs.cv,"in this paper, we present a novel end-to-end group collaborative learning network, termed gconet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. the proposed gconet+ achieves the new state-of-the-art performance for co-salient object detection (cosod) through mining consensus representations based on the following two essential criteria: 1) intra-group compactness to better formulate the consistency among co-salient objects by capturing their inherent shared attributes using our novel group affinity module (gam); 2) inter-group separability to effectively suppress the influence of noisy objects on the output by introducing our new group collaborating module (gcm) conditioning on the inconsistent consensus. to further improve the accuracy, we design a series of simple yet effective components as follows: i) a recurrent auxiliary classification module (racm) promoting model learning at the semantic level; ii) a confidence enhancement module (cem) assisting the model in improving the quality of the final predictions; and iii) a group-based symmetric triplet (gst) loss guiding the model to learn more discriminative features. extensive experiments on three challenging benchmarks, i.e., coca, cosod3k, and cosal2015, demonstrate that our gconet+ outperforms the existing 12 cutting-edge models. code has been released at https://github.com/zhengpeng7/gconet_plus.",10.1109/tpami.2023.3264571,2022-05-30,2023-04-10,"['peng zheng', 'huazhu fu', 'deng-ping fan', 'qi fan', 'jie qin', 'yu-wing tai', 'chi-keung tang', 'luc van gool']",https://arxiv.org/pdf/2205.15469.pdf
100,2205.15750,variable importance without impossible data,cs.lg cs.ai econ.em stat.ml,"the most popular methods for measuring importance of the variables in a black box prediction algorithm make use of synthetic inputs that combine predictor variables from multiple subjects. these inputs can be unlikely, physically impossible, or even logically impossible. as a result, the predictions for such cases can be based on data very unlike any the black box was trained on. we think that users cannot trust an explanation of the decision of a prediction algorithm when the explanation uses such values. instead we advocate a method called cohort shapley that is grounded in economic game theory and unlike most other game theoretic methods, it uses only actually observed data to quantify variable importance. cohort shapley works by narrowing the cohort of subjects judged to be similar to a target subject on one or more features. we illustrate it on an algorithmic fairness problem where it is essential to attribute importance to protected variables that the model was not trained on.",,2022-05-31,2023-04-12,"['masayoshi mase', 'art b. owen', 'benjamin b. seiler']",https://arxiv.org/pdf/2205.15750.pdf
101,2206.00137,social bias meets data bias: the impacts of labeling and measurement   errors on fairness criteria,cs.lg cs.cy,"although many fairness criteria have been proposed to ensure that machine learning algorithms do not exhibit or amplify our existing social biases, these algorithms are trained on datasets that can themselves be statistically biased. in this paper, we investigate the robustness of a number of existing (demographic) fairness criteria when the algorithm is trained on biased data. we consider two forms of dataset bias: errors by prior decision makers in the labeling process, and errors in measurement of the features of disadvantaged individuals. we analytically show that some constraints (such as demographic parity) can remain robust when facing certain statistical biases, while others (such as equalized odds) are significantly violated if trained on biased data. we also analyze the sensitivity of these criteria and the decision maker's utility to biases. we provide numerical experiments based on three real-world datasets (the fico, adult, and german credit score datasets) supporting our analytical findings. our findings present an additional guideline for choosing among existing fairness criteria, or for proposing new criteria, when available datasets may be biased.",,2022-05-31,2023-04-09,"['yiqiao liao', 'parinaz naghizadeh']",https://arxiv.org/pdf/2206.00137.pdf
102,2206.01209,accelerated first-order methods for convex optimization with locally   lipschitz continuous gradient,math.oc cs.lg cs.na math.na stat.ml,"in this paper we develop accelerated first-order methods for convex optimization with locally lipschitz continuous gradient (llcg), which is beyond the well-studied class of convex optimization with lipschitz continuous gradient. in particular, we first consider unconstrained convex optimization with llcg and propose accelerated proximal gradient (apg) methods for solving it. the proposed apg methods are equipped with a verifiable termination criterion and enjoy an operation complexity of ${\cal o}(\varepsilon^{-1/2}\log \varepsilon^{-1})$ and ${\cal o}(\log \varepsilon^{-1})$ for finding an $\varepsilon$-residual solution of an unconstrained convex and strongly convex optimization problem, respectively. we then consider constrained convex optimization with llcg and propose an first-order proximal augmented lagrangian method for solving it by applying one of our proposed apg methods to approximately solve a sequence of proximal augmented lagrangian subproblems. the resulting method is equipped with a verifiable termination criterion and enjoys an operation complexity of ${\cal o}(\varepsilon^{-1}\log \varepsilon^{-1})$ and ${\cal o}(\varepsilon^{-1/2}\log \varepsilon^{-1})$ for finding an $\varepsilon$-kkt solution of a constrained convex and strongly convex optimization problem, respectively. all the proposed methods in this paper are parameter-free or almost parameter-free except that the knowledge on convexity parameter is required. in addition, preliminary numerical results are presented to demonstrate the performance of our proposed methods. to the best of our knowledge, no prior studies were conducted to investigate accelerated first-order methods with complexity guarantees for convex optimization with llcg. all the complexity results obtained in this paper are new.",,2022-06-02,2023-04-10,"['zhaosong lu', 'sanyou mei']",https://arxiv.org/pdf/2206.01209.pdf
103,2206.01856,poisson2sparse: self-supervised poisson denoising from a single image,eess.iv cs.cv,"image enhancement approaches often assume that the noise is signal independent, and approximate the degradation model as zero-mean additive gaussian. however, this assumption does not hold for biomedical imaging systems where sensor-based sources of noise are proportional to signal strengths, and the noise is better represented as a poisson process. in this work, we explore a sparsity and dictionary learning-based approach and present a novel self-supervised learning method for single-image denoising where the noise is approximated as a poisson process, requiring no clean ground-truth data. specifically, we approximate traditional iterative optimization algorithms for image denoising with a recurrent neural network that enforces sparsity with respect to the weights of the network. since the sparse representations are based on the underlying image, it is able to suppress the spurious components (noise) in the image patches, thereby introducing implicit regularization for denoising tasks through the network structure. experiments on two bio-imaging datasets demonstrate that our method outperforms the state-of-the-art approaches in terms of psnr and ssim. our qualitative results demonstrate that, in addition to higher performance on standard quantitative metrics, we are able to recover much more subtle details than other compared approaches. our code is made publicly available at https://github.com/tacalvin/poisson2sparse",10.1007/978-3-031-16452-1_53,2022-06-03,2022-06-27,"['calvin-khang ta', 'abhishek aich', 'akash gupta', 'amit k. roy-chowdhury']",https://arxiv.org/pdf/2206.01856.pdf
104,2206.02386,restructuring graph for higher homophily via adaptive spectral   clustering,cs.lg cs.si,"while a growing body of literature has been studying new graph neural networks (gnns) that work on both homophilic and heterophilic graphs, little has been done on adapting classical gnns to less-homophilic graphs. although the ability to handle less-homophilic graphs is restricted, classical gnns still stand out in several nice properties such as efficiency, simplicity, and explainability. in this work, we propose a novel graph restructuring method that can be integrated into any type of gnns, including classical gnns, to leverage the benefits of existing gnns while alleviating their limitations. our contribution is threefold: a) learning the weight of pseudo-eigenvectors for an adaptive spectral clustering that aligns well with known node labels, b) proposing a new density-aware homophilic metric that is robust to label imbalance, and c) reconstructing the adjacency matrix based on the result of adaptive spectral clustering to maximize the homophilic scores. the experimental results show that our graph restructuring method can significantly boost the performance of six classical gnns by an average of 25% on less-homophilic graphs. the boosted performance is comparable to state-of-the-art methods.",,2022-06-06,2023-04-09,"['shouheng li', 'dongwoo kim', 'qing wang']",https://arxiv.org/pdf/2206.02386.pdf
105,2206.04041,neural collapse: a review on modelling principles and generalization,cs.lg,"deep classifier neural networks enter the terminal phase of training (tpt) when training error reaches zero and tend to exhibit intriguing neural collapse (nc) properties. neural collapse essentially represents a state at which the within-class variability of final hidden layer outputs is infinitesimally small and their class means form a simplex equiangular tight frame. this simplifies the last layer behaviour to that of a nearest-class center decision rule. despite the simplicity of this state, the dynamics and implications of reaching it are yet to be fully understood. in this work, we review the principles which aid in modelling neural collapse, followed by the implications of this state on generalization and transfer learning capabilities of neural networks. finally, we conclude by discussing potential avenues and directions for future research.",,2022-06-08,2023-04-11,['vignesh kothapalli'],https://arxiv.org/pdf/2206.04041.pdf
106,2206.04734,fast bayesian inference with batch bayesian quadrature via kernel   recombination,cs.lg cs.na math.na stat.co stat.ml,"calculation of bayesian posteriors and model evidences typically requires numerical integration. bayesian quadrature (bq), a surrogate-model-based approach to numerical integration, is capable of superb sample efficiency, but its lack of parallelisation has hindered its practical applications. in this work, we propose a parallelised (batch) bq method, employing techniques from kernel quadrature, that possesses an empirically exponential convergence rate. additionally, just as with nested sampling, our method permits simultaneous inference of both posteriors and model evidence. samples from our bq surrogate model are re-selected to give a sparse set of samples, via a kernel recombination algorithm, requiring negligible additional time to increase the batch size. empirically, we find that our approach significantly outperforms the sampling efficiency of both state-of-the-art bq techniques and nested sampling in various real-world datasets, including lithium-ion battery analytics.",,2022-06-09,2023-01-27,"['masaki adachi', 'satoshi hayakawa', 'martin j√∏rgensen', 'harald oberhauser', 'michael a. osborne']",https://arxiv.org/pdf/2206.04734.pdf
107,2206.05576,optimal solutions for joint beamforming and antenna selection: from   branch and bound to graph neural imitation learning,eess.sp cs.it cs.lg math.it,"this work revisits the joint beamforming (bf) and antenna selection (as) problem, as well as its robust beamforming (rbf) version under imperfect channel state information (csi). such problems arise due to various reasons, e.g., the costly nature of the radio frequency (rf) chains and energy/resource-saving considerations. the joint (r)bf\&as problem is a mixed integer and nonlinear program, and thus finding {\it optimal solutions} is often costly, if not outright impossible. the vast majority of the prior works tackled these problems using techniques such as continuous approximations, greedy methods, and supervised machine learning -- yet these approaches do not ensure optimality or even feasibility of the solutions. the main contribution of this work is threefold. first, an effective {\it branch and bound} (b\&b) framework for solving the problems of interest is proposed. leveraging existing bf and rbf solvers, it is shown that the b\&b framework guarantees global optimality of the considered problems. second, to expedite the potentially costly b\&b algorithm, a machine learning (ml)-based scheme is proposed to help skip intermediate states of the b\&b search tree. the learning model features a {\it graph neural network} (gnn)-based design that is resilient to a commonly encountered challenge in wireless communications, namely, the change of problem size (e.g., the number of users) across the training and test stages. third, comprehensive performance characterizations are presented, showing that the gnn-based method retains the global optimality of b\&b with provably reduced complexity, under reasonable conditions. numerical simulations also show that the ml-based acceleration can often achieve an order-of-magnitude speedup relative to b\&b.",10.1109/tsp.2023.3244096,2022-06-11,2023-01-30,"['sagar shrestha', 'xiao fu', 'mingyi hong']",https://arxiv.org/pdf/2206.05576.pdf
108,2206.05825,"a unified approach to reinforcement learning, quantal response   equilibria, and two-player zero-sum games",cs.lg cs.ai cs.gt,"this work studies an algorithm, which we call magnetic mirror descent, that is inspired by mirror descent and the non-euclidean proximal gradient algorithm. our contribution is demonstrating the virtues of magnetic mirror descent as both an equilibrium solver and as an approach to reinforcement learning in two-player zero-sum games. these virtues include: 1) being the first quantal response equilibria solver to achieve linear convergence for extensive-form games with first order feedback; 2) being the first standard reinforcement learning algorithm to achieve empirically competitive results with cfr in tabular settings; 3) achieving favorable performance in 3x3 dark hex and phantom tic-tac-toe as a self-play deep reinforcement learning algorithm.",,2022-06-12,2023-04-11,"['samuel sokota', ""ryan d'orazio"", 'j. zico kolter', 'nicolas loizou', 'marc lanctot', 'ioannis mitliagkas', 'noam brown', 'christian kroer']",https://arxiv.org/pdf/2206.05825.pdf
109,2206.06650,semi-private computation of data similarity with applications to data   valuation and pricing,cs.it cs.cr math.it,"consider two data providers that want to contribute data to a certain learning model. recent works have shown that the value of the data of one of the providers is dependent on the similarity with the data owned by the other provider. it would thus be beneficial if the two providers can calculate the similarity of their data, while keeping the actual data private. in this work, we devise multiparty computation-protocols to compute similarity of two data sets based on correlation, while offering controllable privacy guarantees. we consider a simple model with two participating providers and develop methods to compute exact and approximate correlation, respectively, with controlled information leakage. both protocols have computational and communication complexities that are linear in the number of data samples. we also provide general bounds on the maximal error in the approximation case, and analyse the resulting errors for practical parameter choices.",10.1109/tifs.2023.3259879,2022-06-14,2023-04-11,"['ren√© b√∏dker christensen', 'shashi raj pandey', 'petar popovski']",https://arxiv.org/pdf/2206.06650.pdf
110,2206.06826,tailored max-out networks for learning convex pwq functions,eess.sy cs.lg cs.sy,"convex piecewise quadratic (pwq) functions frequently appear in control and elsewhere. for instance, it is well-known that the optimal value function (ovf) as well as q-functions for linear mpc are convex pwq functions. now, in learning-based control, these functions are often represented with the help of artificial neural networks (nn). in this context, a recurring question is how to choose the topology of the nn in terms of depth, width, and activations in order to enable efficient learning. an elegant answer to that question could be a topology that, in principle, allows to exactly describe the function to be learned. such solutions are already available for related problems. in fact, suitable topologies are known for piecewise affine (pwa) functions that can, for example, reflect the optimal control law in linear mpc. following this direction, we show in this paper that convex pwq functions can be exactly described by max-out-nn with only one hidden layer and two neurons.",10.23919/ecc55457.2022.9838225,2022-06-14,,"['dieter teichrib', 'moritz schulze darup']",https://arxiv.org/pdf/2206.06826.pdf
111,2206.07090,parallelization of machine learning algorithms respectively on single   machine and spark,cs.dc,"with the rapid development of big data technologies, how to dig out useful information from massive data becomes an essential problem. however, using machine learning algorithms to analyze large data may be time-consuming and inefficient on the traditional single machine. to solve these problems, this paper has made some research on the parallelization of several classic machine learning algorithms respectively on the single machine and the big data platform spark. we compare the runtime and efficiency of traditional machine learning algorithms with parallelized machine learning algorithms respectively on the single machine and spark platform. the research results have shown significant improvement in runtime and efficiency of parallelized machine learning algorithms.",,2022-05-07,2023-04-12,['jiajun shen'],https://arxiv.org/pdf/2206.07090.pdf
112,2206.09414,terrain classification using transfer learning on hyperspectral images:   a comparative study,cs.cv cs.ai cs.lg,"a hyperspectral image contains much more number of channels as compared to a rgb image, hence containing more information about entities within the image. the convolutional neural network (cnn) and the multi-layer perceptron (mlp) have been proven to be an effective method of image classification. however, they suffer from the issues of long training time and requirement of large amounts of the labeled data, to achieve the expected outcome. these issues become more complex while dealing with hyperspectral images. to decrease the training time and reduce the dependence on large labeled dataset, we propose using the method of transfer learning. the hyperspectral dataset is preprocessed to a lower dimension using pca, then deep learning models are applied to it for the purpose of classification. the features learned by this model are then used by the transfer learning model to solve a new classification problem on an unseen dataset. a detailed comparison of cnn and multiple mlp architectural models is performed, to determine an optimum architecture that suits best the objective. the results show that the scaling of layers not always leads to increase in accuracy but often leads to overfitting, and also an increase in the training time.the training time is reduced to greater extent by applying the transfer learning approach rather than just approaching the problem by directly training a new model on large datasets, without much affecting the accuracy.",10.1109/indicon56171.2022.10040049,2022-06-19,,"['uphar singh', 'kumar saurabh', 'neelaksh trehan', 'ranjana vyas', 'o. p. vyas']",https://arxiv.org/pdf/2206.09414.pdf
113,2206.12036,sc-ques: a sentence completion question dataset for english as a second   language learners,cs.cl cs.ai,"sentence completion (sc) questions present a sentence with one or more blanks that need to be filled in, three to five possible words or phrases as options. sc questions are widely used for students learning english as a second language (esl). in this paper, we present a large-scale sc dataset, \textsc{sc-ques}, which is made up of 289,148 esl sc questions from real-world standardized english examinations. furthermore, we build a comprehensive benchmark of automatically solving the sc questions by training the large-scale pre-trained language models on the proposed \textsc{sc-ques} dataset. we conduct detailed analysis of the baseline models performance, limitations and trade-offs. the data and our code are available for research purposes from: \url{https://github.com/ai4ed/sc-ques}.",,2022-06-23,2023-04-07,"['qiongqiong liu', 'yaying huang', 'zitao liu', 'shuyan huang', 'jiahao chen', 'xiangyu zhao', 'guimin lin', 'yuyu zhou', 'weiqi luo']",https://arxiv.org/pdf/2206.12036.pdf
114,2206.12126,temporal attention unit: towards efficient spatiotemporal predictive   learning,cs.cv cs.ai,"spatiotemporal predictive learning aims to generate future frames by learning from historical frames. in this paper, we investigate existing methods and present a general framework of spatiotemporal predictive learning, in which the spatial encoder and decoder capture intra-frame features and the middle temporal module catches inter-frame correlations. while the mainstream methods employ recurrent units to capture long-term temporal dependencies, they suffer from low computational efficiency due to their unparallelizable architectures. to parallelize the temporal module, we propose the temporal attention unit (tau), which decomposes the temporal attention into intra-frame statical attention and inter-frame dynamical attention. moreover, while the mean squared error loss focuses on intra-frame errors, we introduce a novel differential divergence regularization to take inter-frame variations into account. extensive experiments demonstrate that the proposed method enables the derived model to achieve competitive performance on various spatiotemporal prediction benchmarks.",,2022-06-24,2023-04-12,"['cheng tan', 'zhangyang gao', 'lirong wu', 'yongjie xu', 'jun xia', 'siyuan li', 'stan z. li']",https://arxiv.org/pdf/2206.12126.pdf
115,2206.13397,generative modelling with inverse heat dissipation,cs.cv cs.lg stat.ml,"while diffusion models have shown great success in image generation, their noise-inverting generative process does not explicitly consider the structure of images, such as their inherent multi-scale nature. inspired by diffusion models and the empirical success of coarse-to-fine modelling, we propose a new diffusion-like model that generates images through stochastically reversing the heat equation, a pde that locally erases fine-scale information when run over the 2d plane of the image. we interpret the solution of the forward heat equation with constant additive noise as a variational approximation in the diffusion latent variable model. our new model shows emergent qualitative properties not seen in standard diffusion models, such as disentanglement of overall colour and shape in images. spectral analysis on natural images highlights connections to diffusion models and reveals an implicit coarse-to-fine inductive bias in them.",,2022-06-21,2023-04-12,"['severi rissanen', 'markus heinonen', 'arno solin']",https://arxiv.org/pdf/2206.13397.pdf
116,2206.14579,competence-based multimodal curriculum learning for medical report   generation,cs.cl cs.cv cs.lg,"medical report generation task, which targets to produce long and coherent descriptions of medical images, has attracted growing research interests recently. different from the general image captioning tasks, medical report generation is more challenging for data-driven neural models. this is mainly due to 1) the serious data bias and 2) the limited medical data. to alleviate the data bias and make best use of available data, we propose a competence-based multimodal curriculum learning framework (cmcl). specifically, cmcl simulates the learning process of radiologists and optimizes the model in a step by step manner. firstly, cmcl estimates the difficulty of each training instance and evaluates the competence of current model; secondly, cmcl selects the most suitable batch of training instances considering current model competence. by iterating above two steps, cmcl can gradually improve the model's performance. the experiments on the public iu-xray and mimic-cxr datasets show that cmcl can be incorporated into existing models to improve their performance.",,2022-06-24,2023-04-11,"['fenglin liu', 'shen ge', 'yuexian zou', 'xian wu']",https://arxiv.org/pdf/2206.14579.pdf
117,2206.15477,denoised mdps: learning world models better than the world itself,cs.lg,"the ability to separate signal from noise, and reason with clean abstractions, is critical to intelligence. with this ability, humans can efficiently perform real world tasks without considering all possible nuisance factors.how can artificial agents do the same? what kind of information can agents safely discard as noises?   in this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. this framework clarifies the kinds information removed by various prior work on representation learning in reinforcement learning (rl), and leads to our proposed approach of learning a denoised mdp that explicitly factors out certain noise distractors. extensive experiments on variants of deepmind control suite and robodesk demonstrate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy optimization control tasks as well as the non-control task of joint position regression.",,2022-06-30,2023-04-06,"['tongzhou wang', 'simon s. du', 'antonio torralba', 'phillip isola', 'amy zhang', 'yuandong tian']",https://arxiv.org/pdf/2206.15477.pdf
118,2207.00026,lasermix for semi-supervised lidar semantic segmentation,cs.cv cs.lg cs.ro,"densely annotating lidar point clouds is costly, which restrains the scalability of fully-supervised learning methods. in this work, we study the underexplored semi-supervised learning (ssl) in lidar segmentation. our core idea is to leverage the strong spatial cues of lidar point clouds to better exploit unlabeled data. we propose lasermix to mix laser beams from different lidar scans, and then encourage the model to make consistent and confident predictions before and after mixing. our framework has three appealing properties: 1) generic: lasermix is agnostic to lidar representations (e.g., range view and voxel), and hence our ssl framework can be universally applied. 2) statistically grounded: we provide a detailed analysis to theoretically explain the applicability of the proposed framework. 3) effective: comprehensive experimental analysis on popular lidar segmentation datasets (nuscenes, semantickitti, and scribblekitti) demonstrates our effectiveness and superiority. notably, we achieve competitive results over fully-supervised counterparts with 2x to 5x fewer labels and improve the supervised-only baseline significantly by 10.8% on average. we hope this concise yet high-performing framework could facilitate future research in semi-supervised lidar segmentation. code is publicly available.",,2022-06-30,2023-04-13,"['lingdong kong', 'jiawei ren', 'liang pan', 'ziwei liu']",https://arxiv.org/pdf/2207.00026.pdf
119,2207.01463,explicit boundary guided semi-push-pull contrastive learning for   supervised anomaly detection,cs.cv,"most anomaly detection (ad) models are learned using only normal samples in an unsupervised way, which may result in ambiguous decision boundary and insufficient discriminability. in fact, a few anomaly samples are often available in real-world applications, the valuable knowledge of known anomalies should also be effectively exploited. however, utilizing a few known anomalies during training may cause another issue that the model may be biased by those known anomalies and fail to generalize to unseen anomalies. in this paper, we tackle supervised anomaly detection, i.e., we learn ad models using a few available anomalies with the objective to detect both the seen and unseen anomalies. we propose a novel explicit boundary guided semi-push-pull contrastive learning mechanism, which can enhance model's discriminability while mitigating the bias issue. our approach is based on two core designs: first, we find an explicit and compact separating boundary as the guidance for further feature learning. as the boundary only relies on the normal feature distribution, the bias problem caused by a few known anomalies can be alleviated. second, a boundary guided semi-push-pull loss is developed to only pull the normal features together while pushing the abnormal features apart from the separating boundary beyond a certain margin region. in this way, our model can form a more explicit and discriminative decision boundary to distinguish known and also unseen anomalies from normal samples more effectively. code will be available at https://github.com/xcyao00/bgad.",,2022-07-04,2023-04-07,"['xincheng yao', 'ruoqi li', 'jing zhang', 'jun sun', 'chongyang zhang']",https://arxiv.org/pdf/2207.01463.pdf
120,2207.01560,high-dimensional private empirical risk minimization by greedy   coordinate descent,cs.lg cs.cr stat.ml,"in this paper, we study differentially private empirical risk minimization (dp-erm). it has been shown that the worst-case utility of dp-erm reduces polynomially as the dimension increases. this is a major obstacle to privately learning large machine learning models. in high dimension, it is common for some model's parameters to carry more information than others. to exploit this, we propose a differentially private greedy coordinate descent (dp-gcd) algorithm. at each iteration, dp-gcd privately performs a coordinate-wise gradient step along the gradients' (approximately) greatest entry. we show theoretically that dp-gcd can achieve a logarithmic dependence on the dimension for a wide range of problems by naturally exploiting their structural properties (such as quasi-sparse solutions). we illustrate this behavior numerically, both on synthetic and real datasets.",,2022-07-04,2023-04-09,"['paul mangold', 'aur√©lien bellet', 'joseph salmon', 'marc tommasi']",https://arxiv.org/pdf/2207.01560.pdf
121,2207.03128,pointmcd: boosting deep point cloud encoders via multi-view cross-modal   distillation for 3d shape recognition,cs.cv,"as two fundamental representation modalities of 3d objects, 3d point clouds and multi-view 2d images record shape information from different domains of geometric structures and visual appearances. in the current deep learning era, remarkable progress in processing such two data modalities has been achieved through respectively customizing compatible 3d and 2d network architectures. however, unlike multi-view image-based 2d visual modeling paradigms, which have shown leading performance in several common 3d shape recognition benchmarks, point cloud-based 3d geometric modeling paradigms are still highly limited by insufficient learning capacity, due to the difficulty of extracting discriminative features from irregular geometric signals. in this paper, we explore the possibility of boosting deep 3d point cloud encoders by transferring visual knowledge extracted from deep 2d image encoders under a standard teacher-student distillation workflow. generally, we propose pointmcd, a unified multi-view cross-modal distillation architecture, including a pretrained deep image encoder as the teacher and a deep point encoder as the student. to perform heterogeneous feature alignment between 2d visual and 3d geometric domains, we further investigate visibility-aware feature projection (vafp), by which point-wise embeddings are reasonably aggregated into view-specific geometric descriptors. by pair-wisely aligning multi-view visual and geometric descriptors, we can obtain more powerful deep point encoders without exhausting and complicated network modification. experiments on 3d shape classification, part segmentation, and unsupervised learning strongly validate the effectiveness of our method. the code and data will be publicly available at https://github.com/keeganhk/pointmcd.",,2022-07-07,2023-04-13,"['qijian zhang', 'junhui hou', 'yue qian']",https://arxiv.org/pdf/2207.03128.pdf
122,2207.03162,harnessing out-of-distribution examples via augmenting content and style,cs.lg,"machine learning models are vulnerable to out-of-distribution (ood) examples, and such a problem has drawn much attention. however, current methods lack a full understanding of different types of ood data: there are benign ood data that can be properly adapted to enhance the learning performance, while other malign ood data would severely degenerate the classification result. to harness ood data, this paper proposes a hood method that can leverage the content and style from each image instance to identify benign and malign ood data. particularly, we design a variational inference framework to causally disentangle content and style features by constructing a structural causal model. subsequently, we augment the content and style through an intervention process to produce malign and benign ood data, respectively. the benign ood data contain novel styles but hold our interested contents, and they can be leveraged to help train a style-invariant model. in contrast, the malign ood data inherit unknown contents but carry familiar styles, by detecting them can improve model robustness against deceiving anomalies. thanks to the proposed novel disentanglement and data augmentation techniques, hood can effectively deal with ood examples in unknown and open environments, whose effectiveness is empirically validated in three typical ood applications including ood detection, open-set semi-supervised learning, and open-set domain adaptation.",,2022-07-07,2023-04-07,"['zhuo huang', 'xiaobo xia', 'li shen', 'bo han', 'mingming gong', 'chen gong', 'tongliang liu']",https://arxiv.org/pdf/2207.03162.pdf
123,2207.03368,machine learning of percolation models using graph convolutional neural   networks,cond-mat.stat-mech cond-mat.dis-nn cs.lg,"percolation is an important topic in climate, physics, materials science, epidemiology, finance, and so on. prediction of percolation thresholds with machine learning methods remains challenging. in this paper, we build a powerful graph convolutional neural network to study the percolation in both supervised and unsupervised ways. from a supervised learning perspective, the graph convolutional neural network simultaneously and correctly trains data of different lattice types, such as the square and triangular lattices. for the unsupervised perspective, combining the graph convolutional neural network and the confusion method, the percolation threshold can be obtained by the ""w"" shaped performance. the finding of this work opens up the possibility of building a more general framework that can probe the percolation-related phenomenon.",,2022-07-07,2023-04-07,"['hua tian', 'lirong zhang', 'youjin deng', 'wanzhou zhang']",https://arxiv.org/pdf/2207.03368.pdf
124,2207.04994,uncertainty-aware mixed-variable machine learning for materials design,stat.ml cond-mat.mtrl-sci cs.lg,"data-driven design shows the promise of accelerating materials discovery but is challenging due to the prohibitive cost of searching the vast design space of chemistry, structure, and synthesis methods. bayesian optimization (bo) employs uncertainty-aware machine learning models to select promising designs to evaluate, hence reducing the cost. however, bo with mixed numerical and categorical variables, which is of particular interest in materials design, has not been well studied. in this work, we survey frequentist and bayesian approaches to uncertainty quantification of machine learning with mixed variables. we then conduct a systematic comparative study of their performances in bo using a popular representative model from each group, the random forest-based lolo model (frequentist) and the latent variable gaussian process model (bayesian). we examine the efficacy of the two models in the optimization of mathematical functions, as well as properties of structural and functional materials, where we observe performance differences as related to problem dimensionality and complexity. by investigating the machine learning models' predictive and uncertainty estimation capabilities, we provide interpretations of the observed performance differences. our results provide practical guidance on choosing between frequentist and bayesian uncertainty-aware machine learning models for mixed-variable bo in materials design.",10.1038/s41598-022-23431-2,2022-07-11,2022-10-04,"['hengrui zhang', 'wei wayne chen', 'akshay iyer', 'daniel w. apley', 'wei chen']",https://arxiv.org/pdf/2207.04994.pdf
125,2207.05952,implicit regularization of dropout,cs.lg,"it is important to understand how dropout, a popular regularization method, aids in achieving a good generalization solution during neural network training. in this work, we present a theoretical derivation of an implicit regularization of dropout, which is validated by a series of experiments. additionally, we numerically study two implications of the implicit regularization, which intuitively rationalizes why dropout helps generalization. firstly, we find that input weights of hidden neurons tend to condense on isolated orientations trained with dropout. condensation is a feature in the non-linear learning process, which makes the network less complex. secondly, we experimentally find that the training with dropout leads to the neural network with a flatter minimum compared with standard gradient descent training, and the implicit regularization is the key to finding flat solutions. although our theory mainly focuses on dropout used in the last hidden layer, our experiments apply to general dropout in training neural networks. this work points out a distinct characteristic of dropout compared with stochastic gradient descent and serves as an important basis for fully understanding dropout.",,2022-07-13,2023-04-10,"['zhongwang zhang', 'zhi-qin john xu']",https://arxiv.org/pdf/2207.05952.pdf
126,2207.08768,rank-based decomposable losses in machine learning: a survey,cs.lg,"recent works have revealed an essential paradigm in designing loss functions that differentiate individual losses vs. aggregate losses. the individual loss measures the quality of the model on a sample, while the aggregate loss combines individual losses/scores over each training sample. both have a common procedure that aggregates a set of individual values to a single numerical value. the ranking order reflects the most fundamental relation among individual values in designing losses. in addition, decomposability, in which a loss can be decomposed into an ensemble of individual terms, becomes a significant property of organizing losses/scores. this survey provides a systematic and comprehensive review of rank-based decomposable losses in machine learning. specifically, we provide a new taxonomy of loss functions that follows the perspectives of aggregate loss and individual loss. we identify the aggregator to form such losses, which are examples of set functions. we organize the rank-based decomposable losses into eight categories. following these categories, we review the literature on rank-based aggregate losses and rank-based individual losses. we describe general formulas for these losses and connect them with existing research topics. we also suggest future research directions spanning unexplored, remaining, and emerging issues in rank-based decomposable losses.",,2022-07-18,2023-04-12,"['shu hu', 'xin wang', 'siwei lyu']",https://arxiv.org/pdf/2207.08768.pdf
127,2207.10786,delayed feedback in generalised linear bandits revisited,cs.lg stat.ml,"the stochastic generalised linear bandit is a well-understood model for sequential decision-making problems, with many algorithms achieving near-optimal regret guarantees under immediate feedback. however, the stringent requirement for immediate rewards is unmet in many real-world applications where the reward is almost always delayed. we study the phenomenon of delayed rewards in generalised linear bandits in a theoretical manner. we show that a natural adaptation of an optimistic algorithm to the delayed feedback achieves a regret bound where the penalty for the delays is independent of the horizon. this result significantly improves upon existing work, where the best known regret bound has the delay penalty increasing with the horizon. we verify our theoretical results through experiments on simulated data.",,2022-07-21,2023-04-11,"['benjamin howson', 'ciara pike-burke', 'sarah filippi']",https://arxiv.org/pdf/2207.10786.pdf
128,2207.13394,becaptcha-type: biometric keystroke data generation for improved bot   detection,cs.lg cs.cv,"this work proposes a data driven learning model for the synthesis of keystroke biometric data. the proposed method is compared with two statistical approaches based on universal and user-dependent models. these approaches are validated on the bot detection task, using the keystroke synthetic data to improve the training process of keystroke-based bot detection systems. our experimental framework considers a dataset with 136 million keystroke events from 168 thousand subjects. we have analyzed the performance of the three synthesis approaches through qualitative and quantitative experiments. different bot detectors are considered based on several supervised classifiers (support vector machine, random forest, gaussian naive bayes and a long short-term memory network) and a learning framework including human and synthetic samples. the experiments demonstrate the realism of the synthetic samples. the classification results suggest that in scenarios with large labeled data, these synthetic samples can be detected with high accuracy. however, in few-shot learning scenarios it represents an important challenge. furthermore, these results show the great potential of the presented models.",,2022-07-27,2023-04-11,"['daniel dealcala', 'aythami morales', 'ruben tolosana', 'alejandro acien', 'julian fierrez', 'santiago hernandez', 'miguel a. ferrer', 'moises diaz']",https://arxiv.org/pdf/2207.13394.pdf
129,2207.14561,cyclic policy distillation: sample-efficient sim-to-real reinforcement   learning with domain randomization,cs.ro cs.lg,"deep reinforcement learning with domain randomization learns a control policy in various simulations with randomized physical and sensor model parameters to become transferable to the real world in a zero-shot setting. however, a huge number of samples are often required to learn an effective policy when the range of randomized parameters is extensive due to the instability of policy updates. to alleviate this problem, we propose a sample-efficient method named cyclic policy distillation (cpd). cpd divides the range of randomized parameters into several small sub-domains and assigns a local policy to each one. then local policies are learned while cyclically transitioning to sub-domains. cpd accelerates learning through knowledge transfer based on expected performance improvements. finally, all of the learned local policies are distilled into a global policy for sim-to-real transfers. cpd's effectiveness and sample efficiency are demonstrated through simulations with four tasks (pendulum from openaigym and pusher, swimmer, and halfcheetah from mujoco), and a real-robot, ball-dispersal task. we published code and videos from our experiments at https://github.com/yuki-kadokawa/cyclic-policy-distillation.",,2022-07-29,2023-04-10,"['yuki kadokawa', 'lingwei zhu', 'yoshihisa tsurumine', 'takamitsu matsubara']",https://arxiv.org/pdf/2207.14561.pdf
130,2208.03025,efficient and exact multimarginal optimal transport with pairwise costs,math.oc cs.na math.na,"in this paper, we address the numerical solution to the multimarginal optimal transport (mmot) with pairwise costs. mmot, as a natural extension from the classical two-marginal optimal transport, has many important applications including image processing, density functional theory and machine learning, but yet lacks efficient and exact numerical methods. the popular entropy-regularized method may suffer numerical instability and blurring issues. inspired by the back-and-forth method introduced by jacobs and l\'{e}ger, we investigate mmot problems with pairwise costs. first, such problems have a graphical representation and we prove equivalent mmot problems that have a tree representation. second, we introduce a noval algorithm to solve mmot on a rooted tree, by gradient based method on the dual formulation. last, we obtain accurate solutions which can be used for the regularization-free applications.",,2022-08-05,2023-04-08,"['bohan zhou', 'matthew parno']",https://arxiv.org/pdf/2208.03025.pdf
131,2208.03218,radtex: learning efficient radiograph representations from text reports,cs.cv,"automated analysis of chest radiography using deep learning has tremendous potential to enhance the clinical diagnosis of diseases in patients. however, deep learning models typically require large amounts of annotated data to achieve high performance -- often an obstacle to medical domain adaptation. in this paper, we build a data-efficient learning framework that utilizes radiology reports to improve medical image classification performance with limited labeled data (fewer than 1000 examples). specifically, we examine image-captioning pretraining to learn high-quality medical image representations that train on fewer examples. following joint pretraining of a convolutional encoder and transformer decoder, we transfer the learned encoder to various classification tasks. averaged over 9 pathologies, we find that our model achieves higher classification performance than imagenet-supervised and in-domain supervised pretraining when labeled training data is limited.",10.1007/978-3-031-16876-5_3,2022-08-05,2023-04-07,"['keegan quigley', 'miriam cha', 'ruizhi liao', 'geeticka chauhan', 'steven horng', 'seth berkowitz', 'polina golland']",https://arxiv.org/pdf/2208.03218.pdf
132,2208.05100,kl-divergence based deep learning for discrete time model,stat.ml cs.lg,"neural network (deep learning) is a modern model in artificial intelligence and it has been exploited in survival analysis. although several improvements have been shown by previous works, training an excellent deep learning model requires a huge amount of data, which may not hold in practice. to address this challenge, we develop a kullback-leibler-based (kl) deep learning procedure to integrate external survival prediction models with newly collected time-to-event data. time-dependent kl discrimination information is utilized to measure the discrepancy between the external and internal data. this is the first work considering using prior information to deal with short data problem in survival analysis for deep learning. simulation and real data results show that the proposed model achieves better performance and higher robustness compared with previous works.",,2022-08-09,2023-04-11,"['li liu', 'xiangeng fang', 'di wang', 'weijing tang', 'kevin he']",https://arxiv.org/pdf/2208.05100.pdf
133,2208.05140,self-supervised multi-modal training from uncurated image and reports   enables zero-shot oversight artificial intelligence in radiology,eess.iv cs.cl cs.cv cs.lg,"oversight ai is an emerging concept in radiology where the ai forms a symbiosis with radiologists by continuously supporting radiologists in their decision-making. recent advances in vision-language models sheds a light on the long-standing problems of the oversight ai by the understanding both visual and textual concepts and their semantic correspondences. however, there have been limited successes in the application of vision-language models in the medical domain, as the current vision-language models and learning strategies for photographic images and captions call for the web-scale data corpus of image and text pairs which was not often feasible in the medical domain. to address this, here we present a model dubbed medical cross-attention vision-language model (medical x-vl), leveraging the key components to be tailored for the medical domain. our medical x-vl model is based on the following components: self-supervised uni-modal models in medical domain and fusion encoder to bridge them, momentum distillation, sentence-wise contrastive learning for medical reports, and the sentence similarity-adjusted hard negative mining. we experimentally demonstrated that our model enables various zero-shot tasks for oversight ai, ranging from the zero-shot classification to zero-shot error correction. our model outperformed the current state-of-the-art models in two different medical image database, suggesting the novel clinical usage of our oversight ai model for monitoring human errors. our method was especially successful in the data-limited setting, which is frequently encountered in the clinics, suggesting the potential widespread applicability in medical domain.",,2022-08-10,2023-04-12,"['sangjoon park', 'eun sun lee', 'kyung sook shin', 'jeong eun lee', 'jong chul ye']",https://arxiv.org/pdf/2208.05140.pdf
134,2208.07655,a hybrid deep feature-based deformable image registration method for   pathology images,eess.iv cs.cv cs.lg physics.med-ph,"pathologists need to combine information from differently stained pathology slices for accurate diagnosis. deformable image registration is a necessary technique for fusing multi-modal pathology slices. this paper proposes a hybrid deep feature-based deformable image registration framework for stained pathology samples. we first extract dense feature points via the detector-based and detector-free deep learning feature networks and perform points matching. then, to further reduce false matches, an outlier detection method combining the isolation forest statistical model and the local affine correction model is proposed. finally, the interpolation method generates the deformable vector field for pathology image registration based on the above matching points. we evaluate our method on the dataset of the non-rigid histology image registration (anhir) challenge, which is co-organized with the ieee isbi 2019 conference. our technique outperforms the traditional approaches by 17% with the average-average registration target error (rtre) reaching 0.0034. the proposed method achieved state-of-the-art performance and ranked 1st in evaluating the test dataset. the proposed hybrid deep feature-based registration method can potentially become a reliable method for pathology image registration.",,2022-08-16,2023-04-10,"['chulong zhang', 'yuming jiang', 'na li', 'zhicheng zhang', 'md tauhidul islam', 'jingjing dai', 'lin liu', 'wenfeng he', 'wenjian qin', 'jing xiong', 'yaoqin xie', 'xiaokun liang']",https://arxiv.org/pdf/2208.07655.pdf
135,2208.08300,transformer-based deep learning model for stock price prediction: a case   study on bangladesh stock market,q-fin.st cs.lg,"in modern capital market the price of a stock is often considered to be highly volatile and unpredictable because of various social, financial, political and other dynamic factors. with calculated and thoughtful investment, stock market can ensure a handsome profit with minimal capital investment, while incorrect prediction can easily bring catastrophic financial loss to the investors. this paper introduces the application of a recently introduced machine learning model - the transformer model, to predict the future price of stocks of dhaka stock exchange (dse), the leading stock exchange in bangladesh. the transformer model has been widely leveraged for natural language processing and computer vision tasks, but, to the best of our knowledge, has never been used for stock price prediction task at dse. recently the introduction of time2vec encoding to represent the time series features has made it possible to employ the transformer model for the stock price prediction. this paper concentrates on the application of transformer-based model to predict the price movement of eight specific stocks listed in dse based on their historical daily and weekly data. our experiments demonstrate promising results and acceptable root mean squared error on most of the stocks.",10.1142/s146902682350013x,2022-08-17,,"['tashreef muhammad', 'anika bintee aftab', 'md. mainul ahsan', 'maishameem meherin muhu', 'muhammad ibrahim', 'shahidul islam khan', 'mohammad shafiul alam']",https://arxiv.org/pdf/2208.08300.pdf
136,2208.08579,diet: conditional independence testing with marginal dependence measures   of residual information,stat.me cs.lg stat.ml,"conditional randomization tests (crts) assess whether a variable $x$ is predictive of another variable $y$, having observed covariates $z$. crts require fitting a large number of predictive models, which is often computationally intractable. existing solutions to reduce the cost of crts typically split the dataset into a train and test portion, or rely on heuristics for interactions, both of which lead to a loss in power. we propose the decoupled independence test (diet), an algorithm that avoids both of these issues by leveraging marginal independence statistics to test conditional independence relationships. diet tests the marginal independence of two random variables: $f(x \mid z)$ and $f(y \mid z)$ where $f(\cdot \mid z)$ is a conditional cumulative distribution function (cdf). these variables are termed ""information residuals."" we give sufficient conditions for diet to achieve finite sample type-1 error control and power greater than the type-1 error rate. we then prove that when using the mutual information between the information residuals as a test statistic, diet yields the most powerful conditionally valid test. finally, we show diet achieves higher power than other tractable crts on several synthetic and real benchmarks.",,2022-08-17,2023-04-11,"['mukund sudarshan', 'aahlad manas puli', 'wesley tansey', 'rajesh ranganath']",https://arxiv.org/pdf/2208.08579.pdf
137,2208.09198,test-time training for data-efficient ucdr,cs.cv,"image retrieval under generalized test scenarios has gained significant momentum in literature, and the recently proposed protocol of universal cross-domain retrieval is a pioneer in this direction. a common practice in any such generalized classification or retrieval algorithm is to exploit samples from many domains during training to learn a domain-invariant representation of data. such criterion is often restrictive, and thus in this work, for the first time, we explore the generalized retrieval problem in a data-efficient manner. specifically, we aim to generalize any pre-trained cross-domain retrieval network towards any unknown query domain/category, by means of adapting the model on the test data leveraging self-supervised learning techniques. toward that goal, we explored different self-supervised loss functions~(for example, rotnet, jigsaw, barlow twins, etc.) and analyze their effectiveness for the same. extensive experiments demonstrate the proposed approach is simple, easy to implement, and effective in handling data-efficient ucdr.",,2022-08-19,2023-04-11,"['soumava paul', 'titir dutta', 'aheli saha', 'abhishek samanta', 'soma biswas']",https://arxiv.org/pdf/2208.09198.pdf
138,2208.09849,semantic-enhanced image clustering,cs.cv cs.lg,"image clustering is an important and open-challenging task in computer vision. although many methods have been proposed to solve the image clustering task, they only explore images and uncover clusters according to the image features, thus being unable to distinguish visually similar but semantically different images. in this paper, we propose to investigate the task of image clustering with the help of a visual-language pre-training model. different from the zero-shot setting, in which the class names are known, we only know the number of clusters in this setting. therefore, how to map images to a proper semantic space and how to cluster images from both image and semantic spaces are two key problems. to solve the above problems, we propose a novel image clustering method guided by the visual-language pre-training model clip, named \textbf{semantic-enhanced image clustering (sic)}. in this new method, we propose a method to map the given images to a proper semantic space first and efficient methods to generate pseudo-labels according to the relationships between images and semantics. finally, we propose performing clustering with consistency learning in both image space and semantic space, in a self-supervised learning fashion. the theoretical result of convergence analysis shows that our proposed method can converge at a sublinear speed. theoretical analysis of expectation risk also shows that we can reduce the expected risk by improving neighborhood consistency, increasing prediction confidence, or reducing neighborhood imbalance. experimental results on five benchmark datasets clearly show the superiority of our new method.",,2022-08-21,2023-04-08,"['shaotian cai', 'liping qiu', 'xiaojun chen', 'qin zhang', 'longteng chen']",https://arxiv.org/pdf/2208.09849.pdf
139,2208.09859,emergence of hierarchical modes from deep learning,cs.lg cond-mat.dis-nn cond-mat.stat-mech cs.ne q-bio.nc,"large-scale deep neural networks consume expensive training costs, but the training results in less-interpretable weight matrices constructing the networks. here, we propose a mode decomposition learning that can interpret the weight matrices as a hierarchy of latent modes. these modes are akin to patterns in physics studies of memory networks, but the least number of modes increases only logarithmically with the network width, and becomes even a constant when the width further grows. the mode decomposition learning not only saves a significant large amount of training costs, but also explains the network performance with the leading modes, displaying a striking piecewise power-law behavior. the modes specify a progressively compact latent space across the network hierarchy, making a more disentangled subspaces compared to standard training. our mode decomposition learning is also studied in an analytic on-line learning setting, which reveals multi-stage of learning dynamics with a continuous specialization of hidden nodes. therefore, the proposed mode decomposition learning points to a cheap and interpretable route towards the magical deep learning.",10.1103/physrevresearch.5.l022011,2022-08-21,2023-02-27,"['chan li', 'haiping huang']",https://arxiv.org/pdf/2208.09859.pdf
140,2208.11266,scale: online self-supervised lifelong learning without prior knowledge,cs.lg cs.ai,"unsupervised lifelong learning refers to the ability to learn over time while memorizing previous patterns without supervision. although great progress has been made in this direction, existing work often assumes strong prior knowledge about the incoming data (e.g., knowing the class boundaries), which can be impossible to obtain in complex and unpredictable environments. in this paper, motivated by real-world scenarios, we propose a more practical problem setting called online self-supervised lifelong learning without prior knowledge. the proposed setting is challenging due to the non-iid and single-pass data, the absence of external supervision, and no prior knowledge. to address the challenges, we propose self-supervised contrastive lifelong learning without prior knowledge (scale) which can extract and memorize representations on the fly purely from the data continuum. scale is designed around three major components: a pseudo-supervised contrastive loss, a self-supervised forgetting loss, and an online memory update for uniform subset selection. all three components are designed to work collaboratively to maximize learning performance. we perform comprehensive experiments of scale under iid and four non-iid data streams. the results show that scale outperforms the state-of-the-art algorithm in all settings with improvements up to 3.83%, 2.77% and 5.86% in terms of knn accuracy on cifar-10, cifar-100, and tinyimagenet datasets.",,2022-08-23,2023-04-10,"['xiaofan yu', 'yunhui guo', 'sicun gao', 'tajana rosing']",https://arxiv.org/pdf/2208.11266.pdf
141,2208.11639,oracle-free reinforcement learning in mean-field games along a single   sample path,cs.lg cs.gt cs.ma,"we consider online reinforcement learning in mean-field games (mfgs). unlike traditional approaches, we alleviate the need for a mean-field oracle by developing an algorithm that approximates the mean-field equilibrium (mfe) using the single sample path of the generic agent. we call this {\it sandbox learning}, as it can be used as a warm-start for any agent learning in a multi-agent non-cooperative setting. we adopt a two time-scale approach in which an online fixed-point recursion for the mean-field operates on a slower time-scale, in tandem with a control policy update on a faster time-scale for the generic agent. given that the underlying markov decision process (mdp) of the agent is communicating, we provide finite sample convergence guarantees in terms of convergence of the mean-field and control policy to the mean-field equilibrium. the sample complexity of the sandbox learning algorithm is $\tilde{\mathcal{o}}(\epsilon^{-4})$ where $\epsilon$ is the mfe approximation error. this is similar to works which assume access to oracle. finally, we empirically demonstrate the effectiveness of the sandbox learning algorithm in diverse scenarios, including those where the mdp does not necessarily have a single communicating class.",,2022-08-24,2023-04-11,"['muhammad aneeq uz zaman', 'alec koppel', 'sujay bhatt', 'tamer ba≈üar']",https://arxiv.org/pdf/2208.11639.pdf
142,2208.12262,maskclip: masked self-distillation advances contrastive language-image   pretraining,cs.cv,"this paper presents a simple yet effective framework maskclip, which incorporates a newly proposed masked self-distillation into contrastive language-image pretraining. the core idea of masked self-distillation is to distill representation from a full image to the representation predicted from a masked image. such incorporation enjoys two vital benefits. first, masked self-distillation targets local patch representation learning, which is complementary to vision-language contrastive focusing on text-related representation. second, masked self-distillation is also consistent with vision-language contrastive from the perspective of training objective as both utilize the visual encoder for feature aligning, and thus is able to learn local semantics getting indirect supervision from the language. we provide specially designed experiments with a comprehensive analysis to validate the two benefits. symmetrically, we also introduce the local semantic supervision into the text branch, which further improves the pretraining performance. with extensive experiments, we show that maskclip, when applied to various challenging downstream tasks, achieves superior results in linear probing, finetuning, and zero-shot performance with the guidance of the language encoder. code will be release at \url{https://github.com/lightdxy/maskclip}.",,2022-08-25,2023-04-09,"['xiaoyi dong', 'jianmin bao', 'yinglin zheng', 'ting zhang', 'dongdong chen', 'hao yang', 'ming zeng', 'weiming zhang', 'lu yuan', 'dong chen', 'fang wen', 'nenghai yu']",https://arxiv.org/pdf/2208.12262.pdf
143,2208.12697,voxurf: voxel-based efficient and accurate neural surface reconstruction,cs.cv,"neural surface reconstruction aims to reconstruct accurate 3d surfaces based on multi-view images. previous methods based on neural volume rendering mostly train a fully implicit model with mlps, which typically require hours of training for a single scene. recent efforts explore the explicit volumetric representation to accelerate the optimization via memorizing significant information with learnable voxel grids. however, existing voxel-based methods often struggle in reconstructing fine-grained geometry, even when combined with an sdf-based volume rendering scheme. we reveal that this is because 1) the voxel grids tend to break the color-geometry dependency that facilitates fine-geometry learning, and 2) the under-constrained voxel grids lack spatial coherence and are vulnerable to local minima. in this work, we present voxurf, a voxel-based surface reconstruction approach that is both efficient and accurate. voxurf addresses the aforementioned issues via several key designs, including 1) a two-stage training procedure that attains a coherent coarse shape and recovers fine details successively, 2) a dual color network that maintains color-geometry dependency, and 3) a hierarchical geometry feature to encourage information propagation across voxels. extensive experiments show that voxurf achieves high efficiency and high quality at the same time. on the dtu benchmark, voxurf achieves higher reconstruction quality with a 20x training speedup compared to previous fully implicit methods. our code is available at https://github.com/wutong16/voxurf.",,2022-08-26,2023-04-11,"['tong wu', 'jiaqi wang', 'xingang pan', 'xudong xu', 'christian theobalt', 'ziwei liu', 'dahua lin']",https://arxiv.org/pdf/2208.12697.pdf
144,2208.14133,deep generative modeling on limited data with regularization by   nontransferable pre-trained models,cs.lg cs.cv,"deep generative models (dgms) are data-eager because learning a complex model on limited data suffers from a large variance and easily overfits. inspired by the classical perspective of the bias-variance tradeoff, we propose regularized deep generative model (reg-dgm), which leverages a nontransferable pre-trained model to reduce the variance of generative modeling with limited data. formally, reg-dgm optimizes a weighted sum of a certain divergence and the expectation of an energy function, where the divergence is between the data and the model distributions, and the energy function is defined by the pre-trained model w.r.t. the model distribution. we analyze a simple yet representative gaussian-fitting case to demonstrate how the weighting hyperparameter trades off the bias and the variance. theoretically, we characterize the existence and the uniqueness of the global minimum of reg-dgm in a non-parametric setting and prove its convergence with neural networks trained by gradient-based methods. empirically, with various pre-trained feature extractors and a data-dependent energy function, reg-dgm consistently improves the generation performance of strong dgms with limited data and achieves competitive results to the state-of-the-art methods. our implementation is available at https://github.com/ml-gsai/reg-ada-apa.",,2022-08-30,2023-04-10,"['yong zhong', 'hongtao liu', 'xiaodong liu', 'fan bao', 'weiran shen', 'chongxuan li']",https://arxiv.org/pdf/2208.14133.pdf
145,2209.00727,enabling country-scale land cover mapping with meter-resolution   satellite imagery,cs.cv,"high-resolution satellite images can provide abundant, detailed spatial information for land cover classification, which is particularly important for studying the complicated built environment. however, due to the complex land cover patterns, the costly training sample collections, and the severe distribution shifts of satellite imageries, few studies have applied high-resolution images to land cover mapping in detailed categories at large scale. to fill this gap, we present a large-scale land cover dataset, five-billion-pixels. it contains more than 5 billion labeled pixels of 150 high-resolution gaofen-2 (4 m) satellite images, annotated in a 24-category system covering artificial-constructed, agricultural, and natural classes. in addition, we propose a deep-learning-based unsupervised domain adaptation approach that can transfer classification models trained on labeled dataset (referred to as the source domain) to unlabeled data (referred to as the target domain) for large-scale land cover mapping. specifically, we introduce an end-to-end siamese network employing dynamic pseudo-label assignment and class balancing strategy to perform adaptive domain joint learning. to validate the generalizability of our dataset and the proposed approach across different sensors and different geographical regions, we carry out land cover mapping on five megacities in china and six cities in other five asian countries severally using: planetscope (3 m), gaofen-1 (8 m), and sentinel-2 (10 m) satellite images. over a total study area of 60,000 square kilometers, the experiments show promising results even though the input images are entirely unlabeled. the proposed approach, trained with the five-billion-pixels dataset, enables high-quality and detailed land cover mapping across the whole country of china and some other asian countries at meter-resolution.",10.1016/j.isprsjprs.2022.12.011,2022-09-01,2023-04-07,"['xin-yi tong', 'gui-song xia', 'xiao xiang zhu']",https://arxiv.org/pdf/2209.00727.pdf
146,2209.02544,xsimgcl: towards extremely simple graph contrastive learning for   recommendation,cs.ir,"contrastive learning (cl) has recently been demonstrated critical in improving recommendation performance. the underlying principle of cl-based recommendation models is to ensure the consistency between representations derived from different graph augmentations of the user-item bipartite graph. this self-supervised approach allows for the extraction of general features from raw data, thereby mitigating the issue of data sparsity. despite the effectiveness of this paradigm, the factors contributing to its performance gains have yet to be fully understood. this paper provides novel insights into the impact of cl on recommendation. our findings indicate that cl enables the model to learn more evenly distributed user and item representations, which alleviates the prevalent popularity bias and promoting long-tail items. our analysis also suggests that the graph augmentations, previously considered essential, are relatively unreliable and of limited significance in cl-based recommendation. based on these findings, we put forward an extremely simple graph contrastive learning method (xsimgcl) for recommendation, which discards the ineffective graph augmentations and instead employs a simple yet effective noise-based embedding augmentation to generate views for cl. a comprehensive experimental study on four large and highly sparse benchmark datasets demonstrates that, though the proposed method is extremely simple, it can smoothly adjust the uniformity of learned representations and outperforms its graph augmentation-based counterparts by a large margin in both recommendation accuracy and training efficiency. the code and used datasets are released at https://github.com/coder-yu/selfrec.",,2022-09-06,2023-04-11,"['junliang yu', 'xin xia', 'tong chen', 'lizhen cui', 'nguyen quoc viet hung', 'hongzhi yin']",https://arxiv.org/pdf/2209.02544.pdf
147,2209.03683,known by the company we keep: `triadic influence' as a proxy for   compatibility in social relationships,cs.si cond-mat.dis-nn stat.ml,"networks of social interactions are the substrate upon which civilizations are built. often, we create new bonds with people that we like or feel that our relationships are damaged through the intervention of third parties. despite their importance and the huge impact that these processes have in our lives, quantitative scientific understanding of them is still in its infancy, mainly due to the difficulty of collecting large datasets of social networks including individual attributes. in this work, we present a thorough study of real social networks of 13 schools, with more than 3,000 students and 60,000 declared positive and negative relations, including tests for personal traits of all the students. we introduce a metric -- the `triadic influence' -- that measures the influence of nearest-neighbors in the relationships of their contacts. we use neural networks to predict the relationships and to extract the probability that two students are friends or enemies depending on their personal attributes or the triadic influence. we alternatively use a high-dimensional embedding of the network structure to also predict the relationships. remarkably, the triadic influence (a simple one-dimensional metric) achieves the highest accuracy at predicting the relationship between two students. we postulate that the probabilities extracted from the neural networks -- functions of the triadic influence and the personalities of the students -- control the evolution of real social networks, opening a new avenue for the quantitative study of these systems.",10.1073/pnas.2215041120,2022-09-08,2022-09-09,"['miguel ru√≠z-garc√≠a', 'juan ozaita', 'mar√≠a pereda', 'antonio alfonso', 'pablo bra√±as-garza', 'jose a. cuesta', '√°ngel s√°nchez']",https://arxiv.org/pdf/2209.03683.pdf
148,2209.04856,secure shapley value for cross-silo federated learning,cs.cr,"the shapley value (sv) is a fair and principled metric for contribution evaluation in cross-silo federated learning (cross-silo fl), wherein organizations, i.e., clients, collaboratively train prediction models with the coordination of a parameter server. however, existing sv calculation methods for fl assume that the server can access the raw fl models and public test data. this may not be a valid assumption in practice considering the emerging privacy attacks on fl models and the fact that test data might be clients' private assets. hence, we investigate the problem of secure sv calculation for cross-silo fl. we first propose hesv, a one-server solution based solely on homomorphic encryption (he) for privacy protection, which has limitations in efficiency. to overcome these limitations, we propose secsv, an efficient two-server protocol with the following novel features. first, secsv utilizes a hybrid privacy protection scheme to avoid ciphertext--ciphertext multiplications between test data and models, which are extremely expensive under he. second, an efficient secure matrix multiplication method is proposed for secsv. third, secsv strategically identifies and skips some test samples without significantly affecting the evaluation accuracy. our experiments demonstrate that secsv is 7.2-36.6 times as fast as hesv, with a limited loss in the accuracy of calculated svs.",10.14778/3587136.3587141,2022-09-11,2023-04-09,"['shuyuan zheng', 'yang cao', 'masatoshi yoshikawa']",https://arxiv.org/pdf/2209.04856.pdf
149,2209.05917,spade: improving sparse representations using a dual document encoder   for first-stage retrieval,cs.ir,"sparse document representations have been widely used to retrieve relevant documents via exact lexical matching. owing to the pre-computed inverted index, it supports fast ad-hoc search but incurs the vocabulary mismatch problem. although recent neural ranking models using pre-trained language models can address this problem, they usually require expensive query inference costs, implying the trade-off between effectiveness and efficiency. tackling the trade-off, we propose a novel uni-encoder ranking model, sparse retriever using a dual document encoder (spade), learning document representation via the dual encoder. each encoder plays a central role in (i) adjusting the importance of terms to improve lexical matching and (ii) expanding additional terms to support semantic matching. furthermore, our co-training strategy trains the dual encoder effectively and avoids unnecessary intervention in training each other. experimental results on several benchmarks show that spade outperforms existing uni-encoder ranking models.",10.1145/3511808.3557456,2022-09-13,2023-04-13,"['eunseong choi', 'sunkyung lee', 'minjin choi', 'hyeseon ko', 'young-in song', 'jongwuk lee']",https://arxiv.org/pdf/2209.05917.pdf
150,2209.07075,bi-level physics-informed neural networks for pde constrained   optimization using broyden's hypergradients,cs.lg,"deep learning based approaches like physics-informed neural networks (pinns) and deeponets have shown promise on solving pde constrained optimization (pdeco) problems. however, existing methods are insufficient to handle those pde constraints that have a complicated or nonlinear dependency on optimization targets. in this paper, we present a novel bi-level optimization framework to resolve the challenge by decoupling the optimization of the targets and constraints. for the inner loop optimization, we adopt pinns to solve the pde constraints only. for the outer loop, we design a novel method by using broyden's method based on the implicit function theorem (ift), which is efficient and accurate for approximating hypergradients. we further present theoretical explanations and error analysis of the hypergradients computation. extensive experiments on multiple large-scale and nonlinear pde constrained optimization problems demonstrate that our method achieves state-of-the-art results compared with strong baselines.",,2022-09-15,2023-04-11,"['zhongkai hao', 'chengyang ying', 'hang su', 'jun zhu', 'jian song', 'ze cheng']",https://arxiv.org/pdf/2209.07075.pdf
151,2209.08446,dual contrastive network for sequential recommendation with user and   item-centric perspectives,cs.ir,"with the outbreak of today's streaming data, the sequential recommendation is a promising solution to achieve time-aware personalized modeling. it aims to infer the next interacted item of a given user based on the history item sequence. some recent works tend to improve the sequential recommendation via random masking on the history item so as to generate self-supervised signals. but such approaches will indeed result in sparser item sequence and unreliable signals. besides, the existing sequential recommendation models are only user-centric, i.e., based on the historical items by chronological order to predict the probability of candidate items, which ignores whether the items from a provider can be successfully recommended. such user-centric recommendation will make it impossible for the provider to expose their new items and result in popular bias.   in this paper, we propose a novel dual contrastive network (dcn) to generate ground-truth self-supervised signals for sequential recommendation by auxiliary user-sequence from an item-centric perspective. specifically, we propose dual representation contrastive learning to refine the representation learning by minimizing the euclidean distance between the representations of a given user/item and history items/users of them. before the second contrastive learning module, we perform the next user prediction to capture the trends of items preferred by certain types of users and provide personalized exploration opportunities for item providers. finally, we further propose dual interest contrastive learning to self-supervise the dynamic interest from the next item/user prediction and static interest of matching probability. experiments on four benchmark datasets verify the effectiveness of our proposed method. further ablation study also illustrates the boosting effect of the proposed components upon different sequential models.",,2022-09-17,2023-04-13,"['guanyu lin', 'chen gao', 'yinfeng li', 'yu zheng', 'zhiheng li', 'depeng jin', 'dong li', 'jianye hao', 'yong li']",https://arxiv.org/pdf/2209.08446.pdf
152,2209.09500,reduction from complementary-label learning to probability estimates,cs.lg,"complementary-label learning (cll) is a weakly-supervised learning problem that aims to learn a multi-class classifier from only complementary labels, which indicate a class to which an instance does not belong. existing approaches mainly adopt the paradigm of reduction to ordinary classification, which applies specific transformations and surrogate losses to connect cll back to ordinary classification. those approaches, however, face several limitations, such as the tendency to overfit or be hooked on deep models. in this paper, we sidestep those limitations with a novel perspective--reduction to probability estimates of complementary classes. we prove that accurate probability estimates of complementary labels lead to good classifiers through a simple decoding step. the proof establishes a reduction framework from cll to probability estimates. the framework offers explanations of several key cll approaches as its special cases and allows us to design an improved algorithm that is more robust in noisy environments. the framework also suggests a validation procedure based on the quality of probability estimates, leading to an alternative way to validate models with only complementary labels. the flexible framework opens a wide range of unexplored opportunities in using deep and non-deep models for probability estimates to solve the cll problem. empirical experiments further verified the framework's efficacy and robustness in various settings.",,2022-09-20,2023-04-11,"['wei-i lin', 'hsuan-tien lin']",https://arxiv.org/pdf/2209.09500.pdf
153,2209.10080,deep double descent via smooth interpolation,cs.lg stat.ml,"the ability of overparameterized deep networks to interpolate noisy data, while at the same time showing good generalization performance, has been recently characterized in terms of the double descent curve for the test error. common intuition from polynomial regression suggests that overparameterized networks are able to sharply interpolate noisy data, without considerably deviating from the ground-truth signal, thus preserving generalization ability. at present, a precise characterization of the relationship between interpolation and generalization for deep networks is missing. in this work, we quantify sharpness of fit of the training data interpolated by neural network functions, by studying the loss landscape w.r.t. to the input variable locally to each training point, over volumes around cleanly- and noisily-labelled training samples, as we systematically increase the number of model parameters and training epochs. our findings show that loss sharpness in the input space follows both model- and epoch-wise double descent, with worse peaks observed around noisy labels. while small interpolating models sharply fit both clean and noisy data, large interpolating models express a smooth loss landscape, where noisy targets are predicted over large volumes around training data points, in contrast to existing intuition.",,2022-09-20,2023-04-08,"['matteo gamba', 'erik englesson', 'm√•rten bj√∂rkman', 'hossein azizpour']",https://arxiv.org/pdf/2209.10080.pdf
154,2209.10913,how good is neural combinatorial optimization? a systematic evaluation   on the traveling salesman problem,cs.ne,"traditional solvers for tackling combinatorial optimization (co) problems are usually designed by human experts. recently, there has been a surge of interest in utilizing deep learning, especially deep reinforcement learning, to automatically learn effective solvers for co. the resultant new paradigm is termed neural combinatorial optimization (nco). however, the advantages and disadvantages of nco relative to other approaches have not been empirically or theoretically well studied. this work presents a comprehensive comparative study of nco solvers and alternative solvers. specifically, taking the traveling salesman problem as the testbed problem, the performance of the solvers is assessed in five aspects, i.e., effectiveness, efficiency, stability, scalability, and generalization ability. our results show that the solvers learned by nco approaches, in general, still fall short of traditional solvers in nearly all these aspects. a potential benefit of nco solvers would be their superior time and energy efficiency for small-size problem instances when sufficient training instances are available. hopefully, this work would help with a better understanding of the strengths and weaknesses of nco and provide a comprehensive evaluation protocol for further benchmarking nco approaches in comparison to other approaches.",,2022-09-22,2023-04-12,"['shengcai liu', 'yu zhang', 'ke tang', 'xin yao']",https://arxiv.org/pdf/2209.10913.pdf
155,2209.11519,vector quantized semantic communication system,cs.cv eess.sp,"although analog semantic communication systems have received considerable attention in the literature, there is less work on digital semantic communication systems. in this paper, we develop a deep learning (dl)-enabled vector quantized (vq) semantic communication system for image transmission, named vq-deepsc. specifically, we propose a convolutional neural network (cnn)-based transceiver to extract multi-scale semantic features of images and introduce multi-scale semantic embedding spaces to perform semantic feature quantization, rendering the data compatible with digital communication systems. furthermore, we employ adversarial training to improve the quality of received images by introducing a patchgan discriminator. experimental results demonstrate that the proposed vq-deepsc is more robustness than bpg in digital communication systems and has comparable ms-ssim performance to the deepjscc method.",10.1109/lwc.2023.3255221,2022-09-23,2023-04-12,"['qifan fu', 'huiqiang xie', 'zhijin qin', 'gregory slabaugh', 'xiaoming tao']",https://arxiv.org/pdf/2209.11519.pdf
156,2209.11908,fast lifelong adaptive inverse reinforcement learning from   demonstrations,cs.lg cs.ro,"learning from demonstration (lfd) approaches empower end-users to teach robots novel tasks via demonstrations of the desired behaviors, democratizing access to robotics. however, current lfd frameworks are not capable of fast adaptation to heterogeneous human demonstrations nor the large-scale deployment in ubiquitous robotics applications. in this paper, we propose a novel lfd framework, fast lifelong adaptive inverse reinforcement learning (flair). our approach (1) leverages learned strategies to construct policy mixtures for fast adaptation to new demonstrations, allowing for quick end-user personalization, (2) distills common knowledge across demonstrations, achieving accurate task inference; and (3) expands its model only when needed in lifelong deployments, maintaining a concise set of prototypical strategies that can approximate all behaviors via policy mixtures. we empirically validate that flair achieves adaptability (i.e., the robot adapts to heterogeneous, user-specific task preferences), efficiency (i.e., the robot achieves sample-efficient adaptation), and scalability (i.e., the model grows sublinearly with the number of demonstrations while maintaining high performance). flair surpasses benchmarks across three control tasks with an average 57% improvement in policy returns and an average 78% fewer episodes required for demonstration modeling using policy mixtures. finally, we demonstrate the success of flair in a table tennis task and find users rate flair as having higher task (p<.05) and personalization (p<.05) performance.",,2022-09-23,2023-04-12,"['letian chen', 'sravan jayanthi', 'rohan paleja', 'daniel martin', 'viacheslav zakharov', 'matthew gombolay']",https://arxiv.org/pdf/2209.11908.pdf
157,2209.12602,effects of language mismatch in automatic forensic voice comparison   using deep learning embeddings,cs.sd cs.cl eess.as,"in forensic voice comparison the speaker embedding has become widely popular in the last 10 years. most of the pretrained speaker embeddings are trained on english corpora, because it is easily accessible. thus, language dependency can be an important factor in automatic forensic voice comparison, especially when the target language is linguistically very different. there are numerous commercial systems available, but their models are mainly trained on a different language (mostly english) than the target language. in the case of a low-resource language, developing a corpus for forensic purposes containing enough speakers to train deep learning models is costly. this study aims to investigate whether a model pre-trained on english corpus can be used on a target low-resource language (here, hungarian), different from the model is trained on. also, often multiple samples are not available from the offender (unknown speaker). therefore, samples are compared pairwise with and without speaker enrollment for suspect (known) speakers. two corpora are applied that were developed especially for forensic purposes, and a third that is meant for traditional speaker verification. two deep learning based speaker embedding vector extraction methods are used: the x-vector and ecapa-tdnn. speaker verification was evaluated in the likelihood-ratio framework. a comparison is made between the language combinations (modeling, lr calibration, evaluation). the results were evaluated by mincllr and eer metrics. it was found that the model pre-trained on a different language but on a corpus with a huge amount of speakers performs well on samples with language mismatch. the effect of sample durations and speaking styles were also examined. it was found that the longer the duration of the sample in question the better the performance is. also, there is no real difference if various speaking styles are applied.",10.1111/1556-4029.15250,2022-09-26,,"['d√°vid sztah√≥', 'attila fejes']",https://arxiv.org/pdf/2209.12602.pdf
158,2209.12660,marlui: multi-agent reinforcement learning for adaptive uis,cs.hc,"adaptive user interfaces (uis) automatically change an interface to better support users' tasks. recently, machine learning techniques have enabled the transition to more powerful and complex adaptive uis. however, a core challenge for adaptive user interfaces is the reliance on high-quality user data that has to be collected offline for each task. we formulate ui adaptation as a multi-agent reinforcement learning problem to overcome this challenge. in our formulation, a user agent mimics a real user and learns to interact with a ui. simultaneously, an interface agent learns ui adaptations to maximize the user agent's performance. the interface agent learns the task structure from the user agent's behavior and, based on that, can support the user agent in completing its task. our method produces adaptation policies that are learned in simulation only and, therefore, does not need real user data. our experiments show that learned policies generalize to real users and achieve on par performance with data-driven supervised learning baselines.",,2022-09-26,2023-04-13,"['thomas langerak', 'sammy christen', 'mert albaba', 'christoph gebhardt', 'otmar hilliges']",https://arxiv.org/pdf/2209.12660.pdf
159,2209.13351,superyolo: super resolution assisted object detection in multimodal   remote sensing imagery,cs.cv,"accurately and timely detecting multiscale small objects that contain tens of pixels from remote sensing images (rsi) remains challenging. most of the existing solutions primarily design complex deep neural networks to learn strong feature representations for objects separated from the background, which often results in a heavy computation burden. in this article, we propose an accurate yet fast object detection method for rsi, named superyolo, which fuses multimodal data and performs high-resolution (hr) object detection on multiscale objects by utilizing the assisted super resolution (sr) learning and considering both the detection accuracy and computation cost. first, we utilize a symmetric compact multimodal fusion (mf) to extract supplementary information from various data for improving small object detection in rsi. furthermore, we design a simple and flexible sr branch to learn hr feature representations that can discriminate small objects from vast backgrounds with low-resolution (lr) input, thus further improving the detection accuracy. moreover, to avoid introducing additional computation, the sr branch is discarded in the inference stage, and the computation of the network model is reduced due to the lr input. experimental results show that, on the widely used vedai rs dataset, superyolo achieves an accuracy of 75.09% (in terms of map50 ), which is more than 10% higher than the sota large models, such as yolov5l, yolov5x, and rs designed yolors. meanwhile, the parameter size and gflops of superyolo are about 18 times and 3.8 times less than yolov5x. our proposed model shows a favorable accuracy and speed tradeoff compared to the state-of-the-art models. the code will be open-sourced at https://github.com/icey-zhang/superyolo.",10.1109/tgrs.2023.3258666,2022-09-27,2023-04-08,"['jiaqing zhang', 'jie lei', 'weiying xie', 'zhenman fang', 'yunsong li', 'qian du']",https://arxiv.org/pdf/2209.13351.pdf
160,2209.13791,trboost: a generic gradient boosting machine based on trust-region   method,cs.lg,"gradient boosting machines (gbms) have demonstrated remarkable success in solving diverse problems by utilizing taylor expansions in functional space. however, achieving a balance between performance and generality has posed a challenge for gbms. in particular, gradient descent-based gbms employ the first-order taylor expansion to ensure applicability to all loss functions, while newton's method-based gbms use positive hessian information to achieve superior performance at the expense of generality. to address this issue, this study proposes a new generic gradient boosting machine called trust-region boosting (trboost). in each iteration, trboost uses a constrained quadratic model to approximate the objective and applies the trust-region algorithm to solve it and obtain a new learner. unlike newton's method-based gbms, trboost does not require the hessian to be positive definite, thereby allowing it to be applied to arbitrary loss functions while still maintaining competitive performance similar to second-order algorithms. the convergence analysis and numerical experiments conducted in this study confirm that trboost is as general as first-order gbms and yields competitive results compared to second-order gbms. overall, trboost is a promising approach that balances performance and generality, making it a valuable addition to the toolkit of machine learning practitioners.",,2022-09-27,2023-04-11,"['jiaqi luo', 'zihao wei', 'junkai man', 'shixin xu']",https://arxiv.org/pdf/2209.13791.pdf
161,2209.15594,self-stabilization: the implicit bias of gradient descent at the edge of   stability,cs.lg cs.it math.it math.oc stat.ml,"traditional analyses of gradient descent show that when the largest eigenvalue of the hessian, also known as the sharpness $s(\theta)$, is bounded by $2/\eta$, training is ""stable"" and the training loss decreases monotonically. recent works, however, have observed that this assumption does not hold when training modern neural networks with full batch or large batch gradient descent. most recently, cohen et al. (2021) observed two important phenomena. the first, dubbed progressive sharpening, is that the sharpness steadily increases throughout training until it reaches the instability cutoff $2/\eta$. the second, dubbed edge of stability, is that the sharpness hovers at $2/\eta$ for the remainder of training while the loss continues decreasing, albeit non-monotonically. we demonstrate that, far from being chaotic, the dynamics of gradient descent at the edge of stability can be captured by a cubic taylor expansion: as the iterates diverge in direction of the top eigenvector of the hessian due to instability, the cubic term in the local taylor expansion of the loss function causes the curvature to decrease until stability is restored. this property, which we call self-stabilization, is a general property of gradient descent and explains its behavior at the edge of stability. a key consequence of self-stabilization is that gradient descent at the edge of stability implicitly follows projected gradient descent (pgd) under the constraint $s(\theta) \le 2/\eta$. our analysis provides precise predictions for the loss, sharpness, and deviation from the pgd trajectory throughout training, which we verify both empirically in a number of standard settings and theoretically under mild conditions. our analysis uncovers the mechanism for gradient descent's implicit bias towards stability.",,2022-09-30,2023-04-10,"['alex damian', 'eshaan nichani', 'jason d. lee']",https://arxiv.org/pdf/2209.15594.pdf
162,2210.00092,federated training of dual encoding models on small non-iid client   datasets,cs.lg cs.cv,"dual encoding models that encode a pair of inputs are widely used for representation learning. many approaches train dual encoding models by maximizing agreement between pairs of encodings on centralized training data. however, in many scenarios, datasets are inherently decentralized across many clients (user devices or organizations) due to privacy concerns, motivating federated learning. in this work, we focus on federated training of dual encoding models on decentralized data composed of many small, non-iid (independent and identically distributed) client datasets. we show that existing approaches that work well in centralized settings perform poorly when naively adapted to this setting using federated averaging. we observe that, we can simulate large-batch loss computation on individual clients for loss functions that are based on encoding statistics. based on this insight, we propose a novel federated training approach, distributed cross correlation optimization (dcco), which trains dual encoding models using encoding statistics aggregated across clients, without sharing individual data samples. our experimental results on two datasets demonstrate that the proposed dcco approach outperforms federated variants of existing approaches by a large margin.",,2022-09-30,2023-04-10,"['raviteja vemulapalli', 'warren richard morningstar', 'philip andrew mansfield', 'hubert eichner', 'karan singhal', 'arash afkanpour', 'bradley green']",https://arxiv.org/pdf/2210.00092.pdf
163,2210.00173,predictive inference with feature conformal prediction,cs.lg cs.ai stat.me stat.ml,"conformal prediction is a distribution-free technique for establishing valid prediction intervals. although conventionally people conduct conformal prediction in the output space, this is not the only possibility. in this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. from a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as imagenet classification and cityscapes image segmentation.the code is available at \url{https://github.com/alvinwen428/featurecp}.",,2022-09-30,2023-04-08,"['jiaye teng', 'chuan wen', 'dinghuai zhang', 'yoshua bengio', 'yang gao', 'yang yuan']",https://arxiv.org/pdf/2210.00173.pdf
164,2210.00993,efficient bayes inference in neural networks through adaptive importance   sampling,cs.lg cs.ai stat.ml,"bayesian neural networks (bnns) have received an increased interest in the last years. in bnns, a complete posterior distribution of the unknown weight and bias parameters of the network is produced during the training stage. this probabilistic estimation offers several advantages with respect to point-wise estimates, in particular, the ability to provide uncertainty quantification when predicting new data. this feature inherent to the bayesian paradigm, is useful in countless machine learning applications. it is particularly appealing in areas where decision-making has a crucial impact, such as medical healthcare or autonomous driving. the main challenge of bnns is the computational cost of the training procedure since bayesian techniques often face a severe curse of dimensionality. adaptive importance sampling (ais) is one of the most prominent monte carlo methodologies benefiting from sounded convergence guarantees and ease for adaptation. this work aims to show that ais constitutes a successful approach for designing bnns. more precisely, we propose a novel algorithm pmcnet that includes an efficient adaptation mechanism, exploiting geometric information on the complex (often multimodal) posterior distribution. numerical results illustrate the excellent performance and the improved exploration capabilities of the proposed method for both shallow and deep neural networks.",,2022-10-03,2023-04-13,"['yunshi huang', 'emilie chouzenoux', 'victor elvira', 'jean-christophe pesquet']",https://arxiv.org/pdf/2210.00993.pdf
165,2210.01217,one-shot detail retouching with patch space neural transformation   blending,cs.cv cs.gr,"photo retouching is a difficult task for novice users as it requires expert knowledge and advanced tools. photographers often spend a great deal of time generating high-quality retouched photos with intricate details. in this paper, we introduce a one-shot learning based technique to automatically retouch details of an input image based on just a single pair of before and after example images. our approach provides accurate and generalizable detail edit transfer to new images. we achieve these by proposing a new representation for image to image maps. specifically, we propose neural field based transformation blending in the patch space for defining patch to patch transformations for each frequency band. this parametrization of the map with anchor transformations and associated weights, and spatio-spectral localized patches, allows us to capture details well while staying generalizable. we evaluate our technique both on known ground truth filters and artist retouching edits. our method accurately transfers complex detail retouching edits.",,2022-10-03,2023-04-09,"['fazilet gokbudak', 'cengiz oztireli']",https://arxiv.org/pdf/2210.01217.pdf
166,2210.01513,the dynamics of sharpness-aware minimization: bouncing across ravines   and drifting towards wide minima,cs.lg math.oc stat.ml,"we consider sharpness-aware minimization (sam), a gradient-based optimization method for deep networks that has exhibited performance improvements on image and language prediction problems. we show that when sam is applied with a convex quadratic objective, for most random initializations it converges to a cycle that oscillates between either side of the minimum in the direction with the largest curvature, and we provide bounds on the rate of convergence.   in the non-quadratic case, we show that such oscillations effectively perform gradient descent, with a smaller step-size, on the spectral norm of the hessian. in such cases, sam's update may be regarded as a third derivative -- the derivative of the hessian in the leading eigenvector direction -- that encourages drift toward wider minima.",,2022-10-04,2023-04-11,"['peter l. bartlett', 'philip m. long', 'olivier bousquet']",https://arxiv.org/pdf/2210.01513.pdf
167,2210.03266,maximum likelihood-based gridless doa estimation using structured   covariance matrix recovery and sbl with grid refinement,eess.sp cs.it math.it,"we consider the parametric data model employed in applications such as line spectral estimation and direction-of-arrival estimation. we focus on the stochastic maximum likelihood estimation (mle) framework and offer approaches to estimate the parameter of interest in a gridless manner, overcoming the model complexities of the past. this progress is enabled by the modern trend of reparameterization of the objective and exploiting the sparse bayesian learning (sbl) approach. the latter is shown to be a correlation-aware method, and for the underlying problem it is identified as a grid-based technique for recovering a structured covariance matrix of the measurements. for the case when the structured matrix is expressible as a sampled toeplitz matrix, such as when measurements are sampled in time or space at regular intervals, additional constraints and reparameterization of the sbl objective leads to the proposed structured matrix recovery technique based on mle. the proposed optimization problem is non-convex, and we propose a majorization-minimization based iterative procedure to estimate the structured matrix; each iteration solves a semidefinite program. we recover the parameter of interest in a gridless manner by appealing to the caratheodory-fejer result on decomposition of psd toeplitz matrices. for the general case of irregularly spaced time or spatial samples, we propose an iterative sbl procedure that refines grid points to increase resolution near potential source locations, while maintaining a low per iteration complexity. we provide numerical results to evaluate and compare the performance of the proposed techniques with other gridless techniques, and the crb. the proposed correlation-aware approach is more robust to environmental/system effects such as low number of snapshots, correlated sources, small separation between source locations and improves sources identifiability.",10.1109/tsp.2023.3254919,2022-10-06,,"['rohan r. pote', 'bhaskar d. rao']",https://arxiv.org/pdf/2210.03266.pdf
168,2210.03594,label propagation with weak supervision,cs.lg stat.ml,"semi-supervised learning and weakly supervised learning are important paradigms that aim to reduce the growing demand for labeled data in current machine learning applications. in this paper, we introduce a novel analysis of the classical label propagation algorithm (lpa) (zhu & ghahramani, 2002) that moreover takes advantage of useful prior information, specifically probabilistic hypothesized labels on the unlabeled data. we provide an error bound that exploits both the local geometric properties of the underlying graph and the quality of the prior information. we also propose a framework to incorporate multiple sources of noisy information. in particular, we consider the setting of weak supervision, where our sources of information are weak labelers. we demonstrate the ability of our approach on multiple benchmark weakly supervised classification tasks, showing improvements upon existing semi-supervised and weakly supervised methods.",,2022-10-07,2023-04-09,"['rattana pukdee', 'dylan sam', 'maria-florina balcan', 'pradeep ravikumar']",https://arxiv.org/pdf/2210.03594.pdf
169,2210.03772,traffic-aware autonomous driving with differentiable traffic simulation,cs.ro cs.ma,"while there have been advancements in autonomous driving control and traffic simulation, there have been little to no works exploring their unification with deep learning. works in both areas seem to focus on entirely different exclusive problems, yet traffic and driving are inherently related in the real world. in this paper, we present traffic-aware autonomous driving (traad), a generalizable distillation-style method for traffic-informed imitation learning that directly optimizes for faster traffic flow and lower energy consumption. traad focuses on the supervision of speed control in imitation learning systems, as most driving research focuses on perception and steering. moreover, our method addresses the lack of co-simulation between traffic and driving simulators and provides a basis for directly involving traffic simulation with autonomous driving in future work. our results show that, with information from traffic simulation involved in the supervision of imitation learning methods, an autonomous vehicle can learn how to accelerate in a fashion that is beneficial for traffic flow and overall energy consumption for all nearby vehicles.",,2022-10-07,2023-04-06,"['laura zheng', 'sanghyun son', 'ming c. lin']",https://arxiv.org/pdf/2210.03772.pdf
170,2210.03879,improving data-efficient fossil segmentation via model editing,cs.cv,"most computer vision research focuses on datasets containing thousands of images of commonplace objects. however, many high-impact datasets, such as those in medicine and the geosciences, contain fine-grain objects that require domain-expert knowledge to recognize and are time-consuming to collect and annotate. as a result, these datasets contain few labeled images, and current machine vision models cannot train intensively on them. originally introduced to correct large-language models, model-editing techniques in machine learning have been shown to improve model performance using only small amounts of data and additional training. using a mask r-cnn to segment ancient reef fossils in rock sample images, we present a two-part paradigm to improve fossil segmentation with few labeled images: we first identify model weaknesses using image perturbations and then mitigate those weaknesses using model editing.   specifically, we apply domain-informed image perturbations to expose the mask r-cnn's inability to distinguish between different classes of fossils and its inconsistency in segmenting fossils with different textures. to address these shortcomings, we extend an existing model-editing method for correcting systematic mistakes in image classification to image segmentation with no additional labeled data needed and show its effectiveness in decreasing confusion between different kinds of fossils. we also highlight the best settings for model editing in our situation: making a single edit using all relevant pixels in one image (vs. using multiple images, multiple edits, or fewer pixels). though we focus on fossil segmentation, our approach may be useful in other similar fine-grain segmentation problems where data is limited.",,2022-10-07,2023-04-09,"['indu panigrahi', 'ryan manzuk', 'adam maloof', 'ruth fong']",https://arxiv.org/pdf/2210.03879.pdf
171,2210.04222,correlative information maximization based biologically plausible neural   networks for correlated source separation,eess.sp cs.lg,"the brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. most prior attempts at this problem proposed neural networks that implement independent component analysis which works under the limitation that latent causes are mutually independent. here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. to derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. the online formulation of this optimization problem naturally leads to neural networks with local learning rules. our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. choices of simplex or polytopic source domains result in networks with piecewise-linear activation functions. we provide numerical examples to demonstrate the superior correlated source separation capability for both synthetic and natural sources.",,2022-10-09,2023-04-08,"['bariscan bozkurt', 'ates isfendiyaroglu', 'cengiz pehlevan', 'alper t. erdogan']",https://arxiv.org/pdf/2210.04222.pdf
172,2210.05178,pre-training for robots: offline rl enables learning new tasks from a   handful of trials,cs.ro cs.lg,"progress in deep learning highlights the tremendous potential of utilizing diverse robotic datasets for attaining effective generalization and makes it enticing to consider leveraging broad datasets for attaining robust generalization in robotic learning as well. however, in practice, we often want to learn a new skill in a new environment that is unlikely to be contained in the prior data. therefore we ask: how can we leverage existing diverse offline datasets in combination with small amounts of task-specific data to solve new tasks, while still enjoying the generalization benefits of training on large amounts of data? in this paper, we demonstrate that end-to-end offline rl can be an effective approach for doing this, without the need for any representation learning or vision-based pre-training. we present pre-training for robots (ptr), a framework based on offline rl that attempts to effectively learn new tasks by combining pre-training on existing robotic datasets with rapid fine-tuning on a new task, with as few as 10 demonstrations. ptr utilizes an existing offline rl method, conservative q-learning (cql), but extends it to include several crucial design decisions that enable ptr to actually work and outperform a variety of prior methods. to our knowledge, ptr is the first rl method that succeeds at learning new tasks in a new domain on a real widowx robot with as few as 10 task demonstrations, by effectively leveraging an existing dataset of diverse multi-task robot data collected in a variety of toy kitchens. we also demonstrate that ptr can enable effective autonomous fine-tuning and improvement in a handful of trials, without needing any demonstrations. an accompanying overview video can be found in the supplementary material and at this anonymous url: https://sites.google.com/view/ptr-rss",,2022-10-11,2023-04-13,"['aviral kumar', 'anikait singh', 'frederik ebert', 'mitsuhiko nakamoto', 'yanlai yang', 'chelsea finn', 'sergey levine']",https://arxiv.org/pdf/2210.05178.pdf
173,2210.06732,equal improvability: a new fairness notion considering the long-term   impact,cs.lg cs.cy,"devising a fair classifier that does not discriminate against different groups is an important problem in machine learning. although researchers have proposed various ways of defining group fairness, most of them only focused on the immediate fairness, ignoring the long-term impact of a fair classifier under the dynamic scenario where each individual can improve its feature over time. such dynamic scenarios happen in real world, e.g., college admission and credit loaning, where each rejected sample makes effort to change its features to get accepted afterwards. in this dynamic setting, the long-term fairness should equalize the samples' feature distribution across different groups after the rejected samples make some effort to improve. in order to promote long-term fairness, we propose a new fairness notion called equal improvability (ei), which equalizes the potential acceptance rate of the rejected samples across different groups assuming a bounded level of effort will be spent by each rejected sample. we analyze the properties of ei and its connections with existing fairness notions. to find a classifier that satisfies the ei requirement, we propose and study three different approaches that solve ei-regularized optimization problems. through experiments on both synthetic and real datasets, we demonstrate that the proposed ei-regularized algorithms encourage us to find a fair classifier in terms of ei. finally, we provide experimental results on dynamic scenarios which highlight the advantages of our ei metric in achieving the long-term fairness. codes are available in a github repository, see https://github.com/guldoganozgur/ei_fairness.",,2022-10-13,2023-04-09,"['ozgur guldogan', 'yuchen zeng', 'jy-yong sohn', 'ramtin pedarsani', 'kangwook lee']",https://arxiv.org/pdf/2210.06732.pdf
174,2210.07713,an empirical evaluation of multivariate time series classification with   input transformation across different dimensions,cs.lg,"in current research, machine and deep learning solutions for the classification of temporal data are shifting from single-channel datasets (univariate) to problems with multiple channels of information (multivariate). the majority of these works are focused on the method novelty and architecture, and the format of the input data is often treated implicitly. particularly, multivariate datasets are often treated as a stack of univariate time series in terms of input preprocessing, with scaling methods applied across each channel separately. in this evaluation, we aim to demonstrate that the additional channel dimension is far from trivial and different approaches to scaling can lead to significantly different results in the accuracy of a solution. to that end, we test seven different data transformation methods on four different temporal dimensions and study their effect on the classification accuracy of five recent methods. we show that, for the large majority of tested datasets, the best transformation-dimension configuration leads to an increase in the accuracy compared to the result of each model with the same hyperparameters and no scaling, ranging from 0.16 to 76.79 percentage points. we also show that if we keep the transformation method constant, there is a statistically significant difference in accuracy results when applying it across different dimensions, with accuracy differences ranging from 0.23 to 47.79 percentage points. finally, we explore the relation of the transformation methods and dimensions to the classifiers, and we conclude that there is no prominent general trend, and the optimal configuration is dataset- and classifier-specific.",10.1109/icmla55696.2022.00012,2022-10-14,2023-04-12,"['leonardos pantiskas', 'kees verstoep', 'mark hoogendoorn', 'henri bal']",https://arxiv.org/pdf/2210.07713.pdf
175,2210.07839,contrastive audio-visual masked autoencoder,cs.mm cs.cv cs.sd eess.as,"in this paper, we first extend the recent masked auto-encoder (mae) model from a single modality to audio-visual multi-modalities. subsequently, we propose the contrastive audio-visual masked auto-encoder (cav-mae) by combining contrastive learning and masked data modeling, two major self-supervised learning frameworks, to learn a joint and coordinated audio-visual representation. our experiments show that the contrastive audio-visual correspondence learning objective not only enables the model to perform audio-visual retrieval tasks, but also helps the model learn a better joint representation. as a result, our fully self-supervised pretrained cav-mae achieves a new sota accuracy of 65.9% on vggsound, and is comparable with the previous best supervised pretrained model on audioset in the audio-visual event classification task. code and pretrained models are at https://github.com/yuangongnd/cav-mae.",,2022-10-02,2023-04-11,"['yuan gong', 'andrew rouditchenko', 'alexander h. liu', 'david harwath', 'leonid karlinsky', 'hilde kuehne', 'james glass']",https://arxiv.org/pdf/2210.07839.pdf
176,2210.08659,anticipatory fleet repositioning for shared-use autonomous mobility   services: an optimization and learning-based approach,eess.sy cs.ai cs.cy cs.sy,"the development of mobility-on-demand services, rich transportation data sources, and autonomous vehicles (avs) creates significant opportunities for shared-use av mobility services (samss) to provide accessible and demand-responsive personal mobility. sams fleet operation involves multiple interrelated decisions, with a primary focus on efficiently fulfilling passenger ride requests with a high level of service quality. this paper focuses on improving the efficiency and service quality of a sams vehicle fleet via anticipatory repositioning of idle vehicles. the rebalancing problem is formulated as a markov decision process, which we propose solving using an advantage actor critic (a2c) reinforcement learning-based method. the proposed approach learns a rebalancing policy that anticipates future demand and cooperates with an optimization-based assignment strategy. the approach allows for centralized repositioning decisions and can handle large vehicle fleets since the problem size does not change with the fleet size. using new york city taxi data and an agent-based simulation tool, two versions of the a2c av repositioning approach are tested. the first version, a2c-avr(a), learns to anticipate future demand based on past observations, while the second, a2c-avr(b), uses demand forecasts. the models are compared to an optimization-based rebalancing approach and show significant reduction in mean passenger waiting times, with a slightly increased percentage of empty fleet miles travelled. the experiments demonstrate the model's ability to anticipate future demand and its transferability to cases unseen at the training stage.",,2022-10-16,2023-04-12,"['monika filipovska', 'michael hyland', 'haimanti bala']",https://arxiv.org/pdf/2210.08659.pdf
177,2210.08711,continuous pseudo-labeling from the start,cs.lg,"self-training (st), or pseudo-labeling has sparked significant interest in the automatic speech recognition (asr) community recently because of its success in harnessing unlabeled data. unlike prior semi-supervised learning approaches that relied on iteratively regenerating pseudo-labels (pls) from a trained model and using them to train a new model, recent state-of-the-art methods perform `continuous training' where pls are generated using a very recent version of the model being trained. nevertheless, these approaches still rely on bootstrapping the st using an initial supervised learning phase where the model is trained on labeled data alone. we believe this has the potential for over-fitting to the labeled dataset in low resource settings and that st from the start of training should reduce over-fitting. in this paper we show how we can do this by dynamically controlling the evolution of pls during the training process in asr. to the best of our knowledge, this is the first study that shows the feasibility of generating pls from the very start of the training. we are able to achieve this using two techniques that avoid instabilities which lead to degenerate models that do not generalize. firstly, we control the evolution of pls through a curriculum that uses the online changes in pls to control the membership of the cache of pls and improve generalization. secondly, we find that by sampling transcriptions from the predictive distribution, rather than only using the best transcription, we can stabilize training further. with these techniques, our st models match prior works without an external language model.",,2022-10-16,2023-04-07,"['dan berrebbi', 'ronan collobert', 'samy bengio', 'navdeep jaitly', 'tatiana likhomanenko']",https://arxiv.org/pdf/2210.08711.pdf
178,2210.09014,addressing contingency in algorithmic (mis)information classification:   toward a responsible machine learning agenda,cs.cy cs.ai cs.lg cs.si,"machine learning (ml) enabled classification models are becoming increasingly popular for tackling the sheer volume and speed of online misinformation and other content that could be identified as harmful. in building these models, data scientists need to take a stance on the legitimacy, authoritativeness and objectivity of the sources of ``truth"" used for model training and testing. this has political, ethical and epistemic implications which are rarely addressed in technical papers. despite (and due to) their reported high accuracy and performance, ml-driven moderation systems have the potential to shape online public debate and create downstream negative impacts such as undue censorship and the reinforcing of false beliefs. using collaborative ethnography and theoretical insights from social studies of science and expertise, we offer a critical analysis of the process of building ml models for (mis)information classification: we identify a series of algorithmic contingencies--key moments during model development that could lead to different future outcomes, uncertainty and harmful effects as these tools are deployed by social media platforms. we conclude by offering a tentative path toward reflexive and responsible development of ml tools for moderating misinformation and other harmful content online.",,2022-10-05,2023-04-13,"['andr√©s dom√≠nguez hern√°ndez', 'richard owen', 'dan saattrup nielsen', 'ryan mcconville']",https://arxiv.org/pdf/2210.09014.pdf
179,2210.10914,prophet attention: predicting attention with future attention for image   captioning,cs.cv cs.cl,"recently, attention based models have been used extensively in many sequence-to-sequence learning systems. especially for image captioning, the attention based models are expected to ground correct image regions with proper generated words. however, for each time step in the decoding process, the attention based models usually use the hidden state of the current input to attend to the image regions. under this setting, these attention models have a ""deviated focus"" problem that they calculate the attention weights based on previous words instead of the one to be generated, impairing the performance of both grounding and captioning. in this paper, we propose the prophet attention, similar to the form of self-supervision. in the training stage, this module utilizes the future information to calculate the ""ideal"" attention weights towards image regions. these calculated ""ideal"" weights are further used to regularize the ""deviated"" attention. in this manner, image regions are grounded with the correct words. the proposed prophet attention can be easily incorporated into existing image captioning models to improve their performance of both grounding and captioning. the experiments on the flickr30k entities and the mscoco datasets show that the proposed prophet attention consistently outperforms baselines in both automatic metrics and human evaluations. it is worth noticing that we set new state-of-the-arts on the two benchmark datasets and achieve the 1st place on the leaderboard of the online mscoco benchmark in terms of the default ranking score, i.e., cider-c40.",,2022-10-19,2023-04-11,"['fenglin liu', 'xuancheng ren', 'xian wu', 'wei fan', 'yuexian zou', 'xu sun']",https://arxiv.org/pdf/2210.10914.pdf
180,2210.11200,removing grid structure in angle-resolved photoemission spectra via deep   learning method,cond-mat.mtrl-sci cs.lg physics.data-an,"spectroscopic data may often contain unwanted extrinsic signals. for example, in arpes experiment, a wire mesh is typically placed in front of the ccd to block stray photo-electrons, but could cause a grid-like structure in the spectra during quick measurement mode. in the past, this structure was often removed using the mathematical fourier filtering method by erasing the periodic structure. however, this method may lead to information loss and vacancies in the spectra because the grid structure is not strictly linearly superimposed. here, we propose a deep learning method to effectively overcome this problem. our method takes advantage of the self-correlation information within the spectra themselves and can greatly optimize the quality of the spectra while removing the grid structure and noise simultaneously. it has the potential to be extended to all spectroscopic measurements to eliminate other extrinsic signals and enhance the spectral quality based on the self-correlation of the spectra solely.",10.1103/physrevb.107.165106,2022-10-20,,"['junde liu', 'dongchen huang', 'yi-feng yang', 'tian qian']",https://arxiv.org/pdf/2210.11200.pdf
181,2210.11452,global convergence of sgd on two layer neural nets,cs.lg math.oc stat.ml,"in this note we demonstrate provable convergence of sgd to the global minima of appropriately regularized $\ell_2-$empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates, if they are using adequately smooth and bounded activations like sigmoid and tanh. we build on the results in [1] and leverage a constant amount of frobenius norm regularization on the weights, along with sampling of the initial weights from an appropriate distribution. we also give a continuous time sgd convergence result that also applies to smooth unbounded activations like softplus. our key idea is to show the existence loss functions on constant sized neural nets which are ""villani functions"". [1] bin shi, weijie j. su, and michael i. jordan. on learning rates and schr\""odinger operators, 2020. arxiv:2004.06977",,2022-10-20,2023-04-08,"['pulkit gopalani', 'anirbit mukherjee']",https://arxiv.org/pdf/2210.11452.pdf
182,2210.13634,vitruvio: 3d building meshes via single perspective sketches,cs.cv cs.ai cs.gr cs.hc,"today's architectural engineering and construction (aec) software require a learning curve to generate a three-dimension building representation. this limits the ability to quickly validate the volumetric implications of an initial design idea communicated via a single sketch. allowing designers to translate a single sketch to a 3d building will enable owners to instantly visualize 3d project information without the cognitive load required. if previous state-of-the-art (sota) data-driven methods for single view reconstruction (svr) showed outstanding results in the reconstruction process from a single image or sketch, they lacked specific applications, analysis, and experiments in the aec. therefore, this research addresses this gap, introducing the first deep learning method focused only on buildings that aim to convert a single sketch to a 3d building mesh: vitruvio. vitruvio adapts occupancy network for svr tasks on a specific building dataset (manhattan 1k). this adaptation brings two main improvements. first, it accelerates the inference process by more than 26% (from 0.5s to 0.37s). second, it increases the reconstruction accuracy (measured by the chamfer distance) by 18%. during this adaptation in the aec domain, we evaluate the effect of the building orientation in the learning procedure since it constitutes an important design factor. while aligning all the buildings to a canonical pose improved the overall quantitative metrics, it did not capture fine-grain details in more complex building shapes (as shown in our qualitative analysis). finally, vitruvio outputs a 3d-printable building mesh with arbitrary topology and genus from a single perspective sketch, providing a step forward to allow owners and designers to communicate 3d information via a 2d, effective, intuitive, and universal communication medium: the sketch.",,2022-10-24,2023-04-11,"['alberto tono', 'heyaojing huang', 'ashwin agrawal', 'martin fischer']",https://arxiv.org/pdf/2210.13634.pdf
183,2210.14386,moment estimation for nonparametric mixture models through implicit   tensor decomposition,math.na cs.na stat.ml,"we present an alternating least squares type numerical optimization scheme to estimate conditionally-independent mixture models in $\mathbb{r}^n$, without parameterizing the distributions. following the method of moments, we tackle an incomplete tensor decomposition problem to learn the mixing weights and componentwise means. then we compute the cumulative distribution functions, higher moments and other statistics of the component distributions through linear solves. crucially for computations in high dimensions, the steep costs associated with high-order tensors are evaded, via the development of efficient tensor-free operations. numerical experiments demonstrate the competitive performance of the algorithm, and its applicability to many models and applications. furthermore we provide theoretical analyses, establishing identifiability from low-order moments of the mixture and guaranteeing local linear convergence of the als algorithm.",,2022-10-25,2023-04-09,"['yifan zhang', 'joe kileel']",https://arxiv.org/pdf/2210.14386.pdf
184,2210.14889,perfectly secure steganography using minimum entropy coupling,cs.cr cs.ai cs.mm,"steganography is the practice of encoding secret information into innocuous content in such a manner that an adversarial third party would not realize that there is hidden meaning. while this problem has classically been studied in security literature, recent advances in generative models have led to a shared interest among security and machine learning researchers in developing scalable steganography techniques. in this work, we show that a steganography procedure is perfectly secure under cachin (1998)'s information theoretic-model of steganography if and only if it is induced by a coupling. furthermore, we show that, among perfectly secure procedures, a procedure is maximally efficient if and only if it is induced by a minimum entropy coupling. these insights yield what are, to the best of our knowledge, the first steganography algorithms to achieve perfect security guarantees with non-trivial efficiency; additionally, these algorithms are highly scalable. to provide empirical validation, we compare a minimum entropy coupling-based approach to three modern baselines -- arithmetic coding, meteor, and adaptive dynamic grouping -- using gpt-2, wavernn, and image transformer as communication channels. we find that the minimum entropy coupling-based approach achieves superior encoding efficiency, despite its stronger security constraints. in aggregate, these results suggest that it may be natural to view information-theoretic steganography through the lens of minimum entropy coupling.",,2022-10-24,2023-04-11,"['christian schroeder de witt', 'samuel sokota', 'j. zico kolter', 'jakob foerster', 'martin strohmeier']",https://arxiv.org/pdf/2210.14889.pdf
185,2210.14891,broken neural scaling laws,cs.lg cs.ai,"we present a smoothly broken power law functional form (referred to by us as a broken neural scaling law (bnsl)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, model input size, number of training steps, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. this set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, ai alignment, robotics, out-of-distribution (ood) generalization, continual learning, transfer learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, sparsity, retrieval, quantization, pruning, fairness, molecules, computer programming/coding, math word problems, ""emergent"" ""phase transitions / changes"", arithmetic, unsupervised/self-supervised learning, & reinforcement learning (single agent & multi-agent). when compared to other functional forms for neural scaling behavior, this functional form yields extrapolations of scaling behavior that are considerably more accurate on this set. moreover, this functional form accurately models & extrapolates scaling behavior that other functional forms are incapable of expressing such as the non-monotonic transitions present in the scaling behavior of phenomena such as double descent & the delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. lastly, we use this functional form to glean insights about the limit of the predictability of scaling behavior. code is available at https://github.com/ethancaballero/broken_neural_scaling_laws",,2022-10-26,2023-04-10,"['ethan caballero', 'kshitij gupta', 'irina rish', 'david krueger']",https://arxiv.org/pdf/2210.14891.pdf
186,2210.16193,m3fgm:a node masking and multi-granularity message passing-based   federated graph model for spatial-temporal data prediction,cs.lg cs.ai,"researchers are solving the challenges of spatial-temporal prediction by combining federated learning (fl) and graph models with respect to the constrain of privacy and security. in order to make better use of the power of graph model, some researchs also combine split learning(sl). however, there are still several issues left unattended: 1) clients might not be able to access the server during inference phase; 2) the graph of clients designed manually in the server model may not reveal the proper relationship between clients. this paper proposes a new gnn-oriented split federated learning method, named node {\bfseries m}asking and {\bfseries m}ulti-granularity {\bfseries m}essage passing-based federated graph model (m$^3$fgm) for the above issues. for the first issue, the server model of m$^3$fgm employs a masknode layer to simulate the case of clients being offline. we also redesign the decoder of the client model using a dual-sub-decoders structure so that each client model can use its local data to predict independently when offline. as for the second issue, a new gnn layer named multi-granularity message passing (mgmp) layer enables each client node to perceive global and local information. we conducted extensive experiments in two different scenarios on two real traffic datasets. results show that m$^3$fgm outperforms the baselines and variant models, achieves the best results in both datasets and scenarios.",,2022-10-27,2023-04-12,"['yuxing tian', 'zheng liu', 'yanwen qu', 'song li', 'jiachi luo']",https://arxiv.org/pdf/2210.16193.pdf
187,2210.16307,investigation of chemical structure recognition by encoder-decoder   models in learning progress,physics.chem-ph cs.lg q-bio.bm,"descriptor generation methods using latent representations of encoder$-$decoder (ed) models with smiles as input are useful because of the continuity of descriptor and restorability to the structure. however, it is not clear how the structure is recognized in the learning progress of ed models. in this work, we created ed models of various learning progress and investigated the relationship between structural information and learning progress. we showed that compound substructures were learned early in ed models by monitoring the accuracy of downstream tasks and input$-$output substructure similarity using substructure$-$based descriptors, which suggests that existing evaluation methods based on the accuracy of downstream tasks may not be sensitive enough to evaluate the performance of ed models with smiles as descriptor generation methods. on the other hand, we showed that structure restoration was time$-$consuming, and in particular, insufficient learning led to the estimation of a larger structure than the actual one. it can be inferred that determining the endpoint of the structure is a difficult task for the model. to our knowledge, this is the first study to link the learning progress of smiles by ed model to chemical structures for a wide range of chemicals.",10.1021/acs.jcim.2c00765,2022-10-24,2023-03-07,"['shumpei nemoto', 'tadahaya mizuno', 'hiroyuki kusuhara']",https://arxiv.org/pdf/2210.16307.pdf
188,2210.17051,accelerating carbon capture and storage modeling using fourier neural   operators,cs.lg physics.flu-dyn,"carbon capture and storage (ccs) is an important strategy for reducing carbon dioxide emissions and mitigating climate change. we consider the storage aspect of ccs, which involves injecting carbon dioxide into underground reservoirs. this requires accurate and high-resolution predictions of carbon dioxide plume migration and reservoir pressure buildup. however, such modeling is challenging at scale due to the high computational costs of existing numerical methods. we introduce a novel machine learning approach for four-dimensional spatial-temporal modeling, which speeds up predictions nearly 700,000 times compared to existing methods. it provides highly accurate predictions under diverse reservoir conditions, geological heterogeneity, and injection schemes. our framework, nested fourier neural operator (fno), learns the solution operator for the family of partial differential equations governing the carbon dioxide-water multiphase flow. it uses a hierarchy of fno models to produce outputs at different refinement levels. thus, our approach enables unprecedented real-time high-resolution modeling for carbon dioxide storage.",10.1039/d2ee04204e,2022-10-31,,"['gege wen', 'zongyi li', 'qirui long', 'kamyar azizzadenesheli', 'anima anandkumar', 'sally m. benson']",https://arxiv.org/pdf/2210.17051.pdf
189,2211.00024,a robust estimator of mutual information for deep learning   interpretability,physics.data-an astro-ph.im cs.lg,"we develop the use of mutual information (mi), a well-established metric in information theory, to interpret the inner workings of deep learning models. to accurately estimate mi from a finite number of samples, we present gmm-mi (pronounced $``$jimmie$""$), an algorithm based on gaussian mixture models that can be applied to both discrete and continuous settings. gmm-mi is computationally efficient, robust to the choice of hyperparameters and provides the uncertainty on the mi estimate due to the finite sample size. we extensively validate gmm-mi on toy data for which the ground truth mi is known, comparing its performance against established mutual information estimators. we then demonstrate the use of our mi estimator in the context of representation learning, working with synthetic data and physical datasets describing highly non-linear processes. we train deep learning models to encode high-dimensional data within a meaningful compressed (latent) representation, and use gmm-mi to quantify both the level of disentanglement between the latent variables, and their association with relevant physical quantities, thus unlocking the interpretability of the latent representation. we make gmm-mi publicly available.",10.1088/2632-2153/acc444,2022-10-31,2023-03-23,"['davide piras', 'hiranya v. peiris', 'andrew pontzen', 'luisa lucie-smith', 'ningyuan guo', 'brian nord']",https://arxiv.org/pdf/2211.00024.pdf
190,2211.01280,an exponentially converging particle method for the mixed nash   equilibrium of continuous games,math.oc cs.gt cs.lg,"we consider the problem of computing mixed nash equilibria of two-player zero-sum games with continuous sets of pure strategies and with first-order access to the payoff function. this problem arises for example in game-theory-inspired machine learning applications, such as distributionally-robust learning. in those applications, the strategy sets are high-dimensional and thus methods based on discretisation cannot tractably return high-accuracy solutions.   in this paper, we introduce and analyze a particle-based method that enjoys guaranteed local convergence for this problem. this method consists in parametrizing the mixed strategies as atomic measures and applying proximal point updates to both the atoms' weights and positions. it can be interpreted as a time-implicit discretization of the ""interacting"" wasserstein-fisher-rao gradient flow.   we prove that, under non-degeneracy assumptions, this method converges at an exponential rate to the exact mixed nash equilibrium from any initialization satisfying a natural notion of closeness to optimality. we illustrate our results with numerical experiments and discuss applications to max-margin and distributionally-robust classification using two-layer neural networks, where our method has a natural interpretation as a simultaneous training of the network's weights and of the adversarial distribution.",,2022-11-02,2023-04-13,"['guillaume wang', 'l√©na√Øc chizat']",https://arxiv.org/pdf/2211.01280.pdf
191,2211.01562,pinto: faithful language reasoning using prompt-generated rationales,cs.cl,"neural language models (lms) have achieved impressive results on various language-based reasoning tasks by utilizing latent knowledge encoded in their own pretrained parameters. to make this reasoning process more explicit, recent works retrieve a rationalizing lm's internal knowledge by training or prompting it to generate free-text rationales, which can be used to guide task predictions made by either the same lm or a separate reasoning lm. however, rationalizing lms require expensive rationale annotation and/or computation, without any assurance that their generated rationales improve lm task performance or faithfully reflect lm decision-making. in this paper, we propose pinto, an lm pipeline that rationalizes via prompt-based learning, and learns to faithfully reason over rationales via counterfactual regularization. first, pinto maps out a suitable reasoning process for the task input by prompting a frozen rationalizing lm to generate a free-text rationale. second, pinto's reasoning lm is fine-tuned to solve the task using the generated rationale as context, while regularized to output less confident predictions when the rationale is perturbed. across four datasets, we show that pinto significantly improves the generalization ability of the reasoning lm, yielding higher performance on both in-distribution and out-of-distribution test sets. also, we find that pinto's rationales are more faithful to its task predictions than those generated by competitive baselines.",,2022-11-02,2023-04-06,"['peifeng wang', 'aaron chan', 'filip ilievski', 'muhao chen', 'xiang ren']",https://arxiv.org/pdf/2211.01562.pdf
192,2211.01668,quantum similarity testing with convolutional neural networks,quant-ph cs.lg,"the task of testing whether two uncharacterized quantum devices behave in the same way is crucial for benchmarking near-term quantum computers and quantum simulators, but has so far remained open for continuous-variable quantum systems. in this letter, we develop a machine learning algorithm for comparing unknown continuous variable states using limited and noisy data. the algorithm works on non-gaussian quantum states for which similarity testing could not be achieved with previous techniques. our approach is based on a convolutional neural network that assesses the similarity of quantum states based on a lower-dimensional state representation built from measurement data. the network can be trained offline with classically simulated data from a fiducial set of states sharing structural similarities with the states to be tested, or with experimental data generated by measurements on the fiducial states, or with a combination of simulated and experimental data. we test the performance of the model on noisy cat states and states generated by arbitrary selective number-dependent phase gates. our network can also be applied to the problem of comparing continuous variable states across different experimental platforms, with different sets of achievable measurements, and to the problem of experimentally testing whether two states are equivalent up to gaussian unitary transformations.",,2022-11-03,2023-04-13,"['ya-dong wu', 'yan zhu', 'ge bai', 'yuexuan wang', 'giulio chiribella']",https://arxiv.org/pdf/2211.01668.pdf
193,2211.02165,twenty-five years of advances in beamforming: from convex and nonconvex   optimization to learning techniques,eess.sp cs.it math.it,"beamforming is a signal processing technique to steer, shape, and focus an electromagnetic wave using an array of sensors toward a desired direction. it has been used in several engineering applications such as radar, sonar, acoustics, astronomy, seismology, medical imaging, and communications. with the advances in multi-antenna technologies largely for radar and communications, there has been a great interest on beamformer design mostly relying on convex/nonconvex optimization. recently, machine learning is being leveraged for obtaining attractive solutions to more complex beamforming problems. this article captures the evolution of beamforming in the last twenty-five years from convex-to-nonconvex optimization and optimization-to-learning approaches. it provides a glimpse of this important signal processing technique into a variety of transmit-receive architectures, propagation zones, paths, and conventional/emerging applications.",10.1109/msp.2023.3262366,2022-11-03,2023-03-22,"['ahmet m. elbir', 'kumar vijay mishra', 'sergiy a. vorobyov', 'robert w. heath']",https://arxiv.org/pdf/2211.02165.pdf
194,2211.02763,bayesian learning of causal structure and mechanisms with gflownets and   variational bayes,cs.lg stat.ml,"bayesian causal structure learning aims to learn a posterior distribution over directed acyclic graphs (dags), and the mechanisms that define the relationship between parent and child variables. by taking a bayesian approach, it is possible to reason about the uncertainty of the causal model. the notion of modelling the uncertainty over models is particularly crucial for causal structure learning since the model could be unidentifiable when given only a finite amount of observational data. in this paper, we introduce a novel method to jointly learn the structure and mechanisms of the causal model using variational bayes, which we call variational bayes-dag-gflownet (vbg). we extend the method of bayesian causal structure learning using gflownets to learn not only the posterior distribution over the structure, but also the parameters of a linear-gaussian model. our results on simulated data suggest that vbg is competitive against several baselines in modelling the posterior over dags and mechanisms, while offering several advantages over existing methods, including the guarantee to sample acyclic graphs, and the flexibility to generalize to non-linear causal mechanisms.",,2022-11-04,2023-04-08,"['mizu nishikawa-toomey', 'tristan deleu', 'jithendaraa subramanian', 'yoshua bengio', 'laurent charlin']",https://arxiv.org/pdf/2211.02763.pdf
195,2211.02947,prototypical quadruplet for few-shot class incremental learning,cs.cv cs.lg,"scarcity of data and incremental learning of new tasks pose two major bottlenecks for many modern computer vision algorithms. the phenomenon of catastrophic forgetting, i.e., the model's inability to classify previously learned data after training with new batches of data, is a major challenge. conventional methods address catastrophic forgetting while compromising the current session's training. generative replay-based approaches, such as generative adversarial networks (gans), have been proposed to mitigate catastrophic forgetting, but training gans with few samples may lead to instability. to address these challenges, we propose a novel method that improves classification robustness by identifying a better embedding space using an improved contrasting loss. our approach retains previously acquired knowledge in the embedding space, even when trained with new classes, by updating previous session class prototypes to represent the true class mean, which is crucial for our nearest class mean classification strategy. we demonstrate the effectiveness of our method by showing that the embedding space remains intact after training the model with new classes and outperforms existing state-of-the-art algorithms in terms of accuracy across different sessions.",,2022-11-05,2023-04-08,"['sanchar palit', 'biplab banerjee', 'subhasis chaudhuri']",https://arxiv.org/pdf/2211.02947.pdf
196,2211.04339,toward adaptive semantic communications: efficient data transmission via   online learned nonlinear transform source-channel coding,cs.it cs.lg eess.sp math.it,"the emerging field semantic communication is driving the research of end-to-end data transmission. by utilizing the powerful representation ability of deep learning models, learned data transmission schemes have exhibited superior performance than the established source and channel coding methods. while, so far, research efforts mainly concentrated on architecture and model improvements toward a static target domain. despite their successes, such learned models are still suboptimal due to the limitations in model capacity and imperfect optimization and generalization, particularly when the testing data distribution or channel response is different from that adopted for model training, as is likely to be the case in real-world. to tackle this, we propose a novel online learned joint source and channel coding approach that leverages the deep learning model's overfitting property. specifically, we update the off-the-shelf pre-trained models after deployment in a lightweight online fashion to adapt to the distribution shifts in source data and environment domain. we take the overfitting concept to the extreme, proposing a series of implementation-friendly methods to adapt the codec model or representations to an individual data or channel state instance, which can further lead to substantial gains in terms of the bandwidth ratio-distortion performance. the proposed methods enable the communication-efficient adaptation for all parameters in the network without sacrificing decoding speed. our experiments, including user study, on continually changing target source data and wireless channel environments, demonstrate the effectiveness and efficiency of our approach, on which we outperform existing state-of-the-art engineered transmission scheme (vvc combined with 5g ldpc coded transmission).",,2022-11-08,2023-04-11,"['jincheng dai', 'sixian wang', 'ke yang', 'kailin tan', 'xiaoqi qin', 'zhongwei si', 'kai niu', 'ping zhang']",https://arxiv.org/pdf/2211.04339.pdf
197,2211.04658,supra: superpixel guided loss for improved multi-modal segmentation in   endoscopy,cs.cv cs.lg q-bio.qm,"domain shift is a well-known problem in the medical imaging community. in particular, for endoscopic image analysis where the data can have different modalities the performance of deep learning (dl) methods gets adversely affected. in other words, methods developed on one modality cannot be used for a different modality. however, in real clinical settings, endoscopists switch between modalities for better mucosal visualisation. in this paper, we explore the domain generalisation technique to enable dl methods to be used in such scenarios. to this extend, we propose to use super pixels generated with simple linear iterative clustering (slic) which we refer to as ""supra"" for superpixel augmented method. supra first generates a preliminary segmentation mask making use of our new loss ""slicloss"" that encourages both an accurate and color-consistent segmentation. we demonstrate that slicloss when combined with binary cross entropy loss (bce) can improve the model's generalisability with data that presents significant domain shift. we validate this novel compound loss on a vanilla u-net using the endouda dataset, which contains images for barret's esophagus and polyps from two modalities. we show that our method yields an improvement of nearly 20% in the target domain set compared to the baseline.",,2022-11-08,2023-04-09,"['rafael martinez-garcia-pe√±a', 'mansoor ali teevno', 'gilberto ochoa-ruiz', 'sharib ali']",https://arxiv.org/pdf/2211.04658.pdf
198,2211.05207,interpretable machine learning system to eeg patterns on the   ictal-interictal-injury continuum,cs.cv cs.ai cs.lg,"in intensive care units (icus), critically ill patients are monitored with electroencephalograms (eegs) to prevent serious brain injury. the number of patients who can be monitored is constrained by the availability of trained physicians to read eegs, and eeg interpretation can be subjective and prone to inter-observer variability. automated deep learning systems for eeg could reduce human bias and accelerate the diagnostic process. however, black box deep learning models are untrustworthy, difficult to troubleshoot, and lack accountability in real-world applications, leading to a lack of trust and adoption by clinicians. to address these challenges, we propose a novel interpretable deep learning model that not only predicts the presence of harmful brainwave patterns but also provides high-quality case-based explanations of its decisions. our model performs better than the corresponding black box model, despite being constrained to be interpretable. the learned 2d embedded space provides the first global overview of the structure of ictal-interictal-injury continuum brainwave patterns. the ability to understand how our model arrived at its decisions will not only help clinicians to diagnose and treat harmful brain activities more accurately but also increase their trust and adoption of machine learning models in clinical practice; this could be an integral component of the icu neurologists' standard workflow.",,2022-11-09,2023-04-11,"['alina jade barnett', 'zhicheng guo', 'jin jing', 'wendong ge', 'cynthia rudin', 'm. brandon westover']",https://arxiv.org/pdf/2211.05207.pdf
199,2211.06512,stackelberg meta-learning based control for guided cooperative lqg   systems,eess.sy cs.sy,"guided cooperation allows intelligent agents with heterogeneous capabilities to work together by following a leader-follower type of interaction. however, the associated control problem becomes challenging when the leader agent does not have complete information about follower agents. there is a need for learning and adaptation of cooperation plans. to this end, we develop a meta-learning-based stackelberg game-theoretic framework to address the challenges in the guided cooperative control for linear systems. we first formulate the guided cooperation between agents as a dynamic stackelberg game and use the feedback stackelberg equilibrium as the agent-wise cooperation strategy. we further leverage meta-learning to address the incomplete information of follower agents, where the leader agent learns a meta-response model from a prescribed set of followers offline and adapts to a new coming cooperation task with a small amount of learning data. we use a case study in robot teaming to corroborate the effectiveness of our framework. comparison with other learning approaches also shows that our learned cooperation strategy provides better transferability for different cooperation tasks.",,2022-11-11,2023-04-06,"['yuhan zhao', 'quanyan zhu']",https://arxiv.org/pdf/2211.06512.pdf
200,2211.06524,quantum split neural network learning using cross-channel pooling,quant-ph cs.ai cs.lg,"in recent years, the field of quantum science has attracted significant interest across various disciplines, including quantum machine learning, quantum communication, and quantum computing. among these emerging areas, quantum federated learning (qfl) has gained particular attention due to the integration of quantum neural networks (qnns) with traditional federated learning (fl) techniques. in this study, a novel approach entitled quantum split learning (qsl) is presented, which represents an advanced extension of classical split learning. previous research in classical computing has demonstrated numerous advantages of split learning, such as accelerated convergence, reduced communication costs, and enhanced privacy protection. to maximize the potential of qsl, cross-channel pooling is introduced, a technique that capitalizes on the distinctive properties of quantum state tomography facilitated by qnns. through rigorous numerical analysis, evidence is provided that qsl not only achieves a 1.64\% higher top-1 accuracy compared to qfl but also demonstrates robust privacy preservation in the context of the mnist classification task.",,2022-11-11,2023-04-08,"['won joon yun', 'hankyul baek', 'joongheon kim']",https://arxiv.org/pdf/2211.06524.pdf
201,2211.06687,large-scale contrastive language-audio pretraining with feature fusion   and keyword-to-caption augmentation,cs.sd eess.as,"contrastive learning has shown remarkable success in the field of multimodal representation learning. in this paper, we propose a pipeline of contrastive language-audio pretraining to develop an audio representation by combining audio data with natural language descriptions. to accomplish this target, we first release laion-audio-630k, a large collection of 633,526 audio-text pairs from different data sources. second, we construct a contrastive language-audio pretraining model by considering different audio encoders and text encoders. we incorporate the feature fusion mechanism and keyword-to-caption augmentation into the model design to further enable the model to process audio inputs of variable lengths and enhance the performance. third, we perform comprehensive experiments to evaluate our model across three tasks: text-to-audio retrieval, zero-shot audio classification, and supervised audio classification. the results demonstrate that our model achieves superior performance in text-to-audio retrieval task. in audio classification tasks, the model achieves state-of-the-art performance in the zero-shot setting and is able to obtain performance comparable to models' results in the non-zero-shot setting. laion-audio-630k and the proposed model are both available to the public.",,2022-11-12,2023-04-07,"['yusong wu', 'ke chen', 'tianyu zhang', 'yuchen hui', 'taylor berg-kirkpatrick', 'shlomo dubnov']",https://arxiv.org/pdf/2211.06687.pdf
202,2211.07126,discharge summary hospital course summarisation of in patient electronic   health record text with clinical concept guided deep pre-trained transformer   models,cs.cl,"brief hospital course (bhc) summaries are succinct summaries of an entire hospital encounter, embedded within discharge summaries, written by senior clinicians responsible for the overall care of a patient. methods to automatically produce summaries from inpatient documentation would be invaluable in reducing clinician manual burden of summarising documents under high time-pressure to admit and discharge patients. automatically producing these summaries from the inpatient course, is a complex, multi-document summarisation task, as source notes are written from various perspectives (e.g. nursing, doctor, radiology), during the course of the hospitalisation. we demonstrate a range of methods for bhc summarisation demonstrating the performance of deep learning summarisation models across extractive and abstractive summarisation scenarios. we also test a novel ensemble extractive and abstractive summarisation model that incorporates a medical concept ontology (snomed) as a clinical guidance signal and shows superior performance in 2 real-world clinical data sets.",10.1016/j.jbi.2023.104358,2022-11-14,2023-04-10,"['thomas searle', 'zina ibrahim', 'james teo', 'richard dobson']",https://arxiv.org/pdf/2211.07126.pdf
203,2211.07881,et-al: entropy-targeted active learning for bias mitigation in materials   data,cond-mat.mtrl-sci cs.db cs.lg,"growing materials data and data-driven informatics drastically promote the discovery and design of materials. while there are significant advancements in data-driven models, the quality of data resources is less studied despite its huge impact on model performance. in this work, we focus on data bias arising from uneven coverage of materials families in existing knowledge. observing different diversities among crystal systems in common materials databases, we propose an information entropy-based metric for measuring this bias. to mitigate the bias, we develop an entropy-targeted active learning (et-al) framework, which guides the acquisition of new data to improve the diversity of underrepresented crystal systems. we demonstrate the capability of et-al for bias mitigation and the resulting improvement in downstream machine learning models. this approach is broadly applicable to data-driven materials discovery, including autonomous data acquisition and dataset trimming to reduce bias, as well as data-driven informatics in other scientific domains.",10.1063/5.0138913,2022-11-14,2023-02-19,"['hengrui zhang', 'wei wayne chen', 'james m. rondinelli', 'wei chen']",https://arxiv.org/pdf/2211.07881.pdf
204,2211.08573,realization of causal representation learning and redefined dag for   causal ai,cs.lg stat.me,"causal dag(directed acyclic graph) usually lies in a 2d plane without distinguishing correlation changes and causal effects. also, the causal effect is often approximately estimated by averaging the population's correlation changes. now, ai(artificial intelligence) enables much larger-scale structural modeling, whose complex hidden confoundings make the approximation errors no longer ignorable but can snowball to considerable population-level causal representation bias. such bias has caused significant problems: ungeneralizable causal models, unrevealed individual-level features, not utilizable causal knowledge in dl(deep learning), etc. in short, dag must be redefined to enable a new framework for causal ai.   observational time series can only reflect correlation changes in statistics. but the dl-based autoencoder can represent them as individual-level feature changes in latent space to reflect causal effects. in this paper, we introduce the redefined do-dag concept and propose causal representation learning (crl) framework as the generic solution, along with a novel architecture to realize crl and experimentally verify its feasibility.",,2022-11-15,2023-04-12,"['jia li', 'xiang li', 'xiaowei jia', 'michael steinbach', 'vipin kumar']",https://arxiv.org/pdf/2211.08573.pdf
205,2211.08591,exploring supervised machine learning for multi-phase identification and   quantification from powder x-ray diffraction spectra,cond-mat.mtrl-sci cs.lg,"powder x-ray diffraction analysis is a critical component of materials characterization methodologies. discerning characteristic bragg intensity peaks and assigning them to known crystalline phases is the first qualitative step of evaluating diffraction spectra. subsequent to phase identification, rietveld refinement may be employed to extract the abundance of quantitative, material-specific parameters hidden within powder data. these characterization procedures are yet time-consuming and inhibit efficiency in materials science workflows. the ever-increasing popularity and propulsion of data science techniques has provided an obvious solution on the course towards materials analysis automation. deep learning has become a prime focus for predicting crystallographic parameters and features from x-ray spectra. however, the infeasibility of curating large, well-labelled experimental datasets means that one must resort to a large number of theoretic simulations for powder data augmentation to effectively train deep models. herein, we are interested in conventional supervised learning algorithms in lieu of deep learning for multi-label crystalline phase identification and quantitative phase analysis for a biomedical application. first, models were trained using very limited experimental data. further, we incorporated simulated xrd data to assess model generalizability as well as the efficacy of simulation-based training for predictive analysis in a real-world x-ray diffraction application.",10.1007/s10853-023-08343-4,2022-11-15,,"['jaimie greasley', 'patrick hosein']",https://arxiv.org/pdf/2211.08591.pdf
206,2211.09119,token turing machines,cs.lg cs.cv cs.ro,"we propose token turing machines (ttm), a sequential, autoregressive transformer model with memory for real-world sequential visual understanding. our model is inspired by the seminal neural turing machine, and has an external memory consisting of a set of tokens which summarise the previous history (i.e., frames). this memory is efficiently addressed, read and written using a transformer as the processing unit/controller at each step. the model's memory module ensures that a new observation will only be processed with the contents of the memory (and not the entire history), meaning that it can efficiently process long sequences with a bounded computational cost at each step. we show that ttm outperforms other alternatives, such as other transformer models designed for long sequences and recurrent neural networks, on two real-world sequential visual understanding tasks: online temporal activity detection from videos and vision-based robot action policy learning.   code is publicly available at: https://github.com/google-research/scenic/tree/main/scenic/projects/token_turing",,2022-11-16,2023-04-13,"['michael s. ryoo', 'keerthana gopalakrishnan', 'kumara kahatapitiya', 'ted xiao', 'kanishka rao', 'austin stone', 'yao lu', 'julian ibarz', 'anurag arnab']",https://arxiv.org/pdf/2211.09119.pdf
207,2211.09981,weighted ensemble self-supervised learning,cs.lg cs.ai stat.ml,"ensembling has proven to be a powerful technique for boosting model performance, uncertainty estimation, and robustness in supervised learning. advances in self-supervised learning (ssl) enable leveraging large unlabeled corpora for state-of-the-art few-shot and supervised learning performance. in this paper, we explore how ensemble methods can improve recent ssl techniques by developing a framework that permits data-dependent weighted cross-entropy losses. we refrain from ensembling the representation backbone; this choice yields an efficient ensemble method that incurs a small training cost and requires no architectural changes or computational overhead to downstream evaluation. the effectiveness of our method is demonstrated with two state-of-the-art ssl methods, dino (caron et al., 2021) and msn (assran et al., 2022). our method outperforms both in multiple evaluation metrics on imagenet-1k, particularly in the few-shot setting. we explore several weighting schemes and find that those which increase the diversity of ensemble heads lead to better downstream evaluation results. thorough experiments yield improved prior art baselines which our method still surpasses; e.g., our overall improvement with msn vit-b/16 is 3.9 p.p. for 1-shot learning.",,2022-11-17,2023-04-09,"['yangjun ruan', 'saurabh singh', 'warren morningstar', 'alexander a. alemi', 'sergey ioffe', 'ian fischer', 'joshua v. dillon']",https://arxiv.org/pdf/2211.09981.pdf
208,2211.10832,neurosketch: fast and approximate evaluation of range aggregate queries   with neural networks,cs.db,"range aggregate queries (raqs) are an integral part of many real-world applications, where, often, fast and approximate answers for the queries are desired. recent work has studied answering raqs using machine learning (ml) models, where a model of the data is learned to answer the queries. however, there is no theoretical understanding of why and when the ml based approaches perform well. furthermore, since the ml approaches model the data, they fail to capitalize on any query specific information to improve performance in practice. in this paper, we focus on modeling ``queries'' rather than data and train neural networks to learn the query answers. this change of focus allows us to theoretically study our ml approach to provide a distribution and query dependent error bound for neural networks when answering raqs. we confirm our theoretical results by developing neurosketch, a neural network framework to answer raqs in practice. extensive experimental study on real-world, tpc-benchmark and synthetic datasets show that neurosketch answers raqs multiple orders of magnitude faster than state-of-the-art and with better accuracy.",,2022-11-19,2023-04-07,"['sepanta zeighami', 'cyrus shahabi', 'vatsal sharan']",https://arxiv.org/pdf/2211.10832.pdf
209,2211.10853,demon in the machine: learning to extract work and absorb entropy from   fluctuating nanosystems,cond-mat.stat-mech cs.ne,"we use monte carlo and genetic algorithms to train neural-network feedback-control protocols for simulated fluctuating nanosystems. these protocols convert the information obtained by the feedback process into heat or work, allowing the extraction of work from a colloidal particle pulled by an optical trap and the absorption of entropy by an ising model undergoing magnetization reversal. the learning framework requires no prior knowledge of the system, depends only upon measurements that are accessible experimentally, and scales to systems of considerable complexity. it could be used in the laboratory to learn protocols for fluctuating nanosystems that convert measurement information into stored work or heat.",10.1103/physrevx.13.021005,2022-11-19,2023-04-10,['stephen whitelam'],https://arxiv.org/pdf/2211.10853.pdf
210,2211.11061,deep learning delay coordinate dynamics for chaotic attractors from   partial observable data,cs.lg nlin.cd,"a common problem in time series analysis is to predict dynamics with only scalar or partial observations of the underlying dynamical system. for data on a smooth compact manifold, takens theorem proves a time delayed embedding of the partial state is diffeomorphic to the attractor, although for chaotic and highly nonlinear systems learning these delay coordinate mappings is challenging. we utilize deep artificial neural networks (anns) to learn discrete discrete time maps and continuous time flows of the partial state. given training data for the full state, we also learn a reconstruction map. thus, predictions of a time series can be made from the current state and several previous observations with embedding parameters determined from time series analysis. the state space for time evolution is of comparable dimension to reduced order manifold models. these are advantages over recurrent neural network models, which require a high dimensional internal state or additional memory terms and hyperparameters. we demonstrate the capacity of deep anns to predict chaotic behavior from a scalar observation on a manifold of dimension three via the lorenz system. we also consider multivariate observations on the kuramoto-sivashinsky equation, where the observation dimension required for accurately reproducing dynamics increases with the manifold dimension via the spatial extent of the system.",10.1103/physreve.107.034215,2022-11-20,,"['charles d. young', 'michael d. graham']",https://arxiv.org/pdf/2211.11061.pdf
211,2211.11316,ehsnet: end-to-end holistic learning network for large-size remote   sensing image semantic segmentation,cs.cv,"this paper presents ehsnet, a new end-to-end segmentation network designed for the holistic learning of large-size remote sensing image semantic segmentation (lriss). large-size remote sensing images (lris) can lead to gpu memory exhaustion due to their extremely large size, which has been handled in previous works through either global-local fusion or multi-stage refinement, both of which are limited in their ability to fully exploit the abundant information available in lris. unlike them, ehsnet features three memory-friendly modules to utilize the characteristics of lris: a long-range dependency module to develop long-range spatial context, an efficient cross-correlation module to build holistic contextual relationships, and a boundary-aware enhancement module to preserve complete object boundaries. moreover, ehsnet manages to process holistic lriss with the aid of memory offloading. to the best of our knowledge, ehsnet is the first method capable of performing holistic lriss. to make matters better, ehsnet outperforms previous state-of-the-art competitors by a significant margin of +5.65 miou on fbp and +4.28 miou on inria aerial, demonstrating its effectiveness. we hope that ehsnet will provide a new perspective for lriss. the code and models will be made publicly available.",,2022-11-21,2023-04-10,"['wei chen', 'yansheng li', 'bo dang', 'yongjun zhang']",https://arxiv.org/pdf/2211.11316.pdf
212,2211.11761,from node interaction to hop interaction: new effective and scalable   graph learning paradigm,cs.lg,"existing graph neural networks (gnns) follow the message-passing mechanism that conducts information interaction among nodes iteratively. while considerable progress has been made, such node interaction paradigms still have the following limitation. first, the scalability limitation precludes the broad application of gnns in large-scale industrial settings since the node interaction among rapidly expanding neighbors incurs high computation and memory costs. second, the over-smoothing problem restricts the discrimination ability of nodes, i.e., node representations of different classes will converge to indistinguishable after repeated node interactions. in this work, we propose a novel hop interaction paradigm to address these limitations simultaneously. the core idea is to convert the interaction target among nodes to pre-processed multi-hop features inside each node. we design a simple yet effective hopgnn framework that can easily utilize existing gnns to achieve hop interaction. furthermore, we propose a multi-task learning strategy with a self-supervised learning objective to enhance hopgnn. we conduct extensive experiments on 12 benchmark datasets in a wide range of domains, scales, and smoothness of graphs. experimental results show that our methods achieve superior performance while maintaining high scalability and efficiency. the code is at https://github.com/jc-202/hopgnn.",,2022-11-21,2023-04-13,"['jie chen', 'zilong li', 'yin zhu', 'junping zhang', 'jian pu']",https://arxiv.org/pdf/2211.11761.pdf
213,2211.12005,self-ensemble protection: training checkpoints are good data protectors,cs.lg cs.cr stat.ml,"as data becomes increasingly vital, a company would be very cautious about releasing data, because the competitors could use it to train high-performance models, thereby posing a tremendous threat to the company's commercial competence. to prevent training good models on the data, we could add imperceptible perturbations to it. since such perturbations aim at hurting the entire training process, they should reflect the vulnerability of dnn training, rather than that of a single model. based on this new idea, we seek perturbed examples that are always unrecognized (never correctly classified) in training. in this paper, we uncover them by model checkpoints' gradients, forming the proposed self-ensemble protection (sep), which is very effective because (1) learning on examples ignored during normal training tends to yield dnns ignoring normal examples; (2) checkpoints' cross-model gradients are close to orthogonal, meaning that they are as diverse as dnns with different architectures. that is, our amazing performance of ensemble only requires the computation of training one model. by extensive experiments with 9 baselines on 3 datasets and 5 architectures, sep is verified to be a new state-of-the-art, e.g., our small $\ell_\infty=2/255$ perturbations reduce the accuracy of a cifar-10 resnet18 from 94.56% to 14.68%, compared to 41.35% by the best-known method. code is available at https://github.com/sizhe-chen/sep.",,2022-11-21,2023-04-12,"['sizhe chen', 'geng yuan', 'xinwen cheng', 'yifan gong', 'minghai qin', 'yanzhi wang', 'xiaolin huang']",https://arxiv.org/pdf/2211.12005.pdf
214,2211.12817,reason from context with self-supervised learning,cs.cv cs.ai,"self-supervised learning (ssl) learns to capture discriminative visual features useful for knowledge transfers. to better accommodate the object-centric nature of current downstream tasks such as object recognition and detection, various methods have been proposed to suppress contextual biases or disentangle objects from contexts. nevertheless, these methods may prove inadequate in situations where object identity needs to be reasoned from associated context, such as recognizing or inferring tiny or obscured objects. as an initial effort in the ssl literature, we investigate whether and how contextual associations can be enhanced for visual reasoning within ssl regimes, by (a) proposing a new self-supervised method with external memories for context reasoning (seco), and (b) introducing two new downstream tasks, lift-the-flap and object priming, addressing the problems of ""what"" and ""where"" in context reasoning. in both tasks, seco outperformed all state-of-the-art (sota) ssl methods by a significant margin. our network analysis revealed that the proposed external memory in seco learns to store prior contextual knowledge, facilitating target identity inference in the lift-the-flap task. moreover, we conducted psychophysics experiments and introduced a human benchmark in object priming dataset (hop). our results demonstrate that seco exhibits human-like behaviors.",,2022-11-23,2023-04-11,"['xiao liu', 'ankur sikarwar', 'gabriel kreiman', 'zenglin shi', 'mengmi zhang']",https://arxiv.org/pdf/2211.12817.pdf
215,2211.12883,mitigating and evaluating static bias of action representations in the   background and the foreground,cs.cv,"in video action recognition, shortcut static features can interfere with the learning of motion features, resulting in poor out-of-distribution (ood) generalization. the video background is clearly a source of static bias, but the video foreground, such as the clothing of the actor, can also provide static bias. in this paper, we empirically verify the existence of foreground static bias by creating test videos with conflicting signals from the static and moving portions of the video. to tackle this issue, we propose a simple yet effective technique, stillmix, to learn robust action representations. specifically, stillmix identifies bias-inducing video frames using a 2d reference network and mixes them with videos for training, serving as effective bias suppression even when we cannot explicitly extract the source of bias within each video frame or enumerate types of bias. finally, to precisely evaluate static bias, we synthesize two new benchmarks, scuba for static cues in the background, and scufo for static cues in the foreground. with extensive experiments, we demonstrate that stillmix mitigates both types of static bias and improves video representations for downstream applications.",,2022-11-23,2023-04-07,"['haoxin li', 'yuan liu', 'hanwang zhang', 'boyang li']",https://arxiv.org/pdf/2211.12883.pdf
216,2211.13606,collaborative training of medical artificial intelligence models with   non-uniform labels,cs.lg cs.ai eess.iv,"due to the rapid advancements in recent years, medical image analysis is largely dominated by deep learning (dl). however, building powerful and robust dl models requires training with large multi-party datasets. while multiple stakeholders have provided publicly available datasets, the ways in which these data are labeled vary widely. for instance, an institution might provide a dataset of chest radiographs containing labels denoting the presence of pneumonia, while another institution might have a focus on determining the presence of metastases in the lung. training a single ai model utilizing all these data is not feasible with conventional federated learning (fl). this prompts us to propose an extension to the widespread fl process, namely flexible federated learning (ffl) for collaborative training on such data. using 695,000 chest radiographs from five institutions from across the globe - each with differing labels - we demonstrate that having heterogeneously labeled datasets, ffl-based training leads to significant performance increase compared to conventional fl training, where only the uniformly annotated images are utilized. we believe that our proposed algorithm could accelerate the process of bringing collaborative training methods from research and simulation phase to the real-world applications in healthcare.",10.1038/s41598-023-33303-y,2022-11-24,2023-04-13,"['soroosh tayebi arasteh', 'peter isfort', 'marwin saehn', 'gustav mueller-franzes', 'firas khader', 'jakob nikolas kather', 'christiane kuhl', 'sven nebelung', 'daniel truhn']",https://arxiv.org/pdf/2211.13606.pdf
217,2211.14425,patchgt: transformer over non-trainable clusters for learning graph   representations,cs.lg cs.ai math.gt,"recently the transformer structure has shown good performances in graph learning tasks. however, these transformer models directly work on graph nodes and may have difficulties learning high-level information. inspired by the vision transformer, which applies to image patches, we propose a new transformer-based graph neural network: patch graph transformer (patchgt). unlike previous transformer-based models for learning graph representations, patchgt learns from non-trainable graph patches, not from nodes directly. it can help save computation and improve the model performance. the key idea is to segment a graph into patches based on spectral clustering without any trainable parameters, with which the model can first use gnn layers to learn patch-level representations and then use transformer to obtain graph-level representations. the architecture leverages the spectral information of graphs and combines the strengths of gnns and transformers. further, we show the limitations of previous hierarchical trainable clusters theoretically and empirically. we also prove the proposed non-trainable spectral clustering method is permutation invariant and can help address the information bottlenecks in the graph. patchgt achieves higher expressiveness than 1-wl-type gnns, and the empirical study shows that patchgt achieves competitive performances on benchmark datasets and provides interpretability to its predictions. the implementation of our algorithm is released at our github repo: https://github.com/tufts-ml/patchgt.",,2022-11-25,2023-04-07,"['han gao', 'xu han', 'jiaoyang huang', 'jian-xun wang', 'li-ping liu']",https://arxiv.org/pdf/2211.14425.pdf
218,2211.14492,enhancing constraint programming via supervised learning for job shop   scheduling,cs.ai,"constraint programming (cp) is a powerful technique for solving constraint satisfaction and optimization problems. in cp solvers, the variable ordering strategy used to select which variable to explore first in the solving process has a significant impact on solver effectiveness. to address this issue, we propose a novel variable ordering strategy based on supervised learning, which we evaluate in the context of job shop scheduling problems. our learning-based methods predict the optimal solution of a problem instance and use the predicted solution to order variables for cp solvers. \added[]{unlike traditional variable ordering methods, our methods can learn from the characteristics of each problem instance and customize the variable ordering strategy accordingly, leading to improved solver performance.} our experiments demonstrate that training machine learning models is highly efficient and can achieve high accuracy. furthermore, our learned variable ordering methods perform competitively when compared to four existing methods. finally, we demonstrate that hybridising the machine learning-based variable ordering methods with traditional domain-based methods is beneficial.",,2022-11-26,2023-04-12,"['yuan sun', 'su nguyen', 'dhananjay thiruvady', 'xiaodong li', 'andreas t. ernst', 'uwe aickelin']",https://arxiv.org/pdf/2211.14492.pdf
219,2211.14545,ensemble multi-quantiles: adaptively flexible distribution prediction   for uncertainty quantification,cs.lg,"we propose a novel, succinct, and effective approach to quantify uncertainty in machine learning. it incorporates adaptively flexible distribution prediction for $\mathbb{p}(\mathbf{y}|\mathbf{x}=x)$ in regression tasks. for predicting this conditional distribution, its quantiles of probability levels spreading the interval $(0,1)$ are boosted by additive models which are designed by us with intuitions and interpretability. we seek an adaptive balance between the structural integrity and the flexibility for $\mathbb{p}(\mathbf{y}|\mathbf{x}=x)$, while gaussian assumption results in a lack of flexibility for real data and highly flexible approaches (e.g., estimating the quantiles separately without a distribution structure) inevitably have drawbacks and may not lead to good generalization. this ensemble multi-quantiles approach called emq proposed by us is totally data-driven, and can gradually depart from gaussian and discover the optimal conditional distribution in the boosting. on extensive regression tasks from uci datasets, we show that emq achieves state-of-the-art performance comparing to many recent uncertainty quantification methods. visualization results further illustrate the necessity and the merits of such an ensemble model.",,2022-11-26,2023-04-10,"['xing yan', 'yonghua su', 'wenxuan ma']",https://arxiv.org/pdf/2211.14545.pdf
220,2211.14699,a theoretical study of inductive biases in contrastive learning,cs.lg stat.ml,"understanding self-supervised learning is important but challenging. previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. however, the recent work of saunshi et al. argues that the model architecture -- a component largely ignored by previous works -- also has significant influences on the downstream performance of self-supervised learning. in this work, we provide the first theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. in particular, we focus on contrastive learning -- a popular self-supervised learning method that is widely used in the vision domain. we show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. as a result, our theory can capture the more realistic setting where contrastive representations have much lower dimensionality than the number of clusters in the data distribution. we instantiate our theory on several synthetic data distributions, and provide empirical evidence to support the theory.",,2022-11-26,2023-04-08,"['jeff z. haochen', 'tengyu ma']",https://arxiv.org/pdf/2211.14699.pdf
221,2211.15088,class adaptive network calibration,cs.cv,"recent studies have revealed that, beyond conventional accuracy, calibration should also be considered for training modern deep neural networks. to address miscalibration during learning, some methods have explored different penalty functions as part of the learning objective, alongside a standard classification loss, with a hyper-parameter controlling the relative contribution of each term. nevertheless, these methods share two major drawbacks: 1) the scalar balancing weight is the same for all classes, hindering the ability to address different intrinsic difficulties or imbalance among classes; and 2) the balancing weight is usually fixed without an adaptive strategy, which may prevent from reaching the best compromise between accuracy and calibration, and requires hyper-parameter search for each application. we propose class adaptive label smoothing (cals) for calibrating deep networks, which allows to learn class-wise multipliers during training, yielding a powerful alternative to common label smoothing penalties. our method builds on a general augmented lagrangian approach, a well-established technique in constrained optimization, but we introduce several modifications to tailor it for large-scale, class-adaptive training. comprehensive evaluation and multiple comparisons on a variety of benchmarks, including standard and long-tailed image classification, semantic segmentation, and text classification, demonstrate the superiority of the proposed method. the code is available at https://github.com/by-liu/cals.",,2022-11-28,2023-04-12,"['bingyuan liu', 'j√©r√¥me rony', 'adrian galdran', 'jose dolz', 'ismail ben ayed']",https://arxiv.org/pdf/2211.15088.pdf
222,2211.15845,lifelong embedding learning and transfer for growing knowledge graphs,cs.cl cs.ai,"existing knowledge graph (kg) embedding models have primarily focused on static kgs. however, real-world kgs do not remain static, but rather evolve and grow in tandem with the development of kg applications. consequently, new facts and previously unseen entities and relations continually emerge, necessitating an embedding model that can quickly learn and transfer new knowledge through growth. motivated by this, we delve into an expanding field of kg embedding in this paper, i.e., lifelong kg embedding. we consider knowledge transfer and retention of the learning on growing snapshots of a kg without having to learn embeddings from scratch. the proposed model includes a masked kg autoencoder for embedding learning and update, with an embedding transfer strategy to inject the learned knowledge into the new entity and relation embeddings, and an embedding regularization method to avoid catastrophic forgetting. to investigate the impacts of different aspects of kg growth, we construct four datasets to evaluate the performance of lifelong kg embedding. experimental results show that the proposed model outperforms the state-of-the-art inductive and lifelong embedding baselines.",,2022-11-28,2023-04-09,"['yuanning cui', 'yuxin wang', 'zequn sun', 'wenqiang liu', 'yiqiao jiang', 'kexin han', 'wei hu']",https://arxiv.org/pdf/2211.15845.pdf
223,2211.16078,behavior estimation from multi-source data for offline reinforcement   learning,cs.lg cs.ro,"offline reinforcement learning (rl) have received rising interest due to its appealing data efficiency. the present study addresses behavior estimation, a task that lays the foundation of many offline rl algorithms. behavior estimation aims at estimating the policy with which training data are generated. in particular, this work considers a scenario where the data are collected from multiple sources. in this case, neglecting data heterogeneity, existing approaches for behavior estimation suffers from behavior misspecification. to overcome this drawback, the present study proposes a latent variable model to infer a set of policies from data, which allows an agent to use as behavior policy the policy that best describes a particular trajectory. this model provides with a agent fine-grained characterization for multi-source data and helps it overcome behavior misspecification. this work also proposes a learning algorithm for this model and illustrates its practical usage via extending an existing offline rl algorithm. lastly, with extensive evaluation this work confirms the existence of behavior misspecification and the efficacy of the proposed model.",,2022-11-29,2023-04-11,"['guoxi zhang', 'hisashi kashima']",https://arxiv.org/pdf/2211.16078.pdf
224,2212.00622,vertical federated learning: a structured literature review,cs.lg cs.ai cs.dc,"federated learning (fl) has emerged as a promising distributed learning paradigm with an added advantage of data privacy. with the growing interest in having collaboration among data owners, fl has gained significant attention of organizations. the idea of fl is to enable collaborating participants train machine learning (ml) models on decentralized data without breaching privacy. in simpler words, federated learning is the approach of ``bringing the model to the data, instead of bringing the data to the mode''. federated learning, when applied to data which is partitioned vertically across participants, is able to build a complete ml model by combining local models trained only using the data with distinct features at the local sites. this architecture of fl is referred to as vertical federated learning (vfl), which differs from the conventional fl on horizontally partitioned data. as vfl is different from conventional fl, it comes with its own issues and challenges. in this paper, we present a structured literature review discussing the state-of-the-art approaches in vfl. additionally, the literature review highlights the existing solutions to challenges in vfl and provides potential research directions in this domain.",,2022-12-01,2023-04-09,"['afsana khan', 'marijn ten thij', 'anna wilbik']",https://arxiv.org/pdf/2212.00622.pdf
225,2212.01222,evaluation of explanation methods of ai -- cnns in image classification   tasks with reference-based and no-reference metrics,cs.cv,"the most popular methods in ai-machine learning paradigm are mainly black boxes. this is why explanation of ai decisions is of emergency. although dedicated explanation tools have been massively developed, the evaluation of their quality remains an open research question. in this paper, we generalize the methodologies of evaluation of post-hoc explainers of cnns' decisions in visual classification tasks with reference and no-reference based metrics. we apply them on our previously developed explainers (fem, mlfem), and popular grad-cam. the reference-based metrics are pearson correlation coefficient and similarity computed between the explanation map and its ground truth represented by a gaze fixation density map obtained with a psycho-visual experiment. as a no-reference metric, we use stability metric, proposed by alvarez-melis and jaakkola. we study its behaviour, consensus with reference-based metrics and show that in case of several kinds of degradation on input images, this metric is in agreement with reference-based ones. therefore, it can be used for evaluation of the quality of explainers when the ground truth is not available.",10.54364/aaiml.2023.1143,2022-12-02,2023-01-21,"['a. zhukov', 'j. benois-pineau', 'r. giot']",https://arxiv.org/pdf/2212.01222.pdf
226,2212.01920,review on 6d object pose estimation with the focus on indoor scene   understanding,cs.cv cs.ro,"6d object pose estimation problem has been extensively studied in the field of computer vision and robotics. it has wide range of applications such as robot manipulation, augmented reality, and 3d scene understanding. with the advent of deep learning, many breakthroughs have been made; however, approaches continue to struggle when they encounter unseen instances, new categories, or real-world challenges such as cluttered backgrounds and occlusions. in this study, we will explore the available methods based on input modality, problem formulation, and whether it is a category-level or instance-level approach. as a part of our discussion, we will focus on how 6d object pose estimation can be used for understanding 3d scenes.",10.54364/aaiml.2022.1141,2022-12-04,,"['negar nejatishahidin', 'pooya fayyazsanavi']",https://arxiv.org/pdf/2212.01920.pdf
227,2212.03246,mobiletl: on-device transfer learning with inverted residual blocks,cs.lg cs.ai,"transfer learning on edge is challenging due to on-device limited resources. existing work addresses this issue by training a subset of parameters or adding model patches. developed with inference in mind, inverted residual blocks (irbs) split a convolutional layer into depthwise and pointwise convolutions, leading to more stacking layers, e.g., convolution, normalization, and activation layers. though they are efficient for inference, irbs require that additional activation maps are stored in memory for training weights for convolution layers and scales for normalization layers. as a result, their high memory cost prohibits training irbs on resource-limited edge devices, and making them unsuitable in the context of transfer learning. to address this issue, we present mobiletl, a memory and computationally efficient on-device transfer learning method for models built with irbs. mobiletl trains the shifts for internal normalization layers to avoid storing activation maps for the backward pass. also, mobiletl approximates the backward computation of the activation layer (e.g., hard-swish and relu6) as a signed function which enables storing a binary mask instead of activation maps for the backward pass. mobiletl fine-tunes a few top blocks (close to output) rather than propagating the gradient through the whole network to reduce the computation cost. our method reduces memory usage by 46% and 53% for mobilenetv2 and v3 irbs, respectively. for mobilenetv3, we observe a 36% reduction in floating-point operations (flops) when fine-tuning 5 blocks, while only incurring a 0.6% accuracy reduction on cifar10. extensive experiments on multiple datasets demonstrate that our method is pareto-optimal (best accuracy under given hardware constraints) compared to prior work in transfer learning for edge devices.",,2022-12-05,2023-04-08,"['hung-yueh chiang', 'natalia frumkin', 'feng liang', 'diana marculescu']",https://arxiv.org/pdf/2212.03246.pdf
228,2212.03793,"radar: a ttp-based extensible, explainable, and effective system for   network traffic analysis and malware detection",cs.cr,"network analysis and machine learning techniques have been widely applied for building malware detection systems. though these systems attain impressive results, they often are $(i)$ not extensible, being monolithic, well tuned for the specific task they have been designed for but very difficult to adapt and/or extend to other settings, and $(ii)$ not interpretable, being black boxes whose inner complexity makes it impossible to link the result of detection with its root cause, making further analysis of threats a challenge. in this paper we present radar, an extensible and explainable system that exploits the popular ttp (tactics, techniques, and procedures) ontology of adversary behaviour described in the industry-standard mitre att\&ck framework in order to unequivocally identify and classify malicious behaviour using network traffic. we evaluate radar on a very large dataset comprising of 2,286,907 malicious and benign samples, representing a total of 84,792,452 network flows. the experimental analysis confirms that the proposed methodology can be effectively exploited: radar's ability to detect malware is comparable to other state-of-the-art non-interpretable systems' capabilities. to the best of our knowledge, radar is the first ttp-based system for malware detection that uses machine learning while being extensible and explainable.",,2022-12-07,2023-04-13,"['yashovardhan sharma', 'simon birnbach', 'ivan martinovic']",https://arxiv.org/pdf/2212.03793.pdf
229,2212.04362,ciaosr: continuous implicit attention-in-attention network for   arbitrary-scale image super-resolution,cs.cv,"learning continuous image representations is recently gaining popularity for image super-resolution (sr) because of its ability to reconstruct high-resolution images with arbitrary scales from low-resolution inputs. existing methods mostly ensemble nearby features to predict the new pixel at any queried coordinate in the sr image. such a local ensemble suffers from some limitations: i) it has no learnable parameters and it neglects the similarity of the visual features; ii) it has a limited receptive field and cannot ensemble relevant features in a large field which are important in an image. to address these issues, this paper proposes a continuous implicit attention-in-attention network, called ciaosr. we explicitly design an implicit attention network to learn the ensemble weights for the nearby local features. furthermore, we embed a scale-aware attention in this implicit attention network to exploit additional non-local information. extensive experiments on benchmark datasets demonstrate ciaosr significantly outperforms the existing single image sr methods with the same backbone. in addition, ciaosr also achieves the state-of-the-art performance on the arbitrary-scale sr task. the effectiveness of the method is also demonstrated on the real-world sr setting. more importantly, ciaosr can be flexibly integrated into any backbone to improve the sr performance.",,2022-12-08,2023-04-13,"['jiezhang cao', 'qin wang', 'yongqin xian', 'yawei li', 'bingbing ni', 'zhiming pi', 'kai zhang', 'yulun zhang', 'radu timofte', 'luc van gool']",https://arxiv.org/pdf/2212.04362.pdf
230,2212.05762,momentum contrastive pre-training for question answering,cs.cl cs.ai,"existing pre-training methods for extractive question answering (qa) generate cloze-like queries different from natural questions in syntax structure, which could overfit pre-trained models to simple keyword matching. in order to address this problem, we propose a novel momentum contrastive pre-training for question answering (mcross) method for extractive qa. specifically, mcross introduces a momentum contrastive learning framework to align the answer probability between cloze-like and natural query-passage sample pairs. hence, the pre-trained models can better transfer the knowledge learned in cloze-like samples to answering natural questions. experimental results on three benchmarking qa datasets show that our method achieves noticeable improvement compared with all baselines in both supervised and zero-shot scenarios.",,2022-12-12,2023-04-12,"['minda hu', 'muzhi li', 'yasheng wang', 'irwin king']",https://arxiv.org/pdf/2212.05762.pdf
231,2212.05961,rpn: a word vector level data augmentation algorithm in deep learning   for language understanding,cs.cl cs.ai,"data augmentation is a widely used technique in machine learning to improve model performance. however, existing data augmentation techniques in natural language understanding (nlu) may not fully capture the complexity of natural language variations, and they can be challenging to apply to large datasets. this paper proposes the random position noise (rpn) algorithm, a novel data augmentation technique that operates at the word vector level. rpn modifies the word embeddings of the original text by introducing noise based on the existing values of selected word vectors, allowing for more fine-grained modifications and better capturing natural language variations. unlike traditional data augmentation methods, rpn does not require gradients in the computational graph during virtual sample updates, making it simpler to apply to large datasets. experimental results demonstrate that rpn consistently outperforms existing data augmentation techniques across various nlu tasks, including sentiment analysis, natural language inference, and paraphrase detection. moreover, rpn performs well in low-resource settings and is applicable to any model featuring a word embeddings layer. the proposed rpn algorithm is a promising approach for enhancing nlu performance and addressing the challenges associated with traditional data augmentation techniques in large-scale nlu tasks. our experimental results demonstrated that the rpn algorithm achieved state-of-the-art performance in all seven nlu tasks, thereby highlighting its effectiveness and potential for real-world nlu applications.",,2022-12-12,2023-04-13,"['zhengqing yuan', 'zhuanzhe zhao', 'yongming liu', 'xiaolong zhang', 'xuecong hou', 'yue wang', 'huiwen xue']",https://arxiv.org/pdf/2212.05961.pdf
232,2212.06301,egocentric video task translation,cs.cv,"different video understanding tasks are typically treated in isolation, and even with distinct types of curated data (e.g., classifying sports in one dataset, tracking animals in another). however, in wearable cameras, the immersive egocentric perspective of a person engaging with the world around them presents an interconnected web of video understanding tasks -- hand-object manipulations, navigation in the space, or human-human interactions -- that unfold continuously, driven by the person's goals. we argue that this calls for a much more unified approach. we propose egotask translation (egot2), which takes a collection of models optimized on separate tasks and learns to translate their outputs for improved performance on any or all of them at once. unlike traditional transfer or multi-task learning, egot2's flipped design entails separate task-specific backbones and a task translator shared across all tasks, which captures synergies between even heterogeneous tasks and mitigates task competition. demonstrating our model on a wide array of video tasks from ego4d, we show its advantages over existing transfer paradigms and achieve top-ranked results on four of the ego4d 2022 benchmark challenges.",,2022-12-12,2023-04-06,"['zihui xue', 'yale song', 'kristen grauman', 'lorenzo torresani']",https://arxiv.org/pdf/2212.06301.pdf
233,2212.08208,location-aware adaptive normalization: a deep learning approach for   wildfire danger forecasting,cs.cv,"climate change is expected to intensify and increase extreme events in the weather cycle. since this has a significant impact on various sectors of our life, recent works are concerned with identifying and predicting such extreme events from earth observations. with respect to wildfire danger forecasting, previous deep learning approaches duplicate static variables along the time dimension and neglect the intrinsic differences between static and dynamic variables. furthermore, most existing multi-branch architectures lose the interconnections between the branches during the feature learning stage. to address these issues, this paper proposes a 2d/3d two-branch convolutional neural network (cnn) with a location-aware adaptive normalization layer (loan). using loan as a building block, we can modulate the dynamic features conditional on their geographical locations. thus, our approach considers feature properties as a unified yet compound 2d/3d model. besides, we propose using the sinusoidal-based encoding of the day of the year to provide the model with explicit temporal information about the target day within the year. our experimental results show a better performance of our approach than other baselines on the challenging firecube dataset. the results show that location-aware adaptive feature normalization is a promising technique to learn the relation between dynamic variables and their geographic locations, which is highly relevant for areas where remote sensing data builds the basis for analysis. the source code is available at https://github.com/hakamshams/loan.",,2022-12-15,2023-04-07,"['mohamad hakam shams eddin', 'ribana roscher', 'juergen gall']",https://arxiv.org/pdf/2212.08208.pdf
234,2212.09102,face generation and editing with stylegan: a survey,cs.cv cs.lg,"our goal with this survey is to provide an overview of the state of the art deep learning technologies for face generation and editing. we will cover popular latest architectures and discuss key ideas that make them work, such as inversion, latent representation, loss functions, training procedures, editing methods, and cross domain style transfer. we particularly focus on gan-based architectures that have culminated in the stylegan approaches, which allow generation of high-quality face images and offer rich interfaces for controllable semantics editing and preserving photo quality. we aim to provide an entry point into the field for readers that have basic knowledge about the field of deep learning and are looking for an accessible introduction and overview.",,2022-12-18,2023-04-13,"['andrew melnik', 'maksim miasayedzenkau', 'dzianis makarovets', 'dzianis pirshtuk', 'eren akbulut', 'dennis holzmann', 'tarek renusch', 'gustav reichert', 'helge ritter']",https://arxiv.org/pdf/2212.09102.pdf
235,2212.09925,plug & play directed evolution of proteins with gradient-based discrete   mcmc,cs.lg q-bio.bm,"a long-standing goal of machine-learning-based protein engineering is to accelerate the discovery of novel mutations that improve the function of a known protein. we introduce a sampling framework for evolving proteins in silico that supports mixing and matching a variety of unsupervised models, such as protein language models, and supervised models that predict protein function from sequence. by composing these models, we aim to improve our ability to evaluate unseen mutations and constrain search to regions of sequence space likely to contain functional proteins. our framework achieves this without any model fine-tuning or re-training by constructing a product of experts distribution directly in discrete protein space. instead of resorting to brute force search or random sampling, which is typical of classic directed evolution, we introduce a fast mcmc sampler that uses gradients to propose promising mutations. we conduct in silico directed evolution experiments on wide fitness landscapes and across a range of different pre-trained unsupervised models, including a 650m parameter protein language model. our results demonstrate an ability to efficiently discover variants with high evolutionary likelihood as well as estimated activity multiple mutations away from a wild type protein, suggesting our sampler provides a practical and effective new paradigm for machine-learning-based protein engineering.",10.1088/2632-2153/accacd,2022-12-19,2023-04-06,"['patrick emami', 'aidan perreault', 'jeffrey law', 'david biagioni', 'peter c. st. john']",https://arxiv.org/pdf/2212.09925.pdf
236,2212.09967,learning subgrid-scale models with neural ordinary differential   equations,math.na cs.ce cs.lg cs.na,"we propose a new approach to learning the subgrid-scale model when simulating partial differential equations (pdes) solved by the method of lines and their representation in chaotic ordinary differential equations, based on neural ordinary differential equations (nodes). solving systems with fine temporal and spatial grid scales is an ongoing computational challenge, and closure models are generally difficult to tune. machine learning approaches have increased the accuracy and efficiency of computational fluid dynamics solvers. in this approach neural networks are used to learn the coarse- to fine-grid map, which can be viewed as subgrid-scale parameterization. we propose a strategy that uses the node and partial knowledge to learn the source dynamics at a continuous level. our method inherits the advantages of nodes and can be used to parameterize subgrid scales, approximate coupling operators, and improve the efficiency of low-order solvers. numerical results with the two-scale lorenz 96 ode, the convection-diffusion pde, and the viscous burgers' pde are used to illustrate this approach.",,2022-12-19,2023-04-12,"['shinhoo kang', 'emil m. constantinescu']",https://arxiv.org/pdf/2212.09967.pdf
237,2212.13067,online active learning for soft sensor development using semi-supervised   autoencoders,cs.lg stat.ml,"data-driven soft sensors are extensively used in industrial and chemical processes to predict hard-to-measure process variables whose real value is difficult to track during routine operations. the regression models used by these sensors often require a large number of labeled examples, yet obtaining the label information can be very expensive given the high time and cost required by quality inspections. in this context, active learning methods can be highly beneficial as they can suggest the most informative labels to query. however, most of the active learning strategies proposed for regression focus on the offline setting. in this work, we adapt some of these approaches to the stream-based scenario and show how they can be used to select the most informative data points. we also demonstrate how to use a semi-supervised architecture based on orthogonal autoencoders to learn salient features in a lower dimensional space. the tennessee eastman process is used to compare the predictive performance of the proposed approaches.",,2022-12-26,2023-04-09,"['davide cacciarelli', 'murat kulahci', 'john tyssedal']",https://arxiv.org/pdf/2212.13067.pdf
238,2212.14258,hier: metric learning beyond class labels via hierarchical   regularization,cs.cv cs.ai,"supervision for metric learning has long been given in the form of equivalence between human-labeled classes. although this type of supervision has been a basis of metric learning for decades, we argue that it hinders further advances in the field. in this regard, we propose a new regularization method, dubbed hier, to discover the latent semantic hierarchy of training data, and to deploy the hierarchy to provide richer and more fine-grained supervision than inter-class separability induced by common metric learning losses.hier achieves this goal with no annotation for the semantic hierarchy but by learning hierarchical proxies in hyperbolic spaces. the hierarchical proxies are learnable parameters, and each of them is trained to serve as an ancestor of a group of data or other proxies to approximate the semantic hierarchy among them. hier deals with the proxies along with data in hyperbolic space since the geometric properties of the space are well-suited to represent their hierarchical structure. the efficacy of hier is evaluated on four standard benchmarks, where it consistently improved the performance of conventional methods when integrated with them, and consequently achieved the best records, surpassing even the existing hyperbolic metric learning technique, in almost all settings.",,2022-12-29,2023-04-10,"['sungyeon kim', 'boseung jeong', 'suha kwak']",https://arxiv.org/pdf/2212.14258.pdf
239,2212.14337,biologically plausible learning on neuromorphic hardware architectures,cs.ne cs.et,"with an ever-growing number of parameters defining increasingly complex networks, deep learning has led to several breakthroughs surpassing human performance. as a result, data movement for these millions of model parameters causes a growing imbalance known as the memory wall. neuromorphic computing is an emerging paradigm that confronts this imbalance by performing computations directly in analog memories. on the software side, the sequential backpropagation algorithm prevents efficient parallelization and thus fast convergence. a novel method, direct feedback alignment, resolves inherent layer dependencies by directly passing the error from the output to each layer. at the intersection of hardware/software co-design, there is a demand for developing algorithms that are tolerable to hardware nonidealities. therefore, this work explores the interrelationship of implementing bio-plausible learning in-situ on neuromorphic hardware, emphasizing energy, area, and latency constraints. using the benchmarking framework dnn+neurosim, we investigate the impact of hardware nonidealities and quantization on algorithm performance, as well as how network topologies and algorithm-level design choices can scale latency, energy and area consumption of a chip. to the best of our knowledge, this work is the first to compare the impact of different learning algorithms on compute-in-memory-based hardware and vice versa. the best results achieved for accuracy remain backpropagation-based, notably when facing hardware imperfections. direct feedback alignment, on the other hand, allows for significant speedup due to parallelization, reducing training time by a factor approaching n for n-layered networks.",,2022-12-29,2023-04-11,"['christopher wolters', 'brady taylor', 'edward hanson', 'xiaoxuan yang', 'ulf schlichtmann', 'yiran chen']",https://arxiv.org/pdf/2212.14337.pdf
240,2212.14548,how would stance detection techniques evolve after the launch of   chatgpt?,cs.cl,"stance detection refers to the task of extracting the standpoint (favor, against or neither) towards a target in given texts. such research gains increasing attention with the proliferation of social media contents. the conventional framework of handling stance detection is converting it into text classification tasks. deep learning models have already replaced rule-based models and traditional machine learning models in solving such problems. current deep neural networks are facing two main challenges which are insufficient labeled data and information in social media posts and the unexplainable nature of deep learning models. a new pre-trained language model chatgpt was launched on nov 30, 2022. for the stance detection tasks, our experiments show that chatgpt can achieve sota or similar performance for commonly used datasets including semeval-2016 and p-stance. at the same time, chatgpt can provide explanation for its own prediction, which is beyond the capability of any existing model. the explanations for the cases it cannot provide classification results are especially useful. chatgpt has the potential to be the best ai model for stance detection tasks in nlp, or at least change the research paradigm of this field. chatgpt also opens up the possibility of building explanatory ai for stance detection.",,2022-12-30,2023-04-10,"['bowen zhang', 'daijun ding', 'liwen jing']",https://arxiv.org/pdf/2212.14548.pdf
241,2212.14613,delving into semantic scale imbalance,cs.cv cs.ai cs.lg,"model bias triggered by long-tailed data has been widely studied. however, measure based on the number of samples cannot explicate three phenomena simultaneously: (1) given enough data, the classification performance gain is marginal with additional samples. (2) classification performance decays precipitously as the number of training samples decreases when there is insufficient data. (3) model trained on sample-balanced datasets still has different biases for different classes. in this work, we define and quantify the semantic scale of classes, which is used to measure the feature diversity of classes. it is exciting to find experimentally that there is a marginal effect of semantic scale, which perfectly describes the first two phenomena. further, the quantitative measurement of semantic scale imbalance is proposed, which can accurately reflect model bias on multiple datasets, even on sample-balanced data, revealing a novel perspective for the study of class imbalance. due to the prevalence of semantic scale imbalance, we propose semantic-scale-balanced learning, including a general loss improvement scheme and a dynamic re-weighting training framework that overcomes the challenge of calculating semantic scales in real-time during iterations. comprehensive experiments show that dynamic semantic-scale-balanced learning consistently enables the model to perform superiorly on large-scale long-tailed and non-long-tailed natural and medical datasets, which is a good starting point for mitigating the prevalent but unnoticed model bias.",,2022-12-30,2023-04-08,"['yanbiao ma', 'licheng jiao', 'fang liu', 'yuxin li', 'shuyuan yang', 'xu liu']",https://arxiv.org/pdf/2212.14613.pdf
242,2212.14776,on the interpretability of attention networks,cs.lg,"attention mechanisms form a core component of several successful deep learning architectures, and are based on one key idea: ''the output depends only on a small (but unknown) segment of the input.'' in several practical applications like image captioning and language translation, this is mostly true. in trained models with an attention mechanism, the outputs of an intermediate module that encodes the segment of input responsible for the output is often used as a way to peek into the `reasoning` of the network. we make such a notion more precise for a variant of the classification problem that we term selective dependence classification (sdc) when used with attention model architectures. under such a setting, we demonstrate various error modes where an attention model can be accurate but fail to be interpretable, and show that such models do occur as a result of training. we illustrate various situations that can accentuate and mitigate this behaviour. finally, we use our objective definition of interpretability for sdc tasks to evaluate a few attention model learning algorithms designed to encourage sparsity and demonstrate that these algorithms help improve interpretability.",,2022-12-30,2023-04-09,"['lakshmi narayan pandey', 'rahul vashisht', 'harish g. ramaswamy']",https://arxiv.org/pdf/2212.14776.pdf
243,2212.14806,pain level and pain-related behaviour classification using gru-based   sparsely-connected rnns,eess.sp cs.hc cs.lg,"there is a growing body of studies on applying deep learning to biometrics analysis. certain circumstances, however, could impair the objective measures and accuracy of the proposed biometric data analysis methods. for instance, people with chronic pain (cp) unconsciously adapt specific body movements to protect themselves from injury or additional pain. because there is no dedicated benchmark database to analyse this correlation, we considered one of the specific circumstances that potentially influence a person's biometrics during daily activities in this study and classified pain level and pain-related behaviour in the emopain database. to achieve this, we proposed a sparsely-connected recurrent neural networks (s-rnns) ensemble with the gated recurrent unit (gru) that incorporates multiple autoencoders using a shared training framework. this architecture is fed by multidimensional data collected from inertial measurement unit (imu) and surface electromyography (semg) sensors. furthermore, to compensate for variations in the temporal dimension that may not be perfectly represented in the latent space of s-rnns, we fused hand-crafted features derived from information-theoretic approaches with represented features in the shared hidden state. we conducted several experiments which indicate that the proposed method outperforms the state-of-the-art approaches in classifying both pain level and pain-related behaviour.",10.1109/jstsp.2023.3262358,2022-12-20,,"['mohammad mahdi dehshibi', 'temitayo olugbade', 'fernando diaz-de-maria', 'nadia bianchi-berthouze', 'ana tajadura-jim√©nez']",https://arxiv.org/pdf/2212.14806.pdf
244,2301.00004,sesnet: sequence-structure feature-integrated deep learning method for   data-efficient protein engineering,q-bio.qm cs.lg,"deep learning has been widely used for protein engineering. however, it is limited by the lack of sufficient experimental data to train an accurate model for predicting the functional fitness of high-order mutants. here, we develop sesnet, a supervised deep-learning model to predict the fitness for protein mutants by leveraging both sequence and structure information, and exploiting attention mechanism. our model integrates local evolutionary context from homologous sequences, the global evolutionary context encoding rich semantic from the universal protein sequence space and the structure information accounting for the microenvironment around each residue in a protein. we show that sesnet outperforms state-of-the-art models for predicting the sequence-function relationship on 26 deep mutational scanning datasets. more importantly, we propose a data augmentation strategy by leveraging the data from unsupervised models to pre-train our model. after that, our model can achieve strikingly high accuracy in prediction of the fitness of protein mutants, especially for the higher order variants (> 4 mutation sites), when finetuned by using only a small number of experimental mutation data (<50). the strategy proposed is of great practical value as the required experimental effort, i.e., producing a few tens of experimental mutation data on a given protein, is generally affordable by an ordinary biochemical group and can be applied on almost any protein.",10.1186/s13321-023-00688-x,2022-12-28,,"['mingchen li', 'liqi kang', 'yi xiong', 'yu guang wang', 'guisheng fan', 'pan tan', 'liang hong']",https://arxiv.org/pdf/2301.00004.pdf
245,2301.01026,continual causal effect estimation: challenges and opportunities,cs.lg stat.ml,"a further understanding of cause and effect within observational data is critical across many domains, such as economics, health care, public policy, web mining, online advertising, and marketing campaigns. although significant advances have been made to overcome the challenges in causal effect estimation with observational data, such as missing counterfactual outcomes and selection bias between treatment and control groups, the existing methods mainly focus on source-specific and stationary observational data. such learning strategies assume that all observational data are already available during the training phase and from only one source. this practical concern of accessibility is ubiquitous in various academic and industrial applications. that's what it boiled down to: in the era of big data, we face new challenges in causal inference with observational data, i.e., the extensibility for incrementally available observational data, the adaptability for extra domain adaptation problem except for the imbalance between treatment and control groups, and the accessibility for an enormous amount of data. in this position paper, we formally define the problem of continual treatment effect estimation, describe its research challenges, and then present possible solutions to this problem. moreover, we will discuss future research directions on this topic.",,2023-01-03,2023-04-10,"['zhixuan chu', 'sheng li']",https://arxiv.org/pdf/2301.01026.pdf
246,2301.03398,asynchronous multi-agent reinforcement learning for efficient real-time   multi-robot cooperative exploration,cs.ro cs.ai,"we consider the problem of cooperative exploration where multiple robots need to cooperatively explore an unknown region as fast as possible. multi-agent reinforcement learning (marl) has recently become a trending paradigm for solving this challenge. however, existing marl-based methods adopt action-making steps as the metric for exploration efficiency by assuming all the agents are acting in a fully synchronous manner: i.e., every single agent produces an action simultaneously and every single action is executed instantaneously at each time step. despite its mathematical simplicity, such a synchronous marl formulation can be problematic for real-world robotic applications. it can be typical that different robots may take slightly different wall-clock times to accomplish an atomic action or even periodically get lost due to hardware issues. simply waiting for every robot being ready for the next action can be particularly time-inefficient. therefore, we propose an asynchronous marl solution, asynchronous coordination explorer (ace), to tackle this real-world challenge. we first extend a classical marl algorithm, multi-agent ppo (mappo), to the asynchronous setting and additionally apply action-delay randomization to enforce the learned policy to generalize better to varying action delays in the real world. moreover, each navigation agent is represented as a team-size-invariant cnn-based policy, which greatly benefits real-robot deployment by handling possible robot lost and allows bandwidth-efficient intra-agent communication through low-dimensional cnn features. we first validate our approach in a grid-based scenario. both simulation and real-robot results show that ace reduces over 10% actual exploration time compared with classical approaches. we also apply our framework to a high-fidelity visual-based environment, habitat, achieving 28% improvement in exploration efficiency.",,2023-01-09,2023-04-11,"['chao yu', 'xinyi yang', 'jiaxuan gao', 'jiayu chen', 'yunfei li', 'jijia liu', 'yunfei xiang', 'ruixin huang', 'huazhong yang', 'yi wu', 'yu wang']",https://arxiv.org/pdf/2301.03398.pdf
247,2301.04017,reconstructing individual data points in federated learning hardened   with differential privacy and secure aggregation,cs.cr cs.lg,"federated learning (fl) is a framework for users to jointly train a machine learning model. fl is promoted as a privacy-enhancing technology (pet) that provides data minimization: data never ""leaves"" personal devices and users share only model updates with a server (e.g., a company) coordinating the distributed training. while prior work showed that in vanilla fl a malicious server can extract users' private data from the model updates, in this work we take it further and demonstrate that a malicious server can reconstruct user data even in hardened versions of the protocol. more precisely, we propose an attack against fl protected with distributed differential privacy (ddp) and secure aggregation (sa). our attack method is based on the introduction of sybil devices that deviate from the protocol to expose individual users' data for reconstruction by the server. the underlying root cause for the vulnerability to our attack is a power imbalance: the server orchestrates the whole protocol and users are given little guarantees about the selection of other users participating in the protocol. moving forward, we discuss requirements for privacy guarantees in fl. we conclude that users should only participate in the protocol when they trust the server or they apply local primitives such as local dp, shifting power away from the server. yet, the latter approaches come at significant overhead in terms of performance degradation of the trained model, making them less likely to be deployed in practice.",,2023-01-09,2023-04-12,"['franziska boenisch', 'adam dziedzic', 'roei schuster', 'ali shahin shamsabadi', 'ilia shumailov', 'nicolas papernot']",https://arxiv.org/pdf/2301.04017.pdf
248,2301.04224,pix2map: cross-modal retrieval for inferring street maps from images,cs.cv cs.lg,"self-driving vehicles rely on urban street maps for autonomous navigation. in this paper, we introduce pix2map, a method for inferring urban street map topology directly from ego-view images, as needed to continually update and expand existing maps. this is a challenging task, as we need to infer a complex urban road topology directly from raw image data. the main insight of this paper is that this problem can be posed as cross-modal retrieval by learning a joint, cross-modal embedding space for images and existing maps, represented as discrete graphs that encode the topological layout of the visual surroundings. we conduct our experimental evaluation using the argoverse dataset and show that it is indeed possible to accurately retrieve street maps corresponding to both seen and unseen roads solely from image data. moreover, we show that our retrieved maps can be used to update or expand existing maps and even show proof-of-concept results for visual localization and image retrieval from spatial graphs.",,2023-01-10,2023-04-09,"['xindi wu', 'kwunfung lau', 'francesco ferroni', 'aljo≈°a o≈°ep', 'deva ramanan']",https://arxiv.org/pdf/2301.04224.pdf
249,2301.05339,a comprehensive review of data-driven co-speech gesture generation,cs.gr cs.cv cs.hc cs.lg,"gestures that accompany speech are an essential part of natural and efficient embodied human communication. the automatic generation of such co-speech gestures is a long-standing problem in computer animation and is considered an enabling technology in film, games, virtual social spaces, and for interaction with social robots. the problem is made challenging by the idiosyncratic and non-periodic nature of human co-speech gesture motion, and by the great diversity of communicative functions that gestures encompass. gesture generation has seen surging interest recently, owing to the emergence of more and larger datasets of human gesture motion, combined with strides in deep-learning-based generative models, that benefit from the growing availability of data. this review article summarizes co-speech gesture generation research, with a particular focus on deep generative models. first, we articulate the theory describing human gesticulation and how it complements speech. next, we briefly discuss rule-based and classical statistical gesture synthesis, before delving into deep learning approaches. we employ the choice of input modalities as an organizing principle, examining systems that generate gestures from audio, text, and non-linguistic input. we also chronicle the evolution of the related training data sets in terms of size, diversity, motion quality, and collection method. finally, we identify key research challenges in gesture generation, including data availability and quality; producing human-like motion; grounding the gesture in the co-occurring speech in interaction with other speakers, and in the environment; performing gesture evaluation; and integration of gesture synthesis into applications. we highlight recent approaches to tackling the various key challenges, as well as the limitations of these approaches, and point toward areas of future development.",10.1111/cgf.14776,2023-01-12,2023-04-10,"['simbarashe nyatsanga', 'taras kucherenko', 'chaitanya ahuja', 'gustav eje henter', 'michael neff']",https://arxiv.org/pdf/2301.05339.pdf
250,2301.05526,self-training guided disentangled adaptation for cross-domain remote   sensing image semantic segmentation,cs.cv,"deep convolutional neural networks (dcnns) based remote sensing (rs) image semantic segmentation technology has achieved great success used in many real-world applications such as geographic element analysis. however, strong dependency on annotated data of specific scene makes it hard for dcnns to fit different rs scenes. to solve this problem, recent works gradually focus on cross-domain rs image semantic segmentation task. in this task, different ground sampling distance, remote sensing sensor variation and different geographical landscapes are three main factors causing dramatic domain shift between source and target images. to decrease the negative influence of domain shift, we propose a self-training guided disentangled adaptation network (st-dasegnet). we first propose source student backbone and target student backbone to respectively extract the source-style and target-style feature for both source and target images. towards the intermediate output feature maps of each backbone, we adopt adversarial learning for alignment. then, we propose a domain disentangled module to extract the universal feature and purify the distinct feature of source-style and target-style features. finally, these two features are fused and served as input of source student decoder and target student decoder to generate final predictions. based on our proposed domain disentangled module, we further propose exponential moving average (ema) based cross-domain separated self-training mechanism to ease the instability and disadvantageous effect during adversarial optimization. extensive experiments and analysis on benchmark rs datasets show that st-dasegnet outperforms previous methods on cross-domain rs image semantic segmentation task and achieves state-of-the-art (sota) results. our code is available at https://github.com/cv516buaa/st-dasegnet.",,2023-01-13,2023-04-12,"['qi zhao', 'shuchang lyu', 'binghao liu', 'lijiang chen', 'hongbo zhao']",https://arxiv.org/pdf/2301.05526.pdf
251,2301.06304,lysto: the lymphocyte assessment hackathon and benchmark dataset,eess.iv cs.cv,"we introduce lysto, the lymphocyte assessment hackathon, which was held in conjunction with the miccai 2019 conference in shenzen (china). the competition required participants to automatically assess the number of lymphocytes, in particular t-cells, in histopathological images of colon, breast, and prostate cancer stained with cd3 and cd8 immunohistochemistry. differently from other challenges setup in medical image analysis, lysto participants were solely given a few hours to address this problem. in this paper, we describe the goal and the multi-phase organization of the hackathon; we describe the proposed methods and the on-site results. additionally, we present post-competition results where we show how the presented methods perform on an independent set of lung cancer slides, which was not part of the initial competition, as well as a comparison on lymphocyte assessment between presented methods and a panel of pathologists. we show that some of the participants were capable to achieve pathologist-level performance at lymphocyte assessment. after the hackathon, lysto was left as a lightweight plug-and-play benchmark dataset on grand-challenge website, together with an automatic evaluation platform. lysto has supported a number of research in lymphocyte assessment in oncology. lysto will be a long-lasting educational challenge for deep learning and digital pathology, it is available at https://lysto.grand-challenge.org/.",,2023-01-16,2023-04-13,"['yiping jiao', 'jeroen van der laak', 'shadi albarqouni', 'zhang li', 'tao tan', 'abhir bhalerao', 'jiabo ma', 'jiamei sun', 'johnathan pocock', 'josien p. w. pluim', 'navid alemi koohbanani', 'raja muhammad saad bashir', 'shan e ahmed raza', 'sibo liu', 'simon graham', 'suzanne wetstein', 'syed ali khurram', 'thomas watson', 'nasir rajpoot', 'mitko veta', 'francesco ciompi']",https://arxiv.org/pdf/2301.06304.pdf
252,2301.06646,async-hfl: efficient and robust asynchronous federated learning in   hierarchical iot networks,cs.lg cs.dc cs.ni,"federated learning (fl) has gained increasing interest in recent years as a distributed on-device learning paradigm. however, multiple challenges remain to be addressed for deploying fl in real-world internet-of-things (iot) networks with hierarchies. although existing works have proposed various approaches to account data heterogeneity, system heterogeneity, unexpected stragglers and scalibility, none of them provides a systematic solution to address all of the challenges in a hierarchical and unreliable iot network. in this paper, we propose an asynchronous and hierarchical framework (async-hfl) for performing fl in a common three-tier iot network architecture. in response to the largely varied delays, async-hfl employs asynchronous aggregations at both the gateway and the cloud levels thus avoids long waiting time. to fully unleash the potential of async-hfl in converging speed under system heterogeneities and stragglers, we design device selection at the gateway level and device-gateway association at the cloud level. device selection chooses edge devices to trigger local training in real-time while device-gateway association determines the network topology periodically after several cloud epochs, both satisfying bandwidth limitation. we evaluate async-hfl's convergence speedup using large-scale simulations based on ns-3 and a network topology from nycmesh. our results show that async-hfl converges 1.08-1.31x faster in wall-clock time and saves up to 21.6% total communication cost compared to state-of-the-art asynchronous fl algorithms (with client selection). we further validate async-hfl on a physical deployment and observe robust convergence under unexpected stragglers.",10.1145/3576842.3582377,2023-01-16,2023-04-10,"['xiaofan yu', 'ludmila cherkasova', 'harsh vardhan', 'quanling zhao', 'emily ekaireb', 'xiyuan zhang', 'arya mazumdar', 'tajana rosing']",https://arxiv.org/pdf/2301.06646.pdf
253,2301.06855,event-based shape from polarization,cs.cv,"state-of-the-art solutions for shape-from-polarization (sfp) suffer from a speed-resolution tradeoff: they either sacrifice the number of polarization angles measured or necessitate lengthy acquisition times due to framerate constraints, thus compromising either accuracy or latency. we tackle this tradeoff using event cameras. event cameras operate at microseconds resolution with negligible motion blur, and output a continuous stream of events that precisely measures how light changes over time asynchronously. we propose a setup that consists of a linear polarizer rotating at high-speeds in front of an event camera. our method uses the continuous event stream caused by the rotation to reconstruct relative intensities at multiple polarizer angles. experiments demonstrate that our method outperforms physics-based baselines using frames, reducing the mae by 25% in synthetic and real-world dataset. in the real world, we observe, however, that the challenging conditions (i.e., when few events are generated) harm the performance of physics-based solutions. to overcome this, we propose a learning-based approach that learns to estimate surface normals even at low event-rates, improving the physics-based approach by 52% on the real world dataset. the proposed system achieves an acquisition speed equivalent to 50 fps (>twice the framerate of the commercial polarization sensor) while retaining the spatial resolution of 1mp. our evaluation is based on the first large-scale dataset for event-based sfp",,2023-01-17,2023-04-11,"['manasi muglikar', 'leonard bauersfeld', 'diederik paul moeys', 'davide scaramuzza']",https://arxiv.org/pdf/2301.06855.pdf
254,2301.07284,label inference attack against split learning under regression setting,cs.cr cs.lg,"as a crucial building block in vertical federated learning (vfl), split learning (sl) has demonstrated its practice in the two-party model training collaboration, where one party holds the features of data samples and another party holds the corresponding labels. such method is claimed to be private considering the shared information is only the embedding vectors and gradients instead of private raw data and labels. however, some recent works have shown that the private labels could be leaked by the gradients. these existing attack only works under the classification setting where the private labels are discrete. in this work, we step further to study the leakage in the scenario of the regression model, where the private labels are continuous numbers (instead of discrete labels in classification). this makes previous attacks harder to infer the continuous labels due to the unbounded output range. to address the limitation, we propose a novel learning-based attack that integrates gradient information and extra learning regularization objectives in aspects of model training properties, which can infer the labels under regression settings effectively. the comprehensive experiments on various datasets and models have demonstrated the effectiveness of our proposed attack. we hope our work can pave the way for future analyses that make the vfl framework more secure.",,2023-01-17,2023-04-07,"['shangyu xie', 'xin yang', 'yuanshun yao', 'tianyi liu', 'taiqing wang', 'jiankai sun']",https://arxiv.org/pdf/2301.07284.pdf
255,2301.07609,physics-informed information field theory for modeling physical systems   with uncertainty quantification,stat.ml cs.lg physics.data-an,"data-driven approaches coupled with physical knowledge are powerful techniques to model systems. the goal of such models is to efficiently solve for the underlying field by combining measurements with known physical laws. as many systems contain unknown elements, such as missing parameters, noisy data, or incomplete physical laws, this is widely approached as an uncertainty quantification problem. the common techniques to handle all the variables typically depend on the numerical scheme used to approximate the posterior, and it is desirable to have a method which is independent of any such discretization. information field theory (ift) provides the tools necessary to perform statistics over fields that are not necessarily gaussian. we extend ift to physics-informed ift (pift) by encoding the functional priors with information about the physical laws which describe the field. the posteriors derived from this pift remain independent of any numerical scheme and can capture multiple modes, allowing for the solution of problems which are ill-posed. we demonstrate our approach through an analytical example involving the klein-gordon equation. we then develop a variant of stochastic gradient langevin dynamics to draw samples from the joint posterior over the field and model parameters. we apply our method to numerical examples with various degrees of model-form error and to inverse problems involving nonlinear differential equations. as an addendum, the method is equipped with a metric which allows the posterior to automatically quantify model-form uncertainty. because of this, our numerical experiments show that the method remains robust to even an incorrect representation of the physics given sufficient data. we numerically demonstrate that the method correctly identifies when the physics cannot be trusted, in which case it automatically treats learning the field as a regression problem.",10.1016/j.jcp.2023.112100,2023-01-18,2023-04-12,"['alex alberts', 'ilias bilionis']",https://arxiv.org/pdf/2301.07609.pdf
256,2301.07850,concept discovery for fast adapatation,cs.lg,"the advances in deep learning have enabled machine learning methods to outperform human beings in various areas, but it remains a great challenge for a well-trained model to quickly adapt to a new task. one promising solution to realize this goal is through meta-learning, also known as learning to learn, which has achieved promising results in few-shot learning. however, current approaches are still enormously different from human beings' learning process, especially in the ability to extract structural and transferable knowledge. this drawback makes current meta-learning frameworks non-interpretable and hard to extend to more complex tasks. we tackle this problem by introducing concept discovery to the few-shot learning problem, where we achieve more effective adaptation by meta-learning the structure among the data features, leading to a composite representation of the data. our proposed method concept-based model-agnostic meta-learning (comaml) has been shown to achieve consistent improvements in the structured data for both synthesized datasets and real-world datasets.",,2023-01-18,2023-04-09,"['shengyu feng', 'hanghang tong']",https://arxiv.org/pdf/2301.07850.pdf
257,2301.08243,self-supervised learning from images with a joint-embedding predictive   architecture,cs.cv cs.ai cs.lg eess.iv,"this paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. we introduce the image-based joint-embedding predictive architecture (i-jepa), a non-generative approach for self-supervised learning from images. the idea behind i-jepa is simple: from a single context block, predict the representations of various target blocks in the same image. a core design choice to guide i-jepa towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. empirically, when combined with vision transformers, we find i-jepa to be highly scalable. for instance, we train a vit-huge/14 on imagenet using 16 a100 gpus in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.",,2023-01-19,2023-04-13,"['mahmoud assran', 'quentin duval', 'ishan misra', 'piotr bojanowski', 'pascal vincent', 'michael rabbat', 'yann lecun', 'nicolas ballas']",https://arxiv.org/pdf/2301.08243.pdf
258,2301.08840,compact optimization learning for ac optimal power flow,cs.lg,"this paper reconsiders end-to-end learning approaches to the optimal power flow (opf). existing methods, which learn the input/output mapping of the opf, suffer from scalability issues due to the high dimensionality of the output space. this paper first shows that the space of optimal solutions can be significantly compressed using principal component analysis (pca). it then proposes compact learning, a new method that learns in a subspace of the principal components before translating the vectors into the original output space. this compression reduces the number of trainable parameters substantially, improving scalability and effectiveness. compact learning is evaluated on a variety of test cases from the pglib with up to 30,000 buses. the paper also shows that the output of compact learning can be used to warm-start an exact ac solver to restore feasibility, while bringing significant speed-ups.",,2023-01-20,2023-04-07,"['seonho park', 'wenbo chen', 'terrence w. k. mak', 'pascal van hentenryck']",https://arxiv.org/pdf/2301.08840.pdf
259,2301.08968,the best of both worlds: accurate global and personalized models through   federated learning with data-free hyper-knowledge distillation,cs.lg,"heterogeneity of data distributed across clients limits the performance of global models trained through federated learning, especially in the settings with highly imbalanced class distributions of local datasets. in recent years, personalized federated learning (pfl) has emerged as a potential solution to the challenges presented by heterogeneous data. however, existing pfl methods typically enhance performance of local models at the expense of the global model's accuracy. we propose fedhkd (federated hyper-knowledge distillation), a novel fl algorithm in which clients rely on knowledge distillation (kd) to train local models. in particular, each client extracts and sends to the server the means of local data representations and the corresponding soft predictions -- information that we refer to as ``hyper-knowledge"". the server aggregates this information and broadcasts it to the clients in support of local training. notably, unlike other kd-based pfl methods, fedhkd does not rely on a public dataset nor it deploys a generative model at the server. we analyze convergence of fedhkd and conduct extensive experiments on visual datasets in a variety of scenarios, demonstrating that fedhkd provides significant improvement in both personalized as well as global model performance compared to state-of-the-art fl methods designed for heterogeneous data settings.",,2023-01-21,2023-04-09,"['huancheng chen', 'n/a johnny', 'n/a wang', 'haris vikalo']",https://arxiv.org/pdf/2301.08968.pdf
260,2301.09479,modality-agnostic variational compression of implicit neural   representations,stat.ml cs.ai cs.lg,"we introduce a modality-agnostic neural compression algorithm based on a functional view of data and parameterised as an implicit neural representation (inr). bridging the gap between latent coding and sparsity, we obtain compact latent representations non-linearly mapped to a soft gating mechanism. this allows the specialisation of a shared inr network to each data item through subnetwork selection. after obtaining a dataset of such latent representations, we directly optimise the rate/distortion trade-off in a modality-agnostic space using neural compression. variational compression of implicit neural representations (vc-inr) shows improved performance given the same representational capacity pre quantisation while also outperforming previous quantisation schemes used for other inr techniques. our experiments demonstrate strong results over a large set of diverse modalities using the same algorithm without any modality-specific inductive biases. we show results on images, climate data, 3d shapes and scenes as well as audio and video, introducing vc-inr as the first inr-based method to outperform codecs as well-known and diverse as jpeg 2000, mp3 and avc/hevc on their respective modalities.",,2023-01-23,2023-04-07,"['jonathan richard schwarz', 'jihoon tack', 'yee whye teh', 'jaeho lee', 'jinwoo shin']",https://arxiv.org/pdf/2301.09479.pdf
261,2301.09799,ldmic: learning-based distributed multi-view image coding,eess.iv cs.ai cs.cv cs.lg cs.mm,"multi-view image compression plays a critical role in 3d-related applications. existing methods adopt a predictive coding architecture, which requires joint encoding to compress the corresponding disparity as well as residual information. this demands collaboration among cameras and enforces the epipolar geometric constraint between different views, which makes it challenging to deploy these methods in distributed camera systems with randomly overlapping fields of view. meanwhile, distributed source coding theory indicates that efficient data compression of correlated sources can be achieved by independent encoding and joint decoding, which motivates us to design a learning-based distributed multi-view image coding (ldmic) framework. with independent encoders, ldmic introduces a simple yet effective joint context transfer module based on the cross-attention mechanism at the decoder to effectively capture the global inter-view correlations, which is insensitive to the geometric relationships between images. experimental results show that ldmic significantly outperforms both traditional and learning-based mic methods while enjoying fast encoding speed. code will be released at https://github.com/xinjie-q/ldmic.",,2023-01-23,2023-04-12,"['xinjie zhang', 'jiawei shao', 'jun zhang']",https://arxiv.org/pdf/2301.09799.pdf
262,2301.11518,online learning in stackelberg games with an omniscient follower,cs.lg,"we study the problem of online learning in a two-player decentralized cooperative stackelberg game. in each round, the leader first takes an action, followed by the follower who takes their action after observing the leader's move. the goal of the leader is to learn to minimize the cumulative regret based on the history of interactions. differing from the traditional formulation of repeated stackelberg games, we assume the follower is omniscient, with full knowledge of the true reward, and that they always best-respond to the leader's actions. we analyze the sample complexity of regret minimization in this repeated stackelberg game. we show that depending on the reward structure, the existence of the omniscient follower may change the sample complexity drastically, from constant to exponential, even for linear cooperative stackelberg games. this poses unique challenges for the learning process of the leader and the subsequent regret analysis.",,2023-01-26,2023-04-11,"['geng zhao', 'banghua zhu', 'jiantao jiao', 'michael i. jordan']",https://arxiv.org/pdf/2301.11518.pdf
263,2301.12382,"data-driven intelligent computational design for products: method,   techniques, and applications",cs.ai,"data-driven intelligent computational design (dicd) is a research hotspot emerged under the context of fast-developing artificial intelligence. it emphasizes on utilizing deep learning algorithms to extract and represent the design features hidden in historical or fabricated design process data, and then learn the combination and mapping patterns of these design features for the purposes of design solution retrieval, generation, optimization, evaluation, etc. due to its capability of automatically and efficiently generating design solutions and thus supporting human-in-the-loop intelligent and innovative design activities, dicd has drawn the attentions from both academic and industrial fields. however, as an emerging research subject, there are still many unexplored issues that limit the development and application of dicd, such as specific dataset building, engineering design related feature engineering, systematic methods and techniques for dicd implementation in the entire product design process, etc. in this regard, a systematic and operable road map for dicd implementation from full-process perspective is established, including a general workflow for dicd project planning, an overall framework for dicd project implementation, the computing mechanisms for dicd implementation, key enabling technologies for detailed dicd implementation, and three application scenarios of dicd. the road map reveals the common mechanisms and calculation principles of existing dicd researches, and thus it can provide systematic guidance for the possible dicd applications that have not been explored.",,2023-01-29,2023-04-11,"['maolin yang', 'pingyu jiang', 'tianshuo zang', 'yuhao liu']",https://arxiv.org/pdf/2301.12382.pdf
264,2301.12664,solving high-dimensional pdes with latent spectral models,cs.lg physics.comp-ph,"deep models have achieved impressive progress in solving partial differential equations (pdes). a burgeoning paradigm is learning neural operators to approximate the input-output mappings of pdes. while previous deep models have explored the multiscale architectures and various operator designs, they are limited to learning the operators as a whole in the coordinate space. in real physical science problems, pdes are complex coupled equations with numerical solvers relying on discretization into high-dimensional coordinate space, which cannot be precisely approximated by a single operator nor efficiently learned due to the curse of dimensionality. we present latent spectral models (lsm) toward an efficient and precise solver for high-dimensional pdes. going beyond the coordinate space, lsm enables an attention-based hierarchical projection network to reduce the high-dimensional data into a compact latent space in linear time. inspired by classical spectral methods in numerical analysis, we design a neural spectral block to solve pdes in the latent space that approximates complex input-output mappings via learning multiple basis operators, enjoying nice theoretical guarantees for convergence and approximation. experimentally, lsm achieves consistent state-of-the-art and yields a relative error reduction of 11.5% averaged on seven benchmarks covering both solid and fluid physics.",,2023-01-29,2023-04-10,"['haixu wu', 'tengge hu', 'huakun luo', 'jianmin wang', 'mingsheng long']",https://arxiv.org/pdf/2301.12664.pdf
265,2301.12872,a machine learning approach for correcting radial velocities using   physical observables,astro-ph.ep astro-ph.im astro-ph.sr cs.lg,"precision radial velocity (rv) measurements continue to be a key tool to detect and characterise extrasolar planets. while instrumental precision keeps improving, stellar activity remains a barrier to obtain reliable measurements below 1-2 m/s accuracy. using simulations and real data, we investigate the capabilities of a deep neural network approach to produce activity free doppler measurements of stars. as case studies we use observations of two known stars (eps eridani and aumicroscopii), both with clear signals of activity induced rv variability. synthetic data using the starsim code are generated for the observables (inputs) and the resulting rv signal (labels), and used to train a deep neural network algorithm. we identify an architecture consisting of convolutional and fully connected layers that is adequate to the task. the indices investigated are mean line-profile parameters (width, bisector, contrast) and multi-band photometry. we demonstrate that the rv-independent approach can drastically reduce spurious doppler variability from known physical effects such as spots, rotation and convective blueshift. we identify the combinations of activity indices with most predictive power. when applied to real observations, we observe a good match of the correction with the observed variability, but we also find that the noise reduction is not as good as in the simulations, probably due to the lack of detail in the simulated physics. we demonstrate that a model-driven machine learning approach is sufficient to clean doppler signals from activity induced variability for well known physical effects. there are dozens of known activity related observables whose inversion power remains unexplored indicating that the use of additional indicators, more complete models, and more observations with optimised sampling strategies can lead to significant improvements in our detrending capabilities.",10.1051/0004-6361/202245092,2023-01-30,,"['m. perger', 'g. anglada-escud√©', 'd. baroch', 'm. lafarga', 'i. ribas', 'j. c. morales', 'e. herrero', 'p. j. amado', 'j. r. barnes', 'j. a. caballero', 's. v. jeffers', 'a. quirrenbach', 'a. reiners']",https://arxiv.org/pdf/2301.12872.pdf
266,2301.12920,active learning for multilingual semantic parser,cs.cl,"current multilingual semantic parsing (msp) datasets are almost all collected by translating the utterances in the existing datasets from the resource-rich language to the target language. however, manual translation is costly. to reduce the translation effort, this paper proposes the first active learning procedure for msp (al-msp). al-msp selects only a subset from the existing datasets to be translated. we also propose a novel selection method that prioritizes the examples diversifying the logical form structures with more lexical choices, and a novel hyperparameter tuning method that needs no extra annotation cost. our experiments show that al-msp significantly reduces translation costs with ideal selection methods. our selection method with proper hyperparameters yields better parsing performance than the other baselines on two multilingual datasets.",,2023-01-30,2023-04-13,"['zhuang li', 'gholamreza haffari']",https://arxiv.org/pdf/2301.12920.pdf
267,2301.13112,benchmarking optimality of time series classification methods in   distinguishing diffusions,stat.ml cs.lg,"statistical optimality benchmarking is crucial for analyzing and designing time series classification (tsc) algorithms. this study proposes to benchmark the optimality of tsc algorithms in distinguishing diffusion processes by the likelihood ratio test (lrt). the lrt is an optimal classifier by the neyman-pearson lemma. the lrt benchmarks are computationally efficient because the lrt does not need training, and the diffusion processes can be efficiently simulated and are flexible to reflect the specific features of real-world applications. we demonstrate the benchmarking with three widely-used tsc algorithms: random forest, resnet, and rocket. these algorithms can achieve the lrt optimality for univariate time series and multivariate gaussian processes. however, these model-agnostic algorithms are suboptimal in classifying high-dimensional nonlinear multivariate time series. additionally, the lrt benchmark provides tools to analyze the dependence of classification accuracy on the time length, dimension, temporal sampling frequency, and randomness of the time series.",,2023-01-30,2023-04-11,"['zehong zhang', 'fei lu', 'esther xu fei', 'terry lyons', 'yannis kevrekidis', 'tom woolf']",https://arxiv.org/pdf/2301.13112.pdf
268,2301.13306,"autobidders with budget and roi constraints: efficiency, regret, and   pacing dynamics",cs.gt cs.lg,"we study a game between autobidding algorithms that compete in an online advertising platform. each autobidder is tasked with maximizing its advertiser's total value over multiple rounds of a repeated auction, subject to budget and/or return-on-investment constraints. we propose a gradient-based learning algorithm that is guaranteed to satisfy all constraints and achieves vanishing individual regret. our algorithm uses only bandit feedback and can be used with the first- or second-price auction, as well as with any ""intermediate"" auction format. our main result is that when these autobidders play against each other, the resulting expected liquid welfare over all rounds is at least half of the expected optimal liquid welfare achieved by any allocation. this holds whether or not the bidding dynamics converges to an equilibrium and regardless of the correlation structure between advertiser valuations.",,2023-01-30,2023-04-11,"['brendan lucier', 'sarath pattathil', 'aleksandrs slivkins', 'mengxiao zhang']",https://arxiv.org/pdf/2301.13306.pdf
269,2302.00873,predicting the silent majority on graphs: knowledge transferable graph   neural network,cs.lg cs.si,"graphs consisting of vocal nodes (""the vocal minority"") and silent nodes (""the silent majority""), namely vs-graph, are ubiquitous in the real world. the vocal nodes tend to have abundant features and labels. in contrast, silent nodes only have incomplete features and rare labels, e.g., the description and political tendency of politicians (vocal) are abundant while not for ordinary people (silent) on the twitter's social network. predicting the silent majority remains a crucial yet challenging problem. however, most existing message-passing based gnns assume that all nodes belong to the same domain, without considering the missing features and distribution-shift between domains, leading to poor ability to deal with vs-graph. to combat the above challenges, we propose knowledge transferable graph neural network (kt-gnn), which models distribution shifts during message passing and representation learning by transferring knowledge from vocal nodes to silent nodes. specifically, we design the domain-adapted ""feature completion and message passing mechanism"" for node representation learning while preserving domain difference. and a knowledge transferable classifier based on kl-divergence is followed. comprehensive experiments on real-world scenarios (i.e., company financial risk assessment and political elections) demonstrate the superior performance of our method. our source code has been open sourced.",10.1145/3543507.3583287,2023-02-01,2023-04-08,"['wendong bi', 'bingbing xu', 'xiaoqian sun', 'li xu', 'huawei shen', 'xueqi cheng']",https://arxiv.org/pdf/2302.00873.pdf
270,2302.01952,on a continuous time model of gradient descent dynamics and instability   in deep learning,stat.ml cs.lg,"the recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. to add to the theoretical tools available to study gradient descent we propose the principal flow (pf), a continuous time flow that approximates gradient descent dynamics. to our knowledge, the pf is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. through its dependence on the eigendecomposition of the hessian the pf sheds light on the recently observed edge of stability phenomena in deep learning. using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.",,2023-02-03,2023-04-11,"['mihaela rosca', 'yan wu', 'chongli qin', 'benoit dherin']",https://arxiv.org/pdf/2302.01952.pdf
271,2302.02615,rethinking out-of-distribution (ood) detection: masked image modeling is   all you need,cs.cv,"the core of out-of-distribution (ood) detection is to learn the in-distribution (id) representation, which is distinguishable from ood samples. previous work applied recognition-based methods to learn the id features, which tend to learn shortcuts instead of comprehensive representations. in this work, we find surprisingly that simply using reconstruction-based methods could boost the performance of ood detection significantly. we deeply explore the main contributors of ood detection and find that reconstruction-based pretext tasks have the potential to provide a generally applicable and efficacious prior, which benefits the model in learning intrinsic data distributions of the id dataset. specifically, we take masked image modeling as a pretext task for our ood detection framework (mood). without bells and whistles, mood outperforms previous sota of one-class ood detection by 5.7%, multi-class ood detection by 3.0%, and near-distribution ood detection by 2.1%. it even defeats the 10-shot-per-class outlier exposure ood detection, although we do not include any ood samples for our detection",,2023-02-06,2023-04-11,"['jingyao li', 'pengguang chen', 'shaozuo yu', 'zexin he', 'shu liu', 'jiaya jia']",https://arxiv.org/pdf/2302.02615.pdf
272,2302.03003,otre: where optimal transport guided unpaired image-to-image translation   meets regularization by enhancing,eess.iv cs.cv stat.ml,"non-mydriatic retinal color fundus photography (cfp) is widely available due to the advantage of not requiring pupillary dilation, however, is prone to poor quality due to operators, systemic imperfections, or patient-related causes. optimal retinal image quality is mandated for accurate medical diagnoses and automated analyses. herein, we leveraged the optimal transport (ot) theory to propose an unpaired image-to-image translation scheme for mapping low-quality retinal cfps to high-quality counterparts. furthermore, to improve the flexibility, robustness, and applicability of our image enhancement pipeline in the clinical practice, we generalized a state-of-the-art model-based image reconstruction method, regularization by denoising, by plugging in priors learned by our ot-guided image-to-image translation network. we named it as regularization by enhancing (re). we validated the integrated framework, otre, on three publicly available retinal image datasets by assessing the quality after enhancement and their performance on various downstream tasks, including diabetic retinopathy grading, vessel segmentation, and diabetic lesion segmentation. the experimental results demonstrated the superiority of our proposed framework over some state-of-the-art unsupervised competitors and a state-of-the-art supervised method.",,2023-02-06,2023-04-08,"['wenhui zhu', 'peijie qiu', 'oana m. dumitrascu', 'jacob m. sobczak', 'mohammad farazi', 'zhangsihao yang', 'keshav nandakumar', 'yalin wang']",https://arxiv.org/pdf/2302.03003.pdf
273,2302.03493,revised conditional t-sne: looking beyond the nearest neighbors,cs.lg stat.ml,"conditional t-sne (ct-sne) is a recent extension to t-sne that allows removal of known cluster information from the embedding, to obtain a visualization revealing structure beyond label information. this is useful, for example, when one wants to factor out unwanted differences between a set of classes. we show that ct-sne fails in many realistic settings, namely if the data is well clustered over the labels in the original high-dimensional space. we introduce a revised method by conditioning the high-dimensional similarities instead of the low-dimensional similarities and storing within- and across-label nearest neighbors separately. this also enables the use of recently proposed speedups for t-sne, improving the scalability. from experiments on synthetic data, we find that our proposed method resolves the considered problems and improves the embedding quality. on real data containing batch effects, the expected improvement is not always there. we argue revised ct-sne is preferable overall, given its improved scalability. the results also highlight new open questions, such as how to handle distance variations between clusters.",10.1007/978-3-031-30047-9_14,2023-02-07,2023-04-11,"['edith heiter', 'bo kang', 'ruth seurinck', 'jefrey lijffijt']",https://arxiv.org/pdf/2302.03493.pdf
274,2302.04054,towards inferential reproducibility of machine learning research,cs.lg cs.ai cs.cl stat.ap stat.ml,"reliability of machine learning evaluation -- the consistency of observed evaluation scores across replicated model training runs -- is affected by several sources of nondeterminism which can be regarded as measurement noise. current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. this limits the scope of conclusions that can be drawn from such experiments. instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. we show how to use linear mixed effects models (lmems) to analyze performance evaluation scores, and to conduct statistical inference with a generalized likelihood ratio test (glrt). this allows us to incorporate arbitrary sources of noise like meta-parameter variations into statistical significance testing, and to assess performance differences conditional on data properties. furthermore, a variance component analysis (vca) enables the analysis of the contribution of noise sources to overall variance and the computation of a reliability coefficient by the ratio of substantial to total variance.",,2023-02-08,2023-04-13,"['michael hagmann', 'philipp meier', 'stefan riezler']",https://arxiv.org/pdf/2302.04054.pdf
275,2302.04802,near-field terahertz communications: model-based and model-free channel   estimation,eess.sp cs.it math.it,"terahertz (thz) band is expected to be one of the key enabling technologies of the sixth generation (6g) wireless networks because of its abundant available bandwidth and very narrow beam width. due to high frequency operations, electrically small array apertures are employed, and the signal wavefront becomes spherical in the near-field. therefore, near-field signal model should be considered for channel acquisition in thz systems. unlike prior works which mostly ignore the impact of near-field beam-split (nb) and consider either narrowband scenario or far-field models, this paper introduces both a model-based and a model-free techniques for wideband thz channel estimation in the presence of nb. the model-based approach is based on orthogonal matching pursuit (omp) algorithm, for which we design an nb-aware dictionary. the key idea is to exploit the angular and range deviations due to the nb. we then employ the omp algorithm, which accounts for the deviations thereby ipso facto mitigating the effect of nb. we further introduce a federated learning (fl)-based approach as a model-free solution for channel estimation in a multi-user scenario to achieve reduced complexity and training overhead. through numerical simulations, we demonstrate the effectiveness of the proposed channel estimation techniques for wideband thz systems in comparison with the existing state-of-the-art techniques.",10.1109/access.2023.3266297,2023-02-09,,"['ahmet m. elbir', 'wei shi', 'anastasios k. papazafeiropoulos', 'pandelis kourtessis', 'symeon chatzinotas']",https://arxiv.org/pdf/2302.04802.pdf
276,2302.05757,multispectral contrastive learning with viewmaker networks,cs.cv cs.ai,"contrastive learning methods have been applied to a range of domains and modalities by training models to identify similar ""views"" of data points. however, specialized scientific modalities pose a challenge for this paradigm, as identifying good views for each scientific instrument is complex and time-intensive. in this paper, we focus on applying contrastive learning approaches to a variety of remote sensing datasets. we show that viewmaker networks, a recently proposed method for generating views, are promising for producing views in this setting without requiring extensive domain knowledge and trial and error. we apply viewmaker to four multispectral imaging problems, each with a different format, finding that viewmaker can outperform cropping- and reflection-based methods for contrastive learning in every case when evaluated on downstream classification tasks. this provides additional evidence that domain-agnostic methods can empower contrastive learning to scale to real-world scientific domains. open source code can be found at https://github.com/jbayrooti/divmaker.",,2023-02-11,2023-04-11,"['jasmine bayrooti', 'noah goodman', 'alex tamkin']",https://arxiv.org/pdf/2302.05757.pdf
277,2302.05823,data efficiency and extrapolation trends in neural network interatomic   potentials,cs.lg physics.chem-ph,"over the last few years, key architectural advances have been proposed for neural network interatomic potentials (nnips), such as incorporating message-passing networks, equivariance, or many-body expansion terms. although modern nnip models exhibit small differences in energy/forces errors, improvements in accuracy are still considered the main target when developing new nnip architectures. in this work, we show how architectural and optimization choices influence the generalization of nnips, revealing trends in molecular dynamics (md) stability, data efficiency, and loss landscapes. using the 3bpa dataset, we show that test errors in nnip follow a scaling relation and can be robust to noise, but cannot predict md stability in the high-accuracy regime. to circumvent this problem, we propose the use of loss landscape visualizations and a metric of loss entropy for predicting the generalization power of nnips. with a large-scale study on nequip and mace, we show that the loss entropy predicts out-of-distribution error and md stability despite being computed only on the training set. using this probe, we demonstrate how the choice of optimizers, loss function weighting, data normalization, and other architectural decisions influence the extrapolation behavior of nnips. finally, we relate loss entropy to data efficiency, demonstrating that flatter landscapes also predict learning curve slopes. our work provides a deep learning justification for the extrapolation performance of many common nnips, and introduces tools beyond accuracy metrics that can be used to inform the development of next-generation models.",,2023-02-11,2023-04-12,"['joshua a. vita', 'daniel schwalbe-koda']",https://arxiv.org/pdf/2302.05823.pdf
278,2302.06120,knowledge from large-scale protein contact prediction models can be   transferred to the data-scarce rna contact prediction task,q-bio.qm cs.lg,"rna, whose functionality is largely determined by its structure, plays an important role in many biological activities. the prediction of pairwise structural proximity between each nucleotide of an rna sequence can characterize the structural information of the rna. historically, this problem has been tackled by machine learning models using expert-engineered features and trained on scarce labeled datasets. here, we find that the knowledge learned by a protein-coevolution transformer-based deep neural network can be transferred to the rna contact prediction task. as protein datasets are orders of magnitude larger than those for rna contact prediction, our findings and the subsequent framework greatly reduce the data scarcity bottleneck. experiments confirm that rna contact prediction through transfer learning using a publicly available protein model is greatly improved. our findings indicate that the learned structural patterns of proteins can be transferred to rnas, opening up potential new avenues for research.",,2023-02-13,2023-04-07,"['yiren jian', 'chongyang gao', 'chen zeng', 'yunjie zhao', 'soroush vosoughi']",https://arxiv.org/pdf/2302.06120.pdf
279,2302.06905,iterative minimization algorithm on mixture family,cs.it math.it,"iterative minimization algorithms appear in various areas including machine learning, neural network, and information theory. the em algorithm is one of the famous one in the former area, and arimoto-blahut algorithm is a typical one in the latter area. however, these two topics had been separately studied for a long time. in this paper, we generalize an algorithm that was recently proposed in the context of arimoto-blahut algorithm. then, we show various convergence theorems, one of which covers the case when each iterative step is done approximately. also, we apply this algorithm to the target problem in em algorithm, and propose its improvement. in addition, we apply it to other various problems in information theory.",,2023-02-14,2023-04-11,['masahito hayashi'],https://arxiv.org/pdf/2302.06905.pdf
280,2302.07684,a federated learning benchmark for drug-target interaction,cs.lg cs.dc,"aggregating pharmaceutical data in the drug-target interaction (dti) domain has the potential to deliver life-saving breakthroughs. it is, however, notoriously difficult due to regulatory constraints and commercial interests. this work proposes the application of federated learning, which we argue to be reconcilable with the industry's constraints, as it does not require sharing of any information that would reveal the entities' data or any other high-level summary of it. when used on a representative graphdta model and the kiba dataset it achieves up to 15% improved performance relative to the best available non-privacy preserving alternative. our extensive battery of experiments shows that, unlike in other domains, the non-iid data distribution in the dti datasets does not deteriorate fl performance. additionally, we identify a material trade-off between the benefits of adding new data, and the cost of adding more clients.",,2023-02-15,2023-04-08,"['gianluca mittone', 'filip svoboda', 'marco aldinucci', 'nicholas d. lane', 'pietro lio']",https://arxiv.org/pdf/2302.07684.pdf
281,2302.07946,experimenting with emerging risc-v systems for decentralised machine   learning,cs.dc cs.lg,"decentralised machine learning (dml) enables collaborative machine learning without centralised input data. federated learning (fl) and edge inference are examples of dml. while tools for dml (especially fl) are starting to flourish, many are not flexible and portable enough to experiment with novel processors (e.g., risc-v), non-fully connected network topologies, and asynchronous collaboration schemes. we overcome these limitations via a domain-specific language allowing us to map dml schemes to an underlying middleware, i.e. the fastflow parallel programming library. we experiment with it by generating different working dml schemes on x86-64 and arm platforms and an emerging risc-v one. we characterise the performance and energy efficiency of the presented schemes and systems. as a byproduct, we introduce a risc-v porting of the pytorch framework, the first publicly available to our knowledge.",,2023-02-15,2023-04-08,"['gianluca mittone', 'nicol√≤ tonci', 'robert birke', 'iacopo colonnelli', 'doriana mediƒá', 'andrea bartolini', 'roberto esposito', 'emanuele parisi', 'francesco beneventi', 'mirko polato', 'massimo torquati', 'luca benini', 'marco aldinucci']",https://arxiv.org/pdf/2302.07946.pdf
282,2302.08007,"with shared microexponents, a little shifting goes a long way",cs.lg cs.ai cs.ar,"this paper introduces block data representations (bdr), a framework for exploring and evaluating a wide spectrum of narrow-precision formats for deep learning. it enables comparison of popular quantization standards, and through bdr, new formats based on shared microexponents (mx) are identified, which outperform other state-of-the-art quantization approaches, including narrow-precision floating-point and block floating-point. mx utilizes multiple levels of quantization scaling with ultra-fine scaling factors based on shared microexponents in the hardware. the effectiveness of mx is demonstrated on real-world models including large-scale generative pretraining and inferencing, and production-scale recommendation systems.",,2023-02-15,2023-04-12,"['bita rouhani', 'ritchie zhao', 'venmugil elango', 'rasoul shafipour', 'mathew hall', 'maral mesmakhosroshahi', 'ankit more', 'levi melnick', 'maximilian golub', 'girish varatkar', 'lei shao', 'gaurav kolhe', 'dimitry melts', 'jasmine klar', ""renee l'heureux"", 'matt perry', 'doug burger', 'eric chung', 'zhaoxia deng', 'sam naghshineh', 'jongsoo park', 'maxim naumov']",https://arxiv.org/pdf/2302.08007.pdf
283,2302.09051,"complex qa and language models hybrid architectures, survey",cs.cl cs.ai cs.ir cs.lg,"this paper reviews the state-of-the-art of language models architectures and strategies for ""complex"" question-answering (qa, cqa, cps) with a focus on hybridization. large language models (llm) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. how does the concept of personal freedom vary between different cultures ? what is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... recent projects like chatgpt and galactica have allowed non-specialists to grasp the great potential as well as the equally strong limitations of llm in complex qa. in this paper, we start by reviewing required skills and evaluation techniques. we integrate findings from the robust community edited research papers big, bloom and helm which open source, benchmark and analyze limits and challenges of llm in terms of tasks complexity and strict evaluation on accuracy (e.g. fairness, robustness, toxicity, ...) as a baseline. we discuss some challenges associated with complex qa, including domain adaptation, decomposition and efficient multi-step qa, long form and non-factoid qa, safety and multi-sensitivity data protection, multimodal search, hallucinations, explainability and truthfulness, temporal reasoning. we analyze current solutions and promising research trends, using elements such as: hybrid llm architectural patterns, training and prompting strategies, active human reinforcement learning supervised with ai, neuro-symbolic and structured knowledge grounding, program synthesis, iterated decomposition and others.",,2023-02-17,2023-04-07,"['xavier daull', 'patrice bellot', 'emmanuel bruno', 'vincent martin', 'elisabeth murisasco']",https://arxiv.org/pdf/2302.09051.pdf
284,2302.09498,mutual exclusive modulator for long-tailed recognition,cs.cv,"the long-tailed recognition (ltr) is the task of learning high-performance classifiers given extremely imbalanced training samples between categories. most of the existing works address the problem by either enhancing the features of tail classes or re-balancing the classifiers to reduce the inductive bias. in this paper, we try to look into the root cause of the ltr task, i.e., training samples for each class are greatly imbalanced, and propose a straightforward solution. we split the categories into three groups, i.e., many, medium and few, according to the number of training images. the three groups of categories are separately predicted to reduce the difficulty for classification. this idea naturally arises a new problem of how to assign a given sample to the right class groups? we introduce a mutual exclusive modulator which can estimate the probability of an image belonging to each group. particularly, the modulator consists of a light-weight module and learned with a mutual exclusive objective. hence, the output probabilities of the modulator encode the data volume clues of the training dataset. they are further utilized as prior information to guide the prediction of the classifier. we conduct extensive experiments on multiple datasets, e.g., imagenet-lt, place-lt and inaturalist 2018 to evaluate the proposed approach. our method achieves competitive performance compared to the state-of-the-art benchmarks.",,2023-02-19,2023-04-11,"['haixu long', 'xiaolin zhang', 'yanbin liu', 'zongtai luo', 'jianbo liu']",https://arxiv.org/pdf/2302.09498.pdf
285,2302.10632,multi-modal self-supervised learning for recommendation,cs.ir,"the online emergence of multi-modal sharing platforms (eg, tiktok, youtube) is powering personalized recommender systems to incorporate various modalities (eg, visual, textual and acoustic) into the latent user representations. while existing works on multi-modal recommendation exploit multimedia content features in enhancing item embeddings, their model representation capability is limited by heavy label reliance and weak robustness on sparse user behavior data. inspired by the recent progress of self-supervised learning in alleviating label scarcity issue, we explore deriving self-supervision signals with effectively learning of modality-aware user preference and cross-modal dependencies. to this end, we propose a new multi-modal self-supervised learning (mmssl) method which tackles two key challenges. specifically, to characterize the inter-dependency between the user-item collaborative view and item multi-modal semantic view, we design a modality-aware interactive structure learning paradigm via adversarial perturbations for data augmentation. in addition, to capture the effects that user's modality-aware interaction pattern would interweave with each other, a cross-modal contrastive learning approach is introduced to jointly preserve the inter-modal semantic commonality and user preference diversity. experiments on real-world datasets verify the superiority of our method in offering great potential for multimedia recommendation over various state-of-the-art baselines. the implementation is released at: https://github.com/hkuds/mmssl.",10.1145/3543507.3583206,2023-02-21,2023-04-07,"['wei wei', 'chao huang', 'lianghao xia', 'chuxu zhang']",https://arxiv.org/pdf/2302.10632.pdf
286,2302.11024,"gradient flows for sampling: mean-field models, gaussian approximations   and affine invariance",stat.ml cs.na math.na,"sampling a probability distribution with an unknown normalization constant is a fundamental problem in computational science and engineering. this task may be cast as an optimization problem over all probability measures, and an initial distribution can be evolved to the desired minimizer dynamically via gradient flows. mean-field models, whose law is governed by the gradient flow in the space of probability measures, may also be identified; particle approximations of these mean-field models form the basis of algorithms. the gradient flow approach is also the basis of algorithms for variational inference, in which the optimization is performed over a parameterized family of probability distributions such as gaussians, and the underlying gradient flow is restricted to the parameterized family.   by choosing different energy functionals and metrics for the gradient flow, different algorithms with different convergence properties arise. in this paper, we concentrate on the kullback-leibler divergence after showing that, up to scaling, it has the unique property that the gradient flows resulting from this choice of energy do not depend on the normalization constant. for the metrics, we focus on variants of the fisher-rao, wasserstein, and stein metrics; we introduce the affine invariance property for gradient flows, and their corresponding mean-field models, determine whether a given metric leads to affine invariance, and modify it to make it affine invariant if it does not. we study the resulting gradient flows in both probability density space and gaussian space. the flow in the gaussian space may be understood as a gaussian approximation of the flow. we demonstrate that the gaussian approximation based on the metric and through moment closure coincide, establish connections between them, and study their long-time convergence properties showing the advantages of affine invariance.",,2023-02-21,2023-04-11,"['yifan chen', 'daniel zhengyu huang', 'jiaoyang huang', 'sebastian reich', 'andrew m. stuart']",https://arxiv.org/pdf/2302.11024.pdf
287,2302.11474,randomized numerical linear algebra : a perspective on the field with an   eye to software,math.na cs.ms cs.na math.oc,"randomized numerical linear algebra - randnla, for short - concerns the use of randomization as a resource to develop improved algorithms for large-scale linear algebra computations.   the origins of contemporary randnla lay in theoretical computer science, where it blossomed from a simple idea: randomization provides an avenue for computing approximate solutions to linear algebra problems more efficiently than deterministic algorithms. this idea proved fruitful in the development of scalable algorithms for machine learning and statistical data analysis applications. however, randnla's true potential only came into focus upon integration with the fields of numerical analysis and ""classical"" numerical linear algebra. through the efforts of many individuals, randomized algorithms have been developed that provide full control over the accuracy of their solutions and that can be every bit as reliable as algorithms that might be found in libraries such as lapack. recent years have even seen the incorporation of certain randnla methods into matlab, the nag library, nvidia's cusolver, and scikit-learn.   for all its success, we believe that randnla has yet to realize its full potential. in particular, we believe the scientific community stands to benefit significantly from suitably defined ""randblas"" and ""randlapack"" libraries, to serve as standards conceptually analogous to blas and lapack. this 200-page monograph represents a step toward defining such standards. in it, we cover topics spanning basic sketching, least squares and optimization, low-rank approximation, full matrix decompositions, leverage score sampling, and sketching data with tensor product structures (among others). much of the provided pseudo-code has been tested via publicly available matlab and python implementations.",,2023-02-22,2023-04-12,"['riley murray', 'james demmel', 'michael w. mahoney', 'n. benjamin erichson', 'maksim melnichenko', 'osman asif malik', 'laura grigori', 'piotr luszczek', 'micha≈Ç derezi≈Ñski', 'miles e. lopes', 'tianyu liang', 'hengrui luo', 'jack dongarra']",https://arxiv.org/pdf/2302.11474.pdf
288,2302.11520,guiding large language models via directional stimulus prompting,cs.cl,"we introduce a new framework, directional stimulus prompting, that uses a tuneable language model (lm) to provide guidance for the black-box frozen large language model (llm) on downstream tasks. unlike prior work that manually or automatically finds the optimal prompt for each task, we train a policy lm to generate discrete tokens as directional stimulus of each input, which is a hint/cue such as keywords of an article for summarization. the directional stimulus is then combined with the original input and fed into the llm to guide its generation toward the desired target. the policy lm can be trained through 1) supervised learning from annotated data and 2) reinforcement learning from offline and online rewards to explore directional stimulus that better aligns llms with human preferences. this framework is flexibly applicable to various lms and tasks. to verify its effectiveness, we apply our framework to summarization and dialogue response generation tasks. experimental results demonstrate that it can significantly improve llms' performance with a small collection of training data: a t5 (780m) trained with 2,000 samples from the cnn/daily mail dataset improves codex (175b)'s performance by 9.0% in rouge-avg scores; only 80 dialogues can boost the combined score by 39.7%, achieving comparable or even better performance than some fully trained models on the multiwoz dataset. we have made our code publicly available.",,2023-02-22,2023-04-07,"['zekun li', 'baolin peng', 'pengcheng he', 'michel galley', 'jianfeng gao', 'xifeng yan']",https://arxiv.org/pdf/2302.11520.pdf
289,2302.11559,word level bangla sign language dataset for continuous bsl recognition,cs.cv,"an robust sign language recognition system can greatly alleviate communication barriers, particularly for people who struggle with verbal communication. this is crucial for human growth and progress as it enables the expression of thoughts, feelings, and ideas. however, sign recognition is a complex task that faces numerous challenges such as same gesture patterns for multiple signs, lighting, clothing, carrying conditions, and the presence of large poses, as well as illumination discrepancies across different views. additionally, the absence of an extensive bangla sign language video dataset makes it even more challenging to operate recognition systems, particularly when utilizing deep learning techniques. in order to address this issue, firstly, we created a large-scale dataset called the mvbsl-w50, which comprises 50 isolated words across 13 categories. secondly, we developed an attention-based bi-gru model that captures the temporal dynamics of pose information for individuals communicating through sign language. the proposed model utilizes human pose information, which has shown to be successful in analyzing sign language patterns. by focusing solely on movement information and disregarding body appearance and environmental factors, the model is simplified and can achieve a speedier performance. the accuracy of the model is reported to be 85.64%.",,2023-02-22,2023-04-09,"['md shamimul islam', 'a. j. m. akhtarujjaman joha', 'md nur hossain', 'sohaib abdullah', 'ibrahim elwarfalli', 'md mahedi hasan']",https://arxiv.org/pdf/2302.11559.pdf
290,2302.11933,improving safety in physical human-robot collaboration via deep metric   learning,cs.ro cs.ai,"direct physical interaction with robots is becoming increasingly important in flexible production scenarios, but robots without protective fences also pose a greater risk to the operator. in order to keep the risk potential low, relatively simple measures are prescribed for operation, such as stopping the robot if there is physical contact or if a safety distance is violated. although human injuries can be largely avoided in this way, all such solutions have in common that real cooperation between humans and robots is hardly possible and therefore the advantages of working with such systems cannot develop its full potential. in human-robot collaboration scenarios, more sophisticated solutions are required that make it possible to adapt the robot's behavior to the operator and/or the current situation. most importantly, during free robot movement, physical contact must be allowed for meaningful interaction and not recognized as a collision. however, here lies a key challenge for future systems: detecting human contact by using robot proprioception and machine learning algorithms. this work uses the deep metric learning (dml) approach to distinguish between non-contact robot movement, intentional contact aimed at physical human-robot interaction, and collision situations. the achieved results are promising and show show that dml achieves 98.6\% accuracy, which is 4\% higher than the existing standards (i.e. a deep learning network trained without dml). it also indicates a promising generalization capability for easy portability to other robots (target robots) by detecting contact (distinguishing between contactless and intentional or accidental contact) without having to retrain the model with target robot data.",10.1109/etfa52439.2022.9921623,2023-02-23,2023-04-13,"['maryam rezayati', 'grammatiki zanni', 'ying zaoshi', 'davide scaramuzza', 'hans wernher van de venn']",https://arxiv.org/pdf/2302.11933.pdf
291,2302.11996,k-shap: policy clustering algorithm for anonymous state-action pairs,cs.lg cs.ai,"learning agent behaviors from observational data has shown to improve our understanding of their decision-making processes, advancing our ability to explain their interactions with the environment and other agents. while multiple learning techniques have been proposed in the literature, there is one particular setting that has not been explored yet: multi agent systems where agent identities remain anonymous. for instance, in financial markets labeled data that identifies market participant strategies is typically proprietary, and only the anonymous state-action pairs that result from the interaction of multiple market participants are publicly available. as a result, sequences of agent actions are not observable, restricting the applicability of existing work. in this paper, we propose a policy clustering algorithm, called k-shap, that learns to group anonymous state-action pairs according to the agent policies. we frame the problem as an imitation learning (il) task, and we learn a world-policy able to mimic all the agent behaviors upon different environmental states. we leverage the world-policy to explain each anonymous observation through an additive feature attribution method called shap (shapley additive explanations). finally, by clustering the explanations we show that we are able to identify different agent policies and group observations accordingly. we evaluate our approach on simulated synthetic market data and a real-world financial dataset. we show that our proposal significantly and consistently outperforms the existing methods, identifying different agent strategies.",,2023-02-23,2023-04-13,"['andrea coletta', 'svitlana vyetrenko', 'tucker balch']",https://arxiv.org/pdf/2302.11996.pdf
292,2302.12604,neural laplace control for continuous-time delayed systems,cs.lg cs.ai cs.ro stat.ml,"many real-world offline reinforcement learning (rl) problems involve continuous-time environments with delays. such environments are characterized by two distinctive features: firstly, the state x(t) is observed at irregular time intervals, and secondly, the current action a(t) only affects the future state x(t + g) with an unknown delay g > 0. a prime example of such an environment is satellite control where the communication link between earth and a satellite causes irregular observations and delays. existing offline rl algorithms have achieved success in environments with irregularly observed states in time or known delays. however, environments involving both irregular observations in time and unknown delays remains an open and challenging problem. to this end, we propose neural laplace control, a continuous-time model-based offline rl method that combines a neural laplace dynamics model with a model predictive control (mpc) planner--and is able to learn from an offline dataset sampled with irregular time intervals from an environment that has a inherent unknown constant delay. we show experimentally on continuous-time delayed environments it is able to achieve near expert policy performance.",,2023-02-24,2023-04-10,"['samuel holt', 'alihan h√ºy√ºk', 'zhaozhi qian', 'hao sun', 'mihaela van der schaar']",https://arxiv.org/pdf/2302.12604.pdf
293,2302.12744,anomalous no2 emitting ship detection with tropomi satellite data and   machine learning,cs.lg physics.ao-ph,"starting from 2021, more demanding $\text{no}_\text{x}$ emission restrictions were introduced for ships operating in the north and baltic sea waters. since all methods currently used for ship compliance monitoring are financially and time demanding, it is important to prioritize the inspection of ships that have high chances of being non-compliant. the current state-of-the-art approach for a large-scale ship $\text{no}_\text{2}$ estimation is a supervised machine learning-based segmentation of ship plumes on tropomi/s5p images. however, challenging data annotation and insufficiently complex ship emission proxy used for the validation limit the applicability of the model for ship compliance monitoring. in this study, we present a method for the automated selection of potentially non-compliant ships using a combination of machine learning models on tropomi satellite data. it is based on a proposed regression model predicting the amount of $\text{no}_\text{2}$ that is expected to be produced by a ship with certain properties operating in the given atmospheric conditions. the model does not require manual labeling and is validated with tropomi data directly. the differences between the predicted and actual amount of produced $\text{no}_\text{2}$ are integrated over observations of the ship in time and are used as a measure of the inspection worthiness of a ship. to assure the robustness of the results, we compare the obtained results with the results of the previously developed segmentation-based method. ships that are also highly deviating in accordance with the segmentation method require further attention. if no other explanations can be found by checking the tropomi data, the respective ships are advised to be the candidates for inspection.",,2023-02-24,2023-04-07,"['solomiia kurchaba', 'jasper van vliet', 'fons j. verbeek', 'cor j. veenman']",https://arxiv.org/pdf/2302.12744.pdf
294,2302.13144,revisiting lqr control from the perspective of receding-horizon policy   gradient,math.oc cs.ai cs.lg cs.sy eess.sy,"we revisit in this paper the discrete-time linear quadratic regulator (lqr) problem from the perspective of receding-horizon policy gradient (rhpg), a newly developed model-free learning framework for control applications. we provide a fine-grained sample complexity analysis for rhpg to learn a control policy that is both stabilizing and $\epsilon$-close to the optimal lqr solution, and our algorithm does not require knowing a stabilizing control policy for initialization. combined with the recent application of rhpg in learning the kalman filter, we demonstrate the general applicability of rhpg in linear control and estimation with streamlined analyses.",,2023-02-25,2023-04-06,"['xiangyuan zhang', 'tamer ba≈üar']",https://arxiv.org/pdf/2302.13144.pdf
295,2302.13610,a prototypical semantic decoupling method via joint contrastive learning   for few-shot name entity recognition,cs.cl,"few-shot named entity recognition (ner) aims at identifying named entities based on only few labeled instances. most existing prototype-based sequence labeling models tend to memorize entity mentions which would be easily confused by close prototypes. in this paper, we proposed a prototypical semantic decoupling method via joint contrastive learning (psdc) for few-shot ner. specifically, we decouple class-specific prototypes and contextual semantic prototypes by two masking strategies to lead the model to focus on two different semantic information for inference. besides, we further introduce joint contrastive learning objectives to better integrate two kinds of decoupling information and prevent semantic collapse. experimental results on two few-shot ner benchmarks demonstrate that psdc consistently outperforms the previous sota methods in terms of overall performance. extensive analysis further validates the effectiveness and generalization of psdc.",,2023-02-27,2023-04-12,"['guanting dong', 'zechen wang', 'liwen wang', 'daichi guo', 'dayuan fu', 'yuxiang wu', 'chen zeng', 'xuefeng li', 'tingfeng hui', 'keqing he', 'xinyue cui', 'qixiang gao', 'weiran xu']",https://arxiv.org/pdf/2302.13610.pdf
296,2302.13741,hulk: graph neural networks for optimizing regionally distributed   computing systems,cs.dc cs.cl,"large deep learning models have shown great potential for delivering exceptional results in various applications. however, the training process can be incredibly challenging due to the models' vast parameter sizes, often consisting of hundreds of billions of parameters. common distributed training methods, such as data parallelism, tensor parallelism, and pipeline parallelism, demand significant data communication throughout the process, leading to prolonged wait times for some machines in physically distant distributed systems. to address this issue, we propose a novel solution called hulk, which utilizes a modified graph neural network to optimize distributed computing systems. hulk not only optimizes data communication efficiency between different countries or even different regions within the same city, but also provides optimal distributed deployment of models in parallel. for example, it can place certain layers on a machine in a specific region or pass specific parameters of a model to a machine in a particular location. by using hulk in experiments, we were able to improve the time efficiency of training large deep learning models on distributed systems by more than 20\%. our open source collection of unlabeled data:https://github.com/dlyuangod/hulk.",,2023-02-27,2023-04-13,"['zhengqing yuan', 'huiwen xue', 'chao zhang', 'yongming liu']",https://arxiv.org/pdf/2302.13741.pdf
297,2303.01105,evidence-empowered transfer learning for alzheimer's disease,eess.iv cs.cv cs.lg,"transfer learning has been widely utilized to mitigate the data scarcity problem in the field of alzheimer's disease (ad). conventional transfer learning relies on re-using models trained on ad-irrelevant tasks such as natural image classification. however, it often leads to negative transfer due to the discrepancy between the non-medical source and target medical domains. to address this, we present evidence-empowered transfer learning for ad diagnosis. unlike conventional approaches, we leverage an ad-relevant auxiliary task, namely morphological change prediction, without requiring additional mri data. in this auxiliary task, the diagnosis model learns the evidential and transferable knowledge from morphological features in mri scans. experimental results demonstrate that our framework is not only effective in improving detection performance regardless of model capacity, but also more data-efficient and faithful.",,2023-03-02,2023-04-13,"['kai tzu-iunn ong', 'hana kim', 'minjin kim', 'jinseong jang', 'beomseok sohn', 'yoon seong choi', 'dosik hwang', 'seong jae hwang', 'jinyoung yeo']",https://arxiv.org/pdf/2303.01105.pdf
298,2303.01513,learning machines for health and beyond,cs.lg cs.ai,"machine learning techniques are effective for building predictive models because they are good at identifying patterns in large datasets. development of a model for complex real life problems often stops at the point of publication, proof of concept or when made accessible through some mode of deployment. however, a model in the medical domain risks becoming obsolete as soon as patient demographic changes. the maintenance and monitoring of predictive models post-publication is crucial to guarantee their safe and effective long term use. as machine learning techniques are effectively trained to look for patterns in available datasets, the performance of a model for complex real life problems will not peak and remain fixed at the point of publication or even point of deployment. rather, data changes over time, and they also changed when models are transported to new places to be used by new demography.",,2023-03-02,2023-04-10,"['mahed abroshan', 'oscar giles', 'sam greenbury', 'jack roberts', 'mihaela van der schaar', 'jannetta s steyn', 'alan wilson', 'may yong']",https://arxiv.org/pdf/2303.01513.pdf
299,2303.01559,improving gan training via feature space shrinkage,cs.cv cs.ai,"due to the outstanding capability for data generation, generative adversarial networks (gans) have attracted considerable attention in unsupervised learning. however, training gans is difficult, since the training distribution is dynamic for the discriminator, leading to unstable image representation. in this paper, we address the problem of training gans from a novel perspective, \emph{i.e.,} robust image classification. motivated by studies on robust image representation, we propose a simple yet effective module, namely adaptivemix, for gans, which shrinks the regions of training data in the image representation space of the discriminator. considering it is intractable to directly bound feature space, we propose to construct hard samples and narrow down the feature distance between hard and easy samples. the hard samples are constructed by mixing a pair of training images. we evaluate the effectiveness of our adaptivemix with widely-used and state-of-the-art gan architectures. the evaluation results demonstrate that our adaptivemix can facilitate the training of gans and effectively improve the image quality of generated samples. we also show that our adaptivemix can be further applied to image classification and out-of-distribution (ood) detection tasks, by equipping it with state-of-the-art methods. extensive experiments on seven publicly available datasets show that our method effectively boosts the performance of baselines. the code is publicly available at https://github.com/wentianzhang-ml/adaptivemix.",,2023-03-02,2023-04-08,"['haozhe liu', 'wentian zhang', 'bing li', 'haoqian wu', 'nanjun he', 'yawen huang', 'yuexiang li', 'bernard ghanem', 'yefeng zheng']",https://arxiv.org/pdf/2303.01559.pdf
300,2303.02468,lon-ea at semeval-2023 task 11: a comparison of activation functions for   soft and hard label prediction,cs.cl cs.lg,"we study the influence of different activation functions in the output layer of deep neural network models for soft and hard label prediction in the learning with disagreement task. in this task, the goal is to quantify the amount of disagreement via predicting soft labels. to predict the soft labels, we use bert-based preprocessors and encoders and vary the activation function used in the output layer, while keeping other parameters constant. the soft labels are then used for the hard label prediction. the activation functions considered are sigmoid as well as a step-function that is added to the model post-training and a sinusoidal activation function, which is introduced for the first time in this paper.",,2023-03-04,2023-04-07,"['peyman hosseini', 'mehran hosseini', 'sana sabah al-azzawi', 'marcus liwicki', 'ignacio castro', 'matthew purver']",https://arxiv.org/pdf/2303.02468.pdf
301,2303.03388,multi-modal multi-kernel graph learning for autism prediction and   biomarker discovery,cs.lg cs.ai,"due to its complexity, graph learning-based multi-modal integration and classification is one of the most challenging obstacles for disease prediction. to effectively offset the negative impact between modalities in the process of multi-modal integration and extract heterogeneous information from graphs, we propose a novel method called mmkgl (multi-modal multi-kernel graph learning). for the problem of negative impact between modalities, we propose a multi-modal graph embedding module to construct a multi-modal graph. different from conventional methods that manually construct static graphs for all modalities, each modality generates a separate graph by adaptive learning, where a function graph and a supervision graph are introduced for optimization during the multi-graph fusion embedding process. we then propose a multi-kernel graph learning module to extract heterogeneous information from the multi-modal graph. the information in the multi-modal graph at different levels is aggregated by convolutional kernels with different receptive field sizes, followed by generating a cross-kernel discovery tensor for disease prediction. our method is evaluated on the benchmark autism brain imaging data exchange (abide) dataset and outperforms the state-of-the-art methods. in addition, discriminative brain regions associated with autism are identified by our model, providing guidance for the study of autism pathology.",,2023-03-03,2023-04-09,"['junbin mao', 'jin liu', 'hanhe lin', 'hulin kuang', 'shirui pan', 'yi pan']",https://arxiv.org/pdf/2303.03388.pdf
302,2303.04011,one-4-all: neural potential fields for embodied navigation,cs.ro cs.cv cs.lg,"a fundamental task in robotics is to navigate between two locations. in particular, real-world navigation can require long-horizon planning using high-dimensional rgb images, which poses a substantial challenge for end-to-end learning-based approaches. current semi-parametric methods instead achieve long-horizon navigation by combining learned modules with a topological memory of the environment, often represented as a graph over previously collected images. however, using these graphs in practice typically involves tuning a number of pruning heuristics to avoid spurious edges, limit runtime memory usage and allow reasonably fast graph queries. in this work, we present one-4-all (o4a), a method leveraging self-supervised and manifold learning to obtain a graph-free, end-to-end navigation pipeline in which the goal is specified as an image. navigation is achieved by greedily minimizing a potential function defined continuously over the o4a latent space. our system is trained offline on non-expert exploration sequences of rgb data and controls, and does not require any depth or pose measurements. we show that o4a can reach long-range goals in 8 simulated gibson indoor environments, and further demonstrate successful real-world navigation using a jackal ugv platform.",,2023-03-07,2023-04-11,"['sacha morin', 'miguel saavedra-ruiz', 'liam paull']",https://arxiv.org/pdf/2303.04011.pdf
303,2303.04150,evolutionary reinforcement learning: a survey,cs.ne cs.ai cs.lg,"reinforcement learning (rl) is a machine learning approach that trains agents to maximize cumulative rewards through interactions with environments. the integration of rl with deep learning has recently resulted in impressive achievements in a wide range of challenging tasks, including board games, arcade games, and robot control. despite these successes, there remain several crucial challenges, including brittle convergence properties caused by sensitive hyperparameters, difficulties in temporal credit assignment with long time horizons and sparse rewards, a lack of diverse exploration, especially in continuous search space scenarios, difficulties in credit assignment in multi-agent reinforcement learning, and conflicting objectives for rewards. evolutionary computation (ec), which maintains a population of learning agents, has demonstrated promising performance in addressing these limitations. this article presents a comprehensive survey of state-of-the-art methods for integrating ec into rl, referred to as evolutionary reinforcement learning (evorl). we categorize evorl methods according to key research fields in rl, including hyperparameter optimization, policy search, exploration, reward shaping, meta-rl, and multi-objective rl. we then discuss future research directions in terms of efficient methods, benchmarks, and scalable platforms. this survey serves as a resource for researchers and practitioners interested in the field of evorl, highlighting the important challenges and opportunities for future research. with the help of this survey, researchers and practitioners can develop more efficient methods and tailored benchmarks for evorl, further advancing this promising cross-disciplinary research field.",,2023-03-06,2023-04-11,"['hui bai', 'ran cheng', 'yaochu jin']",https://arxiv.org/pdf/2303.04150.pdf
304,2303.04738,"defectors: a large, diverse python dataset for defect prediction",cs.se,"defect prediction has been a popular research topic where machine learning (ml) and deep learning (dl) have found numerous applications. however, these ml/dl-based defect prediction models are often limited by the quality and size of their datasets. in this paper, we present defectors, a large dataset for just-in-time and line-level defect prediction. defectors consists of $\approx$ 213k source code files ($\approx$ 93k defective and $\approx$ 120k defect-free) that span across 24 popular python projects. these projects come from 18 different domains, including machine learning, automation, and internet-of-things. such a scale and diversity make defectors a suitable dataset for training ml/dl models, especially transformer models that require large and diverse datasets. we also foresee several application areas of our dataset including defect prediction and defect explanation.   dataset link: https://doi.org/10.5281/zenodo.7708984",,2023-03-08,2023-04-11,"['parvez mahbub', 'ohiduzzaman shuvo', 'mohammad masudur rahman']",https://arxiv.org/pdf/2303.04738.pdf
305,2303.04848,computational spectral imaging: a contemporary overview,cs.it eess.iv math.it,"spectral imaging collects and processes information along spatial and spectral coordinates quantified in discrete voxels, which can be treated as a 3d spectral data cube. the spectral images (sis) allow identifying objects, crops, and materials in the scene through their spectral behavior. since most spectral optical systems can only employ 1d or maximum 2d sensors, it is challenging to directly acquire the 3d information from available commercial sensors. as an alternative, computational spectral imaging (csi) has emerged as a sensing tool where the 3d data can be obtained using 2d encoded projections. then, a computational recovery process must be employed to retrieve the si. csi enables the development of snapshot optical systems that reduce acquisition time and provide low computational storage costs compared to conventional scanning systems. recent advances in deep learning (dl) have allowed the design of data-driven csi to improve the si reconstruction or, even more, perform high-level tasks such as classification, unmixing, or anomaly detection directly from 2d encoded projections. this work summarises the advances in csi, starting with si and its relevance; continuing with the most relevant compressive spectral optical systems. then, csi with dl will be introduced, and the recent advances in combining the physical optical design with computational dl algorithms to solve high-level tasks.",10.1364/josaa.482406,2023-03-08,,"['jorge bacca', 'emmanuel martinez', 'henry arguello']",https://arxiv.org/pdf/2303.04848.pdf
306,2303.06050,optimal foraging strategies can be learned and outperform l\'evy walks,cond-mat.stat-mech cs.ai physics.bio-ph q-bio.pe,"l\'evy walks and other theoretical models of optimal foraging have been successfully used to describe real-world scenarios, attracting attention in several fields such as economy, physics, ecology, and evolutionary biology. however, it remains unclear in most cases which strategies maximize foraging efficiency and whether such strategies can be learned by living organisms. to address these questions, we model foragers as reinforcement learning agents. we first prove theoretically that maximizing rewards in our reinforcement learning model is equivalent to optimizing foraging efficiency. we then show with numerical experiments that our agents learn foraging strategies which outperform the efficiency of known strategies such as l\'evy walks.",,2023-03-10,2023-04-12,"['gorka mu√±oz-gil', 'andrea l√≥pez-incera', 'lukas j. fiderer', 'hans j. briegel']",https://arxiv.org/pdf/2303.06050.pdf
307,2303.06561,phase diagram of initial condensation for two-layer neural networks,cs.lg cond-mat.dis-nn math.oc stat.ml,"the phenomenon of distinct behaviors exhibited by neural networks under varying scales of initialization remains an enigma in deep learning research. in this paper, based on the earlier work by luo et al.~\cite{luo2021phase}, we present a phase diagram of initial condensation for two-layer neural networks. condensation is a phenomenon wherein the weight vectors of neural networks concentrate on isolated orientations during the training process, and it is a feature in non-linear learning process that enables neural networks to possess better generalization abilities. our phase diagram serves to provide a comprehensive understanding of the dynamical regimes of neural networks and their dependence on the choice of hyperparameters related to initialization. furthermore, we demonstrate in detail the underlying mechanisms by which small initialization leads to condensation at the initial training stage.",,2023-03-11,2023-04-07,"['zhengan chen', 'yuqing li', 'tao luo', 'zhangchen zhou', 'zhi-qin john xu']",https://arxiv.org/pdf/2303.06561.pdf
308,2303.07068,n-step temporal difference learning with optimal n,cs.lg,"we consider the problem of finding the optimal value of n in the n-step temporal difference (td) learning algorithm. we find the optimal n by resorting to a model-free optimization technique involving a one-simulation simultaneous perturbation stochastic approximation (spsa) based procedure that we adopt to the discrete optimization setting by using a random projection approach. we prove the convergence of our proposed algorithm, sdpsa, using a differential inclusions approach and show that it finds the optimal value of n in n-step td. through experiments, we show that the optimal value of n is achieved with sdpsa for arbitrary initial values.",,2023-03-13,2023-04-13,"['lakshmi mandal', 'shalabh bhatnagar']",https://arxiv.org/pdf/2303.07068.pdf
309,2303.08054,statistical hardware design with multi-model active learning,cs.ar cs.lg,"with the rising complexity of numerous novel applications that serve our modern society comes the strong need to design efficient computing platforms. designing efficient hardware is, however, a complex multi-objective problem that deals with multiple parameters and their interactions. given that there are a large number of parameters and objectives involved in hardware design, synthesizing all possible combinations is not a feasible method to find the optimal solution. one promising approach to tackle this problem is statistical modeling of a desired hardware performance. here, we propose a model-based active learning approach to solve this problem. our proposed method uses bayesian models to characterize various aspects of hardware performance. we also use transfer learning and gaussian regression bootstrapping techniques in conjunction with active learning to create more accurate models. our proposed statistical modeling method provides hardware models that are sufficiently accurate to perform design space exploration as well as performance prediction simultaneously. we use our proposed method to perform design space exploration and performance prediction for various hardware setups, such as micro-architecture design and opencl kernels for fpga targets. our experiments show that the number of samples required to create performance models significantly reduces while maintaining the predictive power of our proposed statistical models. for instance, in our performance prediction setting, the proposed method needs 65% fewer samples to create the model, and in the design space exploration setting, our proposed method can find the best parameter settings by exploring less than 50 samples.",,2023-03-14,2023-04-09,"['alireza ghaffari', 'masoud asgharian', 'yvon savaria']",https://arxiv.org/pdf/2303.08054.pdf
310,2303.08416,lung nodule segmentation and low-confidence region prediction with   uncertainty-aware attention mechanism,eess.iv cs.cv,"radiologists have different training and clinical experiences, which may result in various segmentation annotations for lung nodules, causing segmentation uncertainty. conventional methods usually select a single annotation as the learning target or try to learn a latent space of various annotations, but these approaches waste the valuable information of consensus or disagreements ingrained in the multiple annotations. in this paper, we propose an uncertainty-aware attention mechanism (uaam) that utilizes consensus and disagreements among multiple annotations to facilitate better segmentation. to achieve this, we introduce the multi-confidence mask (mcm), which is a combination of a low-confidence (lc) mask and a high-confidence (hc) mask. the lc mask indicates regions with a low segmentation confidence, which may cause different segmentation options among radiologists. following uaam, we further design an uncertainty-guide segmentation network (ugs-net), which contains three modules: a feature extracting module that captures a general feature of a lung nodule, an uncertainty-aware module that produces three features for the annotations' union, intersection, and annotation set, and an intersection-union constraining module that uses distances between the three features to balance the predictions of final segmentation, lc mask, and hc mask. to fully demonstrate the performance of our method, we propose a complex nodule validation on lidc-idri, which tests ugs-net's segmentation performance on lung nodules that are difficult to segment using u-net. experimental results demonstrate that our method can significantly improve the segmentation performance on nodules with poor segmentation by u-net.",,2023-03-15,2023-04-11,"['han yang', 'qiuli wang', 'yue zhang', 'zhulin an', 'chen liu', 'xiaohong zhang', 's. kevin zhou']",https://arxiv.org/pdf/2303.08416.pdf
311,2303.08435,physics-informed optical kernel regression using complex-valued neural   fields,cs.cv cs.lg eess.iv,"lithography is fundamental to integrated circuit fabrication, necessitating large computation overhead. the advancement of machine learning (ml)-based lithography models alleviates the trade-offs between manufacturing process expense and capability. however, all previous methods regard the lithography system as an image-to-image black box mapping, utilizing network parameters to learn by rote mappings from massive mask-to-aerial or mask-to-resist image pairs, resulting in poor generalization capability. in this paper, we propose a new ml-based paradigm disassembling the rigorous lithographic model into non-parametric mask operations and learned optical kernels containing determinant source, pupil, and lithography information. by optimizing complex-valued neural fields to perform optical kernel regression from coordinates, our method can accurately restore lithography system using a small-scale training dataset with fewer parameters, demonstrating superior generalization capability as well. experiments show that our framework can use 31% of parameters while achieving 69$\times$ smaller mean squared error with 1.3$\times$ higher throughput than the state-of-the-art.",,2023-03-15,2023-04-09,"['guojin chen', 'zehua pei', 'haoyu yang', 'yuzhe ma', 'bei yu', 'martin d. f. wong']",https://arxiv.org/pdf/2303.08435.pdf
312,2303.08622,zero-shot contrastive loss for text-guided diffusion image style   transfer,cs.cv cs.ai cs.lg stat.ml,"diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. to address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. by leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. our experimental results validate the effectiveness of our proposed method.",,2023-03-15,2023-04-12,"['serin yang', 'hyunmin hwang', 'jong chul ye']",https://arxiv.org/pdf/2303.08622.pdf
313,2303.10800,a global model approach to robust few-shot sar automatic target   recognition,cs.cv cs.lg,"in real-world scenarios, it may not always be possible to collect hundreds of labeled samples per class for training deep learning-based sar automatic target recognition (atr) models. this work specifically tackles the few-shot sar atr problem, where only a handful of labeled samples may be available to support the task of interest. our approach is composed of two stages. in the first, a global representation model is trained via self-supervised learning on a large pool of diverse and unlabeled sar data. in the second stage, the global model is used as a fixed feature extractor and a classifier is trained to partition the feature space given the few-shot support samples, while simultaneously being calibrated to detect anomalous inputs. unlike competing approaches which require a pristine labeled dataset for pretraining via meta-learning, our approach learns highly transferable features from unlabeled data that have little-to-no relation to the downstream task. we evaluate our method in standard and extended mstar operating conditions and find it to achieve high accuracy and robust out-of-distribution detection in many different few-shot settings. our results are particularly significant because they show the merit of a global model approach to sar atr, which makes minimal assumptions, and provides many axes for extendability.",10.1109/lgrs.2023.3264535,2023-03-19,,['nathan inkawhich'],https://arxiv.org/pdf/2303.10800.pdf
314,2303.11470,did you train on my dataset? towards public dataset protection with   clean-label backdoor watermarking,cs.cr cs.ai cs.lg cs.mm,"the huge supporting training data on the internet has been a key factor in the success of deep learning models. however, this abundance of public-available data also raises concerns about the unauthorized exploitation of datasets for commercial purposes, which is forbidden by dataset licenses. in this paper, we propose a backdoor-based watermarking approach that serves as a general framework for safeguarding public-available data. by inserting a small number of watermarking samples into the dataset, our approach enables the learning model to implicitly learn a secret function set by defenders. this hidden function can then be used as a watermark to track down third-party models that use the dataset illegally. unfortunately, existing backdoor insertion methods often entail adding arbitrary and mislabeled data to the training set, leading to a significant drop in performance and easy detection by anomaly detection algorithms. to overcome this challenge, we introduce a clean-label backdoor watermarking framework that uses imperceptible perturbations to replace mislabeled samples. as a result, the watermarking samples remain consistent with the original labels, making them difficult to detect. our experiments on text, image, and audio datasets demonstrate that the proposed framework effectively safeguards datasets with minimal impact on original task performance. we also show that adding just 1% of watermarking samples can inject a traceable watermarking function and that our watermarking samples are stealthy and look benign upon visual inspection.",,2023-03-20,2023-04-10,"['ruixiang tang', 'qizhang feng', 'ninghao liu', 'fan yang', 'xia hu']",https://arxiv.org/pdf/2303.11470.pdf
315,2303.11754,projections of model spaces for latent graph inference,cs.lg,"graph neural networks leverage the connectivity structure of graphs as an inductive bias. latent graph inference focuses on learning an adequate graph structure to diffuse information on and improve the downstream performance of the model. in this work we employ stereographic projections of the hyperbolic and spherical model spaces, as well as products of riemannian manifolds, for the purpose of latent graph inference. stereographically projected model spaces achieve comparable performance to their non-projected counterparts, while providing theoretical guarantees that avoid divergence of the spaces when the curvature tends to zero. we perform experiments on both homophilic and heterophilic graphs.",,2023-03-21,2023-04-12,"['haitz s√°ez de oc√°riz borde', '√°lvaro arroyo', 'ingmar posner']",https://arxiv.org/pdf/2303.11754.pdf
316,2303.11899,large-scale regional traffic signal control using dynamic deep   reinforcement learning,cs.ai,"multi-agent reinforcement learning (marl) based traffic signal control becomes a popular research topic in recent years. most existing marl approaches tend to learn the optimum control strategies in a decentralised manner by considering communication among neighbouring intersections. however, the non-stationary property in marl may lead to extremely slow or even failure of convergence, especially when the number of intersections becomes large. one of the existing methods is to partition the whole network into several regions, each of which utilizes a centralized rl framework to speed up the convergence rate. however, there are two challenges for this strategy: the first one is how to get a flexible partition and the second one is how to search for the optimal joint actions for a region of intersections. in this paper, we propose a novel training framework where our region partitioning rule is based on the adjacency between the intersections and propose dynamic branching dueling q-network (dbdq) to search for optimal joint action efficiently and to maximize the regional reward. the experimental results with both real datasets and synthetic datasets demonstrate the superiority of our framework over other existing frameworks.",,2023-03-21,2023-04-07,"['hankang gu', 'shangbo wang']",https://arxiv.org/pdf/2303.11899.pdf
317,2303.12712,sparks of artificial general intelligence: early experiments with gpt-4,cs.cl cs.ai,"artificial intelligence (ai) researchers have been developing and refining large language models (llms) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. the latest model developed by openai, gpt-4, was trained using an unprecedented scale of compute and data. in this paper, we report on our investigation of an early version of gpt-4, when it was still in active development by openai. we contend that (this early version of) gpt-4 is part of a new cohort of llms (along with chatgpt and google's palm for example) that exhibit more general intelligence than previous ai models. we discuss the rising capabilities and implications of these models. we demonstrate that, beyond its mastery of language, gpt-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. moreover, in all of these tasks, gpt-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as chatgpt. given the breadth and depth of gpt-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (agi) system. in our exploration of gpt-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of agi, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. we conclude with reflections on societal influences of the recent technological leap and future research directions.",,2023-03-22,2023-04-12,"['s√©bastien bubeck', 'varun chandrasekaran', 'ronen eldan', 'johannes gehrke', 'eric horvitz', 'ece kamar', 'peter lee', 'yin tat lee', 'yuanzhi li', 'scott lundberg', 'harsha nori', 'hamid palangi', 'marco tulio ribeiro', 'yi zhang']",https://arxiv.org/pdf/2303.12712.pdf
318,2303.12922,revisiting the fragility of influence functions,cs.lg cs.ai stat.ml stat.ot,"in the last few years, many works have tried to explain the predictions of deep learning models. few methods, however, have been proposed to verify the accuracy or faithfulness of these explanations. recently, influence functions, which is a method that approximates the effect that leave-one-out training has on the loss function, has been shown to be fragile. the proposed reason for their fragility remains unclear. although previous work suggests the use of regularization to increase robustness, this does not hold in all cases. in this work, we seek to investigate the experiments performed in the prior work in an effort to understand the underlying mechanisms of influence function fragility. first, we verify influence functions using procedures from the literature under conditions where the convexity assumptions of influence functions are met. then, we relax these assumptions and study the effects of non-convexity by using deeper models and more complex datasets. here, we analyze the key metrics and procedures that are used to validate influence functions. our results indicate that the validation procedures may cause the observed fragility.",10.1016/j.neunet.2023.03.029,2023-03-22,2023-04-07,"['jacob r. epifano', 'ravi p. ramachandran', 'aaron j. masino', 'ghulam rasool']",https://arxiv.org/pdf/2303.12922.pdf
319,2303.14042,class-incremental exemplar compression for class-incremental learning,cs.cv,"exemplar-based class-incremental learning (cil) finetunes the model with all samples of new classes but few-shot exemplars of old classes in each incremental phase, where the ""few-shot"" abides by the limited memory budget. in this paper, we break this ""few-shot"" limit based on a simple yet surprisingly effective idea: compressing exemplars by downsampling non-discriminative pixels and saving ""many-shot"" compressed exemplars in the memory. without needing any manual annotation, we achieve this compression by generating 0-1 masks on discriminative pixels from class activation maps (cam). we propose an adaptive mask generation model called class-incremental masking (cim) to explicitly resolve two difficulties of using cam: 1) transforming the heatmaps of cam to 0-1 masks with an arbitrary threshold leads to a trade-off between the coverage on discriminative pixels and the quantity of exemplars, as the total memory is fixed; and 2) optimal thresholds vary for different object classes, which is particularly obvious in the dynamic environment of cil. we optimize the cim model alternatively with the conventional cil model through a bilevel optimization problem. we conduct extensive experiments on high-resolution cil benchmarks including food-101, imagenet-100, and imagenet-1000, and show that using the compressed exemplars by cim can achieve a new state-of-the-art cil accuracy, e.g., 4.8 percentage points higher than foster on 10-phase imagenet-1000. our code is available at https://github.com/xfflzl/cim-cil.",,2023-03-24,2023-04-07,"['zilin luo', 'yaoyao liu', 'bernt schiele', 'qianru sun']",https://arxiv.org/pdf/2303.14042.pdf
320,2303.14083,online learning for the random feature model in the student-teacher   framework,cs.lg cond-mat.dis-nn cs.ai,"deep neural networks are widely used prediction algorithms whose performance often improves as the number of weights increases, leading to over-parametrization. we consider a two-layered neural network whose first layer is frozen while the last layer is trainable, known as the random feature model. we study over-parametrization in the context of a student-teacher framework by deriving a set of differential equations for the learning dynamics. for any finite ratio of hidden layer size and input dimension, the student cannot generalize perfectly, and we compute the non-zero asymptotic generalization error. only when the student's hidden layer size is exponentially larger than the input dimension, an approach to perfect generalization is possible.",,2023-03-24,2023-04-06,"['roman worschech', 'bernd rosenow']",https://arxiv.org/pdf/2303.14083.pdf
321,2303.14173,how many dimensions are required to find an adversarial example?,cs.lg cs.cr stat.ml,"past work exploring adversarial vulnerability have focused on situations where an adversary can perturb all dimensions of model input. on the other hand, a range of recent works consider the case where either (i) an adversary can perturb a limited number of input parameters or (ii) a subset of modalities in a multimodal problem. in both of these cases, adversarial examples are effectively constrained to a subspace $v$ in the ambient input space $\mathcal{x}$. motivated by this, in this work we investigate how adversarial vulnerability depends on $\dim(v)$. in particular, we show that the adversarial success of standard pgd attacks with $\ell^p$ norm constraints behaves like a monotonically increasing function of $\epsilon (\frac{\dim(v)}{\dim \mathcal{x}})^{\frac{1}{q}}$ where $\epsilon$ is the perturbation budget and $\frac{1}{p} + \frac{1}{q} =1$, provided $p > 1$ (the case $p=1$ presents additional subtleties which we analyze in some detail). this functional form can be easily derived from a simple toy linear model, and as such our results land further credence to arguments that adversarial examples are endemic to locally linear models on high dimensional spaces.",,2023-03-24,2023-04-10,"['charles godfrey', 'henry kvinge', 'elise bishoff', 'myles mckay', 'davis brown', 'tim doster', 'eleanor byler']",https://arxiv.org/pdf/2303.14173.pdf
322,2303.14548,viewpoint equivariance for multi-view 3d object detection,cs.cv cs.ai cs.lg cs.ro,"3d object detection from visual sensors is a cornerstone capability of robotic systems. state-of-the-art methods focus on reasoning and decoding object bounding boxes from multi-view camera input. in this work we gain intuition from the integral role of multi-view consistency in 3d scene understanding and geometric learning. to this end, we introduce vedet, a novel 3d object detection framework that exploits 3d multi-view geometry to improve localization through viewpoint awareness and equivariance. vedet leverages a query-based transformer architecture and encodes the 3d scene by augmenting image features with positional encodings from their 3d perspective geometry. we design view-conditioned queries at the output level, which enables the generation of multiple virtual frames during training to learn viewpoint equivariance by enforcing multi-view consistency. the multi-view geometry injected at the input level as positional encodings and regularized at the loss level provides rich geometric cues for 3d object detection, leading to state-of-the-art performance on the nuscenes benchmark. the code and model are made available at https://github.com/tri-ml/vedet.",,2023-03-25,2023-04-07,"['dian chen', 'jie li', 'vitor guizilini', 'rares ambrus', 'adrien gaidon']",https://arxiv.org/pdf/2303.14548.pdf
323,2303.14690,topress: a matlab implementation for topology optimization of structures   subjected to design-dependent pressure loads,cs.ms cs.ce,"in a topology optimization setting, design-dependent fluidic pressure loads pose several challenges as their direction, magnitude, and location alter with topology evolution. this paper offers a compact 100-line matlab code, topress, for topology optimization of structures subjected to fluidic pressure loads using the method of moving asymptotes. the code is intended for pedagogical purposes and aims to ease the beginners' and students' learning toward topology optimization with design-dependent fluidic pressure loads. topress is developed per the approach first reported in kumar et al. (struct multidisc optim 61(4):1637-1655, 2020). the darcy law, in conjunction with the drainage term, is used to model the applied pressure load. the consistent nodal loads are determined from the obtained pressure field. the employed approach facilitates inexpensive computation of the load sensitivities using the adjoint-variable method. compliance minimization subject to volume constraint optimization problems are solved. the success and efficacy of the code are demonstrated by solving benchmark numerical examples involving pressure loads, wherein the importance of load sensitivities is also demonstrated. topress contains six main parts, is described in detail, and is extended to solve different problems. steps to include a projection filter are provided to achieve loadbearing designs close to~0-1. the code is provided in appendix~b and can also be downloaded along with its extensions from \url{https://github.com/prabhatin/topress}.",10.1007/s00158-023-03533-9,2023-03-26,2023-04-13,['prabhat kumar'],https://arxiv.org/pdf/2303.14690.pdf
324,2303.14878,gpt-pinn: generative pre-trained physics-informed neural networks toward   non-intrusive meta-learning of parametric pdes,math.na cs.lg cs.na,"physics-informed neural network (pinn) has proven itself a powerful tool to obtain the numerical solutions of nonlinear partial differential equations (pdes) leveraging the expressivity of deep neural networks and the computing power of modern heterogeneous hardware. however, its training is still time-consuming, especially in the multi-query and real-time simulation settings, and its parameterization often overly excessive. in this paper, we propose the generative pre-trained pinn (gpt-pinn) to mitigate both challenges in the setting of parametric pdes. gpt-pinn represents a brand-new meta-learning paradigm for parametric systems. as a network of networks, its outer-/meta-network is hyper-reduced with only one hidden layer having significantly reduced number of neurons. moreover, its activation function at each hidden neuron is a (full) pinn pre-trained at a judiciously selected system configuration. the meta-network adaptively ``learns'' the parametric dependence of the system and ``grows'' this hidden layer one neuron at a time. in the end, by encompassing a very small number of networks trained at this set of adaptively-selected parameter values, the meta-network is capable of generating surrogate solutions for the parametric system across the entire parameter domain accurately and efficiently.",,2023-03-26,2023-04-11,"['yanlai chen', 'shawn koohy']",https://arxiv.org/pdf/2303.14878.pdf
325,2303.14897,seer: language instructed video prediction with latent diffusion models,cs.cv,"imagining the future trajectory is the key for robots to make sound planning and successfully reach their goals. therefore, text-conditioned video prediction (tvp) is an essential task to facilitate general robot policy learning, i.e., predicting future video frames with a given language instruction and reference frames. it is a highly challenging task to ground task-level goals specified by instructions and high-fidelity frames together, requiring large-scale data and computation. to tackle this task and empower robots with the ability to foresee the future, we propose a sample and computation-efficient model, named \textbf{seer}, by inflating the pretrained text-to-image (t2i) stable diffusion models along the temporal axis. we inflate the denoising u-net and language conditioning model with two novel techniques, autoregressive spatial-temporal attention and frame sequential text decomposer, to propagate the rich prior knowledge in the pretrained t2i models across the frames. with the well-designed architecture, seer makes it possible to generate high-fidelity, coherent, and instruction-aligned video frames by fine-tuning a few layers on a small amount of data. the experimental results on something something v2 (ssv2) and bridgedata datasets demonstrate our superior video prediction performance with around 210-hour training on 4 rtx 3090 gpus: decreasing the fvd of the current sota model from 290 to 200 on ssv2 and achieving at least 70\% preference in the human evaluation.",,2023-03-26,2023-04-11,"['xianfan gu', 'chuan wen', 'jiaming song', 'yang gao']",https://arxiv.org/pdf/2303.14897.pdf
326,2303.15226,asynchronous online federated learning with reduced communication   requirements,cs.lg cs.dc stat.ml,"online federated learning (fl) enables geographically distributed devices to learn a global shared model from locally available streaming data. most online fl literature considers a best-case scenario regarding the participating clients and the communication channels. however, these assumptions are often not met in real-world applications. asynchronous settings can reflect a more realistic environment, such as heterogeneous client participation due to available computational power and battery constraints, as well as delays caused by communication channels or straggler devices. further, in most applications, energy efficiency must be taken into consideration. using the principles of partial-sharing-based communications, we propose a communication-efficient asynchronous online federated learning (pao-fed) strategy. by reducing the communication overhead of the participants, the proposed method renders participation in the learning task more accessible and efficient. in addition, the proposed aggregation mechanism accounts for random participation, handles delayed updates and mitigates their effect on accuracy. we prove the first and second-order convergence of the proposed pao-fed method and obtain an expression for its steady-state mean square deviation. finally, we conduct comprehensive simulations to study the performance of the proposed method on both synthetic and real-life datasets. the simulations reveal that in asynchronous settings, the proposed pao-fed is able to achieve the same convergence properties as that of the online federated stochastic gradient while reducing the communication overhead by 98 percent.",,2023-03-27,2023-04-11,"['francois gauthier', 'vinay chakravarthi gogineni', 'stefan werner', 'yih-fang huang', 'anthony kuh']",https://arxiv.org/pdf/2303.15226.pdf
327,2303.15354,from single-hospital to multi-centre applications: enhancing the   generalisability of deep learning models for adverse event prediction in the   icu,cs.lg cs.ai,"deep learning (dl) can aid doctors in detecting worsening patient states early, affording them time to react and prevent bad outcomes. while dl-based early warning models usually work well in the hospitals they were trained for, they tend to be less reliable when applied at new hospitals. this makes it difficult to deploy them at scale. using carefully harmonised intensive care data from four data sources across europe and the us (totalling 334,812 stays), we systematically assessed the reliability of dl models for three common adverse events: death, acute kidney injury (aki), and sepsis. we tested whether using more than one data source and/or explicitly optimising for generalisability during training improves model performance at new hospitals. we found that models achieved high auroc for mortality (0.838-0.869), aki (0.823-0.866), and sepsis (0.749-0.824) at the training hospital. as expected, performance dropped at new hospitals, sometimes by as much as -0.200. using more than one data source for training mitigated the performance drop, with multi-source models performing roughly on par with the best single-source model. this suggests that as data from more hospitals become available for training, model robustness is likely to increase, lower-bounding robustness with the performance of the most applicable data source in the training data. dedicated methods promoting generalisability did not noticeably improve performance in our experiments.",,2023-03-27,2023-04-07,"['patrick rockenschaub', 'adam hilbert', 'tabea kossen', 'falk von dincklage', 'vince istvan madai', 'dietmar frey']",https://arxiv.org/pdf/2303.15354.pdf
328,2303.15747,tabret: pre-training transformer-based tabular models for unseen columns,cs.lg cs.ai,"we present \emph{tabret}, a pre-trainable transformer-based model for tabular data. tabret is designed to work on a downstream task that contains columns not seen in pre-training. unlike other methods, tabret has an extra learning step before fine-tuning called \emph{retokenizing}, which calibrates feature embeddings based on the masked autoencoding loss. in experiments, we pre-trained tabret with a large collection of public health surveys and fine-tuned it on classification tasks in healthcare, and tabret achieved the best auc performance on four datasets. in addition, an ablation study shows retokenizing and random shuffle augmentation of columns during pre-training contributed to performance gains. the code is available at https://github.com/pfnet-research/tabret .",,2023-03-28,2023-04-08,"['soma onishi', 'kenta oono', 'kohei hayashi']",https://arxiv.org/pdf/2303.15747.pdf
329,2303.15849,gas: a gaussian mixture distribution-based adaptive sampling method for   pinns,cs.lg physics.comp-ph,"with the recent study of deep learning in scientific computation, the physics-informed neural networks (pinns) method has drawn widespread attention for solving partial differential equations (pdes). compared to traditional methods, pinns can efficiently handle high-dimensional problems, but the accuracy is relatively low, especially for highly irregular problems. inspired by the idea of adaptive finite element methods and incremental learning, we propose gas, a gaussian mixture distribution-based adaptive sampling method for pinns. during the training procedure, gas uses the current residual information to generate a gaussian mixture distribution for the sampling of additional points, which are then trained together with historical data to speed up the convergence of the loss and achieve higher accuracy. several numerical simulations on 2d and 10d problems show that gas is a promising method that achieves state-of-the-art accuracy among deep solvers, while being comparable with traditional numerical solvers.",,2023-03-28,2023-04-07,"['yuling jiao', 'di li', 'xiliang lu', 'jerry zhijian yang', 'cheng yuan']",https://arxiv.org/pdf/2303.15849.pdf
330,2303.15991,efficient parallel split learning over resource-constrained wireless   edge networks,cs.lg,"the increasingly deeper neural networks hinder the democratization of privacy-enhancing distributed learning, such as federated learning (fl), to resource-constrained devices. to overcome this challenge, in this paper, we advocate the integration of edge computing paradigm and parallel split learning (psl), allowing multiple client devices to offload substantial training workloads to an edge server via layer-wise model split. by observing that existing psl schemes incur excessive training latency and large volume of data transmissions, we propose an innovative psl framework, namely, efficient parallel split learning (epsl), to accelerate model training. to be specific, epsl parallelizes client-side model training and reduces the dimension of local gradients for back propagation (bp) via last-layer gradient aggregation, leading to a significant reduction in server-side training and communication latency. moreover, by considering the heterogeneous channel conditions and computing capabilities at client devices, we jointly optimize subchannel allocation, power control, and cut layer selection to minimize the per-round latency. simulation results show that the proposed epsl framework significantly decreases the training latency needed to achieve a target accuracy compared with the state-of-the-art benchmarks, and the tailored resource management and layer split strategy can considerably reduce latency than the counterpart without optimization.",,2023-03-26,2023-04-07,"['zheng lin', 'guangyu zhu', 'yiqin deng', 'xianhao chen', 'yue gao', 'kaibin huang', 'yuguang fang']",https://arxiv.org/pdf/2303.15991.pdf
331,2303.16071,edge selection and clustering for federated learning in optical   inter-leo satellite constellation,cs.lg cs.ni eess.sp,"low-earth orbit (leo) satellites have been prosperously deployed for various earth observation missions due to its capability of collecting a large amount of image or sensor data. however, traditionally, the data training process is performed in the terrestrial cloud server, which leads to a high transmission overhead. with the recent development of leo, it is more imperative to provide ultra-dense leo constellation with enhanced on-board computation capability. benefited from it, we have proposed a collaborative federated learning for low earth orbit (fello). we allocate the entire process on leos with low payload inter-satellite transmissions, whilst the low-delay terrestrial gateway server (gs) only takes care for initial signal controlling. the gs initially selects an leo server, whereas its leo clients are all determined by clustering mechanism and communication capability through the optical inter-satellite links (isls). the re-clustering of changing leo server will be executed once with low communication quality of fello. in the simulations, we have numerically analyzed the proposed fello under practical walker-based leo constellation configurations along with mnist training dataset for classification mission. the proposed fello outperforms the conventional centralized and distributed architectures with higher classification accuracy as well as comparably lower latency of joint communication and computing.",,2023-03-25,2023-04-10,"['chih-yu chen', 'li-hsiang shen', 'kai-ten feng', 'lie-liang yang', 'jen-ming wu']",https://arxiv.org/pdf/2303.16071.pdf
332,2303.16100,energy-efficient task adaptation for nlp edge inference leveraging   heterogeneous memory architectures,cs.lg cs.ar,"executing machine learning inference tasks on resource-constrained edge devices requires careful hardware-software co-design optimizations. recent examples have shown how transformer-based deep neural network models such as albert can be used to enable the execution of natural language processing (nlp) inference on mobile systems-on-chip housing custom hardware accelerators. however, while these existing solutions are effective in alleviating the latency, energy, and area costs of running single nlp tasks, achieving multi-task inference requires running computations over multiple variants of the model parameters, which are tailored to each of the targeted tasks. this approach leads to either prohibitive on-chip memory requirements or paying the cost of off-chip memory access. this paper proposes adapter-albert, an efficient model optimization for maximal data reuse across different tasks. the proposed model's performance and robustness to data compression methods are evaluated across several language tasks from the glue benchmark. additionally, we demonstrate the advantage of mapping the model to a heterogeneous on-chip memory architecture by performing simulations on a validated nlp edge accelerator to extrapolate performance, power, and area improvements over the execution of a traditional albert model on the same hardware platform.",,2023-03-25,2023-04-12,"['zirui fu', 'aleksandre avaliani', 'marco donato']",https://arxiv.org/pdf/2303.16100.pdf
333,2303.16372,non-asymptotic lower bounds for training data reconstruction,cs.lg cs.cr stat.ml,"we investigate semantic guarantees of private learning algorithms for their resilience to training data reconstruction attacks (dras) by informed adversaries. to this end, we derive non-asymptotic minimax lower bounds on the adversary's reconstruction error against learners that satisfy differential privacy (dp) and metric differential privacy (mdp). furthermore, we demonstrate that our lower bound analysis for the latter also covers the high dimensional regime, wherein, the input data dimensionality may be larger than the adversary's query budget. motivated by the theoretical improvements conferred by metric dp, we extend the privacy analysis of popular deep learning algorithms such as dp-sgd and projected noisy sgd to cover the broader notion of metric differential privacy.",,2023-03-28,2023-04-11,"['prateeti mukherjee', 'satya lokam']",https://arxiv.org/pdf/2303.16372.pdf
334,2303.16580,generalized relation modeling for transformer tracking,cs.cv,"compared with previous two-stream trackers, the recent one-stream tracking pipeline, which allows earlier interaction between the template and search region, has achieved a remarkable performance gain. however, existing one-stream trackers always let the template interact with all parts inside the search region throughout all the encoder layers. this could potentially lead to target-background confusion when the extracted feature representations are not sufficiently discriminative. to alleviate this issue, we propose a generalized relation modeling method based on adaptive token division. the proposed method is a generalized formulation of attention-based relation modeling for transformer tracking, which inherits the merits of both previous two-stream and one-stream pipelines whilst enabling more flexible relation modeling by selecting appropriate search tokens to interact with template tokens. an attention masking strategy and the gumbel-softmax technique are introduced to facilitate the parallel computation and end-to-end learning of the token division module. extensive experiments show that our method is superior to the two-stream and one-stream pipelines and achieves state-of-the-art performance on six challenging benchmarks with a real-time running speed.",,2023-03-29,2023-04-10,"['shenyuan gao', 'chunluan zhou', 'jun zhang']",https://arxiv.org/pdf/2303.16580.pdf
335,2303.16656,learning flow functions from data with applications to nonlinear   oscillators,eess.sy cs.lg cs.sy,"we describe a recurrent neural network (rnn) based architecture to learn the flow function of a causal, time-invariant and continuous-time control system from trajectory data. by restricting the class of control inputs to piecewise constant functions, we show that learning the flow function is equivalent to learning the input-to-state map of a discrete-time dynamical system. this motivates the use of an rnn together with encoder and decoder networks which map the state of the system to the hidden state of the rnn and back. we show that the proposed architecture is able to approximate the flow function by exploiting the system's causality and time-invariance. the output of the learned flow function model can be queried at any time instant. we experimentally validate the proposed method using models of the van der pol and fitzhugh nagumo oscillators. in both cases, the results demonstrate that the architecture is able to closely reproduce the trajectories of these two systems. for the van der pol oscillator, we further show that the trained model generalises to the system's response with a prolonged prediction time horizon as well as control inputs outside the training distribution. for the fitzhugh-nagumo oscillator, we show that the model accurately captures the input-dependent phenomena of excitability.",,2023-03-29,2023-04-11,"['miguel aguiar', 'amritam das', 'karl h. johansson']",https://arxiv.org/pdf/2303.16656.pdf
336,2303.16755,training language models with language feedback at scale,cs.cl cs.ai cs.lg,"pretrained language models often generate outputs that are not in line with human preferences, such as harmful text or factually incorrect summaries. recent work approaches the above issues by learning from a simple form of human feedback: comparisons between pairs of model-generated outputs. however, comparison feedback only conveys limited information about human preferences. in this paper, we introduce imitation learning from language feedback (ilf), a new approach that utilizes more informative language feedback. ilf consists of three steps that are applied iteratively: first, conditioning the language model on the input, an initial lm output, and feedback to generate refinements. second, selecting the refinement incorporating the most feedback. third, finetuning the language model to maximize the likelihood of the chosen refinement given the input. we show theoretically that ilf can be viewed as bayesian inference, similar to reinforcement learning from human feedback. we evaluate ilf's effectiveness on a carefully-controlled toy task and a realistic summarization task. our experiments demonstrate that large language models accurately incorporate feedback and that finetuning with ilf scales well with the dataset size, even outperforming finetuning on human summaries. learning from both language and comparison feedback outperforms learning from each alone, achieving human-level summarization performance.",,2023-03-28,2023-04-09,"['j√©r√©my scheurer', 'jon ander campos', 'tomasz korbak', 'jun shern chan', 'angelica chen', 'kyunghyun cho', 'ethan perez']",https://arxiv.org/pdf/2303.16755.pdf
337,2303.16870,questions of science: chatting with chatgpt about complex systems,physics.soc-ph cs.ai cs.hc,"we present an overview of the complex systems field using chatgpt as a representation of the community's understanding. chatgpt has learned language patterns and styles from a large dataset of internet texts, allowing it to provide answers that reflect common opinions, ideas, and language patterns found in the community. our exploration covers both teaching and learning, and research topics. we recognize the value of chatgpt as a source for the community's ideas.",,2023-03-29,,"['nuno crokidakis', 'marcio argollo de menezes', 'daniel o. cajueiro']",https://arxiv.org/pdf/2303.16870.pdf
338,2303.16897,physics-driven diffusion models for impact sound synthesis from videos,cs.cv cs.lg cs.sd eess.as,"modeling sounds emitted from physical object interactions is critical for immersive perceptual experiences in real and virtual worlds. traditional methods of impact sound synthesis use physics simulation to obtain a set of physics parameters that could represent and synthesize the sound. however, they require fine details of both the object geometries and impact locations, which are rarely available in the real world and can not be applied to synthesize impact sounds from common videos. on the other hand, existing video-driven deep learning-based approaches could only capture the weak correspondence between visual content and impact sounds since they lack of physics knowledge. in this work, we propose a physics-driven diffusion model that can synthesize high-fidelity impact sound for a silent video clip. in addition to the video content, we propose to use additional physics priors to guide the impact sound synthesis procedure. the physics priors include both physics parameters that are directly estimated from noisy real-world impact sound examples without sophisticated setup and learned residual parameters that interpret the sound environment via neural networks. we further implement a novel diffusion model with specific training and inference strategies to combine physics priors and visual information for impact sound synthesis. experimental results show that our model outperforms several existing systems in generating realistic impact sounds. more importantly, the physics-based representations are fully interpretable and transparent, thus enabling us to perform sound editing flexibly.",,2023-03-29,2023-04-11,"['kun su', 'kaizhi qian', 'eli shlizerman', 'antonio torralba', 'chuang gan']",https://arxiv.org/pdf/2303.16897.pdf
339,2303.17118,rpu: the ring processing unit,cs.ar cs.cr,"ring-learning-with-errors (rlwe) has emerged as the foundation of many important techniques for improving security and privacy, including homomorphic encryption and post-quantum cryptography. while promising, these techniques have received limited use due to their extreme overheads of running on general-purpose machines. in this paper, we present a novel vector instruction set architecture (isa) and microarchitecture for accelerating the ring-based computations of rlwe. the isa, named b512, is developed to meet the needs of ring processing workloads while balancing high-performance and general-purpose programming support. having an isa rather than fixed hardware facilitates continued software improvement post-fabrication and the ability to support the evolving workloads. we then propose the ring processing unit (rpu), a high-performance, modular implementation of b512. the rpu has native large word modular arithmetic support, capabilities for very wide parallel processing, and a large capacity high-bandwidth scratchpad to meet the needs of ring processing. we address the challenges of programming the rpu using a newly developed spiral backend. a configurable simulator is built to characterize design tradeoffs and quantify performance. the best performing design was implemented in rtl and used to validate simulator performance. in addition to our characterization, we show that a rpu using 20.5mm2 of gf 12nm can provide a speedup of 1485x over a cpu running a 64k, 128-bit ntt, a core rlwe workload",,2023-03-29,2023-04-13,"['deepraj soni', 'negar neda', 'naifeng zhang', 'benedict reynwar', 'homer gamil', 'benjamin heyman', 'mohammed nabeel', 'ahmad al badawi', 'yuriy polyakov', 'kellie canida', 'massoud pedram', 'michail maniatakos', 'david bruce cousins', 'franz franchetti', 'matthew french', 'andrew schmidt', 'brandon reagen']",https://arxiv.org/pdf/2303.17118.pdf
340,2303.17249,model-agnostic explainable artificial intelligence for object detection   in image data,cs.cv cs.ai,"object detection is a fundamental task in computer vision, which has been greatly progressed through developing large and intricate deep learning models. however, the lack of transparency is a big challenge that may not allow the widespread adoption of these models. explainable artificial intelligence is a field of research where methods are developed to help users understand the behavior, decision logics, and vulnerabilities of ai-based systems. black-box explanation refers to explaining decisions of an ai system without having access to its internals. in this paper, we design and implement a black-box explanation method named black-box object detection explanation by masking (bodem) through adopting a new masking approach for ai-based object detection systems. we propose local and distant masking to generate multiple versions of an input image. local masks are used to disturb pixels within a target object to figure out how the object detector reacts to these changes, while distant masks are used to assess how the detection model's decisions are affected by disturbing pixels outside the object. a saliency map is then created by estimating the importance of pixels through measuring the difference between the detection output before and after masking. finally, a heatmap is created that visualizes how important pixels within the input image are to the detected objects. the experimentations on various object detection datasets and models showed that bodem can be effectively used to explain the behavior of object detectors and reveal their vulnerabilities. this makes bodem suitable for explaining and validating ai based object detection systems in black-box software testing scenarios. furthermore, we conducted data augmentation experiments that showed local masks produced by bodem can be used for further training the object detectors and improve their detection accuracy and robustness.",,2023-03-30,2023-04-12,"['milad moradi', 'ke yan', 'david colwell', 'matthias samwald', 'rhona asgari']",https://arxiv.org/pdf/2303.17249.pdf
341,2303.17573,using ai to measure parkinson's disease severity at home,cs.lg cs.ai,"we present an artificial intelligence system to remotely assess the motor performance of individuals with parkinson's disease (pd). participants performed a motor task (i.e., tapping fingers) in front of a webcam, and data from 250 global participants were rated by three expert neurologists following the movement disorder society unified parkinson's disease rating scale (mds-updrs). the neurologists' ratings were highly reliable, with an intra-class correlation coefficient (icc) of 0.88. we developed computer algorithms to obtain objective measurements that align with the mds-updrs guideline and are strongly correlated with the neurologists' ratings. our machine learning model trained on these measures outperformed an mds-updrs certified rater, with a mean absolute error (mae) of 0.59 compared to the rater's mae of 0.79. however, the model performed slightly worse than the expert neurologists (0.53 mae). the methodology can be replicated for similar motor tasks, providing the possibility of evaluating individuals with pd and other movement disorders remotely, objectively, and in areas with limited access to neurological care.",,2023-03-30,2023-04-13,"['md saiful islam', 'wasifur rahman', 'abdelrahman abdelkader', 'phillip t. yang', 'sangwu lee', 'jamie l. adams', 'ruth b. schneider', 'e. ray dorsey', 'ehsan hoque']",https://arxiv.org/pdf/2303.17573.pdf
342,2303.17824,implementation and (inverse modified) error analysis for   implicitly-templated ode-nets,math.na cs.lg cs.na,"we focus on learning unknown dynamics from data using ode-nets templated on implicit numerical initial value problem solvers. first, we perform inverse modified error analysis of the ode-nets using unrolled implicit schemes for ease of interpretation. it is shown that training an ode-net using an unrolled implicit scheme returns a close approximation of an inverse modified differential equation (imde). in addition, we establish a theoretical basis for hyper-parameter selection when training such ode-nets, whereas current strategies usually treat numerical integration of ode-nets as a black box. we thus formulate an adaptive algorithm which monitors the level of error and adapts the number of (unrolled) implicit solution iterations during the training process, so that the error of the unrolled approximation is less than the current learning loss. this helps accelerate training, while maintaining accuracy. several numerical experiments are performed to demonstrate the advantages of the proposed algorithm compared to nonadaptive unrollings, and validate the theoretical analysis. we also note that this approach naturally allows for incorporating partially known physical terms in the equations, giving rise to what is termed ``gray box"" identification.",,2023-03-31,2023-04-09,"['aiqing zhu', 'tom bertalan', 'beibei zhu', 'yifa tang', 'ioannis g. kevrekidis']",https://arxiv.org/pdf/2303.17824.pdf
343,2304.00160,secure federated learning against model poisoning attacks via client   filtering,cs.cr cs.dc,"given the distributed nature, detecting and defending against the backdoor attack under federated learning (fl) systems is challenging. in this paper, we observe that the cosine similarity of the last layer's weight between the global model and each local update could be used effectively as an indicator of malicious model updates. therefore, we propose cosdefense, a cosine-similarity-based attacker detection algorithm. specifically, under cosdefense, the server calculates the cosine similarity score of the last layer's weight between the global model and each client update, labels malicious clients whose score is much higher than the average, and filters them out of the model aggregation in each round. compared to existing defense schemes, cosdefense does not require any extra information besides the received model updates to operate and is compatible with client sampling. experiment results on three real-world datasets demonstrate that cosdefense could provide robust performance under the state-of-the-art fl poisoning attack.",,2023-03-31,2023-04-08,"['duygu nur yaldiz', 'tuo zhang', 'salman avestimehr']",https://arxiv.org/pdf/2304.00160.pdf
344,2304.00571,dropmae: masked autoencoders with spatial-attention dropout for tracking   tasks,cs.cv,"in this paper, we study masked autoencoder (mae) pretraining on videos for matching-based downstream tasks, including visual object tracking (vot) and video object segmentation (vos). a simple extension of mae is to randomly mask out frame patches in videos and reconstruct the frame pixels. however, we find that this simple baseline heavily relies on spatial cues while ignoring temporal relations for frame reconstruction, thus leading to sub-optimal temporal matching representations for vot and vos. to alleviate this problem, we propose dropmae, which adaptively performs spatial-attention dropout in the frame reconstruction to facilitate temporal correspondence learning in videos. we show that our dropmae is a strong and efficient temporal matching learner, which achieves better finetuning results on matching-based tasks than the imagenetbased mae with 2x faster pre-training speed. moreover, we also find that motion diversity in pre-training videos is more important than scene diversity for improving the performance on vot and vos. our pre-trained dropmae model can be directly loaded in existing vit-based trackers for fine-tuning without further modifications. notably, dropmae sets new state-of-the-art performance on 8 out of 9 highly competitive video tracking and segmentation datasets. our code and pre-trained models are available at https://github.com/jimmy-dq/dropmae.git.",,2023-04-02,2023-04-06,"['qiangqiang wu', 'tianyu yang', 'ziquan liu', 'baoyuan wu', 'ying shan', 'antoni b. chan']",https://arxiv.org/pdf/2304.00571.pdf
345,2304.00601,constructive assimilation: boosting contrastive learning performance   through view generation strategies,cs.cv cs.lg,"transformations based on domain expertise (expert transformations), such as random-resized-crop and color-jitter, have proven critical to the success of contrastive learning techniques such as simclr. recently, several attempts have been made to replace such domain-specific, human-designed transformations with generated views that are learned. however for imagery data, so far none of these view-generation methods has been able to outperform expert transformations. in this work, we tackle a different question: instead of replacing expert transformations with generated views, can we constructively assimilate generated views with expert transformations? we answer this question in the affirmative and propose a view generation method and a simple, effective assimilation method that together improve the state-of-the-art by up to ~3.6% on three different datasets. importantly, we conduct a detailed empirical study that systematically analyzes a range of view generation and assimilation methods and provides a holistic picture of the efficacy of learned views in contrastive representation learning.",,2023-04-02,2023-04-08,"['ligong han', 'seungwook han', 'shivchander sudalairaj', 'charlotte loh', 'rumen dangovski', 'fei deng', 'pulkit agrawal', 'dimitris metaxas', 'leonid karlinsky', 'tsui-wei weng', 'akash srivastava']",https://arxiv.org/pdf/2304.00601.pdf
346,2304.00668,discovering and explaining the non-causality of deep learning in sar atr,cs.cv cs.lg,"in recent years, deep learning has been widely used in sar atr and achieved excellent performance on the mstar dataset. however, due to constrained imaging conditions, mstar has data biases such as background correlation, i.e., background clutter properties have a spurious correlation with target classes. deep learning can overfit clutter to reduce training errors. therefore, the degree of overfitting for clutter reflects the non-causality of deep learning in sar atr. existing methods only qualitatively analyze this phenomenon. in this paper, we quantify the contributions of different regions to target recognition based on the shapley value. the shapley value of clutter measures the degree of overfitting. moreover, we explain how data bias and model bias contribute to non-causality. concisely, data bias leads to comparable signal-to-clutter ratios and clutter textures in training and test sets. and various model structures have different degrees of overfitting for these biases. the experimental results of various models under standard operating conditions on the mstar dataset support our conclusions. our code is available at https://github.com/waterdisappear/data-bias-in-mstar.",10.1109/lgrs.2023.3266493,2023-04-02,2023-04-12,"['weijie li', 'wei yang', 'li liu', 'wenpeng zhang', 'yongxiang liu']",https://arxiv.org/pdf/2304.00668.pdf
347,2304.00759,fedin: federated intermediate layers learning for model heterogeneity,cs.lg,"federated learning (fl) facilitates edge devices to cooperatively train a global shared model while maintaining the training data locally and privately. however, a common but impractical assumption in fl is that the participating edge devices possess the same required resources and share identical global model architecture. in this study, we propose a novel fl method called federated intermediate layers learning (fedin), supporting heterogeneous models without utilizing any public dataset. the training models in fedin are divided into three parts, including an extractor, the intermediate layers, and a classifier. the model architectures of the extractor and classifier are the same in all devices to maintain the consistency of the intermediate layer features, while the architectures of the intermediate layers can vary for heterogeneous devices according to their resource capacities. to exploit the knowledge from features, we propose in training, training the intermediate layers in line with the features from other clients. additionally, we formulate and solve a convex optimization problem to mitigate the gradient divergence problem induced by the conflicts between the in training and the local training. the experiment results show that fedin achieves the best performance in the heterogeneous model environment compared with the state-of-the-art algorithms. furthermore, our ablation study demonstrates the effectiveness of in training and the solution to the convex optimization problem.",,2023-04-03,2023-04-12,"['yun-hin chan', 'zhihan jiang', 'jing deng', 'edith c. -h. ngai']",https://arxiv.org/pdf/2304.00759.pdf
348,2304.01005,federated learning based multilingual emoji prediction in clean and   attack scenarios,cs.cl,"federated learning is a growing field in the machine learning community due to its decentralized and private design. model training in federated learning is distributed over multiple clients giving access to lots of client data while maintaining privacy. then, a server aggregates the training done on these multiple clients without access to their data, which could be emojis widely used in any social media service and instant messaging platforms to express users' sentiments. this paper proposes federated learning-based multilingual emoji prediction in both clean and attack scenarios. emoji prediction data have been crawled from both twitter and semeval emoji datasets. this data is used to train and evaluate different transformer model sizes including a sparsely activated transformer with either the assumption of clean data in all clients or poisoned data via label flipping attack in some clients. experimental results on these models show that federated learning in either clean or attacked scenarios performs similarly to centralized training in multilingual emoji prediction on seen and unseen languages under different data sources and distributions. our trained transformers perform better than other techniques on the semeval emoji dataset in addition to the privacy as well as distributed benefits of federated learning.",,2023-03-30,2023-04-09,"['karim gamal', 'ahmed gaber', 'hossam amer']",https://arxiv.org/pdf/2304.01005.pdf
349,2304.01075,conformal prediction regions for time series using linear   complementarity programming,eess.sy cs.lg cs.sy,"conformal prediction is a statistical tool for producing prediction regions of machine learning models that are valid with high probability. however, applying conformal prediction to time series data leads to conservative prediction regions. in fact, to obtain prediction regions over $t$ time steps with confidence $1-\delta$, {previous works require that each individual prediction region is valid} with confidence $1-\delta/t$. we propose an optimization-based method for reducing this conservatism to enable long horizon planning and verification when using learning-enabled time series predictors. instead of considering prediction errors individually at each time step, we consider a parameterized prediction error over multiple time steps. by optimizing the parameters over an additional dataset, we find prediction regions that are not conservative. we show that this problem can be cast as a mixed integer linear complementarity program (milcp), which we then relax into a linear complementarity program (lcp). additionally, we prove that the relaxed lp has the same optimal cost as the original milcp. finally, we demonstrate the efficacy of our method on a case study using pedestrian trajectory predictors.",,2023-04-03,2023-04-07,"['matthew cleaveland', 'insup lee', 'george j. pappas', 'lars lindemann']",https://arxiv.org/pdf/2304.01075.pdf
350,2304.01203,optimal goal-reaching reinforcement learning via quasimetric learning,cs.lg,"in goal-reaching reinforcement learning (rl), the optimal value function has a particular geometry, called quasimetric structure. this paper introduces quasimetric reinforcement learning (qrl), a new rl method that utilizes quasimetric models to learn optimal value functions. distinct from prior approaches, the qrl objective is specifically designed for quasimetrics, and provides strong theoretical recovery guarantees. empirically, we conduct thorough analyses on a discretized mountaincar environment, identifying properties of qrl and its advantages over alternatives. on offline and online goal-reaching benchmarks, qrl also demonstrates improved sample efficiency and performance, across both state-based and image-based observations.",,2023-04-03,2023-04-06,"['tongzhou wang', 'antonio torralba', 'phillip isola', 'amy zhang']",https://arxiv.org/pdf/2304.01203.pdf
351,2304.01237,a guide for practical use of admg causal data augmentation,cs.lg stat.me,"data augmentation is essential when applying machine learning in small-data regimes. it generates new samples following the observed data distribution while increasing their diversity and variability to help researchers and practitioners improve their models' robustness and, thus, deploy them in the real world. nevertheless, its usage in tabular data still needs to be improved, as prior knowledge about the underlying data mechanism is seldom considered, limiting the fidelity and diversity of the generated data. causal data augmentation strategies have been pointed out as a solution to handle these challenges by relying on conditional independence encoded in a causal graph. in this context, this paper experimentally analyzed the admg causal augmentation method considering different settings to support researchers and practitioners in understanding under which conditions prior knowledge helps generate new data points and, consequently, enhances the robustness of their models. the results highlighted that the studied method (a) is independent of the underlying model mechanism, (b) requires a minimal number of observations that may be challenging in a small-data regime to improve an ml model's accuracy, (c) propagates outliers to the augmented set degrading the performance of the model, and (d) is sensitive to its hyperparameter's value.",,2023-04-03,,"['audrey poinsot', 'alessandro leite']",https://arxiv.org/pdf/2304.01237.pdf
352,2304.01296,dynamic accommodation measurement using purkinje reflections and ml   algorithms,physics.med-ph cs.lg q-bio.qm,"we developed a prototype device for dynamic gaze and accommodation measurements based on 4 purkinje reflections (pr) suitable for use in ar and ophthalmology applications. pr1&2 and pr3&4 are used for accurate gaze and accommodation measurements, respectively. our eye model was developed in zemax and matches the experiments well. our model predicts the accommodation from 4 diopters to 1 diopter with better than 0.25d accuracy. we performed repeatability tests and obtained accurate gaze and accommodation estimations from subjects. we are generating a large synthetic data set using physically accurate models and machine learning.",10.1117/12.2651657,2023-04-03,2023-04-11,"['faik ozan ozhan', 'arda gulersoy', 'ugur aygun', 'afsun sahin', 'hakan urey']",https://arxiv.org/pdf/2304.01296.pdf
353,2304.01432,reducing discretization error in the frank-wolfe method,math.oc cs.ai cs.lg,"the frank-wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. however, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. we view this as an artifact of discretization; that is to say, the frank-wolfe \emph{flow}, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. we propose two improvements: a multistep frank-wolfe method that directly applies optimized higher-order discretization schemes; and an lmo-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $o(1/k)$ to up to $o(1/k^{3/2})$.",,2023-04-03,2023-04-13,"['zhaoyue chen', 'yifan sun']",https://arxiv.org/pdf/2304.01432.pdf
354,2304.01433,tpu v4: an optically reconfigurable supercomputer for machine learning   with hardware support for embeddings,cs.ar cs.ai cs.lg cs.pf,"in response to innovations in machine learning (ml) models, production workloads changed radically and rapidly. tpu v4 is the fifth google domain specific architecture (dsa) and its third supercomputer for such ml models. optical circuit switches (ocses) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3d torus topology if desired. much cheaper, lower power, and faster than infiniband, ocses and underlying optical components are <5% of system cost and <3% of system power. each tpu v4 includes sparsecores, dataflow processors that accelerate models that rely on embeddings by 5x-7x yet use only 5% of die area and power. deployed since 2020, tpu v4 outperforms tpu v3 by 2.1x and improves performance/watt by 2.7x. the tpu v4 supercomputer is 4x larger at 4096 chips and thus ~10x faster overall, which along with ocs flexibility helps large language models. for similar sized systems, it is ~4.3x-4.5x faster than the graphcore ipu bow and is 1.2x-1.7x faster and uses 1.3x-1.9x less power than the nvidia a100. tpu v4s inside the energy-optimized warehouse scale computers of google cloud use ~3x less energy and produce ~20x less co2e than contemporary dsas in a typical on-premise data center.",,2023-04-03,2023-04-10,"['norman p. jouppi', 'george kurian', 'sheng li', 'peter ma', 'rahul nagarajan', 'lifeng nai', 'nishant patil', 'suvinay subramanian', 'andy swing', 'brian towles', 'cliff young', 'xiang zhou', 'zongwei zhou', 'david patterson']",https://arxiv.org/pdf/2304.01433.pdf
355,2304.01492,a unified contrastive transfer framework with propagation structure for   boosting low-resource rumor detection,cs.cl,"the truth is significantly hampered by massive rumors that spread along with breaking news or popular topics. since there is sufficient corpus gathered from the same domain for model training, existing rumor detection algorithms show promising performance on yesterday's news. however, due to a lack of substantial training data and prior expert knowledge, they are poor at spotting rumors concerning unforeseen events, especially those propagated in different languages (i.e., low-resource regimes). in this paper, we propose a unified contrastive transfer framework to detect rumors by adapting the features learned from well-resourced rumor data to that of the low-resourced with only few-shot annotations. more specifically, we first represent rumor circulated on social media as an undirected topology for enhancing the interaction of user opinions, and then train a multi-scale graph convolutional network via a unified contrastive paradigm to mine effective clues simultaneously from post semantics and propagation structure. our model explicitly breaks the barriers of the domain and/or language issues, via language alignment and a novel domain-adaptive contrastive learning mechanism. to well-generalize the representation learning using a small set of annotated target events, we reveal that rumor-indicative signal is closely correlated with the uniformity of the distribution of these events. we design a target-wise contrastive training mechanism with three event-level data augmentation strategies, capable of unifying the representations by distinguishing target events. extensive experiments conducted on four low-resource datasets collected from real-world microblog platforms demonstrate that our framework achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages.",,2023-04-03,2023-04-09,"['hongzhan lin', 'jing ma', 'ruichao yang', 'zhiwei yang', 'mingfei cheng']",https://arxiv.org/pdf/2304.01492.pdf
356,2304.01508,epvt: environment-aware prompt vision transformer for domain   generalization in skin lesion recognition,cs.cv cs.ai cs.lg,"skin lesion recognition using deep learning has made remarkable progress, and there is an increasing need for deploying these systems in real-world scenarios. however, recent research has revealed that deep neural networks for skin lesion recognition may overly depend on disease-irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor generalization in unseen environments. to address this issue, we propose a novel domain generalization method called epvt, which involves embedding prompts into the vision transformer to collaboratively learn knowledge from diverse domains. concretely, epvt leverages a set of domain prompts, each of which plays as a domain expert, to capture domain-specific knowledge; and a shared prompt for general knowledge over the entire dataset. to facilitate knowledge sharing and the interaction of different prompts, we introduce a domain prompt generator that enables low-rank multiplicative updates between domain prompts and the shared prompt. a domain mixup strategy is additionally devised to reduce the co-occurring artifacts in each domain, which allows for more flexible decision margins and mitigates the issue of incorrectly assigned domain labels. experiments on four out-of-distribution datasets and six different biased isic datasets demonstrate the superior generalization ability of epvt in skin lesion recognition across various environments. our code and dataset will be released at https://github.com/siyuanyan1/epvt.",,2023-04-03,2023-04-09,"['siyuan yan', 'chi liu', 'zhen yu', 'lie ju', 'dwarikanath mahapatrainst', 'victoria mar', 'monika janda', 'peter soyer', 'zongyuan ge']",https://arxiv.org/pdf/2304.01508.pdf
357,2304.01547,regularization of the policy updates for stabilizing mean field games,cs.ai,"this work studies non-cooperative multi-agent reinforcement learning (marl) where multiple agents interact in the same environment and whose goal is to maximize the individual returns. challenges arise when scaling up the number of agents due to the resultant non-stationarity that the many agents introduce. in order to address this issue, mean field games (mfg) rely on the symmetry and homogeneity assumptions to approximate games with very large populations. recently, deep reinforcement learning has been used to scale mfg to games with larger number of states. current methods rely on smoothing techniques such as averaging the q-values or the updates on the mean-field distribution. this work presents a different approach to stabilize the learning based on proximal updates on the mean-field policy. we name our algorithm mean field proximal policy optimization (mf-ppo), and we empirically show the effectiveness of our method in the openspiel framework.",,2023-04-04,2023-04-13,"['talal algumaei', 'ruben solozabal', 'reda alami', 'hakim hacid', 'merouane debbah', 'martin takac']",https://arxiv.org/pdf/2304.01547.pdf
358,2304.01598,mm-bsn: self-supervised image denoising for real-world with multi-mask   based on blind-spot network,cs.cv,"recent advances in deep learning have been pushing image denoising techniques to a new level. in self-supervised image denoising, blind-spot network (bsn) is one of the most common methods. however, most of the existing bsn algorithms use a dot-based central mask, which is recognized as inefficient for images with large-scale spatially correlated noise. in this paper, we give the definition of large-noise and propose a multi-mask strategy using multiple convolutional kernels masked in different shapes to further break the noise spatial correlation. furthermore, we propose a novel self-supervised image denoising method that combines the multi-mask strategy with bsn (mm-bsn). we show that different masks can cause significant performance differences, and the proposed mm-bsn can efficiently fuse the features extracted by multi-masked layers, while recovering the texture structures destroyed by multi-masking and information transmission. our mm-bsn can be used to address the problem of large-noise denoising, which cannot be efficiently handled by other bsn methods. extensive experiments on public real-world datasets demonstrate that the proposed mm-bsn achieves state-of-the-art performance among self-supervised and even unpaired image denoising methods for srgb images denoising, without any labelling effort or prior knowledge. code can be found in https://github.com/dannie125/mm-bsn.",,2023-04-04,2023-04-07,"['dan zhang', 'fangfang zhou', 'yuwen jiang', 'zhengming fu']",https://arxiv.org/pdf/2304.01598.pdf
359,2304.01731,selective knowledge sharing for privacy-preserving federated   distillation without a good teacher,cs.lg,"while federated learning is promising for privacy-preserving collaborative learning without revealing local data, it remains vulnerable to white-box attacks and struggles to adapt to heterogeneous clients. federated distillation (fd), built upon knowledge distillation--an effective technique for transferring knowledge from a teacher model to student models--emerges as an alternative paradigm, which provides enhanced privacy guarantees and addresses model heterogeneity. nevertheless, challenges arise due to variations in local data distributions and the absence of a well-trained teacher model, which leads to misleading and ambiguous knowledge sharing that significantly degrades model performance. to address these issues, this paper proposes a selective knowledge sharing mechanism for fd, termed selective-fd. it includes client-side selectors and a server-side selector to accurately and precisely identify knowledge from local and ensemble predictions, respectively. empirical studies, backed by theoretical insights, demonstrate that our approach enhances the generalization capabilities of the fd framework and consistently outperforms baseline methods. this study presents a promising direction for effective knowledge transfer in privacy-preserving collaborative learning.",,2023-04-04,2023-04-10,"['jiawei shao', 'fangzhao wu', 'jun zhang']",https://arxiv.org/pdf/2304.01731.pdf
360,2304.01852,summary of chatgpt/gpt-4 research and perspective towards the future of   large language models,cs.cl,"this paper presents a comprehensive survey of chatgpt and gpt-4, state-of-the-art large language models (llm) from the gpt series, and their prospective applications across diverse domains. indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and reinforcement learning from human feedback (rlhf) have played significant roles in enhancing llms' adaptability and performance. we performed an in-depth analysis of 194 relevant papers on arxiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. the findings reveal a significant and increasing interest in chatgpt/gpt-4 research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. this study endeavors to furnish insights into chatgpt's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.",,2023-04-04,2023-04-08,"['yiheng liu', 'tianle han', 'siyuan ma', 'jiayue zhang', 'yuanyuan yang', 'jiaming tian', 'hao he', 'antong li', 'mengshen he', 'zhengliang liu', 'zihao wu', 'dajiang zhu', 'xiang li', 'ning qiang', 'dingang shen', 'tianming liu', 'bao ge']",https://arxiv.org/pdf/2304.01852.pdf
361,2304.01890,sociocultural knowledge is needed for selection of shots in hate speech   detection tasks,cs.cl cs.ai cs.lg,"we introduce hatelexicon, a lexicon of slurs and targets of hate speech for the countries of brazil, germany, india and kenya, to aid training and interpretability of models. we demonstrate how our lexicon can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target words when making predictions. further, we propose a method to aid shot selection for training in low-resource settings via hatelexicon. in few-shot learning, the selection of shots is of paramount importance to model performance. in our work, we simulate a few-shot setting for german and hindi, using hasoc data for training and the multilingual hatecheck (mhc) as a benchmark. we show that selecting shots based on our lexicon leads to models performing better on mhc than models trained on shots sampled randomly. thus, when given only a few training examples, using our lexicon to select shots containing more sociocultural information leads to better few-shot performance.",,2023-04-04,2023-04-11,"['antonis maronikolakis', 'abdullatif k√∂ksal', 'hinrich sch√ºtze']",https://arxiv.org/pdf/2304.01890.pdf
362,2304.01897,influencerrank: discovering effective influencers via graph   convolutional attentive recurrent neural networks,cs.si cs.ai,"as influencers play considerable roles in social media marketing, companies increase the budget for influencer marketing. hiring effective influencers is crucial in social influencer marketing, but it is challenging to find the right influencers among hundreds of millions of social media users. in this paper, we propose influencerrank that ranks influencers by their effectiveness based on their posting behaviors and social relations over time. to represent the posting behaviors and social relations, the graph convolutional neural networks are applied to model influencers with heterogeneous networks during different historical periods. by learning the network structure with the embedded node features, influencerrank can derive informative representations for influencers at each period. an attentive recurrent neural network finally distinguishes highly effective influencers from other influencers by capturing the knowledge of the dynamics of influencer representations over time. extensive experiments have been conducted on an instagram dataset that consists of 18,397 influencers with their 2,952,075 posts published within 12 months. the experimental results demonstrate that influencerrank outperforms existing baseline methods. an in-depth analysis further reveals that all of our proposed features and model components are beneficial to discover effective influencers.",,2023-04-04,2023-04-12,"['seungbae kim', 'jyun-yu jiang', 'jinyoung han', 'wei wang']",https://arxiv.org/pdf/2304.01897.pdf
363,2304.02012,egc: image generation and classification via a diffusion energy-based   model,cs.cv cs.ai cs.lg,"learning image classification and image generation using the same set of network parameters is a challenging problem. recent advanced approaches perform well in one task often exhibit poor performance in the other. this work introduces an energy-based classifier and generator, namely egc, which can achieve superior performance in both tasks using a single neural network. unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\mathbf{x})$), the forward pass in egc is a classifier that outputs a joint distribution $p(\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. this is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass. egc achieves competitive generation results compared with state-of-the-art approaches on imagenet-1k, celeba-hq and lsun church, while achieving superior classification accuracy and robustness against adversarial attacks on cifar-10. this work represents the first successful attempt to simultaneously excel in both tasks using a single set of network parameters. we believe that egc bridges the gap between discriminative and generative learning.",,2023-04-04,2023-04-13,"['qiushan guo', 'chuofan ma', 'yi jiang', 'zehuan yuan', 'yizhou yu', 'ping luo']",https://arxiv.org/pdf/2304.02012.pdf
364,2304.02084,educelab-scrolls: verifiable recovery of text from herculaneum papyri   using x-ray ct,cs.cv cs.lg,"we present a complete software pipeline for revealing the hidden texts of the herculaneum papyri using x-ray ct images. this enhanced virtual unwrapping pipeline combines machine learning with a novel geometric framework linking 3d and 2d images. we also present educelab-scrolls, a comprehensive open dataset representing two decades of research effort on this problem. educelab-scrolls contains a set of volumetric x-ray ct images of both small fragments and intact, rolled scrolls. the dataset also contains 2d image labels that are used in the supervised training of an ink detection model. labeling is enabled by aligning spectral photography of scroll fragments with x-ray ct images of the same fragments, thus creating a machine-learnable mapping between image spaces and modalities. this alignment permits supervised learning for the detection of ""invisible"" carbon ink in x-ray ct, a task that is ""impossible"" even for human expert labelers. to our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain. our method is capable of revealing accurate lines of text on scroll fragments with known ground truth. revealed text is verified using visual confirmation, quantitative image metrics, and scholarly review. educelab-scrolls has also enabled the discovery, for the first time, of hidden texts from the herculaneum papyri, which we present here. we anticipate that the educelab-scrolls dataset will generate more textual discovery as research continues.",,2023-04-04,2023-04-08,"['stephen parsons', 'c. seth parker', 'christy chapman', 'mami hayashida', 'w. brent seales']",https://arxiv.org/pdf/2304.02084.pdf
365,2304.02213,large language models as master key: unlocking the secrets of materials   science with gpt,cs.cl cs.ai,"the amount of data has growing significance in exploring cutting-edge materials and a number of datasets have been generated either by hand or automated approaches. however, the materials science field struggles to effectively utilize the abundance of data, especially in applied disciplines where materials are evaluated based on device performance rather than their properties. this article presents a new natural language processing (nlp) task called structured information inference (sii) to address the complexities of information extraction at the device level in materials science. we accomplished this task by tuning gpt-3 on an existing perovskite solar cell fair (findable, accessible, interoperable, reusable) dataset with 91.8% f1-score and extended the dataset with data published since its release. the produced data is formatted and normalized, enabling its direct utilization as input in subsequent data analysis. this feature empowers materials scientists to develop models by selecting high-quality review articles within their domain. additionally, we designed experiments to predict the electrical performance of solar cells and design materials or devices with targeted parameters using large language models (llms). our results demonstrate comparable performance to traditional machine learning methods without feature selection, highlighting the potential of llms to acquire scientific knowledge and design new materials akin to materials scientists.",,2023-04-05,2023-04-12,"['tong xie', 'yuwei wan', 'wei huang', 'yufei zhou', 'yixuan liu', 'qingyuan linghu', 'shaozhou wang', 'chunyu kit', 'clara grazian', 'wenjie zhang', 'bram hoex']",https://arxiv.org/pdf/2304.02213.pdf
366,2304.02220,on the universal approximation property of radial basis function neural   networks,cs.lg stat.ml,"in this paper we consider a new class of rbf (radial basis function) neural networks, in which smoothing factors are replaced with shifts. we prove under certain conditions on the activation function that these networks are capable of approximating any continuous multivariate function on any compact subset of the $d$-dimensional euclidean space. for rbf networks with finitely many fixed centroids we describe conditions guaranteeing approximation with arbitrary precision.",,2023-04-05,2023-04-08,"['aysu ismayilova', 'muhammad ismayilov']",https://arxiv.org/pdf/2304.02220.pdf
367,2304.02223,local intrinsic dimensional entropy,cs.lg cs.it math.it,"most entropy measures depend on the spread of the probability distribution over the sample space x, and the maximum entropy achievable scales proportionately with the sample space cardinality |x|. for a finite |x|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |x|=infinity). furthermore, since r and r^d (d in z+) have the same cardinality (from cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. in this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. we find that the average value of the local intrinsic dimension of a distribution, denoted as id-entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimensionality. we find that id-entropy satisfies many desirable properties and can be extended to conditional entropy, joint entropy and mutual-information variants. id-entropy also yields new information bottleneck principles and also links to causality. in the context of deep learning, for feedforward architectures, we show, theoretically and empirically, that the id-entropy of a hidden layer directly controls the generalization gap for both classifiers and auto-encoders, when the target function is lipschitz continuous. our work primarily shows that, for continuous spaces, taking a structural rather than a statistical approach yields entropy measures which preserve intrinsic data dimensionality, while being relevant for studying various architectures.",,2023-04-05,2023-04-06,"['rohan ghosh', 'mehul motani']",https://arxiv.org/pdf/2304.02223.pdf
368,2304.02308,influence of dataset parameters on the performance of direct ue   positioning via deep learning,cs.it math.it,"user equipment (ue) positioning accuracy is of paramount importance in current and future communications standard. however, traditional methods tend to perform poorly in non line of sight (nlos) scenarios. as a result, deep learning is a candidate to enhance the ue positioning accuracy in nlos environments. in this paper, we study the efficiency of deep learning on the 3gpp indoor factory (inf) statistical channel. more specifically, we analyse the impacts of several key elements on the positioning accuracy: the type of radio data used, the number of base stations (bs), the size of the training dataset, and the generalization ability of a trained model.",,2023-04-05,2023-04-13,"['baptiste chatelier', 'vincent corlay', 'cristina ciochina', 'fallou coly', 'julien guillet']",https://arxiv.org/pdf/2304.02308.pdf
369,2304.02396,autorl hyperparameter landscapes,cs.lg cs.ai cs.ro cs.sy eess.sy,"although reinforcement learning (rl) has shown to be capable of producing impressive results, its use is limited by the impact of its hyperparameters on performance. this often makes it difficult to achieve good results in practice. automated rl (autorl) addresses this difficulty, yet little is known about the dynamics of the hyperparameter landscapes that hyperparameter optimization (hpo) methods traverse in search of optimal configurations. in view of existing autorl approaches dynamically adjusting hyperparameter configurations, we propose an approach to build and analyze these hyperparameter landscapes not just for one point in time but at multiple points in time throughout training. addressing an important open question on the legitimacy of such dynamic autorl approaches, we provide thorough empirical evidence that the hyperparameter landscapes strongly vary over time across representative algorithms from rl literature (dqn and sac) in different kinds of environments (cartpole and hopper). this supports the theory that hyperparameters should be dynamically adjusted during training and shows the potential for more insights on autorl problems that can be gained through landscape analyses.",,2023-04-05,2023-04-11,"['aditya mohan', 'carolin benjamins', 'konrad wienecke', 'alexander dockhorn', 'marius lindauer']",https://arxiv.org/pdf/2304.02396.pdf
370,2304.02438,cocomo: computational consciousness modeling for generative and ethical   ai,cs.oh,"the cocomo model proposes a computational solution to the challenge of incorporating ethical and emotional intelligence considerations into ai systems, with the aim of creating ai agents that combine knowledge with compassion. to achieve this goal, cocomo prioritizes fairness, beneficence, non-maleficence, empathy, adaptability, transparency, and critical and exploratory thinking abilities. the model employs consciousness modeling, reinforcement learning, and prompt template formulation to support these desired traits. by incorporating ethical and emotional intelligence considerations, a generative ai model can potentially lead to improved fairness, reduced toxicity, and increased reliability.",,2023-03-17,2023-04-08,['edward y. chang'],https://arxiv.org/pdf/2304.02438.pdf
371,2304.02639,entl: embodied navigation trajectory learner,cs.cv cs.ro,"we propose embodied navigation trajectory learner (entl), a method for extracting long sequence representations for embodied navigation. our approach unifies world modeling, localization and imitation learning into a single sequence prediction task. we train our model using vector-quantized predictions of future states conditioned on current states and actions. entl's generic architecture enables sharing of the spatio-temporal sequence encoder for multiple challenging embodied tasks. we achieve competitive performance on navigation tasks using significantly less data than strong baselines while performing auxiliary tasks such as localization and future frame prediction (a proxy for world modeling). a key property of our approach is that the model is pre-trained without any explicit reward signal, which makes the resulting model generalizable to multiple tasks and environments.",,2023-04-05,2023-04-06,"['klemen kotar', 'aaron walsman', 'roozbeh mottaghi']",https://arxiv.org/pdf/2304.02639.pdf
372,2304.02689,action++: improving semi-supervised medical image segmentation with   adaptive anatomical contrast,cs.cv cs.ai cs.lg eess.iv,"medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects). recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria. however, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced. in this work, we present action++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation. specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed class centers. moreover, we argue that blindly adopting a constant temperature $\tau$ in the contrastive loss on long-tailed medical data is not optimal, and propose to use a dynamic $\tau$ via a simple cosine schedule to yield better separation between majority and minority classes. empirically, we evaluate action++ on acdc and la benchmarks and show that it achieves state-of-the-art across two semi-supervised settings. theoretically, we analyze the performance of adaptive anatomical contrast and confirm its superiority in label efficiency.",,2023-04-05,2023-04-06,"['chenyu you', 'weicheng dai', 'yifei min', 'lawrence staib', 'jasjeet s. sekhon', 'james s. duncan']",https://arxiv.org/pdf/2304.02689.pdf
373,2304.02798,source-free domain adaptation requires penalized diversity,cs.lg cs.cv,"while neural networks are capable of achieving human-like performance in many tasks such as image classification, the impressive performance of each model is limited to its own dataset. source-free domain adaptation (sfda) was introduced to address knowledge transfer between different domains in the absence of source data, thus, increasing data privacy. diversity in representation space can be vital to a model`s adaptability in varied and difficult domains. in unsupervised sfda, the diversity is limited to learning a single hypothesis on the source or learning multiple hypotheses with a shared feature extractor. motivated by the improved predictive performance of ensembles, we propose a novel unsupervised sfda algorithm that promotes representational diversity through the use of separate feature extractors with distinct backbone architectures (dba). although diversity in feature space is increased, the unconstrained mutual information (mi) maximization may potentially introduce amplification of weak hypotheses. thus we introduce the weak hypothesis penalization (whp) regularizer as a mitigation strategy. our work proposes penalized diversity (pd) where the synergy of dba and whp is applied to unsupervised source-free domain adaptation for covariate shift. in addition, pd is augmented with a weighted mi maximization objective for label distribution shift. empirical results on natural, synthetic, and medical domains demonstrate the effectiveness of pd under different distributional shifts.",,2023-04-05,2023-04-12,"['laya rafiee sevyeri', 'ivaxi sheth', 'farhood farahnak', 'alexandre see', 'samira ebrahimi kahou', 'thomas fevens', 'mohammad havaei']",https://arxiv.org/pdf/2304.02798.pdf
374,2304.02836,longitudinal multimodal transformer integrating imaging and latent   clinical signatures from routine ehrs for pulmonary nodule classification,eess.iv cs.cv cs.lg,"the accuracy of predictive models for solitary pulmonary nodule (spn) diagnosis can be greatly increased by incorporating repeat imaging and medical context, such as electronic health records (ehrs). however, clinically routine modalities such as imaging and diagnostic codes can be asynchronous and irregularly sampled over different time scales which are obstacles to longitudinal multimodal learning. in this work, we propose a transformer-based multimodal strategy to integrate repeat imaging with longitudinal clinical signatures from routinely collected ehrs for spn classification. we perform unsupervised disentanglement of latent clinical signatures and leverage time-distance scaled self-attention to jointly learn from clinical signatures expressions and chest computed tomography (ct) scans. our classifier is pretrained on 2,668 scans from a public dataset and 1,149 subjects with longitudinal chest cts, billing codes, medications, and laboratory tests from ehrs of our home institution. evaluation on 227 subjects with challenging spns revealed a significant auc improvement over a longitudinal multimodal baseline (0.824 vs 0.752 auc), as well as improvements over a single cross-section multimodal scenario (0.809 auc) and a longitudinal imaging-only scenario (0.741 auc). this work demonstrates significant advantages with a novel approach for co-learning longitudinal imaging and non-imaging phenotypes with transformers.",,2023-04-05,2023-04-10,"['thomas z. li', 'john m. still', 'kaiwen xu', 'ho hin lee', 'leon y. cai', 'aravind r. krishnan', 'riqiang gao', 'mirza s. khan', 'sanja antic', 'michael kammer', 'kim l. sandler', 'fabien maldonado', 'bennett a. landman', 'thomas a. lasko']",https://arxiv.org/pdf/2304.02836.pdf
375,2304.02906,memefier: dual-stage modality fusion for image meme classification,cs.cv,"hate speech is a societal problem that has significantly grown through the internet. new forms of digital content such as image memes have given rise to spread of hate using multimodal means, being far more difficult to analyse and detect compared to the unimodal case. accurate automatic processing, analysis and understanding of this kind of content will facilitate the endeavor of hindering hate speech proliferation through the digital world. to this end, we propose memefier, a deep learning-based architecture for fine-grained classification of internet image memes, utilizing a dual-stage modality fusion module. the first fusion stage produces feature vectors containing modality alignment information that captures non-trivial connections between the text and image of a meme. the second fusion stage leverages the power of a transformer encoder to learn inter-modality correlations at the token level and yield an informative representation. additionally, we consider external knowledge as an additional input, and background image caption supervision as a regularizing component. extensive experiments on three widely adopted benchmarks, i.e., facebook hateful memes, memotion7k and multioff, indicate that our approach competes and in some cases surpasses state-of-the-art. our code is available on https://github.com/ckoutlis/memefier.",,2023-04-06,2023-04-07,"['christos koutlis', 'manos schinas', 'symeon papadopoulos']",https://arxiv.org/pdf/2304.02906.pdf
376,2304.02911,heavy-tailed regularization of weight matrices in deep neural networks,stat.ml cs.lg,"unraveling the reasons behind the remarkable success and exceptional generalization capabilities of deep neural networks presents a formidable challenge. recent insights from random matrix theory, specifically those concerning the spectral analysis of weight matrices in deep neural networks, offer valuable clues to address this issue. a key finding indicates that the generalization performance of a neural network is associated with the degree of heavy tails in the spectrum of its weight matrices. to capitalize on this discovery, we introduce a novel regularization technique, termed heavy-tailed regularization, which explicitly promotes a more heavy-tailed spectrum in the weight matrix through regularization. firstly, we employ the weighted alpha and stable rank as penalty terms, both of which are differentiable, enabling the direct calculation of their gradients. to circumvent over-regularization, we introduce two variations of the penalty function. then, adopting a bayesian statistics perspective and leveraging knowledge from random matrices, we develop two novel heavy-tailed regularization methods, utilizing powerlaw distribution and frechet distribution as priors for the global spectrum and maximum eigenvalues, respectively. we empirically show that heavytailed regularization outperforms conventional regularization techniques in terms of generalization performance.",,2023-04-06,2023-04-07,"['xuanzhe xiao', 'zeng li', 'chuanlong xie', 'fengwei zhou']",https://arxiv.org/pdf/2304.02911.pdf
377,2304.02970,a closer look at audio-visual semantic segmentation,cs.cv cs.mm,"audio-visual segmentation (avs) is a complex task that involves accurately segmenting the corresponding sounding object based on audio-visual queries. successful audio-visual learning requires two essential components: 1) an unbiased dataset with high-quality pixel-level multi-class labels, and 2) a model capable of effectively linking audio information with its corresponding visual object. however, these two requirements are only partially addressed by current methods, with training sets containing biased audio-visual data, and models that generalise poorly beyond this biased training set. in this work, we propose a new strategy to build cost-effective and relatively unbiased audio-visual semantic segmentation benchmarks. our strategy, called visual post-production (vpo), explores the observation that it is not necessary to have explicit audio-visual pairs extracted from single video sources to build such benchmarks. we also refine the previously proposed avsbench to transform it into the audio-visual semantic segmentation benchmark avsbench-single+. furthermore, this paper introduces a new pixel-wise audio-visual contrastive learning method to enable a better generalisation of the model beyond the training set. we verify the validity of the vpo strategy by showing that state-of-the-art (sota) models trained with datasets built by matching audio and visual data from different sources or with datasets containing audio and visual data from the same video source produce almost the same accuracy. then, using the proposed vpo benchmarks and avsbench-single+, we show that our method produces more accurate audio-visual semantic segmentation than sota models. code and dataset will be available.",,2023-04-06,2023-04-11,"['yuanhong chen', 'yuyuan liu', 'hu wang', 'fengbei liu', 'chong wang', 'gustavo carneiro']",https://arxiv.org/pdf/2304.02970.pdf
378,2304.03031,revisiting dense retrieval with unanswerable counterfactuals,cs.ai,"the retriever-reader framework is popular for open-domain question answering (odqa), where a retriever samples for the reader a set of relevant candidate passages from a large corpus. a key assumption behind this method is that high relevance scores from the retriever likely indicate high answerability from the reader, which implies a high probability that the retrieved passages contain answers to a given question. in this work, we empirically dispel this belief and observe that recent dense retrieval models based on dpr often rank unanswerable counterfactual passages higher than their answerable original passages. to address such answer-unawareness in dense retrievers, we seek to use counterfactual samples as additional training resources to better synchronize the relevance measurement of dpr with the answerability of question-passage pairs. specifically, we present counterfactually-pivoting contrastive learning (picl), a novel representation learning approach for passage retrieval that leverages counterfactual samples as pivots between positive and negative samples in their learned embedding space. we incorporate picl into the retriever training to show the effectiveness of picl on odqa benchmarks and the robustness of the learned models.",,2023-04-06,2023-04-12,"['yongho song', 'dahyun lee', 'kyungjae lee', 'jinyeong yeo']",https://arxiv.org/pdf/2304.03031.pdf
379,2304.03069,adaptive student's t-distribution with method of moments moving   estimator for nonstationary time series,stat.me cs.lg econ.em stat.ml,"the real life time series are usually nonstationary, bringing a difficult question of model adaptation. classical approaches like arma-arch assume arbitrary type of dependence. to avoid such bias, we will focus on recently proposed agnostic philosophy of moving estimator: in time $t$ finding parameters optimizing e.g. $f_t=\sum_{\tau<t} (1-\eta)^{t-\tau} \ln(\rho_\theta (x_\tau))$ moving log-likelihood, evolving in time. it allows for example to estimate parameters using inexpensive exponential moving averages (ema), like absolute central moments $e[|x-\mu|^p]$ evolving for one or multiple powers $p\in\mathbb{r}^+$ using $m_{p,t+1} = m_{p,t} + \eta (|x_t-\mu_t|^p-m_{p,t})$. application of such general adaptive methods of moments will be presented on student's t-distribution, popular especially in economical applications, here applied to log-returns of djia companies. while standard arma-arch approaches provide evolution of $\mu$ and $\sigma$, here we also get evolution of $\nu$ describing $\rho(x)\sim |x|^{-\nu-1}$ tail shape, probability of extreme events - which might turn out catastrophic, destabilizing the market.",,2023-04-06,2023-04-12,['jarek duda'],https://arxiv.org/pdf/2304.03069.pdf
380,2304.03093,inductive graph unlearning,cs.lg cs.cr cs.si,"as a way to implement the ""right to be forgotten"" in machine learning, \textit{machine unlearning} aims to completely remove the contributions and information of the samples to be deleted from a trained model without affecting the contributions of other samples. recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data. to extend machine unlearning to graph data, \textit{grapheraser} has been proposed. however, a critical issue is that \textit{grapheraser} is specifically designed for the transductive graph setting, where the graph is static and attributes and edges of test nodes are visible during training. it is unsuitable for the inductive setting, where the graph could be dynamic and the test graph information is invisible in advance. such inductive capability is essential for production machine learning systems with evolving graphs like social media and transaction networks. to fill this gap, we propose the \underline{{\bf g}}\underline{{\bf u}}ided \underline{{\bf i}}n\underline{{\bf d}}uctiv\underline{{\bf e}} graph unlearning framework (guide). guide consists of three components: guided graph partitioning with fairness and balance, efficient subgraph repair, and similarity-based aggregation. empirically, we evaluate our method on several inductive benchmarks and evolving transaction graphs. generally speaking, guide can be efficiently implemented on the inductive graph learning tasks for its low graph partition cost, no matter on computation or structure information. the code will be available here: https://github.com/happy2git/guide.",,2023-04-06,2023-04-07,"['cheng-long wang', 'mengdi huai', 'di wang']",https://arxiv.org/pdf/2304.03093.pdf
381,2304.03122,"is it conceivable that neurogenesis, neural darwinism, and species   evolution could all serve as inspiration for the creation of evolutionary   deep neural networks?",cs.ne cs.ai,"deep neural networks (dnns) are built using artificial neural networks. they are part of machine learning methods that are capable of learning from data that have been used in a wide range of applications. dnns are mainly handcrafted and they usually contain numerous layers. research frontier has emerged that concerns automated construction of dnns via evolutionary algorithms. this paper emphasizes the importance of what we call two-dimensional brain evolution and how it can inspire two dimensional dnn evolutionary modeling. we also highlight the connection between the dropout method which is widely-used in regularizing dnns and neurogenesis of the brain, and how these concepts could benefit dnns evolution.the paper concludes with several recommendations for enhancing the automatic construction of dnns.",,2023-04-06,2023-04-11,['mohammed al-rawi'],https://arxiv.org/pdf/2304.03122.pdf
382,2304.03287,synthesis of mathematical programs from natural language specifications,cs.ai cs.cl cs.lg,"several decision problems that are encountered in various business domains can be modeled as mathematical programs, i.e. optimization problems. the process of conducting such modeling often requires the involvement of experts trained in operations research and advanced algorithms. surprisingly, despite the significant advances in the methods for program and code synthesis, automl, learning to optimize etc., there has been little or no attention paid to automating the task of synthesizing mathematical programs. we imagine a scenario where the specifications for modeling, i.e. the objective and constraints are expressed in an unstructured form in natural language (nl) and the mathematical program has to be synthesized from such an nl specification. in this work we evaluate the efficacy of employing codet5 with data augmentation and post-processing of beams. we utilize gpt-3 with back translation for generation of synthetic examples. further we apply rules of linear programming to score beams and correct beams based on common error patterns. we observe that with these enhancements codet5 base gives an execution accuracy of 0.73 which is significantly better than zero-shot execution accuracy of 0.41 by chatgpt and 0.36 by codex.",,2023-03-30,,"['ganesh prasath', 'shirish karande']",https://arxiv.org/pdf/2304.03287.pdf
383,2304.03288,vishien-maat: scrollytelling visualization design for explaining siamese   neural network concept to non-technical users,cs.hc cs.lg,"the past decade has witnessed rapid progress in ai research since the breakthrough in deep learning. ai technology has been applied in almost every field; therefore, technical and non-technical end-users must understand these technologies to exploit them. however existing materials are designed for experts, but non-technical users need appealing materials that deliver complex ideas in easy-to-follow steps. one notable tool that fits such a profile is scrollytelling, an approach to storytelling that provides readers with a natural and rich experience at the reader's pace, along with in-depth interactive explanations of complex concepts. hence, this work proposes a novel visualization design for creating a scrollytelling that can effectively explain an ai concept to non-technical users. as a demonstration of our design, we created a scrollytelling to explain the siamese neural network for the visual similarity matching problem. our approach helps create a visualization valuable for a short-timeline situation like a sales pitch. the results show that the visualization based on our novel design helps improve non-technical users' perception and machine learning concept knowledge acquisition compared to traditional materials like online articles.",10.1016/j.visinf.2023.01.004,2023-04-04,,"['noptanit chotisarn', 'sarun gulyanon', 'tianye zhang', 'wei chen']",https://arxiv.org/pdf/2304.03288.pdf
384,2304.03289,a2d: anywhere anytime drumming,cs.hc cs.sd eess.as,"the drum kit, which has only been around for around 100 years, is a popular instrument in many music genres such as pop, rock, and jazz. however, the road to owning a kit is expensive, both financially and space-wise. also, drums are more difficult to move around compared to other instruments, as they do not fit into a single bag. we propose a no-drums approach that uses only two sticks and a smartphone or a webcam to provide an air-drumming experience. the detection algorithm combines deep learning tools with tracking methods for an enhanced user experience. based on both quantitative and qualitative testing with humans-in-the-loop, we show that our system has zero misses for beginner level play and negligible misses for advanced level play. additionally, our limited human trials suggest potential directions for future research.",,2023-04-04,,"['harel yadid', 'almog algranti', 'mark levin', 'ayal taitler']",https://arxiv.org/pdf/2304.03289.pdf
385,2304.03290,adaptive feature fusion: enhancing generalization in deep learning   models,cs.cv cs.ai,"in recent years, deep learning models have demonstrated remarkable success in various domains, such as computer vision, natural language processing, and speech recognition. however, the generalization capabilities of these models can be negatively impacted by the limitations of their feature fusion techniques. this paper introduces an innovative approach, adaptive feature fusion (aff), to enhance the generalization of deep learning models by dynamically adapting the fusion process of feature representations.   the proposed aff framework is designed to incorporate fusion layers into existing deep learning architectures, enabling seamless integration and improved performance. by leveraging a combination of data-driven and model-based fusion strategies, aff is able to adaptively fuse features based on the underlying data characteristics and model requirements. this paper presents a detailed description of the aff framework, including the design and implementation of fusion layers for various architectures.   extensive experiments are conducted on multiple benchmark datasets, with the results demonstrating the superiority of the aff approach in comparison to traditional feature fusion techniques. the analysis showcases the effectiveness of aff in enhancing generalization capabilities, leading to improved performance across different tasks and applications.   finally, the paper discusses various real-world use cases where aff can be employed, providing insights into its practical applicability. the conclusion highlights the potential for future research directions, including the exploration of advanced fusion strategies and the extension of aff to other machine learning paradigms.",,2023-04-04,,['neelesh mungoli'],https://arxiv.org/pdf/2304.03290.pdf
386,2304.03291,comparing nars and reinforcement learning: an analysis of ona and   $q$-learning algorithms,cs.lg cs.ai,"in recent years, reinforcement learning (rl) has emerged as a popular approach for solving sequence-based tasks in machine learning. however, finding suitable alternatives to rl remains an exciting and innovative research area. one such alternative that has garnered attention is the non-axiomatic reasoning system (nars), which is a general-purpose cognitive reasoning framework. in this paper, we delve into the potential of nars as a substitute for rl in solving sequence-based tasks. to investigate this, we conduct a comparative analysis of the performance of ona as an implementation of nars and $q$-learning in various environments that were created using the open ai gym. the environments have different difficulty levels, ranging from simple to complex. our results demonstrate that nars is a promising alternative to rl, with competitive performance in diverse environments, particularly in non-deterministic ones.",,2023-03-17,2023-04-10,"['ali beikmohammadi', 'sindri magn√∫sson']",https://arxiv.org/pdf/2304.03291.pdf
387,2304.03297,neural operator learning for ultrasound tomography inversion,eess.iv cs.cv cs.lg,"neural operator learning as a means of mapping between complex function spaces has garnered significant attention in the field of computational science and engineering (cs&e). in this paper, we apply neural operator learning to the time-of-flight ultrasound computed tomography (usct) problem. we learn the mapping between time-of-flight (tof) data and the heterogeneous sound speed field using a full-wave solver to generate the training data. this novel application of operator learning circumnavigates the need to solve the computationally intensive iterative inverse problem. the operator learns the non-linear mapping offline and predicts the heterogeneous sound field with a single forward pass through the model. this is the first time operator learning has been used for ultrasound tomography and is the first step in potential real-time predictions of soft tissue distribution for tumor identification in beast imaging.",,2023-04-06,,"['haocheng dai', 'michael penwarden', 'robert m. kirby', 'sarang joshi']",https://arxiv.org/pdf/2304.03297.pdf
388,2304.03307,vita-clip: video and text adaptive clip via multimodal prompting,cs.cv eess.iv,"adopting contrastive image-text pretrained models like clip towards video classification has gained attention due to its cost-effectiveness and competitive performance. however, recent works in this area face a trade-off. finetuning the pretrained model to achieve strong supervised performance results in low zero-shot generalization. similarly, freezing the backbone to retain zero-shot capability causes significant drop in supervised accuracy. because of this, recent works in literature typically train separate models for supervised and zero-shot action recognition. in this work, we propose a multimodal prompt learning scheme that works to balance the supervised and zero-shot performance under a single unified training. our prompting approach on the vision side caters for three aspects: 1) global video-level prompts to model the data distribution; 2) local frame-level prompts to provide per-frame discriminative conditioning; and 3) a summary prompt to extract a condensed video representation. additionally, we define a prompting scheme on the text side to augment the textual context. through this prompting scheme, we can achieve state-of-the-art zero-shot performance on kinetics-600, hmdb51 and ucf101 while remaining competitive in the supervised setting. by keeping the pretrained backbone frozen, we optimize a much lower number of parameters and retain the existing general representation which helps achieve the strong zero-shot performance. our codes/models are released at https://github.com/talalwasim/vita-clip.",,2023-04-06,,"['syed talal wasim', 'muzammal naseer', 'salman khan', 'fahad shahbaz khan', 'mubarak shah']",https://arxiv.org/pdf/2304.03307.pdf
389,2304.03323,dsvae: interpretable disentangled representation for synthetic speech   detection,cs.sd cs.cv cs.mm eess.as,"tools to generate high quality synthetic speech signal that is perceptually indistinguishable from speech recorded from human speakers are easily available. several approaches have been proposed for detecting synthetic speech. many of these approaches use deep learning methods as a black box without providing reasoning for the decisions they make. this limits the interpretability of these approaches. in this paper, we propose disentangled spectrogram variational auto encoder (dsvae) which is a two staged trained variational autoencoder that processes spectrograms of speech using disentangled representation learning to generate interpretable representations of a speech signal for detecting synthetic speech. dsvae also creates an activation map to highlight the spectrogram regions that discriminate synthetic and bona fide human speech signals. we evaluated the representations obtained from dsvae using the asvspoof2019 dataset. our experimental results show high accuracy (>98%) on detecting synthetic speech from 6 known and 10 out of 11 unknown speech synthesizers. we also visualize the representation obtained from dsvae for 17 different speech synthesizers and verify that they are indeed interpretable and discriminate bona fide and synthetic speech from each of the synthesizers.",,2023-04-06,,"['amit kumar singh yadav', 'kratika bhagtani', 'ziyue xiang', 'paolo bestagini', 'stefano tubaro', 'edward j. delp']",https://arxiv.org/pdf/2304.03323.pdf
390,2304.03326,finite time lyapunov exponent analysis of model predictive control and   reinforcement learning,math.oc cs.ro cs.sy eess.sy math.ds nlin.cd,"finite-time lyapunov exponents (ftles) provide a powerful approach to compute time-varying analogs of invariant manifolds in unsteady fluid flow fields. these manifolds are useful to visualize the transport mechanisms of passive tracers advecting with the flow. however, many vehicles and mobile sensors are not passive, but are instead actuated according to some intelligent trajectory planning or control law; for example, model predictive control and reinforcement learning are often used to design energy-efficient trajectories in a dynamically changing background flow. in this work, we investigate the use of ftle on such controlled agents to gain insight into optimal transport routes for navigation in known unsteady flows. we find that these controlled ftle (cftle) coherent structures separate the flow field into different regions with similar costs of transport to the goal location. these separatrices are functions of the planning algorithm's hyper-parameters, such as the optimization time horizon and the cost of actuation. computing the invariant sets and manifolds of active agent dynamics in dynamic flow fields is useful in the context of robust motion control, hyperparameter tuning, and determining safe and collision-free trajectories for autonomous systems. moreover, these cftle structures provide insight into effective deployment locations for mobile agents with actuation and energy constraints to traverse the ocean or atmosphere.",,2023-04-06,2023-04-09,"['kartik krishna', 'steven l. brunton', 'zhuoyuan song']",https://arxiv.org/pdf/2304.03326.pdf
391,2304.03337,on the learnability of multilabel ranking,cs.lg stat.ml,"multilabel ranking is a central task in machine learning with widespread applications to web search, news stories, recommender systems, etc. however, the most fundamental question of learnability in a multilabel ranking setting remains unanswered. in this paper, we characterize the learnability of multilabel ranking problems in both the batch and online settings for a large family of ranking losses. along the way, we also give the first equivalence class of ranking losses based on learnability.",,2023-04-06,,"['vinod raman', 'unique subedi', 'ambuj tewari']",https://arxiv.org/pdf/2304.03337.pdf
392,2304.03343,spintronic physical reservoir for autonomous prediction and long-term   household energy load forecasting,cs.lg,"in this study, we have shown autonomous long-term prediction with a spintronic physical reservoir. due to the short-term memory property of the magnetization dynamics, non-linearity arises in the reservoir states which could be used for long-term prediction tasks using simple linear regression for online training. during the prediction stage, the output is directly fed to the input of the reservoir for autonomous prediction. we employ our proposed reservoir for the modeling of the chaotic time series such as mackey-glass and dynamic time-series data, such as household building energy loads. since only the last layer of a rc needs to be trained with linear regression, it is well suited for learning in real time on edge devices. here we show that a skyrmion based magnetic tunnel junction can potentially be used as a prototypical rc but any nanomagnetic magnetic tunnel junction with nonlinear magnetization behavior can implement such a rc. by comparing our spintronic physical rc approach with state-of-the-art energy load forecasting algorithms, such as lstms and rnns, we conclude that the proposed framework presents good performance in achieving high predictions accuracy, while also requiring low memory and energy both of which are at a premium in hardware resource and power constrained edge applications. further, the proposed approach is shown to require very small training datasets and at the same time being at least 16x energy efficient compared to the state-of-the-art sequence to sequence lstm for accurate household load predictions.",,2023-04-06,,"['walid al misba', 'harindra s. mavikumbure', 'md mahadi rajib', 'daniel l. marino', 'victor cobilean', 'milos manic', 'jayasimha atulasimha']",https://arxiv.org/pdf/2304.03343.pdf
393,2304.03359,approximate wireless communication for federated learning,cs.dc cs.sy eess.sy,"this paper presents an approximate wireless communication scheme for federated learning (fl) model aggregation in the uplink transmission. we consider a realistic channel that reveals bit errors during fl model exchange in wireless networks. our study demonstrates that random bit errors during model transmission can significantly affect fl performance. to overcome this challenge, we propose an approximate communication scheme based on the mathematical and statistical proof that machine learning (ml) model gradients are bounded under certain constraints. this bound enables us to introduce a novel encoding scheme for float-to-binary representation of gradient values and their qam constellation mapping. besides, since fl gradients are error-resilient, the proposed scheme simply delivers gradients with errors when the channel quality is satisfactory, eliminating extensive error-correcting codes and/or retransmission. the direct benefits include less overhead and lower latency. the proposed scheme is well-suited for resource-constrained devices in wireless networks. through simulations, we show that the proposed scheme is effective in reducing the impact of bit errors on fl performance and saves at least half the time than transmission with error correction and retransmission to achieve the same learning performance. in addition, we investigated the effectiveness of bit protection mechanisms in high-order modulation when gray coding is employed and found that this approach considerably enhances learning performance.",,2023-04-06,,"['xiang ma', 'haijian sun', 'rose qingyang hu', 'yi qian']",https://arxiv.org/pdf/2304.03359.pdf
394,2304.03361,nmr shift prediction from small data quantities,physics.chem-ph cs.lg,"prediction of chemical shift in nmr using machine learning methods is typically done with the maximum amount of data available to achieve the best results. in some cases, such large amounts of data are not available, e.g. for heteronuclei. we demonstrate a novel machine learning model which is able to achieve good results with comparatively low amounts of data. we show this by predicting 19f and 13c nmr chemical shifts of small molecules in specific solvents.",,2023-04-06,,"['herman rull', 'markus fischer', 'stefan kuhn']",https://arxiv.org/pdf/2304.03361.pdf
395,2304.03365,robust decision-focused learning for reward transfer,cs.lg cs.ai,"decision-focused (df) model-based reinforcement learning has recently been introduced as a powerful algorithm which can focus on learning the mdp dynamics which are most relevant for obtaining high rewards. while this approach increases the performance of agents by focusing the learning towards optimizing for the reward directly, it does so by learning less accurate dynamics (from a mle standpoint), and may thus be brittle to changes in the reward function. in this work, we develop the robust decision-focused (rdf) algorithm which leverages the non-identifiability of df solutions to learn models which maximize expected returns while simultaneously learning models which are robust to changes in the reward function. we demonstrate on a variety of toy example and healthcare simulators that rdf significantly increases the robustness of df to changes in the reward function, without decreasing the overall return the agent obtains.",,2023-04-06,,"['abhishek sharma', 'sonali parbhoo', 'omer gottesman', 'finale doshi-velez']",https://arxiv.org/pdf/2304.03365.pdf
396,2304.03370,reliable learning for test-time attacks and distribution shift,cs.lg cs.cr,"machine learning algorithms are often used in environments which are not captured accurately even by the most carefully obtained training data, either due to the possibility of `adversarial' test-time attacks, or on account of `natural' distribution shift. for test-time attacks, we introduce and analyze a novel robust reliability guarantee, which requires a learner to output predictions along with a reliability radius $\eta$, with the meaning that its prediction is guaranteed to be correct as long as the adversary has not perturbed the test point farther than a distance $\eta$. we provide learners that are optimal in the sense that they always output the best possible reliability radius on any test point, and we characterize the reliable region, i.e. the set of points where a given reliability radius is attainable. we additionally analyze reliable learners under distribution shift, where the test points may come from an arbitrary distribution q different from the training distribution p. for both cases, we bound the probability mass of the reliable region for several interesting examples, for linear separators under nearly log-concave and s-concave distributions, as well as for smooth boundary classifiers under smooth probability distributions.",,2023-04-06,,"['maria-florina balcan', 'steve hanneke', 'rattana pukdee', 'dravyansh sharma']",https://arxiv.org/pdf/2304.03370.pdf
397,2304.03374,optimizing neural networks through activation function discovery and   automatic weight initialization,cs.lg,"automated machine learning (automl) methods improve upon existing models by optimizing various aspects of their design. while present methods focus on hyperparameters and neural network topologies, other aspects of neural network design can be optimized as well. to further the state of the art in automl, this dissertation introduces techniques for discovering more powerful activation functions and establishing more robust weight initialization for neural networks. these contributions improve performance, but also provide new perspectives on neural network optimization. first, the dissertation demonstrates that discovering solutions specialized to specific architectures and tasks gives better performance than reusing general approaches. second, it shows that jointly optimizing different components of neural networks is synergistic, and results in better performance than optimizing individual components alone. third, it demonstrates that learned representations are easier to optimize than hard-coded ones, creating further opportunities for automl. the dissertation thus makes concrete progress towards fully automatic machine learning in the future.",,2023-04-06,,['garrett bingham'],https://arxiv.org/pdf/2304.03374.pdf
398,2304.03376,interpretable statistical representations of neural population dynamics   and geometry,cs.lg math.ds q-bio.nc q-bio.qm,"the dynamics of neuron populations during diverse tasks often evolve on low-dimensional manifolds. however, it remains challenging to discern the contributions of geometry and dynamics for encoding relevant behavioural variables. here, we introduce an unsupervised geometric deep learning framework for representing non-linear dynamical systems based on statistical distributions of local phase portrait features. our method provides robust geometry-aware or geometry-agnostic representations for the unbiased comparison of dynamics based on measured trajectories. we demonstrate that our statistical representation can generalise across neural network instances to discriminate computational mechanisms, obtain interpretable embeddings of neural dynamics in a primate reaching task with geometric correspondence to hand kinematics, and develop a decoding algorithm with state-of-the-art accuracy. our results highlight the importance of using the intrinsic manifold structure over temporal information to develop better decoding algorithms and assimilate data across experiments.",,2023-04-06,,"['adam gosztolai', 'robert l. peach', 'alexis arnaudon', 'mauricio barahona', 'pierre vandergheynst']",https://arxiv.org/pdf/2304.03376.pdf
399,2304.03378,self-supervised video similarity learning,cs.cv cs.lg,"we introduce s$^2$vs, a video similarity learning approach with self-supervision. self-supervised learning (ssl) is typically used to train deep models on a proxy task so as to have strong transferability on target tasks after fine-tuning. here, in contrast to prior work, ssl is used to perform video similarity learning and address multiple retrieval and detection tasks at once with no use of labeled data. this is achieved by learning via instance-discrimination with task-tailored augmentations and the widely used infonce loss together with an additional loss operating jointly on self-similarity and hard-negative similarity. we benchmark our method on tasks where video relevance is defined with varying granularity, ranging from video copies to videos depicting the same incident or event. we learn a single universal model that achieves state-of-the-art performance on all tasks, surpassing previously proposed methods that use labeled data. the code and pretrained models are publicly available at: \url{https://github.com/gkordo/s2vs}",,2023-04-06,,"['giorgos kordopatis-zilos', 'giorgos tolias', 'christos tzelepis', 'ioannis kompatsiaris', 'ioannis patras', 'symeon papadopoulos']",https://arxiv.org/pdf/2304.03378.pdf
400,2304.03382,scalable causal discovery with score matching,cs.lg stat.ml,"this paper demonstrates how to discover the whole causal graph from the second derivative of the log-likelihood in observational non-linear additive gaussian noise models. leveraging scalable machine learning approaches to approximate the score function $\nabla \log p(\mathbf{x})$, we extend the work of rolland et al. (2022) that only recovers the topological order from the score and requires an expensive pruning step removing spurious edges among those admitted by the ordering. our analysis leads to das (acronym for discovery at scale), a practical algorithm that reduces the complexity of the pruning by a factor proportional to the graph size. in practice, das achieves competitive accuracy with current state-of-the-art while being over an order of magnitude faster. overall, our approach enables principled and scalable causal discovery, significantly lowering the compute bar.",,2023-04-06,,"['francesco montagna', 'nicoletta noceti', 'lorenzo rosasco', 'kun zhang', 'francesco locatello']",https://arxiv.org/pdf/2304.03382.pdf
401,2304.03384,beyond nerf underwater: learning neural reflectance fields for true   color correction of marine imagery,cs.cv cs.ro,"underwater imagery often exhibits distorted coloration as a result of light-water interactions, which complicates the study of benthic environments in marine biology and geography. in this research, we propose an algorithm to restore the true color (albedo) in underwater imagery by jointly learning the effects of the medium and neural scene representations. our approach models water effects as a combination of light attenuation with distance and backscattered light. the proposed neural scene representation is based on a neural reflectance field model, which learns albedos, normals, and volume densities of the underwater environment. we introduce a logistic regression model to separate water from the scene and apply distinct light physics during training. our method avoids the need to estimate complex backscatter effects in water by employing several approximations, enhancing sampling efficiency and numerical stability during training. the proposed technique integrates underwater light effects into a volume rendering framework with end-to-end differentiability. experimental results on both synthetic and real-world data demonstrate that our method effectively restores true color from underwater imagery, outperforming existing approaches in terms of color consistency.",,2023-04-06,,"['tianyi zhang', 'matthew johnson-roberson']",https://arxiv.org/pdf/2304.03384.pdf
402,2304.03394,deep learning for opinion mining and topic classification of course   reviews,cs.cl cs.lg,"student opinions for a course are important to educators and administrators, regardless of the type of the course or the institution. reading and manually analyzing open-ended feedback becomes infeasible for massive volumes of comments at institution level or online forums. in this paper, we collected and pre-processed a large number of course reviews publicly available online. we applied machine learning techniques with the goal to gain insight into student sentiments and topics. specifically, we utilized current natural language processing (nlp) techniques, such as word embeddings and deep neural networks, and state-of-the-art bert (bidirectional encoder representations from transformers), roberta (robustly optimized bert approach) and xlnet (generalized auto-regression pre-training). we performed extensive experimentation to compare these techniques versus traditional approaches. this comparative study demonstrates how to apply modern machine learning approaches for sentiment polarity extraction and topic-based classification utilizing course feedback. for sentiment polarity, the top model was roberta with 95.5\% accuracy and 84.7\% f1-macro, while for topic classification, an svm (support vector machine) was the top classifier with 79.8\% accuracy and 80.6\% f1-macro. we also provided an in-depth exploration of the effect of certain hyperparameters on the model performance and discussed our observations. these findings can be used by institutions and course providers as a guide for analyzing their own course feedback using nlp models towards self-evaluation and improvement.",,2023-04-06,,['anna koufakou'],https://arxiv.org/pdf/2304.03394.pdf
403,2304.03398,quantum conformal prediction for reliable uncertainty quantification in   quantum machine learning,quant-ph cs.it cs.lg math.it,"quantum machine learning is a promising programming paradigm for the optimization of quantum algorithms in the current era of noisy intermediate scale quantum (nisq) computers. a fundamental challenge in quantum machine learning is generalization, as the designer targets performance under testing conditions, while having access only to limited training data. existing generalization analyses, while identifying important general trends and scaling laws, cannot be used to assign reliable and informative ""error bars"" to the decisions made by quantum models. in this article, we propose a general methodology that can reliably quantify the uncertainty of quantum models, irrespective of the amount of training data, of the number of shots, of the ansatz, of the training algorithm, and of the presence of quantum hardware noise. the approach, which builds on probabilistic conformal prediction, turns an arbitrary, possibly small, number of shots from a pre-trained quantum model into a set prediction, e.g., an interval, that provably contains the true target with any desired coverage level. experimental results confirm the theoretical calibration guarantees of the proposed framework, referred to as quantum conformal prediction.",,2023-04-06,,"['sangwoo park', 'osvaldo simeone']",https://arxiv.org/pdf/2304.03398.pdf
404,2304.03400,rosteals: robust steganography using autoencoder latent space,cs.cv,"data hiding such as steganography and invisible watermarking has important applications in copyright protection, privacy-preserved communication and content provenance. existing works often fall short in either preserving image quality, or robustness against perturbations or are too complex to train. we propose rosteals, a practical steganography technique leveraging frozen pretrained autoencoders to free the payload embedding from learning the distribution of cover images. rosteals has a light-weight secret encoder of just 300k parameters, is easy to train, has perfect secret recovery performance and comparable image quality on three benchmarks. additionally, rosteals can be adapted for novel cover-less steganography applications in which the cover image can be sampled from noise or conditioned on text prompts via a denoising diffusion process. our model and code are available at \url{https://github.com/tubui/rosteals}.",,2023-04-06,,"['tu bui', 'shruti agarwal', 'ning yu', 'john collomosse']",https://arxiv.org/pdf/2304.03400.pdf
405,2304.03406,localized region contrast for enhancing self-supervised learning in   medical image segmentation,cs.cv cs.ai cs.lg,"recent advancements in self-supervised learning have demonstrated that effective visual representations can be learned from unlabeled images. this has led to increased interest in applying self-supervised learning to the medical domain, where unlabeled images are abundant and labeled images are difficult to obtain. however, most self-supervised learning approaches are modeled as image level discriminative or generative proxy tasks, which may not capture the finer level representations necessary for dense prediction tasks like multi-organ segmentation. in this paper, we propose a novel contrastive learning framework that integrates localized region contrast (lrc) to enhance existing self-supervised pre-training methods for medical image segmentation. our approach involves identifying super-pixels by felzenszwalb's algorithm and performing local contrastive learning using a novel contrastive sampling loss. through extensive experiments on three multi-organ segmentation datasets, we demonstrate that integrating lrc to an existing self-supervised method in a limited annotation setting significantly improves segmentation performance. moreover, we show that lrc can also be applied to fully-supervised pre-training methods to further boost performance.",,2023-04-06,,"['xiangyi yan', 'junayed naushad', 'chenyu you', 'hao tang', 'shanlin sun', 'kun han', 'haoyu ma', 'james duncan', 'xiaohui xie']",https://arxiv.org/pdf/2304.03406.pdf
406,2304.03408,dynamics of finite width kernel and prediction fluctuations in mean   field neural networks,stat.ml cond-mat.dis-nn cs.lg,"we analyze the dynamics of finite width effects in wide but finite feature learning neural networks. unlike many prior analyses, our results, while perturbative in width, are non-perturbative in the strength of feature learning. starting from a dynamical mean field theory (dmft) description of infinite width deep neural network kernel and prediction dynamics, we provide a characterization of the $\mathcal{o}(1/\sqrt{\text{width}})$ fluctuations of the dmft order parameters over random initialization of the network weights. in the lazy limit of network training, all kernels are random but static in time and the prediction variance has a universal form. however, in the rich, feature learning regime, the fluctuations of the kernels and predictions are dynamically coupled with variance that can be computed self-consistently. in two layer networks, we show how feature learning can dynamically reduce the variance of the final ntk and final network predictions. we also show how initialization variance can slow down online learning in wide but finite networks. in deeper networks, kernel variance can dramatically accumulate through subsequent layers at large feature learning strengths, but feature learning continues to improve the snr of the feature kernels. in discrete time, we demonstrate that large learning rate phenomena such as edge of stability effects can be well captured by infinite width dynamics and that initialization variance can decrease dynamically. for cnns trained on cifar-10, we empirically find significant corrections to both the bias and variance of network dynamics due to finite width.",,2023-04-06,,"['blake bordelon', 'cengiz pehlevan']",https://arxiv.org/pdf/2304.03408.pdf
407,2304.03414,towards corpus-scale discovery of selection biases in news coverage:   comparing what sources say about entities as a start,cs.cl,"news sources undergo the process of selecting newsworthy information when covering a certain topic. the process inevitably exhibits selection biases, i.e. news sources' typical patterns of choosing what information to include in news coverage, due to their agenda differences. to understand the magnitude and implications of selection biases, one must first discover (1) on what topics do sources typically have diverging definitions of ""newsworthy"" information, and (2) do the content selection patterns correlate with certain attributes of the news sources, e.g. ideological leaning, etc.   the goal of the paper is to investigate and discuss the challenges of building scalable nlp systems for discovering patterns of media selection biases directly from news content in massive-scale news corpora, without relying on labeled data. to facilitate research in this domain, we propose and study a conceptual framework, where we compare how sources typically mention certain controversial entities, and use such as indicators for the sources' content selection preferences. we empirically show the capabilities of the framework through a case study on nela-2020, a corpus of 1.8m news articles in english from 519 news sources worldwide. we demonstrate an unsupervised representation learning method to capture the selection preferences for how sources typically mention controversial entities. our experiments show that that distributional divergence of such representations, when studied collectively across entities and news sources, serve as good indicators for an individual source's ideological leaning. we hope our findings will provide insights for future research on media selection biases.",,2023-04-06,,"['sihao chen', 'william bruno', 'dan roth']",https://arxiv.org/pdf/2304.03414.pdf
408,2304.03422,a modular framework for stabilizing deep reinforcement learning control,eess.sy cs.lg cs.sy,we propose a framework for the design of feedback controllers that combines the optimization-driven and model-free advantages of deep reinforcement learning with the stability guarantees provided by using the youla-kucera parameterization to define the search domain. recent advances in behavioral systems allow us to construct a data-driven internal model; this enables an alternative realization of the youla-kucera parameterization based entirely on input-output exploration data. using a neural network to express a parameterized set of nonlinear stable operators enables seamless integration with standard deep learning libraries. we demonstrate the approach on a realistic simulation of a two-tank system.,,2023-04-06,,"['nathan p. lawrence', 'philip d. loewen', 'shuyuan wang', 'michael g. forbes', 'r. bhushan gopaluni']",https://arxiv.org/pdf/2304.03422.pdf
409,2304.03431,domain generalization in robust invariant representation,cs.lg cs.ai,"unsupervised approaches for learning representations invariant to common transformations are used quite often for object recognition. learning invariances makes models more robust and practical to use in real-world scenarios. since data transformations that do not change the intrinsic properties of the object cause the majority of the complexity in recognition tasks, models that are invariant to these transformations help reduce the amount of training data required. this further increases the model's efficiency and simplifies training. in this paper, we investigate the generalization of invariant representations on out-of-distribution data and try to answer the question: do model representations invariant to some transformations in a particular seen domain also remain invariant in previously unseen domains? through extensive experiments, we demonstrate that the invariant model learns unstructured latent representations that are robust to distribution shifts, thus making invariance a desirable property for training in resource-constrained settings.",,2023-04-06,,"['gauri gupta', 'ritvik kapila', 'keshav gupta', 'ramesh raskar']",https://arxiv.org/pdf/2304.03431.pdf
410,2304.03440,supervised contrastive learning with heterogeneous similarity for   distribution shifts,cs.lg stat.ml,"distribution shifts are problems where the distribution of data changes between training and testing, which can significantly degrade the performance of a model deployed in the real world. recent studies suggest that one reason for the degradation is a type of overfitting, and that proper regularization can mitigate the degradation, especially when using highly representative models such as neural networks. in this paper, we propose a new regularization using the supervised contrastive learning to prevent such overfitting and to train models that do not degrade their performance under the distribution shifts. we extend the cosine similarity in contrastive loss to a more general similarity measure and propose to use different parameters in the measure when comparing a sample to a positive or negative example, which is analytically shown to act as a kind of margin in contrastive loss. experiments on benchmark datasets that emulate distribution shifts, including subpopulation shift and domain generalization, demonstrate the advantage of the proposed method over existing regularization methods.",,2023-04-06,,['takuro kutsuna'],https://arxiv.org/pdf/2304.03440.pdf
411,2304.03443,ams-drl: learning multi-pursuit evasion for safe targeted navigation of   drones,cs.ro cs.ai,"safe navigation of drones in the presence of adversarial physical attacks from multiple pursuers is a challenging task. this paper proposes a novel approach, asynchronous multi-stage deep reinforcement learning (ams-drl), to train an adversarial neural network that can learn from the actions of multiple pursuers and adapt quickly to their behavior, enabling the drone to avoid attacks and reach its target. our approach guarantees convergence by ensuring nash equilibrium among agents from the game-theory analysis. we evaluate our method in extensive simulations and show that it outperforms baselines with higher navigation success rates. we also analyze how parameters such as the relative maximum speed affect navigation performance. furthermore, we have conducted physical experiments and validated the effectiveness of the trained policies in real-time flights. a success rate heatmap is introduced to elucidate how spatial geometry influences navigation outcomes. project website: https://github.com/ntu-uavg/ams-drl-for-pursuit-evasion.",,2023-04-06,,"['jiaping xiao', 'mir feroskhan']",https://arxiv.org/pdf/2304.03443.pdf
412,2304.03450,striving for authentic and sustained technology use in the classroom:   lessons learned from a longitudinal evaluation of a sensor-based science   education platform,cs.hc,"technology integration in educational settings has led to the development of novel sensor-based tools that enable students to measure and interact with their environment. although reports from using such tools can be positive, evaluations are often conducted under controlled conditions and short timeframes. there is a need for longitudinal data collected in realistic classroom settings. however, sustained and authentic classroom use requires technology platforms to be seen by teachers as both easy to use and of value. we describe our development of a sensor-based platform to support science teaching that followed a 14-month user-centered design process. we share insights from this design and development approach, and report findings from a 6-month large-scale evaluation involving 35 schools and 1245 students. we share lessons learnt, including that technology integration is not an educational goal per se and that technology should be a transparent tool to enable students to achieve their learning goals.",,2023-04-06,,"['yvonne chua', 'sankha cooray', 'juan pablo forero cortes', 'paul denny', 'sonia dupuch', 'dawn l garbett', 'alaeddin nassani', 'jiashuo cao', 'hannah qiao', 'andrew reis', 'deviana reis', 'philipp m. scholl', 'priyashri kamlesh sridhar', 'hussel suriyaarachchi', 'fiona taimana', 'vanessa tanga', 'chamod weerasinghe', 'elliott wen', 'michelle wu', 'qin wu', 'haimo zhang', 'suranga nanayakkara']",https://arxiv.org/pdf/2304.03450.pdf
413,2304.03452,graph enabled cross-domain knowledge transfer,cs.lg,"to leverage machine learning in any decision-making process, one must convert the given knowledge (for example, natural language, unstructured text) into representation vectors that can be understood and processed by machine learning model in their compatible language and data format. the frequently encountered difficulty is, however, the given knowledge is not rich or reliable enough in the first place. in such cases, one seeks to fuse side information from a separate domain to mitigate the gap between good representation learning and the scarce knowledge in the domain of interest. this approach is named cross-domain knowledge transfer. it is crucial to study the problem because of the commonality of scarce knowledge in many scenarios, from online healthcare platform analyses to financial market risk quantification, leaving an obstacle in front of us benefiting from automated decision making. from the machine learning perspective, the paradigm of semi-supervised learning takes advantage of large amount of data without ground truth and achieves impressive learning performance improvement. it is adopted in this dissertation for cross-domain knowledge transfer. (to be continued)",,2023-04-06,,['shibo yao'],https://arxiv.org/pdf/2304.03452.pdf
414,2304.03456,rethinking evaluation protocols of visual representations learned via   self-supervised learning,cs.cv cs.lg,"linear probing (lp) (and $k$-nn) on the upstream dataset with labels (e.g., imagenet) and transfer learning (tl) to various downstream datasets are commonly employed to evaluate the quality of visual representations learned via self-supervised learning (ssl). although existing ssl methods have shown good performances under those evaluation protocols, we observe that the performances are very sensitive to the hyperparameters involved in lp and tl. we argue that this is an undesirable behavior since truly generic representations should be easily adapted to any other visual recognition task, i.e., the learned representations should be robust to the settings of lp and tl hyperparameters. in this work, we try to figure out the cause of performance sensitivity by conducting extensive experiments with state-of-the-art ssl methods. first, we find that input normalization for lp is crucial to eliminate performance variations according to the hyperparameters. specifically, batch normalization before feeding inputs to a linear classifier considerably improves the stability of evaluation, and also resolves inconsistency of $k$-nn and lp metrics. second, for tl, we demonstrate that a weight decay parameter in ssl significantly affects the transferability of learned representations, which cannot be identified by lp or $k$-nn evaluations on the upstream dataset. we believe that the findings of this study will be beneficial for the community by drawing attention to the shortcomings in the current ssl evaluation schemes and underscoring the need to reconsider them.",,2023-04-06,,"['jae-hun lee', 'doyoung yoon', 'byeongmoon ji', 'kyungyul kim', 'sangheum hwang']",https://arxiv.org/pdf/2304.03456.pdf
415,2304.03464,linking representations with multimodal contrastive learning,cs.cv cs.cl econ.gn q-fin.ec,"many applications require grouping instances contained in diverse document datasets into classes. most widely used methods do not employ deep learning and do not exploit the inherently multimodal nature of documents. notably, record linkage is typically conceptualized as a string-matching problem. this study develops clippings, (contrastively linking pooled pre-trained embeddings), a multimodal framework for record linkage. clippings employs end-to-end training of symmetric vision and language bi-encoders, aligned through contrastive language-image pre-training, to learn a metric space where the pooled image-text representation for a given instance is close to representations in the same class and distant from representations in different classes. at inference time, instances can be linked by retrieving their nearest neighbor from an offline exemplar embedding index or by clustering their representations. the study examines two challenging applications: constructing comprehensive supply chains for mid-20th century japan through linking firm level financial records - with each firm name represented by its crop in the document image and the corresponding ocr - and detecting which image-caption pairs in a massive corpus of historical u.s. newspapers came from the same underlying photo wire source. clippings outperforms widely used string matching methods by a wide margin and also outperforms unimodal methods. moreover, a purely self-supervised model trained on only image-ocr pairs also outperforms popular string-matching methods without requiring any labels.",,2023-04-06,2023-04-10,"['abhishek arora', 'xinmei yang', 'shao-yu jheng', 'melissa dell']",https://arxiv.org/pdf/2304.03464.pdf
416,2304.03473,cma-es with learning rate adaptation: can cma-es with default population   size solve multimodal and noisy problems?,cs.ne math.oc,"the covariance matrix adaptation evolution strategy (cma-es) is one of the most successful methods for solving black-box continuous optimization problems. one practically useful aspect of the cma-es is that it can be used without hyperparameter tuning. however, the hyperparameter settings still have a considerable impact, especially for difficult tasks such as solving multimodal or noisy problems. in this study, we investigate whether the cma-es with default population size can solve multimodal and noisy problems. to perform this investigation, we develop a novel learning rate adaptation mechanism for the cma-es, such that the learning rate is adapted so as to maintain a constant signal-to-noise ratio. we investigate the behavior of the cma-es with the proposed learning rate adaptation mechanism through numerical experiments, and compare the results with those obtained for the cma-es with a fixed learning rate. the results demonstrate that, when the proposed learning rate adaptation is used, the cma-es with default population size works well on multimodal and/or noisy problems, without the need for extremely expensive learning rate tuning.",10.1145/3583131.3590358,2023-04-07,,"['masahiro nomura', 'youhei akimoto', 'isao ono']",https://arxiv.org/pdf/2304.03473.pdf
417,2304.03486,can we learn better with hard samples?,cs.cv cs.ai,"in deep learning, mini-batch training is commonly used to optimize network parameters. however, the traditional mini-batch method may not learn the under-represented samples and complex patterns in the data, leading to a longer time for generalization. to address this problem, a variant of the traditional algorithm has been proposed, which trains the network focusing on mini-batches with high loss. the study evaluates the effectiveness of the proposed training using various deep neural networks trained on three benchmark datasets (cifar-10, cifar-100, and stl-10). the deep neural networks used in the study are resnet-18, resnet-50, efficient net b4, efficientnetv2-s, and mobilenetv3-s. the experimental results showed that the proposed method can significantly improve the test accuracy and speed up the convergence compared to the traditional mini-batch training method. furthermore, we introduce a hyper-parameter delta ({\delta}) that decides how many mini-batches are considered for training. experiments on various values of {\delta} found that the performance of the proposed method for smaller {\delta} values generally results in similar test accuracy and faster generalization. we show that the proposed method generalizes in 26.47% less number of epochs than the traditional mini-batch method in efficientnet-b4 on stl-10. the proposed method also improves the test top-1 accuracy by 7.26% in resnet-18 on cifar-100.",,2023-04-07,,"['subin sahayam', 'john zakkam', 'umarani jayaraman']",https://arxiv.org/pdf/2304.03486.pdf
418,2304.03487,paragraph: weighted graph representation for performance optimization of   hpc kernels,cs.dc cs.lg cs.pf,"gpu-based hpc clusters are attracting more scientific application developers due to their extensive parallelism and energy efficiency. in order to achieve portability among a variety of multi/many core architectures, a popular choice for an application developer is to utilize directive-based parallel programming models, such as openmp. however, even with openmp, the developer must choose from among many strategies for exploiting a gpu or a cpu. recently, machine learning (ml) approaches have brought significant advances in the optimizations of hpc applications. to this end, several ways have been proposed to represent application characteristics for ml models. however, the available techniques fail to capture features that are crucial for exposing parallelism. in this paper, we introduce a new graph-based program representation for parallel applications that extends the abstract syntax tree to represent control and data flow information. the originality of this work lies in the addition of new edges exploiting the implicit ordering and parent-child relationships in asts, as well as the introduction of edge weights to account for loop and condition information. we evaluate our proposed representation by training a graph neural network (gnn) to predict the runtime of an openmp code region across cpus and gpus. various transformations utilizing collapse and data transfer between the cpu and gpu are used to construct the dataset. the predicted runtime of the model is used to determine which transformation provides the best performance. results show that our approach is indeed effective and has normalized rmse as low as 0.004 to at most 0.01 in its runtime predictions.",,2023-04-07,,"['ali tehranijamsaz', 'alok mishra', 'akash dutta', 'abid m. malik', 'barbara chapman', 'ali jannesari']",https://arxiv.org/pdf/2304.03487.pdf
419,2304.03489,deep reinforcement learning based optimal infinite-horizon control of   probabilistic boolean control networks,eess.sy cs.sy,"in this paper, a deep reinforcement learning based method is proposed to obtain optimal policies for optimal infinite-horizon control of probabilistic boolean control networks (pbcns). compared with the existing literatures, the proposed method is model-free, namely, the system model and the initial states needn't to be known. meanwhile, it is suitable for large-scale pbcns. first, we establish the connection between deep reinforcement learning and optimal infinite-horizon control, and structure the problem into the framework of the markov decision process. then, pbcns are defined as large-scale or small-scale, depending on whether the memory of the action-values exceeds the ram of the computer. based on the newly introduced definition, q-learning (ql) and double deep q-network (ddqn) are applied to the optimal infinite-horizon control of small-scale and large-scale pbcns, respectively. meanwhile, the optimal state feedback controllers are designed. finally, two examples are presented, which are a small-scale pbcn with 3 nodes, and a large-scale one with 28 nodes. to verify the convergence of ql and ddqn, the optimal control policy and the optimal action-values, which are obtained from both the algorithms, are compared with the ones based on a model-based method named policy iteration. meanwhile, the performance of ql is compared with ddqn in the small-scale pbcn.",,2023-04-07,,"['jingjie ni', 'fangfei li', 'zheng-guang wu']",https://arxiv.org/pdf/2304.03489.pdf
420,2304.03501,continuous input embedding size search for recommender systems,cs.ir,"latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). with the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. to facilitate lightweight recommendation, reinforcement learning (rl) has recently opened up opportunities for identifying varying embedding sizes for different users/items. however, challenged by search efficiency and learning an optimal rl policy, existing rl-based methods are restricted to highly discrete, predefined embedding size choices. this leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a given memory budget. in this paper, we propose continuous input embedding size search (ciess), a novel rl-based method that operates on a continuous search space with arbitrary embedding sizes to choose from. in ciess, we further present an innovative random walk-based exploration strategy to allow the rl policy to efficiently explore more candidate embedding sizes and converge to a better decision. ciess is also model-agnostic and hence generalizable to a variety of latent factor rss, whilst experiments on two real-world datasets have shown state-of-the-art performance of ciess under different memory budgets when paired with three popular recommendation models.",,2023-04-07,,"['yunke qu', 'tong chen', 'xiangyu zhao', 'lizhen cui', 'kai zheng', 'hongzhi yin']",https://arxiv.org/pdf/2304.03501.pdf
421,2304.03505,improving adaptive real-time video communication via cross-layer   optimization,cs.mm cs.ni,"effective adaptive bitrate (abr) algorithm or policy is of paramount importance for real-time video communication (rtvc) amid this pandemic to pursue uncompromised quality of experience (qoe). existing abr methods mainly separate the network bandwidth estimation and video encoder control, and fine-tune video bitrate towards estimated bandwidth, assuming the maximization of bandwidth utilization yields the optimal qoe. however, the qoe of a rtvc system is jointly determined by the quality of compressed video, fluency of video playback, and interaction delay. solely maximizing the bandwidth utilization without comprehensively considering compound impacts incurred by both network and video application layers, does not assure the satisfactory qoe. and the decoupling of network and video layer further exacerbates the user experience due to network-codec incoordination. this work therefore proposes the palette, a reinforcement learning based abr scheme that unifies the processing of network and video application layers to directly maximize the qoe formulated as the weighted function of video quality, stalling rate and delay. to this aim, a cross-layer optimization is proposed to derive fine-grained compression factor of upcoming frame(s) using cross-layer observations like network conditions, video encoding parameters, and video content complexity. as a result, palette manages to resolve the network-codec incoordination and to best catch up with the network fluctuation. compared with state-of-the-art schemes in real-world tests, palette not only reduces 3.1\%-46.3\% of the stalling rate, 20.2\%-50.8\% of the delay, but also improves 0.2\%-7.2\% of the video quality with comparable bandwidth consumption, under a variety of application scenarios.",,2023-04-07,,"['yueheng li', 'hao chen', 'bowei xu', 'zicheng zhang', 'zhan ma']",https://arxiv.org/pdf/2304.03505.pdf
422,2304.03507,distributional signals for node classification in graph neural networks,eess.sp cs.lg,"in graph neural networks (gnns), both node features and labels are examples of graph signals, a key notion in graph signal processing (gsp). while it is common in gsp to impose signal smoothness constraints in learning and estimation tasks, it is unclear how this can be done for discrete node labels. we bridge this gap by introducing the concept of distributional graph signals. in our framework, we work with the distributions of node labels instead of their values and propose notions of smoothness and non-uniformity of such distributional graph signals. we then propose a general regularization method for gnns that allows us to encode distributional smoothness and non-uniformity of the model output in semi-supervised node classification tasks. numerical experiments demonstrate that our method can significantly improve the performance of most base gnn models in different problem settings.",,2023-04-07,,"['feng ji', 'see hian lee', 'kai zhao', 'wee peng tay', 'jielong yang']",https://arxiv.org/pdf/2304.03507.pdf
423,2304.03509,local rose breeds detection system using transfer learning techniques,cs.cv cs.ai,"flower breed detection and giving details of that breed with the suggestion of cultivation processes and the way of taking care is important for flower cultivation, breed invention, and the flower business. among all the local flowers in bangladesh, the rose is one of the most popular and demanded flowers. roses are the most desirable flower not only in bangladesh but also throughout the world. roses can be used for many other purposes apart from decoration. as roses have a great demand in the flower business so rose breed detection will be very essential. however, there is no remarkable work for breed detection of a particular flower unlike the classification of different flowers. in this research, we have proposed a model to detect rose breeds from images using transfer learning techniques. for such work in flowers, resources are not enough in image processing and classification, so we needed a large dataset of the massive number of images to train our model. we have used 1939 raw images of five different breeds and we have generated 9306 images for the training dataset and 388 images for the testing dataset to validate the model using augmentation. we have applied four transfer learning models in this research, which are inception v3, resnet50, xception, and vgg16. among these four models, vgg16 achieved the highest accuracy of 99%, which is an excellent outcome. breed detection of a rose by using transfer learning methods is the first work on breed detection of a particular flower that is publicly available according to the study.",10.1109/icccnt54827.2022.9984329,2023-04-07,,"['amena begum farha', 'md. azizul hakim', 'mst. eshita khatun']",https://arxiv.org/pdf/2304.03509.pdf
424,2304.03535,crisp: curriculum inducing primitive informed subgoal prediction for   hierarchical reinforcement learning,cs.lg,"hierarchical reinforcement learning is a promising approach that uses temporal abstraction to solve complex long horizon problems. however, simultaneously learning a hierarchy of policies is unstable as it is challenging to train higher-level policy when the lower-level primitive is non-stationary. in this paper, we propose a novel hierarchical algorithm by generating a curriculum of achievable subgoals for evolving lower-level primitives using reinforcement learning and imitation learning. the lower level primitive periodically performs data relabeling on a handful of expert demonstrations using our primitive informed parsing approach. we provide expressions to bound the sub-optimality of our method and develop a practical algorithm for hierarchical reinforcement learning. since our approach uses a handful of expert demonstrations, it is suitable for most robotic control tasks. experimental evaluation on complex maze navigation and robotic manipulation environments show that inducing hierarchical curriculum learning significantly improves sample efficiency, and results in efficient goal conditioned policies for solving temporally extended tasks.",,2023-04-07,,"['utsav singh', 'vinay p namboodiri']",https://arxiv.org/pdf/2304.03535.pdf
425,2304.03537,domain adaptive multiple instance learning for instance-level prediction   of pathological images,cs.cv,"pathological image analysis is an important process for detecting abnormalities such as cancer from cell images. however, since the image size is generally very large, the cost of providing detailed annotations is high, which makes it difficult to apply machine learning techniques. one way to improve the performance of identifying abnormalities while keeping the annotation cost low is to use only labels for each slide, or to use information from another dataset that has already been labeled. however, such weak supervisory information often does not provide sufficient performance. in this paper, we proposed a new task setting to improve the classification performance of the target dataset without increasing annotation costs. and to solve this problem, we propose a pipeline that uses multiple instance learning (mil) and domain adaptation (da) methods. furthermore, in order to combine the supervisory information of both methods effectively, we propose a method to create pseudo-labels with high confidence. we conducted experiments on the pathological image dataset we created for this study and showed that the proposed method significantly improves the classification performance compared to existing methods.",,2023-04-07,,"['shusuke takahama', 'yusuke kurose', 'yusuke mukuta', 'hiroyuki abe', 'akihiko yoshizawa', 'tetsuo ushiku', 'masashi fukayama', 'masanobu kitagawa', 'masaru kitsuregawa', 'tatsuya harada']",https://arxiv.org/pdf/2304.03537.pdf
426,2304.03538,adjustable privacy using autoencoder-based learning structure,cs.lg cs.cr,"inference centers need more data to have a more comprehensive and beneficial learning model, and for this purpose, they need to collect data from data providers. on the other hand, data providers are cautious about delivering their datasets to inference centers in terms of privacy considerations. in this paper, by modifying the structure of the autoencoder, we present a method that manages the utility-privacy trade-off well. to be more precise, the data is first compressed using the encoder, then confidential and non-confidential features are separated and uncorrelated using the classifier. the confidential feature is appropriately combined with noise, and the non-confidential feature is enhanced, and at the end, data with the original data format is produced by the decoder. the proposed architecture also allows data providers to set the level of privacy required for confidential features. the proposed method has been examined for both image and categorical databases, and the results show a significant performance improvement compared to previous methods.",,2023-04-07,,"['mohammad ali jamshidi', 'hadi veisi', 'mohammad mahdi mojahedian', 'mohammad reza aref']",https://arxiv.org/pdf/2304.03538.pdf
427,2304.03540,chatpipe: orchestrating data preparation program by optimizing   human-chatgpt interactions,cs.db cs.ai cs.hc cs.lg,"orchestrating a high-quality data preparation program is essential for successful machine learning (ml), but it is known to be time and effort consuming. despite the impressive capabilities of large language models like chatgpt in generating programs by interacting with users through natural language prompts, there are still limitations. specifically, a user must provide specific prompts to iteratively guide chatgpt in improving data preparation programs, which requires a certain level of expertise in programming, the dataset used and the ml task. moreover, once a program has been generated, it is non-trivial to revisit a previous version or make changes to the program without starting the process over again. in this paper, we present chatpipe, a novel system designed to facilitate seamless interaction between users and chatgpt. chatpipe provides users with effective recommendation on next data preparation operations, and guides chatgpt to generate program for the operations. also, chatpipe enables users to easily roll back to previous versions of the program, which facilitates more efficient experimentation and testing. we have developed a web application for chatpipe and prepared several real-world ml tasks from kaggle. these tasks can showcase the capabilities of chatpipe and enable vldb attendees to easily experiment with our novel features to rapidly orchestrate a high-quality data preparation program.",,2023-04-07,,"['sibei chen', 'hanbing liu', 'weiting jin', 'xiangyu sun', 'xiaoyao feng', 'ju fan', 'xiaoyong du', 'nan tang']",https://arxiv.org/pdf/2304.03540.pdf
428,2304.03543,hypertab: hypernetwork approach for deep learning on small tabular   datasets,cs.lg cs.ai,"deep learning has achieved impressive performance in many domains, such as computer vision and natural language processing, but its advantage over classical shallow methods on tabular datasets remains questionable. it is especially challenging to surpass the performance of tree-like ensembles, such as xgboost or random forests, on small-sized datasets (less than 1k samples). to tackle this challenge, we introduce hypertab, a hypernetwork-based approach to solving small sample problems on tabular datasets. by combining the advantages of random forests and neural networks, hypertab generates an ensemble of neural networks, where each target model is specialized to process a specific lower-dimensional view of the data. since each view plays the role of data augmentation, we virtually increase the number of training samples while keeping the number of trainable parameters unchanged, which prevents model overfitting. we evaluated hypertab on more than 40 tabular datasets of a varying number of samples and domains of origin, and compared its performance with shallow and deep learning models representing the current state-of-the-art. we show that hypertab consistently outranks other methods on small data (with a statistically significant difference) and scores comparable to them on larger datasets.   we make a python package with the code available to download at https://pypi.org/project/hypertab/",,2023-04-07,,"['witold wydma≈Ñski', 'oleksii bulenok', 'marek ≈õmieja']",https://arxiv.org/pdf/2304.03543.pdf
429,2304.03545,ai model disgorgement: methods and choices,cs.lg cs.cr,"responsible use of data is an indispensable part of any machine learning (ml) implementation. ml developers must carefully collect and curate their datasets, and document their provenance. they must also make sure to respect intellectual property rights, preserve individual privacy, and use data in an ethical way. over the past few years, ml models have significantly increased in size and complexity. these models require a very large amount of data and compute capacity to train, to the extent that any defects in the training corpus cannot be trivially remedied by retraining the model from scratch. despite sophisticated controls on training data and a significant amount of effort dedicated to ensuring that training corpora are properly composed, the sheer volume of data required for the models makes it challenging to manually inspect each datum comprising a training corpus. one potential fix for training corpus data defects is model disgorgement -- the elimination of not just the improperly used data, but also the effects of improperly used data on any component of an ml model. model disgorgement techniques can be used to address a wide range of issues, such as reducing bias or toxicity, increasing fidelity, and ensuring responsible usage of intellectual property. in this paper, we introduce a taxonomy of possible disgorgement methods that are applicable to modern ml systems. in particular, we investigate the meaning of ""removing the effects"" of data in the trained model in a way that does not require retraining from scratch.",,2023-04-07,,"['alessandro achille', 'michael kearns', 'carson klingenberg', 'stefano soatto']",https://arxiv.org/pdf/2304.03545.pdf
430,2304.03550,hierarchical disentanglement-alignment network for robust sar vehicle   recognition,cs.cv,"due to synthetic aperture radar (sar) imaging characteristics, sar vehicle recognition faces the problem of extracting discriminative and robust target features from a small dataset. deep learning has shown impressive performance on the mstar dataset. however, data bias in a small dataset, such as background correlation, impairs the causality of these methods, i.e., discriminative features contain target and background differences. moreover, different operating conditions of sar lead to target signatures and background clutter variations in imaging results. however, many deep learning-based methods only verify robustness to target or background variations in the current experimental setting. in this paper, we propose a novel domain alignment framework named hierarchical disentanglement-alignment network (hdanet) to enhance features' causality and robustness. concisely, hdanet consists of three parts: the first part uses data augmentation to generate signature variations for domain alignment. the second part disentangles the target features through a multitask-assisted mask to prevent non-causal clutter from interfering with subsequent alignment and recognition. thirdly, a contrastive loss is employed for domain alignment to extract robust target features, and the simsiam structure is applied to mitigate conflicts between contrastive loss and feature discrimination. finally, the proposed method shows high robustness across mstar's multiple target, sensor, and environment variants. noteworthy, we add a new scene variant to verify the robustness to target and background variations. moreover, the saliency map and shapley value qualitatively and quantitatively demonstrate causality. our code is available in \url{https://github.com/waterdisappear/sar-atr-hdanet}.",,2023-04-07,,"['weijie li', 'wei yang', 'li li', 'wenpeng zhang', 'yongxiang liu']",https://arxiv.org/pdf/2304.03550.pdf
431,2304.03552,a physics-informed neural network framework for modeling   obstacle-related equations,cs.lg cs.it cs.na math.ap math.it math.na,"deep learning has been highly successful in some applications. nevertheless, its use for solving partial differential equations (pdes) has only been of recent interest with current state-of-the-art machine learning libraries, e.g., tensorflow or pytorch. physics-informed neural networks (pinns) are an attractive tool for solving partial differential equations based on sparse and noisy data. here extend pinns to solve obstacle-related pdes which present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of the solution that lies above a given obstacle. the performance of the proposed pinns is demonstrated in multiple scenarios for linear and nonlinear pdes subject to regular and irregular obstacles.",,2023-04-07,,"['hamid el bahja', 'jan christian hauffen', 'peter jung', 'bubacarr bah', 'issa karambal']",https://arxiv.org/pdf/2304.03552.pdf
432,2304.03563,do subjectivity and objectivity always agree? a case study with stack   overflow questions,cs.se,"in stack overflow (so), the quality of posts (i.e., questions and answers) is subjectively evaluated by users through a voting mechanism. the net votes (upvotes - downvotes) obtained by a post are often considered an approximation of its quality. however, about half of the questions that received working solutions got more downvotes than upvotes. furthermore, about 18% of the accepted answers (i.e., verified solutions) also do not score the maximum votes. all these counter-intuitive findings cast doubts on the reliability of the evaluation mechanism employed at so. moreover, many users raise concerns against the evaluation, especially downvotes to their posts. therefore, rigorous verification of the subjective evaluation is highly warranted to ensure a non-biased and reliable quality assessment mechanism. in this paper, we compare the subjective assessment of questions with their objective assessment using 2.5 million questions and ten text analysis metrics. according to our investigation, four objective metrics agree with the subjective evaluation, two do not agree, one either agrees or disagrees, and the remaining three neither agree nor disagree with the subjective evaluation. we then develop machine learning models to classify the promoted and discouraged questions. our models outperform the state-of-the-art models with a maximum of about 76% - 87% accuracy.",,2023-04-07,,"['saikat mondal', 'mohammad masudur rahman', 'chanchal k. roy']",https://arxiv.org/pdf/2304.03563.pdf
433,2304.03571,$\beta$-variational autoencoders and transformers for reduced-order   modelling of fluid flows,physics.flu-dyn cs.lg,"variational autoencoder (vae) architectures have the potential to develop reduced-order models (roms) for chaotic fluid flows. we propose a method for learning compact and near-orthogonal roms using a combination of a $\beta$-vae and a transformer, tested on numerical data from a two-dimensional viscous flow in both periodic and chaotic regimes. the $\beta$-vae is trained to learn a compact latent representation of the flow velocity, and the transformer is trained to predict the temporal dynamics in latent space. using the $\beta$-vae to learn disentangled representations in latent-space, we obtain a more interpretable flow model with features that resemble those observed in the proper orthogonal decomposition, but with a more efficient representation. using poincar\'e maps, the results show that our method can capture the underlying dynamics of the flow outperforming other prediction models. the proposed method has potential applications in other fields such as weather forecasting, structural dynamics or biomedical engineering.",,2023-04-07,,"['alberto solera-rico', 'carlos sanmiguel vila', 'm. a. g√≥mez', 'yuning wang', 'abdulrahman almashjary', 'scott t. m. dawson', 'ricardo vinuesa']",https://arxiv.org/pdf/2304.03571.pdf
434,2304.03572,weakly supervised segmentation with point annotations for histopathology   images via contrast-based variational model,eess.iv cs.cv cs.lg,"image segmentation is a fundamental task in the field of imaging and vision. supervised deep learning for segmentation has achieved unparalleled success when sufficient training data with annotated labels are available. however, annotation is known to be expensive to obtain, especially for histopathology images where the target regions are usually with high morphology variations and irregular shapes. thus, weakly supervised learning with sparse annotations of points is promising to reduce the annotation workload. in this work, we propose a contrast-based variational model to generate segmentation results, which serve as reliable complementary supervision to train a deep segmentation model for histopathology images. the proposed method considers the common characteristics of target regions in histopathology images and can be trained in an end-to-end manner. it can generate more regionally consistent and smoother boundary segmentation, and is more robust to unlabeled `novel' regions. experiments on two different histology datasets demonstrate its effectiveness and efficiency in comparison to previous models.",,2023-04-07,,"['hongrun zhang', 'liam burrows', 'yanda meng', 'declan sculthorpe', 'abhik mukherjee', 'sarah e coupland', 'ke chen', 'yalin zheng']",https://arxiv.org/pdf/2304.03572.pdf
435,2304.03585,armantts single-speaker persian dataset,cs.cl,"tts, or text-to-speech, is a complicated process that can be accomplished through appropriate modeling using deep learning methods. in order to implement deep learning models, a suitable dataset is required. since there is a scarce amount of work done in this field for the persian language, this paper will introduce the single speaker dataset: armantts. we compared the characteristics of this dataset with those of various prevalent datasets to prove that armantts meets the necessary standards for teaching a persian text-to-speech conversion model. we also combined the tacotron 2 and hifi gan to design a model that can receive phonemes as input, with the output being the corresponding speech. 4.0 value of mos was obtained from real speech, 3.87 value was obtained by the vocoder prediction and 2.98 value was reached with the synthetic speech generated by the tts model.",,2023-04-07,,"['mohammd hasan shamgholi', 'vahid saeedi', 'javad peymanfard', 'leila alhabib', 'hossein zeinali']",https://arxiv.org/pdf/2304.03585.pdf
436,2304.03588,anomalous sound detection using audio representation with machine id   based contrastive learning pretraining,cs.sd cs.lg eess.as,"existing contrastive learning methods for anomalous sound detection refine the audio representation of each audio sample by using the contrast between the samples' augmentations (e.g., with time or frequency masking). however, they might be biased by the augmented data, due to the lack of physical properties of machine sound, thereby limiting the detection performance. this paper uses contrastive learning to refine audio representations for each machine id, rather than for each audio sample. the proposed two-stage method uses contrastive learning to pretrain the audio representation model by incorporating machine id and a self-supervised id classifier to fine-tune the learnt model, while enhancing the relation between audio features from the same id. experiments show that our method outperforms the state-of-the-art methods using contrastive learning or self-supervised classification in overall anomaly detection performance and stability on dcase 2020 challenge task2 dataset.",,2023-04-07,2023-04-10,"['jian guan', 'feiyang xiao', 'youde liu', 'qiaoxi zhu', 'wenwu wang']",https://arxiv.org/pdf/2304.03588.pdf
437,2304.03589,on efficient training of large-scale deep learning models: a literature   review,cs.lg cs.ai cs.dc,"the field of deep learning has witnessed significant progress, particularly in computer vision (cv), natural language processing (nlp), and speech. the use of large-scale models trained on vast amounts of data holds immense promise for practical applications, enhancing industrial productivity and facilitating social development. with the increasing demands on computational capacity, though numerous studies have explored the efficient training, a comprehensive summarization on acceleration techniques of training deep learning models is still much anticipated. in this survey, we present a detailed review for training acceleration. we consider the fundamental update formulation and split its basic components into five main perspectives: (1) data-centric: including dataset regularization, data sampling, and data-centric curriculum learning techniques, which can significantly reduce the computational complexity of the data samples; (2) model-centric, including acceleration of basic modules, compression training, model initialization and model-centric curriculum learning techniques, which focus on accelerating the training via reducing the calculations on parameters; (3) optimization-centric, including the selection of learning rate, the employment of large batchsize, the designs of efficient objectives, and model average techniques, which pay attention to the training policy and improving the generality for the large-scale models; (4) budgeted training, including some distinctive acceleration methods on source-constrained situations; (5) system-centric, including some efficient open-source distributed libraries/systems which provide adequate hardware support for the implementation of acceleration algorithms. by presenting this comprehensive taxonomy, our survey presents a comprehensive review to understand the general mechanisms within each component and their joint interaction.",,2023-04-07,,"['li shen', 'yan sun', 'zhiyuan yu', 'liang ding', 'xinmei tian', 'dacheng tao']",https://arxiv.org/pdf/2304.03589.pdf
438,2304.03593,deep reinforcement learning-based mapless crowd navigation with   perceived risk of the moving crowd for mobile robots,cs.ro cs.ai cs.lg,"classical map-based navigation methods are commonly used for robot navigation, but they often struggle in crowded environments due to the frozen robot problem (frp). deep reinforcement learning-based methods address the frp problem, however, suffer from the issues of generalization and scalability. to overcome these challenges, we propose a method that uses collision probability (cp) to help the robot navigate safely through crowds. the inclusion of cp in the observation space gives the robot a sense of the level of danger of the moving crowd. the robot will navigate through the crowd when it appears safe but will take a detour when the crowd is moving aggressively. by focusing on the most dangerous obstacle, the robot will not be confused when the crowd density is high, ensuring scalability of the model. our approach was developed using deep reinforcement learning (drl) and trained using the gazebo simulator in a non cooperative crowd environment with obstacles moving at randomized speeds and directions. we then evaluated our model on four different crowd-behavior scenarios with varying densities of crowds. the results shown that our method achieved a 100% success rate in all test settings. we compared our approach with a current state-of-the-art drlbased approach, and our approach has performed significantly better. importantly, our method is highly generalizable and requires no fine-tuning after being trained once. we further demonstrated the crowd navigation capability of our model in real-world tests.",,2023-04-07,,"['hafiq anas', 'ong wee hong', 'owais ahmed malik']",https://arxiv.org/pdf/2304.03593.pdf
439,2304.03602,pallet detection from synthetic data using game engines,cs.cv cs.ai,"this research sets out to assess the viability of using game engines to generate synthetic training data for machine learning in the context of pallet segmentation. using synthetic data has been proven in prior research to be a viable means of training neural networks and saves hours of manual labour due to the reduced need for manual image annotation. machine vision for pallet detection can benefit from synthetic data as the industry increases the development of autonomous warehousing technologies. as per our methodology, we developed a tool capable of automatically generating large amounts of annotated training data from 3d models at pixel-perfect accuracy and a much faster rate than manual approaches. regarding image segmentation, a mask r-cnn pipeline was used, which achieved an ap50 of 86% for individual pallets.",,2023-04-07,,"['jouveer naidoo', 'nicholas bates', 'trevor gee', 'mahla nejati']",https://arxiv.org/pdf/2304.03602.pdf
440,2304.03609,revisiting automated prompting: are we actually doing better?,cs.cl cs.lg,"current literature demonstrates that large language models (llms) are great few-shot learners, and prompting significantly increases their performance on a range of downstream tasks in a few-shot learning setting. an attempt to automate human-led prompting followed, with some progress achieved. in particular, subsequent work demonstrates automation can outperform fine-tuning in certain k-shot learning scenarios.   in this paper, we revisit techniques for automated prompting on six different downstream tasks and a larger range of k-shot learning settings. we find that automated prompting does not consistently outperform simple manual prompts. our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research.",,2023-04-07,,"['yulin zhou', 'yiren zhao', 'ilia shumailov', 'robert mullins', 'yarin gal']",https://arxiv.org/pdf/2304.03609.pdf
441,2304.03626,asynchronous federated continual learning,cs.lg cs.cv,"the standard class-incremental continual learning setting assumes a set of tasks seen one after the other in a fixed and predefined order. this is not very realistic in federated learning environments where each client works independently in an asynchronous manner getting data for the different tasks in time-frames and orders totally uncorrelated with the other ones. we introduce a novel federated learning setting (afcl) where the continual learning of multiple tasks happens at each client with different orderings and in asynchronous time slots. we tackle this novel task using prototype-based learning, a representation loss, fractal pre-training, and a modified aggregation policy. our approach, called fedspace, effectively tackles this task as shown by the results on the cifar-100 dataset using 3 different federated splits with 50, 100, and 500 clients, respectively. the code and federated splits are available at https://github.com/lttm/fedspace.",,2023-04-07,,"['donald shenaj', 'marco toldo', 'alberto rigon', 'pietro zanuttigh']",https://arxiv.org/pdf/2304.03626.pdf
442,2304.03635,a2j-transformer: anchor-to-joint transformer network for 3d interacting   hand pose estimation from a single rgb image,cs.cv,"3d interacting hand pose estimation from a single rgb image is a challenging task, due to serious self-occlusion and inter-occlusion towards hands, confusing similar appearance patterns between 2 hands, ill-posed joint position mapping from 2d to 3d, etc.. to address these, we propose to extend a2j-the state-of-the-art depth-based 3d single hand pose estimation method-to rgb domain under interacting hand condition. our key idea is to equip a2j with strong local-global aware ability to well capture interacting hands' local fine details and global articulated clues among joints jointly. to this end, a2j is evolved under transformer's non-local encoding-decoding framework to build a2j-transformer. it holds 3 main advantages over a2j. first, self-attention across local anchor points is built to make them global spatial context aware to better capture joints' articulation clues for resisting occlusion. secondly, each anchor point is regarded as learnable query with adaptive feature learning for facilitating pattern fitting capacity, instead of having the same local representation with the others. last but not least, anchor point locates in 3d space instead of 2d as in a2j, to leverage 3d pose prediction. experiments on challenging interhand 2.6m demonstrate that, a2j-transformer can achieve state-of-the-art model-free performance (3.38mm mpjpe advancement in 2-hand case) and can also be applied to depth domain with strong generalization.",,2023-04-07,,"['changlong jiang', 'yang xiao', 'cunlin wu', 'mingyang zhang', 'jinghong zheng', 'zhiguo cao', 'joey tianyi zhou']",https://arxiv.org/pdf/2304.03635.pdf
443,2304.03638,compressed regression over adaptive networks,cs.lg cs.ma eess.sp math.oc stat.ml,"in this work we derive the performance achievable by a network of distributed agents that solve, adaptively and in the presence of communication constraints, a regression problem. agents employ the recently proposed actc (adapt-compress-then-combine) diffusion strategy, where the signals exchanged locally by neighboring agents are encoded with randomized differential compression operators. we provide a detailed characterization of the mean-square estimation error, which is shown to comprise a term related to the error that agents would achieve without communication constraints, plus a term arising from compression. the analysis reveals quantitative relationships between the compression loss and fundamental attributes of the distributed regression problem, in particular, the stochastic approximation error caused by the gradient noise and the network topology (through the perron eigenvector). we show that knowledge of such relationships is critical to allocate optimally the communication resources across the agents, taking into account their individual attributes, such as the quality of their data or their degree of centrality in the network topology. we devise an optimized allocation strategy where the parameters necessary for the optimization can be learned online by the agents. illustrative examples show that a significant performance improvement, as compared to a blind (i.e., uniform) resource allocation, can be achieved by optimizing the allocation by means of the provided mean-square-error formulas.",,2023-04-07,,"['marco carpentiero', 'vincenzo matta', 'ali h. sayed']",https://arxiv.org/pdf/2304.03638.pdf
444,2304.03640,feddisc: a computation-efficient federated learning framework for power   systems disturbance and cyber attack discrimination,cs.cr cs.dc cs.lg,"with the growing concern about the security and privacy of smart grid systems, cyberattacks on critical power grid components, such as state estimation, have proven to be one of the top-priority cyber-related issues and have received significant attention in recent years. however, cyberattack detection in smart grids now faces new challenges, including privacy preservation and decentralized power zones with strategic data owners. to address these technical bottlenecks, this paper proposes a novel federated learning-based privacy-preserving and communication-efficient attack detection framework, known as feddisc, that enables discrimination between power system disturbances and cyberattacks. specifically, we first propose a federated learning approach to enable supervisory control and data acquisition subsystems of decentralized power grid zones to collaboratively train an attack detection model without sharing sensitive power related data. secondly, we put forward a representation learning-based deep auto-encoder network to accurately detect power system and cybersecurity anomalies. lastly, to adapt our proposed framework to the timeliness of real-world cyberattack detection in sgs, we leverage the use of a gradient privacy-preserving quantization scheme known as dp-signsgd to improve its communication efficiency. extensive simulations of the proposed framework on publicly available industrial control systems datasets demonstrate that the proposed framework can achieve superior detection accuracy while preserving the privacy of sensitive power grid related information. furthermore, we find that the gradient quantization scheme utilized improves communication efficiency by 40% when compared to a traditional federated learning approach without gradient quantization which suggests suitability in a real-world scenario.",,2023-04-07,,"['muhammad akbar husnoo', 'adnan anwar', 'haftu tasew reda', 'nasser hosseinzadeh', 'shama naz islam', 'abdun naser mahmood', 'robin doss']",https://arxiv.org/pdf/2304.03640.pdf
445,2304.03641,a block coordinate descent method for nonsmooth composite optimization   under orthogonality constraints,math.oc cs.lg cs.na math.na,"nonsmooth composite optimization with orthogonality constraints has a broad spectrum of applications in statistical learning and data science. however, this problem is generally challenging to solve due to its non-convex and non-smooth nature. existing solutions are limited by one or more of the following restrictions: (i) they are full gradient methods that require high computational costs in each iteration; (ii) they are not capable of solving general nonsmooth composite problems; (iii) they are infeasible methods and can only achieve the feasibility of the solution at the limit point; (iv) they lack rigorous convergence guarantees; (v) they only obtain weak optimality of critical points. in this paper, we propose \textit{\textbf{obcd}}, a new block coordinate descent method for solving general nonsmooth composite problems under orthogonality constraints. \textit{\textbf{obcd}} is a feasible method with low computation complexity footprints. in each iteration, our algorithm updates $k$ rows of the solution matrix ($k\geq2$ is a parameter) to preserve the constraints. then, it solves a small-sized nonsmooth composite optimization problem under orthogonality constraints either exactly or approximately. we demonstrate that any exact block-$k$ stationary point is always an approximate block-$k$ stationary point, which is equivalent to the critical stationary point. we are particularly interested in the case where $k=2$ as the resulting subproblem reduces to a one-dimensional nonconvex problem. we propose a breakpoint searching method and a fifth-order iterative method to solve this problem efficiently and effectively. we also propose two novel greedy strategies to find a good working set to further accelerate the convergence of \textit{\textbf{obcd}}. finally, we have conducted extensive experiments on several tasks to demonstrate the superiority of our approach.",,2023-04-07,,['ganzhao yuan'],https://arxiv.org/pdf/2304.03641.pdf
446,2304.03646,fairness through aleatoric uncertainty,cs.lg cs.cy,"we propose a unique solution to tackle the often-competing goals of fairness and utility in machine learning classification tasks. while fairness ensures that the model's predictions are unbiased and do not discriminate against any particular group, utility focuses on maximizing the accuracy of the model's predictions. our aim is to investigate the relationship between uncertainty and fairness. our approach leverages this concept by employing bayesian learning to estimate the uncertainty in sample predictions where the estimation is independent of confounding effects related to the protected attribute. through empirical evidence, we show that samples with low classification uncertainty are modeled more accurately and fairly than those with high uncertainty, which may have biased representations and higher prediction errors. to address the challenge of balancing fairness and utility, we propose a novel fairness-utility objective that is defined based on uncertainty quantification. the weights in this objective are determined by the level of uncertainty, allowing us to optimize both fairness and utility simultaneously. experiments on real-world datasets demonstrate the effectiveness of our approach. our results show that our method outperforms state-of-the-art methods in terms of the fairness-utility tradeoff and this applies to both group and individual fairness metrics. this work presents a fresh perspective on the trade-off between accuracy and fairness in machine learning and highlights the potential of using uncertainty as a means to achieve optimal fairness and utility.",,2023-04-07,,"['anique tahir', 'lu cheng', 'huan liu']",https://arxiv.org/pdf/2304.03646.pdf
447,2304.03650,a cross-scale hierarchical transformer with correspondence-augmented   attention for inferring bird's-eye-view semantic segmentation,cs.cv,"as bird's-eye-view (bev) semantic segmentation is simple-to-visualize and easy-to-handle, it has been applied in autonomous driving to provide the surrounding information to downstream tasks. inferring bev semantic segmentation conditioned on multi-camera-view images is a popular scheme in the community as cheap devices and real-time processing. the recent work implemented this task by learning the content and position relationship via the vision transformer (vit). however, the quadratic complexity of vit confines the relationship learning only in the latent layer, leaving the scale gap to impede the representation of fine-grained objects. and their plain fusion method of multi-view features does not conform to the information absorption intention in representing bev features. to tackle these issues, we propose a novel cross-scale hierarchical transformer with correspondence-augmented attention for semantic segmentation inferring. specifically, we devise a hierarchical framework to refine the bev feature representation, where the last size is only half of the final segmentation. to save the computation increase caused by this hierarchical framework, we exploit the cross-scale transformer to learn feature relationships in a reversed-aligning way, and leverage the residual connection of bev features to facilitate information transmission between scales. we propose correspondence-augmented attention to distinguish conducive and inconducive correspondences. it is implemented in a simple yet effective way, amplifying attention scores before the softmax operation, so that the position-view-related and the position-view-disrelated attention scores are highlighted and suppressed. extensive experiments demonstrate that our method has state-of-the-art performance in inferring bev semantic segmentation conditioned on multi-camera-view images.",,2023-04-07,,"['naiyu fang', 'lemiao qiu', 'shuyou zhang', 'zili wang', 'kerui hu', 'kang wang']",https://arxiv.org/pdf/2304.03650.pdf
448,2304.03657,scart: simulation of cyber attacks for real-time,cs.cr,"real-time systems are often implemented as reactive systems that respond to stimuli and complete tasks in a known bounded time. the development process of such systems usually involves using a cycle-accurate simulation environment and even the digital twine system that can accurately simulate the system and the environment it operates in. in addition, many real-time systems require high reliability and strive to be immune against security attacks. thus, the development environment must support reliability-related events such as the failure of a sensor, malfunction of a subsystem, and foreseen events of cyber security attacks. this paper presents the scart framework - an innovative solution that aims to allow extending simulation environments of real-time systems with the capability to incorporate reliability-related events and advanced cyber security attacks, e.g., an attack on a single sensor as well as ""complex security attacks"" that aim to change the behavior of a group of sensors. we validate our system by applying the new proposed environment on control a drone's flight control system including its navigation system that uses machine learning algorithms. such a system is very challenging since it requires many experiments that can hardly be achieved by using live systems. we showed that using scart is very efficient, can increase the model's accuracy, and significantly reduce false-positive rates. some of these experiments were also validated using a set of ""real drones"".",,2023-04-07,,"['kfir girstein', 'eliron rahimi', 'prof. avi mendelson']",https://arxiv.org/pdf/2304.03657.pdf
449,2304.03659,probing conceptual understanding of large visual-language models,cs.cv,"we present a novel framework for probing and improving relational, compositional and contextual understanding of large visual-language models (v+l). while large v+l models have achieved success in various downstream tasks, it is not clear if they have a conceptual grasp of the content. we propose a novel benchmarking dataset for probing three aspects of content understanding. our probes are grounded in cognitive science and help determine if a v+l model can, for example, determine if snow garnished with a man is implausible, or if it can identify beach furniture by knowing it is located on a beach. we have experimented with 5 well known models, such as clip and vilt, and found that they mostly fail to demonstrate a conceptual understanding. that said, we find interesting insights such as cross-attention helps learning conceptual understanding. we use these insights to propose a new finetuning technique that rewards the three conceptual understanding measures we proposed. we hope that the presented benchmarks will help the community assess and improve the conceptual understanding capabilities of large v+l models.",,2023-04-07,,"['madeline chantry schiappa', 'michael cogswell', 'ajay divakaran', 'yogesh singh rawat']",https://arxiv.org/pdf/2304.03659.pdf
450,2304.03674,machine learning with requirements: a manifesto,cs.lg cs.ai cs.se,"in the recent years, machine learning has made great advancements that have been at the root of many breakthroughs in different application domains. however, it is still an open issue how make them applicable to high-stakes or safety-critical application domains, as they can often be brittle and unreliable. in this paper, we argue that requirements definition and satisfaction can go a long way to make machine learning models even more fitting to the real world, especially in critical domains. to this end, we present two problems in which (i) requirements arise naturally, (ii) machine learning models are or can be fruitfully deployed, and (iii) neglecting the requirements can have dramatic consequences. we show how the requirements specification can be fruitfully integrated into the standard machine learning development pipeline, proposing a novel pyramid development process in which requirements definition may impact all the subsequent phases in the pipeline, and viceversa.",,2023-04-07,,"['eleonora giunchiglia', 'fergus imrie', 'mihaela van der schaar', 'thomas lukasiewicz']",https://arxiv.org/pdf/2304.03674.pdf
451,2304.03691,feature mining for encrypted malicious traffic detection with deep   learning and other machine learning algorithms,cs.cr cs.ai cs.lg,"the popularity of encryption mechanisms poses a great challenge to malicious traffic detection. the reason is traditional detection techniques cannot work without the decryption of encrypted traffic. currently, research on encrypted malicious traffic detection without decryption has focused on feature extraction and the choice of machine learning or deep learning algorithms. in this paper, we first provide an in-depth analysis of traffic features and compare different state-of-the-art traffic feature creation approaches, while proposing a novel concept for encrypted traffic feature which is specifically designed for encrypted malicious traffic analysis. in addition, we propose a framework for encrypted malicious traffic detection. the framework is a two-layer detection framework which consists of both deep learning and traditional machine learning algorithms. through comparative experiments, it outperforms classical deep learning and traditional machine learning algorithms, such as resnet and random forest. moreover, to provide sufficient training data for the deep learning model, we also curate a dataset composed entirely of public datasets. the composed dataset is more comprehensive than using any public dataset alone. lastly, we discuss the future directions of this research.",10.1016/j.cose.2023.103143,2023-04-07,,"['zihao wang', 'vrizlynn l. l. thing']",https://arxiv.org/pdf/2304.03691.pdf
452,2304.03694,high accuracy uncertainty-aware interatomic force modeling with   equivariant bayesian neural networks,physics.chem-ph cs.lg physics.comp-ph,"even though bayesian neural networks offer a promising framework for modeling uncertainty, active learning and incorporating prior physical knowledge, few applications of them can be found in the context of interatomic force modeling. one of the main challenges in their application to learning interatomic forces is the lack of suitable monte carlo markov chain sampling algorithms for the posterior density, as the commonly used algorithms do not converge in a practical amount of time for many of the state-of-the-art architectures. as a response to this challenge, we introduce a new monte carlo markov chain sampling algorithm in this paper which can circumvent the problems of the existing sampling methods. in addition, we introduce a new stochastic neural network model based on the nequip architecture and demonstrate that, when combined with our novel sampling algorithm, we obtain predictions with state-of-the-art accuracy as well as a good measure of uncertainty.",,2023-04-05,,"['tim rensmeyer', 'benjamin craig', 'denis kramer', 'oliver niggemann']",https://arxiv.org/pdf/2304.03694.pdf
453,2304.03696,"reduce, reuse, recycle: modular multi-object navigation",cs.ro cs.cv,"our work focuses on the multi-object navigation (multion) task, where an agent needs to navigate to multiple objects in a given sequence. we systematically investigate the inherent modularity of this task by dividing our approach to contain four modules: (a) an object detection module trained to identify objects from rgb images, (b) a map building module to build a semantic map of the observed objects, (c) an exploration module enabling the agent to explore its surroundings, and finally (d) a navigation module to move to identified target objects. we focus on the navigation and the exploration modules in this work. we show that we can effectively leverage a pointgoal navigation model in the multion task instead of learning to navigate from scratch. our experiments show that a pointgoal agent-based navigation module outperforms analytical path planning on the multion task. we also compare exploration strategies and surprisingly find that a random exploration strategy significantly outperforms more advanced exploration methods. we additionally create multion 2.0, a new large-scale dataset as a test-bed for our approach.",,2023-04-07,,"['sonia raychaudhuri', 'tommaso campari', 'unnat jain', 'manolis savva', 'angel x. chang']",https://arxiv.org/pdf/2304.03696.pdf
454,2304.03697,humanlight: incentivizing ridesharing via human-centric deep   reinforcement learning in traffic signal control,cs.lg cs.ai cs.sy eess.sy,"single occupancy vehicles are the most attractive transportation alternative for many commuters, leading to increased traffic congestion and air pollution. advancements in information technologies create opportunities for smart solutions that incentivize ridesharing and mode shift to higher occupancy vehicles (hovs) to achieve the car lighter vision of cities. in this study, we present humanlight, a novel decentralized adaptive traffic signal control algorithm designed to optimize people throughput at intersections. our proposed controller is founded on reinforcement learning with the reward function embedding the transportation-inspired concept of pressure at the person-level. by rewarding hov commuters with travel time savings for their efforts to merge into a single ride, humanlight achieves equitable allocation of green times. apart from adopting frap, a state-of-the-art (sota) base model, humanlight introduces the concept of active vehicles, loosely defined as vehicles in proximity to the intersection within the action interval window. the proposed algorithm showcases significant headroom and scalability in different network configurations considering multimodal vehicle splits at various scenarios of hov adoption. improvements in person delays and queues range from 15% to over 55% compared to vehicle-level sota controllers. we quantify the impact of incorporating active vehicles in the formulation of our rl model for different network structures. humanlight also enables regulation of the aggressiveness of the hov prioritization. the impact of parameter setting on the generated phase profile is investigated as a key component of acyclic signal controllers affecting pedestrian waiting times. humanlight's scalable, decentralized design can reshape the resolution of traffic management to be more human-centric and empower policies that incentivize ridesharing and public transit systems.",,2023-04-05,,"['dimitris m. vlachogiannis', 'hua wei', 'scott moura', 'jane macfarlane']",https://arxiv.org/pdf/2304.03697.pdf
455,2304.03698,deepfake detection with deep learning: convolutional neural networks   versus transformers,cs.cr cs.cv cs.lg,"the rapid evolvement of deepfake creation technologies is seriously threating media information trustworthiness. the consequences impacting targeted individuals and institutions can be dire. in this work, we study the evolutions of deep learning architectures, particularly cnns and transformers. we identified eight promising deep learning architectures, designed and developed our deepfake detection models and conducted experiments over well-established deepfake datasets. these datasets included the latest second and third generation deepfake datasets. we evaluated the effectiveness of our developed single model detectors in deepfake detection and cross datasets evaluations. we achieved 88.74%, 99.53%, 97.68%, 99.73% and 92.02% accuracy and 99.95%, 100%, 99.88%, 99.99% and 97.61% auc, in the detection of ff++ 2020, google dfd, celeb-df, deeper forensics and dfdc deepfakes, respectively. we also identified and showed the unique strengths of cnns and transformers models and analysed the observed relationships among the different deepfake datasets, to aid future developments in this area.",,2023-04-07,,['vrizlynn l. l. thing'],https://arxiv.org/pdf/2304.03698.pdf
456,2304.03709,meta-causal learning for single domain generalization,cs.cv cs.lg,"single domain generalization aims to learn a model from a single training domain (source domain) and apply it to multiple unseen test domains (target domains). existing methods focus on expanding the distribution of the training domain to cover the target domains, but without estimating the domain shift between the source and target domains. in this paper, we propose a new learning paradigm, namely simulate-analyze-reduce, which first simulates the domain shift by building an auxiliary domain as the target domain, then learns to analyze the causes of domain shift, and finally learns to reduce the domain shift for model adaptation. under this paradigm, we propose a meta-causal learning method to learn meta-knowledge, that is, how to infer the causes of domain shift between the auxiliary and source domains during training. we use the meta-knowledge to analyze the shift between the target and source domains during testing. specifically, we perform multiple transformations on source data to generate the auxiliary domain, perform counterfactual inference to learn to discover the causal factors of the shift between the auxiliary and source domains, and incorporate the inferred causality into factor-aware domain alignments. extensive experiments on several benchmarks of image classification show the effectiveness of our method.",,2023-04-07,,"['jin chen', 'zhi gao', 'xinxiao wu', 'jiebo luo']",https://arxiv.org/pdf/2304.03709.pdf
457,2304.03717,on the importance of contrastive loss in multimodal learning,cs.lg cs.cl cs.cv,"recently, contrastive learning approaches (e.g., clip (radford et al., 2021)) have received huge success in multimodal learning, where the model tries to minimize the distance between the representations of different views (e.g., image and its caption) of the same data point while keeping the representations of different data points away from each other. however, from a theoretical perspective, it is unclear how contrastive learning can learn the representations from different views efficiently, especially when the data is not isotropic. in this work, we analyze the training dynamics of a simple multimodal contrastive learning model and show that contrastive pairs are important for the model to efficiently balance the learned representations. in particular, we show that the positive pairs will drive the model to align the representations at the cost of increasing the condition number, while the negative pairs will reduce the condition number, keeping the learned representations balanced.",,2023-04-07,,"['yunwei ren', 'yuanzhi li']",https://arxiv.org/pdf/2304.03717.pdf
458,2304.03718,integrating edge-ai in structural health monitoring domain,cs.lg cs.cv,"structural health monitoring (shm) tasks like damage detection are crucial for decision-making regarding maintenance and deterioration. for example, crack detection in shm is crucial for bridge maintenance as crack progression can lead to structural instability. however, most ai/ml models in the literature have low latency and late inference time issues while performing in real-time environments. this study aims to explore the integration of edge-ai in the shm domain for real-time bridge inspections. based on edge-ai literature, its capabilities will be valuable integration for a real-time decision support system in shm tasks such that real-time inferences can be performed on physical sites. this study will utilize commercial edge-ai platforms, such as google coral dev board or kneron kl520, to develop and analyze the effectiveness of edge-ai devices. thus, this study proposes an edge ai framework for the structural health monitoring domain. an edge-ai-compatible deep learning model is developed to validate the framework to perform real-time crack classification. the effectiveness of this model will be evaluated based on its accuracy, the confusion matrix generated, and the inference time observed in a real-time setting.",,2023-04-07,,"['anoop mishra', 'gopinath gangisetti', 'deepak khazanchi']",https://arxiv.org/pdf/2304.03718.pdf
459,2304.03720,representer theorems for metric and preference learning: a geometric   perspective,cs.lg cs.ai stat.ml,"we explore the metric and preference learning problem in hilbert spaces. we obtain a novel representer theorem for the simultaneous task of metric and preference learning. our key observation is that the representer theorem can be formulated with respect to the norm induced by the inner product inherent in the problem structure. additionally, we demonstrate how our framework can be applied to the task of metric learning from triplet comparisons and show that it leads to a simple and self-contained representer theorem for this task. in the case of reproducing kernel hilbert spaces (rkhs), we demonstrate that the solution to the learning problem can be expressed using kernel terms, akin to classical representer theorems.",,2023-04-07,,['peyman morteza'],https://arxiv.org/pdf/2304.03720.pdf
460,2304.03722,beyond privacy: navigating the opportunities and challenges of synthetic   data,cs.lg,"generating synthetic data through generative models is gaining interest in the ml community and beyond. in the past, synthetic data was often regarded as a means to private data release, but a surge of recent papers explore how its potential reaches much further than this -- from creating more fair data to data augmentation, and from simulation to text generated by chatgpt. in this perspective we explore whether, and how, synthetic data may become a dominant force in the machine learning world, promising a future where datasets can be tailored to individual needs. just as importantly, we discuss which fundamental challenges the community needs to overcome for wider relevance and application of synthetic data -- the most important of which is quantifying how much we can trust any finding or prediction drawn from synthetic data.",,2023-04-07,,"['boris van breugel', 'mihaela van der schaar']",https://arxiv.org/pdf/2304.03722.pdf
461,2304.03729,full gradient deep reinforcement learning for average-reward criterion,eess.sy cs.lg cs.sy,we extend the provably convergent full gradient dqn algorithm for discounted reward markov decision processes from avrachenkov et al. (2021) to average reward problems. we experimentally compare widely used rvi q-learning with recently proposed differential q-learning in the neural function approximation setting with full gradient dqn and dqn. we also extend this to learn whittle indices for markovian restless multi-armed bandits. we observe a better convergence rate of the proposed full gradient variant across different tasks.,,2023-04-07,,"['tejas pagare', 'vivek borkar', 'konstantin avrachenkov']",https://arxiv.org/pdf/2304.03729.pdf
462,2304.03745,assessing perceived fairness from machine learning developer's   perspective,cs.lg cs.cy cs.hc,"fairness in machine learning (ml) applications is an important practice for developers in research and industry. in ml applications, unfairness is triggered due to bias in the data, curation process, erroneous assumptions, and implicit bias rendered within the algorithmic development process. as ml applications come into broader use developing fair ml applications is critical. literature suggests multiple views on how fairness in ml is described from the users perspective and students as future developers. in particular, ml developers have not been the focus of research relating to perceived fairness. this paper reports on a pilot investigation of ml developers perception of fairness. in describing the perception of fairness, the paper performs an exploratory pilot study to assess the attributes of this construct using a systematic focus group of developers. in the focus group, we asked participants to discuss three questions- 1) what are the characteristics of fairness in ml? 2) what factors influence developers belief about the fairness of ml? and 3) what practices and tools are utilized for fairness in ml development? the findings of this exploratory work from the focus group show that to assess fairness developers generally focus on the overall ml application design and development, i.e., business-specific requirements, data collection, pre-processing, in-processing, and post-processing. thus, we conclude that the procedural aspects of organizational justice theory can explain developers perception of fairness. the findings of this study can be utilized further to assist development teams in integrating fairness in the ml application development lifecycle. it will also motivate ml developers and organizations to develop best practices for assessing the fairness of ml-based applications.",,2023-04-07,,"['anoop mishra', 'deepak khazanchi']",https://arxiv.org/pdf/2304.03745.pdf
463,2304.03755,online learning for scheduling mip heuristics,math.oc cs.ai cs.lg,"mixed integer programming (mip) is np-hard, and yet modern solvers often solve large real-world problems within minutes. this success can partially be attributed to heuristics. since their behavior is highly instance-dependent, relying on hard-coded rules derived from empirical testing on a large heterogeneous corpora of benchmark instances might lead to sub-optimal performance. in this work, we propose an online learning approach that adapts the application of heuristics towards the single instance at hand. we replace the commonly used static heuristic handling with an adaptive framework exploiting past observations about the heuristic's behavior to make future decisions. in particular, we model the problem of controlling large neighborhood search and diving - two broad and complex classes of heuristics - as a multi-armed bandit problem. going beyond existing work in the literature, we control two different classes of heuristics simultaneously by a single learning agent. we verify our approach numerically and show consistent node reductions over the miplib 2017 benchmark set. for harder instances that take at least 1000 seconds to solve, we observe a speedup of 4%.",,2023-04-04,,"['antonia chmiela', 'ambros gleixner', 'pawel lichocki', 'sebastian pokutta']",https://arxiv.org/pdf/2304.03755.pdf
464,2304.03757,replicability and stability in learning,cs.lg math.co stat.ml,"replicability is essential in science as it allows us to validate and verify research findings. impagliazzo, lei, pitassi and sorrell (`22) recently initiated the study of replicability in machine learning. a learning algorithm is replicable if it typically produces the same output when applied on two i.i.d. inputs using the same internal randomness. we study a variant of replicability that does not involve fixing the randomness. an algorithm satisfies this form of replicability if it typically produces the same output when applied on two i.i.d. inputs (without fixing the internal randomness). this variant is called global stability and was introduced by bun, livni and moran ('20) in the context of differential privacy.   impagliazzo et al. showed how to boost any replicable algorithm so that it produces the same output with probability arbitrarily close to 1. in contrast, we demonstrate that for numerous learning tasks, global stability can only be accomplished weakly, where the same output is produced only with probability bounded away from 1. to overcome this limitation, we introduce the concept of list replicability, which is equivalent to global stability. moreover, we prove that list replicability can be boosted so that it is achieved with probability arbitrarily close to 1. we also describe basic relations between standard learning-theoretic complexity measures and list replicable numbers. our results, in addition, imply that besides trivial cases, replicable algorithms (in the sense of impagliazzo et al.) must be randomized.   the proof of the impossibility result is based on a topological fixed-point theorem. for every algorithm, we are able to locate a ""hard input distribution"" by applying the poincar\'{e}-miranda theorem in a related topological setting. the equivalence between global stability and list replicability is algorithmic.",,2023-04-07,2023-04-12,"['zachary chase', 'shay moran', 'amir yehudayoff']",https://arxiv.org/pdf/2304.03757.pdf
465,2304.03767,embodied concept learner: self-supervised learning of concepts and   mapping through instruction following,cs.cv,"humans, even at a very early age, can learn visual concepts and understand geometry and layout through active interaction with the environment, and generalize their compositions to complete tasks described by natural languages in novel scenes. to mimic such capability, we propose embodied concept learner (ecl) in an interactive 3d environment. specifically, a robot agent can ground visual concepts, build semantic maps and plan actions to complete tasks by learning purely from human demonstrations and language instructions, without access to ground-truth semantic and depth supervisions from simulations. ecl consists of: (i) an instruction parser that translates the natural languages into executable programs; (ii) an embodied concept learner that grounds visual concepts based on language descriptions; (iii) a map constructor that estimates depth and constructs semantic maps by leveraging the learned concepts; and (iv) a program executor with deterministic policies to execute each program. ecl has several appealing benefits thanks to its modularized design. firstly, it enables the robotic agent to learn semantics and depth unsupervisedly acting like babies, e.g., ground concepts through active interaction and perceive depth by disparities when moving forward. secondly, ecl is fully transparent and step-by-step interpretable in long-term planning. thirdly, ecl could be beneficial for the embodied instruction following (eif), outperforming previous works on the alfred benchmark when the semantic label is not provided. also, the learned concept can be reused for other downstream tasks, such as reasoning of object states. project page: http://ecl.csail.mit.edu/",,2023-04-07,,"['mingyu ding', 'yan xu', 'zhenfang chen', 'david daniel cox', 'ping luo', 'joshua b. tenenbaum', 'chuang gan']",https://arxiv.org/pdf/2304.03767.pdf
466,2304.03775,biological sequence kernels with guaranteed flexibility,stat.ml cs.lg q-bio.qm,"applying machine learning to biological sequences - dna, rna and protein - has enormous potential to advance human health, environmental sustainability, and fundamental biological understanding. however, many existing machine learning methods are ineffective or unreliable in this problem domain. we study these challenges theoretically, through the lens of kernels. methods based on kernels are ubiquitous: they are used to predict molecular phenotypes, design novel proteins, compare sequence distributions, and more. many methods that do not use kernels explicitly still rely on them implicitly, including a wide variety of both deep learning and physics-based techniques. while kernels for other types of data are well-studied theoretically, the structure of biological sequence space (discrete, variable length sequences), as well as biological notions of sequence similarity, present unique mathematical challenges. we formally analyze how well kernels for biological sequences can approximate arbitrary functions on sequence space and how well they can distinguish different sequence distributions. in particular, we establish conditions under which biological sequence kernels are universal, characteristic and metrize the space of distributions. we show that a large number of existing kernel-based machine learning methods for biological sequences fail to meet our conditions and can as a consequence fail severely. we develop straightforward and computationally tractable ways of modifying existing kernels to satisfy our conditions, imbuing them with strong guarantees on accuracy and reliability. our proof techniques build on and extend the theory of kernels with discrete masses. we illustrate our theoretical results in simulation and on real biological data sets.",,2023-04-06,,"['alan nawzad amin', 'eli nathan weinstein', 'debora susan marks']",https://arxiv.org/pdf/2304.03775.pdf
467,2304.03782,autoqnn: an end-to-end framework for automatically quantizing neural   networks,cs.lg cs.ai cs.cv,"exploring the expected quantizing scheme with suitable mixed-precision policy is the key point to compress deep neural networks (dnns) in high efficiency and accuracy. this exploration implies heavy workloads for domain experts, and an automatic compression method is needed. however, the huge search space of the automatic method introduces plenty of computing budgets that make the automatic process challenging to be applied in real scenarios. in this paper, we propose an end-to-end framework named autoqnn, for automatically quantizing different layers utilizing different schemes and bitwidths without any human labor. autoqnn can seek desirable quantizing schemes and mixed-precision policies for mainstream dnn models efficiently by involving three techniques: quantizing scheme search (qss), quantizing precision learning (qpl), and quantized architecture generation (qag). qss introduces five quantizing schemes and defines three new schemes as a candidate set for scheme search, and then uses the differentiable neural architecture search (dnas) algorithm to seek the layer- or model-desired scheme from the set. qpl is the first method to learn mixed-precision policies by reparameterizing the bitwidths of quantizing schemes, to the best of our knowledge. qpl optimizes both classification loss and precision loss of dnns efficiently and obtains the relatively optimal mixed-precision model within limited model size and memory footprint. qag is designed to convert arbitrary architectures into corresponding quantized ones without manual intervention, to facilitate end-to-end neural network quantization. we have implemented autoqnn and integrated it into keras. extensive experiments demonstrate that autoqnn can consistently outperform state-of-the-art quantization.",10.1007/s11390-022-1632-9,2023-04-07,,"['cheng gong', 'ye lu', 'surong dai', 'deng qian', 'chenkun du', 'tao li']",https://arxiv.org/pdf/2304.03782.pdf
468,2304.03784,generative ai for learning: investigating the potential of synthetic   learning videos,cs.cv cs.ai cs.lg,"recent advances in generative artificial intelligence (ai) have captured worldwide attention. tools such as dalle-2 and chatgpt suggest that tasks previously thought to be beyond the capabilities of ai may now augment the productivity of creative media in various new ways, including through the generation of synthetic video. this research paper explores the utility of using ai-generated synthetic video to create viable educational content for online educational settings. to date, there is limited research investigating the real-world educational value of ai-generated synthetic media. to address this gap, we examined the impact of using ai-generated synthetic video in an online learning platform on both learners content acquisition and learning experience. we took a mixed-method approach, randomly assigning adult learners (n=83) into one of two micro-learning conditions, collecting pre- and post-learning assessments, and surveying participants on their learning experience. the control condition included a traditionally produced instructor video, while the experimental condition included a synthetic video with a realistic ai-generated character. the results show that learners in both conditions demonstrated significant improvement from pre- to post-learning (p<.001), with no significant differences in gains between the two conditions (p=.80). in addition, no differences were observed in how learners perceived the traditional and synthetic videos. these findings suggest that ai-generated synthetic learning videos have the potential to be a viable substitute for videos produced via traditional methods in online educational settings, making high quality educational content more accessible across the globe.",,2023-04-07,,"['daniel leiker', 'ashley ricker gyllen', 'ismail eldesouky', 'mutlu cukurova']",https://arxiv.org/pdf/2304.03784.pdf
469,2304.03805,correcting model misspecification via generative adversarial networks,cs.lg,"machine learning models are often misspecified in the likelihood, which leads to a lack of robustness in the predictions. in this paper, we introduce a framework for correcting likelihood misspecifications in several paradigm agnostic noisy prior models and test the model's ability to remove the misspecification. the ""abc-gan"" framework introduced is a novel generative modeling paradigm, which combines generative adversarial networks (gans) and approximate bayesian computation (abc). this new paradigm assists the existing gans by incorporating any subjective knowledge available about the modeling process via abc, as a regularizer, resulting in a partially interpretable model that operates well under low data regimes. at the same time, unlike any bayesian analysis, the explicit knowledge need not be perfect, since the generator in the gan can be made arbitrarily complex. abc-gan eliminates the need for summary statistics and distance metrics as the discriminator implicitly learns them and enables simultaneous specification of multiple generative models. the model misspecification is simulated in our experiments by introducing noise of various biases and variances. the correction term is learnt via the abc-gan, with skip connections, referred to as skipgan. the strength of the skip connection indicates the amount of correction needed or how misspecified the prior model is. based on a simple experimental setup, we show that the abc-gan models not only correct the misspecification of the prior, but also perform as well as or better than the respective priors under noisier conditions. in this proposal, we show that abc-gans get the best of both worlds.",,2023-04-07,,"['pronoma banerjee', 'manasi v gude', 'rajvi j sampat', 'sharvari m hedaoo', 'soma dhavala', 'snehanshu saha']",https://arxiv.org/pdf/2304.03805.pdf
470,2304.03807,privacy-preserving cnn training with transfer learning,cs.cr cs.cv cs.lg,"privacy-preserving nerual network inference has been well studied while homomorphic cnn training still remains an open challenging task. in this paper, we present a practical solution to implement privacy-preserving cnn training based on mere homomorphic encryption (he) technique. to our best knowledge, this is the first attempt successfully to crack this nut and no work ever before has achieved this goal. several techniques combine to make it done: (1) with transfer learning, privacy-preserving cnn training can be reduced to homomorphic neural network training, or even multiclass logistic regression (mlr) training; (2) via a faster gradient variant called $\texttt{quadratic gradient}$, an enhanced gradient method for mlr with a state-of-the-art performance in converge speed is applied in this work to achieve high performance; (3) we employ the thought of transformation in mathematics to transform approximating softmax function in encryption domain to the well-studied approximation of sigmoid function. a new type of loss function is alongside been developed to complement this change; and (4) we use a simple but flexible matrix-encoding method named $\texttt{volley revolver}$ to manage the data flow in the ciphertexts, which is the key factor to complete the whole homomorphic cnn training. the complete, runnable c++ code to implement our work can be found at: https://github.com/petitioner/he.cnntraining.   we select $\texttt{regnet\_x\_400mf}$ as our pre-train model for using transfer learning. we use the first 128 mnist training images as training data and the whole mnist testing dataset as the testing data. the client only needs to upload 6 ciphertexts to the cloud and it takes $\sim 21$ mins to perform 2 iterations on a cloud with 64 vcpus, resulting in a precision of $21.49\%$.",,2023-04-07,,['john chiang'],https://arxiv.org/pdf/2304.03807.pdf
471,2304.03815,policy poisoning in batch learning for linear quadratic control systems   via state manipulation,eess.sy cs.sy,"in this work, we study policy poisoning through state manipulation, also known as sensor spoofing, and focus specifically on the case of an agent forming a control policy through batch learning in a linear-quadratic (lq) system. in this scenario, an attacker aims to trick the learner into implementing a targeted malicious policy by manipulating the batch data before the agent begins its learning process. an attack model is crafted to carry out the poisoning strategically, with the goal of modifying the batch data as little as possible to avoid detection by the learner. we establish an optimization framework to guide the design of such policy poisoning attacks. the presence of bi-linear constraints in the optimization problem requires the design of a computationally efficient algorithm to obtain a solution. therefore, we develop an iterative scheme based on the alternating direction method of multipliers (admm) which is able to return solutions that are approximately optimal. several case studies are used to demonstrate the effectiveness of the algorithm in carrying out the sensor-based attack on the batch-learning agent in lq control systems.",,2023-04-07,,"['courtney m. king', 'son tung do', 'juntao chen']",https://arxiv.org/pdf/2304.03815.pdf
472,2304.03833,bridging action space mismatch in learning from demonstrations,cs.ro cs.lg,"learning from demonstrations (lfd) methods guide learning agents to a desired solution using demonstrations from a teacher. while some lfd methods can handle small mismatches in the action spaces of the teacher and student, here we address the case where the teacher demonstrates the task in an action space that can be substantially different from that of the student -- thereby inducing a large action space mismatch. we bridge this gap with a framework, morphological adaptation in imitation learning (mail), that allows training an agent from demonstrations by other agents with significantly different morphologies (from the student or each other). mail is able to learn from suboptimal demonstrations, so long as they provide some guidance towards a desired solution. we demonstrate mail on challenging household cloth manipulation tasks and introduce a new dry cloth task -- cloth manipulation in 3d task with obstacles. in these tasks, we train a visual control policy for a robot with one end-effector using demonstrations from a simulated agent with two end-effectors. mail shows up to 27% improvement over lfd and non-lfd baselines. it is deployed to a real franka panda robot, and can handle multiple variations in cloth properties (color, thickness, size, material) and pose (rotation and translation). we further show generalizability to transfers from n-to-m end-effectors, in the context of a simple rearrangement task.",,2023-04-07,,"['gautam salhotra', 'i-chun arthur liu', 'gaurav sukhatme']",https://arxiv.org/pdf/2304.03833.pdf
473,2304.03838,improving identity-robustness for face models,cs.cv cs.ai cs.ds cs.ir cs.lg,"despite the success of deep-learning models in many tasks, there have been concerns about such models learning shortcuts, and their lack of robustness to irrelevant confounders. when it comes to models directly trained on human faces, a sensitive confounder is that of human identities. many face-related tasks should ideally be identity-independent, and perform uniformly across different individuals (i.e. be fair). one way to measure and enforce such robustness and performance uniformity is through enforcing it during training, assuming identity-related information is available at scale. however, due to privacy concerns and also the cost of collecting such information, this is often not the case, and most face datasets simply contain input images and their corresponding task-related labels. thus, improving identity-related robustness without the need for such annotations is of great importance. here, we explore using face-recognition embedding vectors, as proxies for identities, to enforce such robustness. we propose to use the structure in the face-recognition embedding space, to implicitly emphasize rare samples within each class. we do so by weighting samples according to their conditional inverse density (cid) in the proxy embedding space. our experiments suggest that such a simple sample weighting scheme, not only improves the training robustness, it often improves the overall performance as a result of such robustness. we also show that employing such constraints during training results in models that are significantly less sensitive to different levels of bias in the dataset.",,2023-04-07,,"['qi qi', 'shervin ardeshir']",https://arxiv.org/pdf/2304.03838.pdf
474,2304.03840,markov games with decoupled dynamics: price of anarchy and sample   complexity,cs.gt math.oc,"this paper studies the finite-time horizon markov games where the agents' dynamics are decoupled but the rewards can possibly be coupled across agents. the policy class is restricted to local policies where agents make decisions using their local state. we first introduce the notion of smooth markov games which extends the smoothness argument for normal form games to our setting, and leverage the smoothness property to bound the price of anarchy of the markov game. for a specific type of markov game called the markov potential game, we also develop a distributed learning algorithm, multi-agent soft policy iteration (ma-spi), which provably converges to a nash equilibrium. sample complexity of the algorithm is also provided. lastly, our results are validated using a dynamic covering game.",,2023-04-07,,"['runyu zhang', 'yuyang zhang', 'rohit konda', 'bryce ferguson', 'jason marden', 'na li']",https://arxiv.org/pdf/2304.03840.pdf
475,2304.03841,efficient secure aggregation for privacy-preserving federated machine   learning,cs.cr,"federated learning introduces a novel approach to training machine learning (ml) models on distributed data while preserving user's data privacy. this is done by distributing the model to clients to perform training on their local data and computing the final model at a central server. to prevent any data leakage from the local model updates, various works with focus on secure aggregation for privacy preserving federated learning have been proposed. despite their merits, most of the existing protocols still incur high communication and computation overhead on the participating entities and might not be optimized to efficiently handle the large update vectors for ml models. in this paper, we present e-seaml, a novel secure aggregation protocol with high communication and computation efficiency. e-seaml only requires one round of communication in the aggregation phase and it is up to 318x and 1224x faster for the user and the server (respectively) as compared to its most efficient counterpart. e-seaml also allows for efficiently verifying the integrity of the final model by allowing the aggregation server to generate a proof of honest aggregation for the participating users. this high efficiency and versatility is achieved by extending (and weakening) the assumption of the existing works on the set of honest parties (i.e., users) to a set of assisting nodes. therefore, we assume a set of assisting nodes which assist the aggregation server in the aggregation process. we also discuss, given the minimal computation and communication overhead on the assisting nodes, how one could assume a set of rotating users to as assisting nodes in each iteration. we provide the open-sourced implementation of e-seaml for public verifiability and testing.",,2023-04-07,,"['rouzbeh behnia', 'mohammadreza ebrahimi', 'arman riasi', 'balaji padmanabhan', 'thang hoang']",https://arxiv.org/pdf/2304.03841.pdf
476,2304.03844,multilingual augmentation for robust visual question answering in remote   sensing images,cs.cv,"aiming at answering questions based on the content of remotely sensed images, visual question answering for remote sensing data (rsvqa) has attracted much attention nowadays. however, previous works in rsvqa have focused little on the robustness of rsvqa. as we aim to enhance the reliability of rsvqa models, how to learn robust representations against new words and different question templates with the same meaning is the key challenge. with the proposed augmented dataset, we are able to obtain more questions in addition to the original ones with the same meaning. to make better use of this information, in this study, we propose a contrastive learning strategy for training robust rsvqa models against diverse question templates and words. experimental results demonstrate that the proposed augmented dataset is effective in improving the robustness of the rsvqa model. in addition, the contrastive learning strategy performs well on the low resolution (lr) dataset.",,2023-04-07,,"['zhenghang yuan', 'lichao mou', 'xiao xiang zhu']",https://arxiv.org/pdf/2304.03844.pdf
477,2304.03853,stepmix: a python package for pseudo-likelihood estimation of   generalized mixture models with external variables,stat.me cs.lg stat.ml,"stepmix is an open-source software package for the pseudo-likelihood estimation (one-, two- and three-step approaches) of generalized finite mixture models (latent profile and latent class analysis) with external variables (covariates and distal outcomes). in many applications in social sciences, the main objective is not only to cluster individuals into latent classes, but also to use these classes to develop more complex statistical models. these models generally divide into a measurement model that relates the latent classes to observed indicators, and a structural model that relates covariates and outcome variables to the latent classes. the measurement and structural models can be estimated jointly using the so-called one-step approach or sequentially using stepwise methods, which present significant advantages for practitioners regarding the interpretability of the estimated latent classes. in addition to the one-step approach, stepmix implements the most important stepwise estimation methods from the literature, including the bias-adjusted three-step methods with bch and ml corrections and the more recent two-step approach. these pseudo-likelihood estimators are presented in this paper under a unified framework as specific expectation-maximization subroutines. to facilitate and promote their adoption among the data science community, stepmix follows the object-oriented design of the scikit-learn library and provides interfaces in both python and r.",,2023-04-07,2023-04-11,"['sacha morin', 'robin legault', 'zsuzsa bakk', 'charles-√©douard gigu√®re', 'roxane de la sablonni√®re', '√©ric lacourse']",https://arxiv.org/pdf/2304.03853.pdf
478,2304.03854,revisiting deep learning for variable type recovery,cs.lg,"compiled binary executables are often the only available artifact in reverse engineering, malware analysis, and software systems maintenance. unfortunately, the lack of semantic information like variable types makes comprehending binaries difficult. in efforts to improve the comprehensibility of binaries, researchers have recently used machine learning techniques to predict semantic information contained in the original source code. chen et al. implemented dirty, a transformer-based encoder-decoder architecture capable of augmenting decompiled code with variable names and types by leveraging decompiler output tokens and variable size information. chen et al. were able to demonstrate a substantial increase in name and type extraction accuracy on hex-rays decompiler outputs compared to existing static analysis and ai-based techniques. we extend the original dirty results by re-training the dirty model on a dataset produced by the open-source ghidra decompiler. although chen et al. concluded that ghidra was not a suitable decompiler candidate due to its difficulty in parsing and incorporating dwarf symbols during analysis, we demonstrate that straightforward parsing of variable data generated by ghidra results in similar retyping performance. we hope this work inspires further interest and adoption of the ghidra decompiler for use in research projects.",,2023-04-07,,"['kevin cao', 'kevin leach']",https://arxiv.org/pdf/2304.03854.pdf
479,2304.03864,sgdp: a stream-graph neural network based data prefetcher,cs.os cs.dc cs.lg,"data prefetching is important for storage system optimization and access performance improvement. traditional prefetchers work well for mining access patterns of sequential logical block address (lba) but cannot handle complex non-sequential patterns that commonly exist in real-world applications. the state-of-the-art (sota) learning-based prefetchers cover more lba accesses. however, they do not adequately consider the spatial interdependencies between lba deltas, which leads to limited performance and robustness. this paper proposes a novel stream-graph neural network-based data prefetcher (sgdp). specifically, sgdp models lba delta streams using a weighted directed graph structure to represent interactive relations among lba deltas and further extracts hybrid features by graph neural networks for data prefetching. we conduct extensive experiments on eight real-world datasets. empirical results verify that sgdp outperforms the sota methods in terms of the hit ratio by 6.21%, the effective prefetching ratio by 7.00%, and speeds up inference time by 3.13x on average. besides, we generalize sgdp to different variants by different stream constructions, further expanding its application scenarios and demonstrating its robustness. sgdp offers a novel data prefetching solution and has been verified in commercial hybrid storage systems in the experimental phase. our codes and appendix are available at https://github.com/yyysjz1997/sgdp/.",,2023-04-07,,"['yiyuan yang', 'rongshang li', 'qiquan shi', 'xijun li', 'gang hu', 'xing li', 'mingxuan yuan']",https://arxiv.org/pdf/2304.03864.pdf
480,2304.03866,conservative objective models are a special kind of contrastive   divergence-based energy model,stat.ml cs.ai cs.lg,"in this work we theoretically show that conservative objective models (coms) for offline model-based optimisation (mbo) are a special kind of contrastive divergence-based energy model, one where the energy function represents both the unconditional probability of the input and the conditional probability of the reward variable. while the initial formulation only samples modes from its learned distribution, we propose a simple fix that replaces its gradient ascent sampler with a langevin mcmc sampler. this gives rise to a special probabilistic model where the probability of sampling an input is proportional to its predicted reward. lastly, we show that better samples can be obtained if the model is decoupled so that the unconditional and conditional probabilities are modelled separately.",,2023-04-07,,"['christopher beckham', 'christopher pal']",https://arxiv.org/pdf/2304.03866.pdf
481,2304.03867,masked student dataset of expressions,cs.cv cs.hc,"facial expression recognition (fer) algorithms work well in constrained environments with little or no occlusion of the face. however, real-world face occlusion is prevalent, most notably with the need to use a face mask in the current covid-19 scenario. while there are works on the problem of occlusion in fer, little has been done before on the particular face mask scenario. moreover, the few works in this area largely use synthetically created masked fer datasets. motivated by these challenges posed by the pandemic to fer, we present a novel dataset, the masked student dataset of expressions or msd-e, consisting of 1,960 real-world non-masked and masked facial expression images collected from 142 individuals. along with the issue of obfuscated facial features, we illustrate how other subtler issues in masked fer are represented in our dataset. we then provide baseline results using resnet-18, finding that its performance dips in the non-masked case when trained for fer in the presence of masks. to tackle this, we test two training paradigms: contrastive learning and knowledge distillation, and find that they increase the model's performance in the masked scenario while maintaining its non-masked performance. we further visualise our results using t-sne plots and grad-cam, demonstrating that these paradigms capitalise on the limited features available in the masked scenario. finally, we benchmark sota methods on msd-e.",,2023-04-07,,"['sridhar sola', 'darshan gera']",https://arxiv.org/pdf/2304.03867.pdf
482,2304.03868,compact and high-performance tcam based on scaled double-gate fefets,cs.et,"ternary content addressable memory (tcam), widely used in network routers and high-associativity caches, is gaining popularity in machine learning and data-analytic applications. ferroelectric fets (fefets) are a promising candidate for implementing tcam owing to their high on/off ratio, non-volatility, and cmos compatibility. however, conventional single-gate fefets (sg-fefets) suffer from relatively high write voltage, low endurance, potential read disturbance, and face scaling challenges. recently, a double-gate fefet (dg-fefet) has been proposed and outperforms sg-fefets in many aspects. this paper investigates tcam design challenges specific to dg-fefets and introduces a novel 1.5t1fe tcam design based on dg-fefets. a 2-step search with early termination is employed to reduce the cell area and improve energy efficiency. a shared driver design is proposed to reduce the peripherals area. detailed analysis and spice simulation show that the 1.5t1fe dg-tcam leads to superior search speed and energy efficiency. the 1.5t1fe tcam design can also be built with sg-fefets, which achieve search latency and energy improvement compared with 2fefet tcam.",,2023-04-07,2023-04-13,"['liu liu', 'shubham kumar', 'simon thomann', 'yogesh singh chauhan', 'hussam amrouch', 'xiaobo sharon hu']",https://arxiv.org/pdf/2304.03868.pdf
483,2304.03870,aspest: bridging the gap between active learning and selective   prediction,cs.lg,"selective prediction aims to learn a reliable model that abstains from making predictions when the model uncertainty is high. these predictions can then be deferred to a human expert for further evaluation. in many real-world scenarios, however, the distribution of test data is different from the training data. this results in more inaccurate predictions, necessitating increased human labeling, which is difficult and expensive in many scenarios. active learning circumvents this difficulty by only querying the most informative examples and, in several cases, has been shown to lower the overall labeling effort. in this work, we bridge the gap between selective prediction and active learning, proposing a new learning paradigm called active selective prediction which learns to query more informative samples from the shifted target domain while increasing accuracy and coverage. for this new problem, we propose a simple but effective solution, aspest, that trains ensembles of model snapshots using self-training with their aggregated outputs as pseudo labels. extensive experiments on several image, text and structured datasets with domain shifts demonstrate that active selective prediction can significantly outperform prior work on selective prediction and active learning (e.g. on the mnist$\to$svhn benchmark with the labeling budget of 100, aspest improves the auc metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop.",,2023-04-07,,"['jiefeng chen', 'jinsung yoon', 'sayna ebrahimi', 'sercan arik', 'somesh jha', 'tomas pfister']",https://arxiv.org/pdf/2304.03870.pdf
484,2304.03877,ofter: an online pipeline for time series forecasting,stat.ml cs.lg q-fin.st stat.me,"we introduce ofter, a time series forecasting pipeline tailored for mid-sized multivariate time series. ofter utilizes the non-parametric models of k-nearest neighbors and generalized regression neural networks, integrated with a dimensionality reduction component. to circumvent the curse of dimensionality, we employ a weighted norm based on a modified version of the maximal correlation coefficient. the pipeline we introduce is specifically designed for online tasks, has an interpretable output, and is able to outperform several state-of-the art baselines. the computational efficacy of the algorithm, its online nature, and its ability to operate in low signal-to-noise regimes, render ofter an ideal approach for financial multivariate time series problems, such as daily equity forecasting. our work demonstrates that while deep learning models hold significant promise for time series forecasting, traditional methods carefully integrating mainstream tools remain very competitive alternatives with the added benefits of scalability and interpretability.",,2023-04-07,,"['nikolas michael', 'mihai cucuringu', 'sam howison']",https://arxiv.org/pdf/2304.03877.pdf
485,2304.03879,gpt4rec: a generative framework for personalized recommendation and user   interests interpretation,cs.ir cs.lg,"recent advancements in natural language processing (nlp) have led to the development of nlp-based recommender systems that have shown superior performance. however, current models commonly treat items as mere ids and adopt discriminative modeling, resulting in limitations of (1) fully leveraging the content information of items and the language modeling capabilities of nlp models; (2) interpreting user interests to improve relevance and diversity; and (3) adapting practical circumstances such as growing item inventories. to address these limitations, we present gpt4rec, a novel and flexible generative framework inspired by search engines. it first generates hypothetical ""search queries"" given item titles in a user's history, and then retrieves items for recommendation by searching these queries. the framework overcomes previous limitations by learning both user and item embeddings in the language space. to well-capture user interests with different aspects and granularity for improving relevance and diversity, we propose a multi-query generation technique with beam search. the generated queries naturally serve as interpretable representations of user interests and can be searched to recommend cold-start items. with gpt-2 language model and bm25 search engine, our framework outperforms state-of-the-art methods by $75.7\%$ and $22.2\%$ in recall@k on two public datasets. experiments further revealed that multi-query generation with beam search improves both the diversity of retrieved items and the coverage of a user's multi-interests. the adaptiveness and interpretability of generated queries are discussed with qualitative case studies.",,2023-04-07,,"['jinming li', 'wentao zhang', 'tian wang', 'guanglei xiong', 'alan lu', 'gerard medioni']",https://arxiv.org/pdf/2304.03879.pdf
486,2304.03889,diffdock-pp: rigid protein-protein docking with diffusion models,q-bio.bm cs.lg,"understanding how proteins structurally interact is crucial to modern biology, with applications in drug discovery and protein design. recent machine learning methods have formulated protein-small molecule docking as a generative problem with significant performance boosts over both traditional and deep learning baselines. in this work, we propose a similar approach for rigid protein-protein docking: diffdock-pp is a diffusion generative model that learns to translate and rotate unbound protein structures into their bound conformations. we achieve state-of-the-art performance on dips with a median c-rmsd of 4.85, outperforming all considered baselines. additionally, diffdock-pp is faster than all search-based methods and generates reliable confidence estimates for its predictions. our code is publicly available at $\texttt{https://github.com/ketatam/diffdock-pp}$",,2023-04-07,,"['mohamed amine ketata', 'cedrik laue', 'ruslan mammadov', 'hannes st√§rk', 'menghua wu', 'gabriele corso', 'c√©line marquet', 'regina barzilay', 'tommi s. jaakkola']",https://arxiv.org/pdf/2304.03889.pdf
487,2304.03892,towards automated urban planning: when generative and chatgpt-like ai   meets urban planning,cs.ai cs.cy cs.lg,"the two fields of urban planning and artificial intelligence (ai) arose and developed separately. however, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. in the present paper, we introduce the importance of urban planning from the sustainability, living, economic, disaster, and environmental perspectives. we review the fundamental concepts of urban planning and relate these concepts to crucial open problems of machine learning, including adversarial learning, generative neural networks, deep encoder-decoder networks, conversational ai, and geospatial and temporal machine learning, thereby assaying how ai can contribute to modern urban planning. thus, a central problem is automated land-use configuration, which is formulated as the generation of land uses and building configuration for a target area from surrounding geospatial, human mobility, social media, environment, and economic activities. finally, we delineate some implications of ai for urban planning and propose key research areas at the intersection of both topics.",,2023-04-07,,"['dongjie wang', 'chang-tien lu', 'yanjie fu']",https://arxiv.org/pdf/2304.03892.pdf
488,2304.03894,a multifidelity approach to continual learning for physical systems,math.na cs.lg cs.na,"we introduce a novel continual learning method based on multifidelity deep neural networks. this method learns the correlation between the output of previously trained models and the desired output of the model on the current training dataset, limiting catastrophic forgetting. on its own the multifidelity continual learning method shows robust results that limit forgetting across several datasets. additionally, we show that the multifidelity method can be combined with existing continual learning methods, including replay and memory aware synapses, to further limit catastrophic forgetting. the proposed continual learning method is especially suited for physical problems where the data satisfy the same physical laws on each domain, or for physics-informed neural networks, because in these cases we expect there to be a strong correlation between the output of the previous model and the model on the current training domain.",,2023-04-07,,"['amanda howard', 'yucheng fu', 'panos stinis']",https://arxiv.org/pdf/2304.03894.pdf
489,2304.03896,spiking neural networks for detecting satellite-based internet-of-things   signals,cs.it eess.sp math.it,"with the rapid growth of iot networks, ubiquitous coverage is becoming increasingly necessary. low earth orbit (leo) satellite constellations for iot have been proposed to provide coverage to regions where terrestrial systems cannot. however, leo constellations for uplink communications are severely limited by the high density of user devices, which causes a high level of co-channel interference. this research presents a novel framework that utilizes spiking neural networks (snns) to detect iot signals in the presence of uplink interference. the key advantage of snns is the extremely low power consumption relative to traditional deep learning (dl) networks. the performance of the spiking-based neural network detectors is compared against state-of-the-art dl networks and the conventional matched filter detector. results indicate that both dl and snn-based receivers surpass the matched filter detector in interference-heavy scenarios, owing to their capacity to effectively distinguish target signals amidst co-channel interference. moreover, our work highlights the ultra-low power consumption of snns compared to other dl methods for signal detection. the strong detection performance and low power consumption of snns make them particularly suitable for onboard signal detection in iot leo satellites, especially in high interference conditions.",,2023-04-07,,"['kosta dakic', 'bassel al homssi', 'sumeet walia', 'akram al-hourani']",https://arxiv.org/pdf/2304.03896.pdf
490,2304.03898,the short text matching model enhanced with knowledge via contrastive   learning,cs.cl cs.ai,"in recent years, short text matching tasks have been widely applied in the fields ofadvertising search and recommendation. the difficulty lies in the lack of semantic information and word ambiguity caused by the short length of the text. previous works have introduced complement sentences or knowledge bases to provide additional feature information. however, these methods have not fully interacted between the original sentence and the complement sentence, and have not considered the noise issue that may arise from the introduction of external knowledge bases. therefore, this paper proposes a short text matching model that combines contrastive learning and external knowledge. the model uses a generative model to generate corresponding complement sentences and uses the contrastive learning method to guide the model to obtain more semantically meaningful encoding of the original sentence. in addition, to avoid noise, we use keywords as the main semantics of the original sentence to retrieve corresponding knowledge words in the knowledge base, and construct a knowledge graph. the graph encoding model is used to integrate the knowledge base information into the model. our designed model achieves state-of-the-art performance on two publicly available chinese text matching datasets, demonstrating the effectiveness of our model.",,2023-04-07,,"['qiqiang zhong', 'mengmeng cui', 'hanjie mai', 'qiang zhang', 'shaohua xu', 'xiangzheng liu', 'yanlong du']",https://arxiv.org/pdf/2304.03898.pdf
491,2304.03903,high-fidelity clothed avatar reconstruction from a single image,cs.cv cs.ai,"this paper presents a framework for efficient 3d clothed avatar reconstruction. by combining the advantages of the high accuracy of optimization-based methods and the efficiency of learning-based methods, we propose a coarse-to-fine way to realize a high-fidelity clothed avatar reconstruction (car) from a single image. at the first stage, we use an implicit model to learn the general shape in the canonical space of a person in a learning-based way, and at the second stage, we refine the surface detail by estimating the non-rigid deformation in the posed space in an optimization way. a hyper-network is utilized to generate a good initialization so that the convergence o f the optimization process is greatly accelerated. extensive experiments on various datasets show that the proposed car successfully produces high-fidelity avatars for arbitrarily clothed humans in real scenes.",,2023-04-08,,"['tingting liao', 'xiaomei zhang', 'yuliang xiu', 'hongwei yi', 'xudong liu', 'guo-jun qi', 'yong zhang', 'xuan wang', 'xiangyu zhu', 'zhen lei']",https://arxiv.org/pdf/2304.03903.pdf
492,2304.03906,instructbio: a large-scale semi-supervised learning paradigm for   biochemical problems,cs.lg cs.ai cs.ce,"in the field of artificial intelligence for science, it is consistently an essential challenge to face a limited amount of labeled data for real-world problems. the prevailing approach is to pretrain a powerful task-agnostic model on a large unlabeled corpus but may struggle to transfer knowledge to downstream tasks. in this study, we propose instructmol, a semi-supervised learning algorithm, to take better advantage of unlabeled examples. it introduces an instructor model to provide the confidence ratios as the measurement of pseudo-labels' reliability. these confidence scores then guide the target model to pay distinct attention to different data points, avoiding the over-reliance on labeled data and the negative influence of incorrect pseudo-annotations. comprehensive experiments show that instructbio substantially improves the generalization ability of molecular models, in not only molecular property predictions but also activity cliff estimations, demonstrating the superiority of the proposed method. furthermore, our evidence indicates that instructbio can be equipped with cutting-edge pretraining methods and used to establish large-scale and task-specific pseudo-labeled molecular datasets, which reduces the predictive errors and shortens the training process. our work provides strong evidence that semi-supervised learning can be a promising tool to overcome the data scarcity limitation and advance molecular representation learning.",,2023-04-08,,"['fang wu', 'huiling qin', 'wenhao gao', 'siyuan li', 'connor w. coley', 'stan z. li', 'xianyuan zhan', 'jinbo xu']",https://arxiv.org/pdf/2304.03906.pdf
493,2304.03907,stochastic nonlinear control via finite-dimensional spectral dynamic   embedding,cs.lg math.oc,"optimal control is notoriously difficult for stochastic nonlinear systems. ren et al. introduced spectral dynamics embedding for developing reinforcement learning methods for controlling an unknown system. it uses an infinite-dimensional feature to linearly represent the state-value function and exploits finite-dimensional truncation approximation for practical implementation. however, the finite-dimensional approximation properties in control have not been investigated even when the model is known. in this paper, we provide a tractable stochastic nonlinear control algorithm that exploits the nonlinear dynamics upon the finite-dimensional feature approximation, spectral dynamics embedding control (sdec), with an in-depth theoretical analysis to characterize the approximation error induced by the finite-dimension truncation and statistical error induced by finite-sample approximation in both policy evaluation and policy optimization. we also empirically test the algorithm and compare the performance with koopman-based methods and ilqr methods on the pendulum swingup problem.",,2023-04-08,,"['tongzheng ren', 'zhaolin ren', 'na li', 'bo dai']",https://arxiv.org/pdf/2304.03907.pdf
494,2304.03917,mc-mlp:multiple coordinate frames in all-mlp architecture for vision,cs.cv,"in deep learning, multi-layer perceptrons (mlps) have once again garnered attention from researchers. this paper introduces mc-mlp, a general mlp-like backbone for computer vision that is composed of a series of fully-connected (fc) layers. in mc-mlp, we propose that the same semantic information has varying levels of difficulty in learning, depending on the coordinate frame of features. to address this, we perform an orthogonal transform on the feature information, equivalent to changing the coordinate frame of features. through this design, mc-mlp is equipped with multi-coordinate frame receptive fields and the ability to learn information across different coordinate frames. experiments demonstrate that mc-mlp outperforms most mlps in image classification tasks, achieving better performance at the same parameter level. the code will be available at: https://github.com/zzm11/mc-mlp.",,2023-04-08,,"['zhimin zhu', 'jianguo zhao', 'tong mu', 'yuliang yang', 'mengyu zhu']",https://arxiv.org/pdf/2304.03917.pdf
495,2304.03928,interpretable machine learning-accelerated seed treatment by   nanomaterials for environmental stress alleviation,cs.lg stat.ap,"crops are constantly challenged by different environmental conditions. seed treatment by nanomaterials is a cost-effective and environmentally-friendly solution for environmental stress mitigation in crop plants. here, 56 seed nanopriming treatments are used to alleviate environmental stresses in maize. seven selected nanopriming treatments significantly increase the stress resistance index (sri) by 13.9% and 12.6% under salinity stress and combined heat-drought stress, respectively. metabolomics data reveals that zno nanopriming treatment, with the highest sri value, mainly regulates the pathways of amino acid metabolism, secondary metabolite synthesis, carbohydrate metabolism, and translation. understanding the mechanism of seed nanopriming is still difficult due to the variety of nanomaterials and the complexity of interactions between nanomaterials and plants. using the nanopriming data, we present an interpretable structure-activity relationship (isar) approach based on interpretable machine learning for predicting and understanding its stress mitigation effects. the post hoc and model-based interpretation approaches of machine learning are combined to provide complementary benefits and give researchers or policymakers more illuminating or trustworthy results. the concentration, size, and zeta potential of nanoparticles are identified as dominant factors for correlating root dry weight under salinity stress, and their effects and interactions are explained. additionally, a web-based interactive tool is developed for offering prediction-level interpretation and gathering more details about specific nanopriming treatments. this work offers a promising framework for accelerating the agricultural applications of nanomaterials and may profoundly contribute to nanosafety assessment.",,2023-04-08,,"['hengjie yu', 'dan luo', 'sam f. y. li', 'maozhen qu', 'da liu', 'yingchao he', 'fang cheng']",https://arxiv.org/pdf/2304.03928.pdf
496,2304.03931,exploring data geometry for continual learning,cs.cv,"continual learning aims to efficiently learn from a non-stationary stream of data while avoiding forgetting the knowledge of old data. in many practical applications, data complies with non-euclidean geometry. as such, the commonly used euclidean space cannot gracefully capture non-euclidean geometric structures of data, leading to inferior results. in this paper, we study continual learning from a novel perspective by exploring data geometry for the non-stationary stream of data. our method dynamically expands the geometry of the underlying space to match growing geometric structures induced by new data, and prevents forgetting by keeping geometric structures of old data into account. in doing so, making use of the mixed curvature space, we propose an incremental search scheme, through which the growing geometric structures are encoded. then, we introduce an angular-regularization loss and a neighbor-robustness loss to train the model, capable of penalizing the change of global geometric structures and local geometric structures. experiments show that our method achieves better performance than baseline methods designed in euclidean space.",,2023-04-08,,"['zhi gao', 'chen xu', 'feng li', 'yunde jia', 'mehrtash harandi', 'yuwei wu']",https://arxiv.org/pdf/2304.03931.pdf
497,2304.03933,efficient multimodal sampling via tempered distribution flow,stat.me cs.lg stat.co stat.ml,"sampling from high-dimensional distributions is a fundamental problem in statistical research and practice. however, great challenges emerge when the target density function is unnormalized and contains isolated modes. we tackle this difficulty by fitting an invertible transformation mapping, called a transport map, between a reference probability measure and the target distribution, so that sampling from the target distribution can be achieved by pushing forward a reference sample through the transport map. we theoretically analyze the limitations of existing transport-based sampling methods using the wasserstein gradient flow theory, and propose a new method called temperflow that addresses the multimodality issue. temperflow adaptively learns a sequence of tempered distributions to progressively approach the target distribution, and we prove that it overcomes the limitations of existing methods. various experiments demonstrate the superior performance of this novel sampler compared to traditional methods, and we show its applications in modern deep learning tasks such as image generation. the programming code for the numerical experiments is available at https://github.com/yixuan/temperflow.",10.1080/01621459.2023.2198059,2023-04-08,,"['yixuan qiu', 'xiao wang']",https://arxiv.org/pdf/2304.03933.pdf
498,2304.03935,last-layer fairness fine-tuning is simple and effective for neural   networks,cs.lg,"as machine learning has been deployed ubiquitously across applications in modern data science, algorithmic fairness has become a great concern and varieties of fairness criteria have been proposed. among them, imposing fairness constraints during learning, i.e. in-processing fair training, has been a popular type of training method because they don't require accessing sensitive attributes during test time in contrast to post-processing methods. although imposing fairness constraints have been studied extensively for classical machine learning models, the effect these techniques have on deep neural networks is still unclear. recent research has shown that adding fairness constraints to the objective function leads to severe over-fitting to fairness criteria in large models, and how to solve this challenge is an important open question. to address this challenge, we leverage the wisdom and power of pre-training and fine-tuning and develop a simple but novel framework to train fair neural networks in an efficient and inexpensive way. we conduct comprehensive experiments on two popular image datasets with state-of-art architectures under different fairness notions to show that last-layer fine-tuning is sufficient for promoting fairness of the deep neural network. our framework brings new insights into representation learning in training fair neural networks.",,2023-04-08,,"['yuzhen mao', 'zhun deng', 'huaxiu yao', 'ting ye', 'kenji kawaguchi', 'james zou']",https://arxiv.org/pdf/2304.03935.pdf
499,2304.03945,knowledge relation rank enhanced heterogeneous learning interaction   modeling for neural graph forgetting knowledge tracing,cs.lg,"recently, knowledge tracing models have been applied in educational data mining such as the self-attention knowledge tracing model(sakt), which models the relationship between exercises and knowledge concepts(kcs). however, relation modeling in traditional knowledge tracing models only considers the static question-knowledge relationship and knowledge-knowledge relationship and treats these relationships with equal importance. this kind of relation modeling is difficult to avoid the influence of subjective labeling and considers the relationship between exercises and kcs, or kcs and kcs separately. in this work, a novel knowledge tracing model, named knowledge relation rank enhanced heterogeneous learning interaction modeling for neural graph forgetting knowledge tracing(ngfkt), is proposed to reduce the impact of the subjective labeling by calibrating the skill relation matrix and the q-matrix and apply the graph convolutional network(gcn) to model the heterogeneous interactions between students, exercises, and skills. specifically, the skill relation matrix and q-matrix are generated by the knowledge relation importance rank calibration method(krirc). then the calibrated skill relation matrix, q-matrix, and the heterogeneous interactions are treated as the input of the gcn to generate the exercise embedding and skill embedding. next, the exercise embedding, skill embedding, item difficulty, and contingency table are incorporated to generate an exercise relation matrix as the inputs of the position-relation-forgetting attention mechanism. finally, the position-relation-forgetting attention mechanism is applied to make the predictions. experiments are conducted on the two public educational datasets and results indicate that the ngfkt model outperforms all baseline models in terms of auc, acc, and performance stability(ps).",,2023-04-08,,"['linqing li', 'zhifeng wang']",https://arxiv.org/pdf/2304.03945.pdf
500,2304.03947,model-agnostic decentralized collaborative learning for on-device poi   recommendation,cs.ir,"as an indispensable personalized service in location-based social networks (lbsns), the next point-of-interest (poi) recommendation aims to help people discover attractive and interesting places. currently, most poi recommenders are based on the conventional centralized paradigm that heavily relies on the cloud to train the recommendation models with large volumes of collected users' sensitive check-in data. although a few recent works have explored on-device frameworks for resilient and privacy-preserving poi recommendations, they invariably hold the assumption of model homogeneity for parameters/gradients aggregation and collaboration. however, users' mobile devices in the real world have various hardware configurations (e.g., compute resources), leading to heterogeneous on-device models with different architectures and sizes. in light of this, we propose a novel on-device poi recommendation framework, namely model-agnostic collaborative learning for on-device poi recommendation (mac), allowing users to customize their own model structures (e.g., dimension \& number of hidden layers). to counteract the sparsity of on-device user data, we propose to pre-select neighbors for collaboration based on physical distances, category-level preferences, and social networks. to assimilate knowledge from the above-selected neighbors in an efficient and secure way, we adopt the knowledge distillation framework with mutual information maximization. instead of sharing sensitive models/gradients, clients in mac only share their soft decisions on a preloaded reference dataset. to filter out low-quality neighbors, we propose two sampling strategies, performance-triggered sampling and similarity-based sampling, to speed up the training process and obtain optimal recommenders. in addition, we design two novel approaches to generate more effective reference datasets while protecting users' privacy.",,2023-04-08,,"['jing long', 'tong chen', 'nguyen quoc viet hung', 'guandong xu', 'kai zheng', 'hongzhi yin']",https://arxiv.org/pdf/2304.03947.pdf
501,2304.03955,robust deep learning models against semantic-preserving adversarial   attack,cs.lg,"deep learning models can be fooled by small $l_p$-norm adversarial perturbations and natural perturbations in terms of attributes. although the robustness against each perturbation has been explored, it remains a challenge to address the robustness against joint perturbations effectively. in this paper, we study the robustness of deep learning models against joint perturbations by proposing a novel attack mechanism named semantic-preserving adversarial (spa) attack, which can then be used to enhance adversarial training. specifically, we introduce an attribute manipulator to generate natural and human-comprehensible perturbations and a noise generator to generate diverse adversarial noises. based on such combined noises, we optimize both the attribute value and the diversity variable to generate jointly-perturbed samples. for robust training, we adversarially train the deep learning model against the generated joint perturbations. empirical results on four benchmarks show that the spa attack causes a larger performance decline with small $l_{\infty}$ norm-ball constraints compared to existing approaches. furthermore, our spa-enhanced training outperforms existing defense methods against such joint perturbations.",,2023-04-08,,"['dashan gao', 'yunce zhao', 'yinghua yao', 'zeqi zhang', 'bifei mao', 'xin yao']",https://arxiv.org/pdf/2304.03955.pdf
502,2304.03958,keydetect --detection of anomalies and user based on keystroke dynamics,cs.cv cs.cr,"cyber attacks has always been of a great concern. websites and services with poor security layers are the most vulnerable to such cyber attacks. the attackers can easily access sensitive data like credit card details and social security number from such vulnerable services. currently to stop cyber attacks, various different methods are opted from using two-step verification methods like one-time password and push notification services to using high-end bio-metric devices like finger print reader and iris scanner are used as security layers. these current security measures carry a lot of cons and the worst is that user always need to carry the authentication device on them to access their data. to overcome this, we are proposing a technique of using keystroke dynamics (typing pattern) of a user to authenticate the genuine user. in the method, we are taking a data set of 51 users typing a password in 8 sessions done on alternate days to record mood fluctuations of the user. developed and implemented anomaly-detection algorithm based on distance metrics and machine learning algorithms like artificial neural networks (ann) and convolutional neural network (cnn) to classify the users. in ann, we implemented multi-class classification using 1-d convolution as the data was correlated and multi-class classification with negative class which was used to classify anomaly based on all users put together. we were able to achieve an accuracy of 95.05% using ann with negative class. from the results achieved, we can say that the model works perfectly and can be bought into the market as a security layer and a good alternative to two-step verification using external devices. this technique will enable users to have two-step security layer without worrying about carry an authentication device.",,2023-04-08,,"['soumyatattwa kar', 'abhishek bamotra', 'bhavya duvvuri', 'radhika mohanan']",https://arxiv.org/pdf/2304.03958.pdf
503,2304.03969,pump it up: predict water pump status using attentive tabular learning,cs.lg,"water crisis is a crucial concern around the globe. appropriate and timely maintenance of water pumps in drought-hit countries is vital for communities relying on the well. in this paper, we analyze and apply a sequential attentive deep neural architecture, tabnet, for predicting water pump repair status in tanzania. the model combines the valuable benefits of tree-based algorithms and neural networks, enabling end-to-end training, model interpretability, sparse feature selection, and efficient learning on tabular data. finally, we compare the performance of tabnet with popular gradient tree-boosting algorithms like xgboost, lightgbm,catboost, and demonstrate how we can further uplift the performance by choosing focal loss as the objective function while training on imbalanced data.",,2023-04-08,,"['karan pathak', 'l shalini']",https://arxiv.org/pdf/2304.03969.pdf
504,2304.03973,robcaps: evaluating the robustness of capsule networks against affine   transformations and adversarial attacks,cs.lg,"capsule networks (capsnets) are able to hierarchically preserve the pose relationships between multiple objects for image classification tasks. other than achieving high accuracy, another relevant factor in deploying capsnets in safety-critical applications is the robustness against input transformations and malicious adversarial attacks.   in this paper, we systematically analyze and evaluate different factors affecting the robustness of capsnets, compared to traditional convolutional neural networks (cnns). towards a comprehensive comparison, we test two capsnet models and two cnn models on the mnist, gtsrb, and cifar10 datasets, as well as on the affine-transformed versions of such datasets. with a thorough analysis, we show which properties of these architectures better contribute to increasing the robustness and their limitations. overall, capsnets achieve better robustness against adversarial examples and affine transformations, compared to a traditional cnn with a similar number of parameters. similar conclusions have been derived for deeper versions of capsnets and cnns. moreover, our results unleash a key finding that the dynamic routing does not contribute much to improving the capsnets' robustness. indeed, the main generalization contribution is due to the hierarchical feature learning through capsules.",,2023-04-08,,"['alberto marchisio', 'antonio de marco', 'alessio colucci', 'maurizio martina', 'muhammad shafique']",https://arxiv.org/pdf/2304.03973.pdf
505,2304.03977,emp-ssl: towards self-supervised learning in one training epoch,cs.cv cs.ai,"recently, self-supervised learning (ssl) has achieved tremendous success in learning image representation. despite the empirical success, most self-supervised learning methods are rather ""inefficient"" learners, typically taking hundreds of training epochs to fully converge. in this work, we show that the key towards efficient self-supervised learning is to increase the number of crops from each image instance. leveraging one of the state-of-the-art ssl method, we introduce a simplistic form of self-supervised learning method called extreme-multi-patch self-supervised-learning (emp-ssl) that does not rely on many heuristic techniques for ssl such as weight sharing between the branches, feature-wise normalization, output quantization, and stop gradient, etc, and reduces the training epochs by two orders of magnitude. we show that the proposed method is able to converge to 85.1% on cifar-10, 58.5% on cifar-100, 38.1% on tiny imagenet and 58.5% on imagenet-100 in just one epoch. furthermore, the proposed method achieves 91.5% on cifar-10, 70.1% on cifar-100, 51.5% on tiny imagenet and 78.9% on imagenet-100 with linear probing in less than ten training epochs. in addition, we show that emp-ssl shows significantly better transferability to out-of-domain datasets compared to baseline ssl methods. we will release the code in https://github.com/tsb0601/emp-ssl.",,2023-04-08,,"['shengbang tong', 'yubei chen', 'yi ma', 'yann lecun']",https://arxiv.org/pdf/2304.03977.pdf
506,2304.03980,continual learning for lidar semantic segmentation: class-incremental   and coarse-to-fine strategies on sparse data,cs.cv,"during the last few years, continual learning (cl) strategies for image classification and segmentation have been widely investigated designing innovative solutions to tackle catastrophic forgetting, like knowledge distillation and self-inpainting. however, the application of continual learning paradigms to point clouds is still unexplored and investigation is required, especially using architectures that capture the sparsity and uneven distribution of lidar data. the current paper analyzes the problem of class incremental learning applied to point cloud semantic segmentation, comparing approaches and state-of-the-art architectures. to the best of our knowledge, this is the first example of class-incremental continual learning for lidar point cloud semantic segmentation. different cl strategies were adapted to lidar point clouds and tested, tackling both classic fine-tuning scenarios and the coarse-to-fine learning paradigm. the framework has been evaluated through two different architectures on semantickitti, obtaining results in line with state-of-the-art cl strategies and standard offline learning.",,2023-04-08,,"['elena camuffo', 'simone milani']",https://arxiv.org/pdf/2304.03980.pdf
507,2304.03983,discovars: a new data analysis perspective -- application in variable   selection for clustering,cs.lg stat.ml,"we present a new data analysis perspective to determine variable importance regardless of the underlying learning task. traditionally, variable selection is considered an important step in supervised learning for both classification and regression problems. the variable selection also becomes critical when costs associated with the data collection and storage are considerably high for cases like remote sensing. therefore, we propose a new methodology to select important variables from the data by first creating dependency networks among all variables and then ranking them (i.e. nodes) by graph centrality measures. selecting top-$n$ variables according to preferred centrality measure will yield a strong candidate subset of variables for further learning tasks e.g. clustering. we present our tool as a shiny app which is a user-friendly interface development environment. we also extend the user interface for two well-known unsupervised variable selection methods from literature for comparison reasons.",,2023-04-08,,['ayhan demiriz'],https://arxiv.org/pdf/2304.03983.pdf
508,2304.03984,dream: adaptive reinforcement learning based on attention mechanism for   temporal knowledge graph reasoning,cs.ai cs.ir,"temporal knowledge graphs (tkgs) model the temporal evolution of events and have recently attracted increasing attention. since tkgs are intrinsically incomplete, it is necessary to reason out missing elements. although existing tkg reasoning methods have the ability to predict missing future events, they fail to generate explicit reasoning paths and lack explainability. as reinforcement learning (rl) for multi-hop reasoning on traditional knowledge graphs starts showing superior explainability and performance in recent advances, it has opened up opportunities for exploring rl techniques on tkg reasoning. however, the performance of rl-based tkg reasoning methods is limited due to: (1) lack of ability to capture temporal evolution and semantic dependence jointly; (2) excessive reliance on manually designed rewards. to overcome these challenges, we propose an adaptive reinforcement learning model based on attention mechanism (dream) to predict missing elements in the future. specifically, the model contains two components: (1) a multi-faceted attention representation learning method that captures semantic dependence and temporal evolution jointly; (2) an adaptive rl framework that conducts multi-hop reasoning by adaptively learning the reward functions. experimental results demonstrate dream outperforms state-of-the-art models on public dataset",,2023-04-08,,"['shangfei zheng', 'hongzhi yin', 'tong chen', 'quoc viet hung nguyen', 'wei chen', 'lei zhao']",https://arxiv.org/pdf/2304.03984.pdf
509,2304.03996,a unified characterization of private learnability via graph theory,cs.lg,"we provide a unified framework for characterizing pure and approximate differentially private (dp) learnabiliity. the framework uses the language of graph theory: for a concept class $\mathcal{h}$, we define the contradiction graph $g$ of $\mathcal{h}$. it vertices are realizable datasets, and two datasets $s,s'$ are connected by an edge if they contradict each other (i.e., there is a point $x$ that is labeled differently in $s$ and $s'$). our main finding is that the combinatorial structure of $g$ is deeply related to learning $\mathcal{h}$ under dp. learning $\mathcal{h}$ under pure dp is captured by the fractional clique number of $g$. learning $\mathcal{h}$ under approximate dp is captured by the clique number of $g$. consequently, we identify graph-theoretic dimensions that characterize dp learnability: the clique dimension and fractional clique dimension. along the way, we reveal properties of the contradiction graph which may be of independent interest. we also suggest several open questions and directions for future research.",,2023-04-08,,"['noga alon', 'shay moran', 'hilla schefler', 'amir yehudayoff']",https://arxiv.org/pdf/2304.03996.pdf
510,2304.03997,redf: a renewable energy demand forecasting model for smart grids using   long short term memory network,cs.lg cs.ai,"the integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. however, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. in this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. we use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. the proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including american electric power, commonwealth edison, dayton power and light, and pennsylvania-new jersey-maryland interconnection. the proposed model is also compared with two other state of the art forecasting algorithms namely, facebook prophet and support vector regressor. the experimental results show that the proposed redf model can accurately predict energy demand with a mean absolute error of 1.4%. this approach has the potential to improve the efficiency and stability of the power grid by allowing for better management of the integration of renewable energy sources.",,2023-04-08,,"['md saef ullah miah', 'junaida sulaiman', 'md. imamul islam', 'md. masuduzzaman']",https://arxiv.org/pdf/2304.03997.pdf
511,2304.03998,evolving reinforcement learning environment to minimize learner's   achievable reward: an application on hardening active directory systems,cs.ne,"we study a stackelberg game between one attacker and one defender in a configurable environment. the defender picks a specific environment configuration. the attacker observes the configuration and attacks via reinforcement learning (rl trained against the observed environment). the defender's goal is to find the environment with minimum achievable reward for the attacker. we apply evolutionary diversity optimization (edo) to generate diverse population of environments for training. environments with clearly high rewards are killed off and replaced by new offsprings to avoid wasting training time. diversity not only improves training quality but also fits well with our rl scenario: rl agents tend to improve gradually, so a slightly worse environment earlier on may become better later. we demonstrate the effectiveness of our approach by focusing on a specific application, active directory (ad). ad is the default security management system for windows domain networks. ad environment describes an attack graph, where nodes represent computers/accounts/etc., and edges represent accesses. the attacker aims to find the best attack path to reach the highest-privilege node. the defender can change the graph by removing a limited number of edges (revoke accesses). our approach generates better defensive plans than the existing approach and scales better.",,2023-04-08,,"['diksha goel', 'aneta neumann', 'frank neumann', 'hung nguyen', 'mingyu guo']",https://arxiv.org/pdf/2304.03998.pdf
512,2304.04000,simbaml: connecting mechanistic models and machine learning with   augmented data,cs.lg,"training sophisticated machine learning (ml) models requires large datasets that are difficult or expensive to collect for many applications. if prior knowledge about system dynamics is available, mechanistic representations can be used to supplement real-world data. we present simbaml (simulation-based ml), an open-source tool that unifies realistic synthetic dataset generation from ordinary differential equation-based models and the direct analysis and inclusion in ml pipelines. simbaml conveniently enables investigating transfer learning from synthetic to real-world data, data augmentation, identifying needs for data collection, and benchmarking physics-informed ml approaches. simbaml is available from https://pypi.org/project/simba-ml/.",,2023-04-08,,"['maixmilian kleissl', 'lukas drews', 'benedict b. heyder', 'julian zabbarov', 'pascal iversen', 'simon witzke', 'bernhard y. renard', 'katharina baum']",https://arxiv.org/pdf/2304.04000.pdf
513,2304.04008,"infinitely wide limits for deep stable neural networks: sub-linear,   linear and super-linear activation functions",cs.lg stat.ml,"there is a growing literature on the study of large-width properties of deep gaussian neural networks (nns), i.e. deep nns with gaussian-distributed parameters or weights, and gaussian stochastic processes. motivated by some empirical and theoretical studies showing the potential of replacing gaussian distributions with stable distributions, namely distributions with heavy tails, in this paper we investigate large-width properties of deep stable nns, i.e. deep nns with stable-distributed parameters. for sub-linear activation functions, a recent work has characterized the infinitely wide limit of a suitable rescaled deep stable nn in terms of a stable stochastic process, both under the assumption of a ``joint growth"" and under the assumption of a ``sequential growth"" of the width over the nn's layers. here, assuming a ``sequential growth"" of the width, we extend such a characterization to a general class of activation functions, which includes sub-linear, asymptotically linear and super-linear functions. as a novelty with respect to previous works, our results rely on the use of a generalized central limit theorem for heavy tails distributions, which allows for an interesting unified treatment of infinitely wide limits for deep stable nns. our study shows that the scaling of stable nns and the stability of their infinitely wide limits may depend on the choice of the activation function, bringing out a critical difference with respect to the gaussian setting.",,2023-04-08,,"['alberto bordino', 'stefano favaro', 'sandra fortini']",https://arxiv.org/pdf/2304.04008.pdf
514,2304.04010,non-asymptotic approximations of gaussian neural networks via   second-order poincar\'e inequalities,cs.lg stat.ml,"there is a growing interest on large-width asymptotic properties of gaussian neural networks (nns), namely nns whose weights are initialized according to gaussian distributions. a well-established result is that, as the width goes to infinity, a gaussian nn converges in distribution to a gaussian stochastic process, which provides an asymptotic or qualitative gaussian approximation of the nn. in this paper, we introduce some non-asymptotic or quantitative gaussian approximations of gaussian nns, quantifying the approximation error with respect to some popular distances for (probability) distributions, e.g. the $1$-wasserstein distance, the total variation distance and the kolmogorov-smirnov distance. our results rely on the use of second-order gaussian poincar\'e inequalities, which provide tight estimates of the approximation error, with optimal rates. this is a novel application of second-order gaussian poincar\'e inequalities, which are well-known in the probabilistic literature for being a powerful tool to obtain gaussian approximations of general functionals of gaussian stochastic processes. a generalization of our results to deep gaussian nns is discussed.",,2023-04-08,,"['alberto bordino', 'stefano favaro', 'sandra fortini']",https://arxiv.org/pdf/2304.04010.pdf
515,2304.04012,pvd-al: progressive volume distillation with active learning for   efficient conversion between different nerf architectures,cs.cv,"neural radiance fields (nerf) have been widely adopted as practical and versatile representations for 3d scenes, facilitating various downstream tasks. however, different architectures, including plain multi-layer perceptron (mlp), tensors, low-rank tensors, hashtables, and their compositions, have their trade-offs. for instance, hashtables-based representations allow for faster rendering but lack clear geometric meaning, making spatial-relation-aware editing challenging. to address this limitation and maximize the potential of each architecture, we propose progressive volume distillation with active learning (pvd-al), a systematic distillation method that enables any-to-any conversions between different architectures. pvd-al decomposes each structure into two parts and progressively performs distillation from shallower to deeper volume representation, leveraging effective information retrieved from the rendering process. additionally, a three-levels of active learning technique provides continuous feedback during the distillation process, resulting in high-performance results. empirical evidence is presented to validate our method on multiple benchmark datasets. for example, pvd-al can distill an mlp-based model from a hashtables-based model at a 10~20x faster speed and 0.8db~2db higher psnr than training the nerf model from scratch. moreover, pvd-al permits the fusion of diverse features among distinct structures, enabling models with multiple editing properties and providing a more efficient model to meet real-time requirements. project website:http://sk-fun.fun/pvd-al.",,2023-04-08,,"['shuangkang fang', 'yufeng wang', 'yi yang', 'weixin xu', 'heng wang', 'wenrui ding', 'shuchang zhou']",https://arxiv.org/pdf/2304.04012.pdf
516,2304.04016,arithmetic intensity balancing convolution for hardware-aware efficient   block design,cs.lg cs.ar cs.cv,"as deep learning advances, edge devices and lightweight neural networks are becoming more important. to reduce latency in the ai accelerator, it's essential to not only reduce flops but also enhance hardware performance. we proposed an arithmetic intensity balancing convolution (abconv) to address the issue of the overall intensity being limited by the small weight arithmetic intensity for convolution with a small spatial size. abconv increased the maximum bound of overall arithmetic intensity and significantly reduced latency, without sacrificing accuracy. we tested the latency and hardware performance of abconv on the arm ethos-u65 npu in various configurations and used it to replace some of mobilenetv1 and resnet50 in image classification for cifar100.",,2023-04-08,,"['shinkook choi', 'junkyeong choi']",https://arxiv.org/pdf/2304.04016.pdf
517,2304.04017,region-aware portrait retouching with sparse interactive guidance,cs.cv,"portrait retouching aims to improve the aesthetic quality of input portrait photos and especially requires human-region priority. \pink{the deep learning-based methods largely elevate the retouching efficiency and provide promising retouched results. however, existing portrait retouching methods focus on automatic retouching, which treats all human-regions equally and ignores users' preferences for specific individuals,} thus suffering from limited flexibility in interactive scenarios. in this work, we emphasize the importance of users' intents and explore the interactive portrait retouching task. specifically, we propose a region-aware retouching framework with two branches: an automatic branch and an interactive branch. \pink{the automatic branch involves an encoding-decoding process, which searches region candidates and performs automatic region-aware retouching without user guidance. the interactive branch encodes sparse user guidance into a priority condition vector and modulates latent features with a region selection module to further emphasize the user-specified regions. experimental results show that our interactive branch effectively captures users' intents and generalizes well to unseen scenes with sparse user guidance, while our automatic branch also outperforms the state-of-the-art retouching methods due to improved region-awareness.}",,2023-04-08,,"['huimin zeng', 'jie huang', 'jiacheng li', 'zhiwei xiong']",https://arxiv.org/pdf/2304.04017.pdf
518,2304.04022,a reinforcement learning-assisted genetic programming algorithm for team   formation problem considering person-job matching,cs.ne cs.ai cs.lg,"an efficient team is essential for the company to successfully complete new projects. to solve the team formation problem considering person-job matching (tfp-pjm), a 0-1 integer programming model is constructed, which considers both person-job matching and team members' willingness to communicate on team efficiency, with the person-job matching score calculated using intuitionistic fuzzy numbers. then, a reinforcement learning-assisted genetic programming algorithm (rl-gp) is proposed to enhance the quality of solutions. the rl-gp adopts the ensemble population strategies. before the population evolution at each generation, the agent selects one from four population search modes according to the information obtained, thus realizing a sound balance of exploration and exploitation. in addition, surrogate models are used in the algorithm to evaluate the formation plans generated by individuals, which speeds up the algorithm learning process. afterward, a series of comparison experiments are conducted to verify the overall performance of rl-gp and the effectiveness of the improved strategies within the algorithm. the hyper-heuristic rules obtained through efficient learning can be utilized as decision-making aids when forming project teams. this study reveals the advantages of reinforcement learning methods, ensemble strategies, and the surrogate model applied to the gp framework. the diversity and intelligent selection of search patterns along with fast adaptation evaluation, are distinct features that enable rl-gp to be deployed in real-world enterprise environments.",,2023-04-08,,"['yangyang guo', 'hao wang', 'lei he', 'witold pedrycz', 'p. n. suganthan', 'yanjie song']",https://arxiv.org/pdf/2304.04022.pdf
519,2304.04023,attack is good augmentation: towards skeleton-contrastive representation   learning,cs.cv,"contrastive learning, relying on effective positive and negative sample pairs, is beneficial to learn informative skeleton representations in unsupervised skeleton-based action recognition. to achieve these positive and negative pairs, existing weak/strong data augmentation methods have to randomly change the appearance of skeletons for indirectly pursuing semantic perturbations. however, such approaches have two limitations: 1) solely perturbing appearance cannot well capture the intrinsic semantic information of skeletons, and 2) randomly perturbation may change the original positive/negative pairs to soft positive/negative ones. to address the above dilemma, we start the first attempt to explore an attack-based augmentation scheme that additionally brings in direct semantic perturbation, for constructing hard positive pairs and further assisting in constructing hard negative pairs. in particular, we propose a novel attack-augmentation mixing-contrastive learning (a$^2$mc) to contrast hard positive features and hard negative features for learning more robust skeleton representations. in a$^2$mc, attack-augmentation (att-aug) is designed to collaboratively perform targeted and untargeted perturbations of skeletons via attack and augmentation respectively, for generating high-quality hard positive features. meanwhile, positive-negative mixer (pnm) is presented to mix hard positive features and negative features for generating hard negative features, which are adopted for updating the mixed memory banks. extensive experiments on three public datasets demonstrate that a$^2$mc is competitive with the state-of-the-art methods.",,2023-04-08,,"['binqian xu', 'xiangbo shu', 'rui yan', 'guo-sen xie', 'yixiao ge', 'mike zheng shou']",https://arxiv.org/pdf/2304.04023.pdf
520,2304.04029,bipol: a novel multi-axes bias evaluation metric with explainability for   nlp,cs.cl,"we introduce bipol, a new metric with explainability, for estimating social bias in text data. harmful bias is prevalent in many online sources of data that are used for training machine learning (ml) models. in a step to address this challenge we create a novel metric that involves a two-step process: corpus-level evaluation based on model classification and sentence-level evaluation based on (sensitive) term frequency (tf). after creating new models to detect bias along multiple axes using sota architectures, we evaluate two popular nlp datasets (copa and squad). as additional contribution, we created a large dataset (with almost 2 million labelled samples) for training models in bias detection and make it publicly available. we also make public our codes.",,2023-04-08,,"['lama alkhaled', 'tosin adewumi', 'sana sabah sabry']",https://arxiv.org/pdf/2304.04029.pdf
521,2304.04046,regularised learning with selected physics for power system dynamics,eess.sy cs.sy,"due to the increasing system stability issues caused by the technological revolutions of power system equipment, the assessment of the dynamic security of the systems for changing operating conditions (ocs) is nowadays crucial. to address the computational time problem of conventional dynamic security assessment tools, many machine learning (ml) approaches have been proposed and well-studied in this context. however, these learned models only rely on data, and thus miss resourceful information offered by the physical system. to this end, this paper focuses on combining the power system dynamical model together with the conventional ml. going beyond the classic physics informed neural networks (pinns), this paper proposes selected physics informed neural networks (spinns) to predict the system dynamics for varying ocs. a two-level structure of feed-forward nns is proposed, where the first nn predicts the generator bus rotor angles (system states) and the second nn learns to adapt to varying ocs. we show a case study on an ieee-9 bus system that considering selected physics in model training reduces the amount of needed training data. moreover, the trained model effectively predicted long-term dynamics that were beyond the time scale of the collected training dataset (extrapolation).",,2023-04-08,,"['haiwei xie', 'federica bellizio', 'jochen l. cremer', 'goran strbac']",https://arxiv.org/pdf/2304.04046.pdf
522,2304.04049,deep generative modeling with backward stochastic differential equations,cs.lg math.pr stat.ml,"this paper proposes a novel deep generative model, called bsde-gen, which combines the flexibility of backward stochastic differential equations (bsdes) with the power of deep neural networks for generating high-dimensional complex target data, particularly in the field of image generation. the incorporation of stochasticity and uncertainty in the generative modeling process makes bsde-gen an effective and natural approach for generating high-dimensional data. the paper provides a theoretical framework for bsde-gen, describes its model architecture, presents the maximum mean discrepancy (mmd) loss function used for training, and reports experimental results.",,2023-04-08,,['xingcheng xu'],https://arxiv.org/pdf/2304.04049.pdf
523,2304.04051,generating a graph colouring heuristic with deep q-learning and graph   neural networks,cs.lg,"the graph colouring problem consists of assigning labels, or colours, to the vertices of a graph such that no two adjacent vertices share the same colour. in this work we investigate whether deep reinforcement learning can be used to discover a competitive construction heuristic for graph colouring. our proposed approach, relcol, uses deep q-learning together with a graph neural network for feature extraction, and employs a novel way of parameterising the graph that results in improved performance. using standard benchmark graphs with varied topologies, we empirically evaluate the benefits and limitations of the heuristic learned by relcol relative to existing construction algorithms, and demonstrate that reinforcement learning is a promising direction for further research on the graph colouring problem.",,2023-04-08,,"['george watkins', 'giovanni montana', 'juergen branke']",https://arxiv.org/pdf/2304.04051.pdf
524,2304.04058,learning energy-based representations of quantum many-body states,quant-ph cs.lg physics.data-an,"efficient representation of quantum many-body states on classical computers is a problem of enormous practical interest. an ideal representation of a quantum state combines a succinct characterization informed by the system's structure and symmetries, along with the ability to predict the physical observables of interest. a number of machine learning approaches have been recently used to construct such classical representations [1-6] which enable predictions of observables [7] and account for physical symmetries [8]. however, the structure of a quantum state gets typically lost unless a specialized ansatz is employed based on prior knowledge of the system [9-12]. moreover, most such approaches give no information about what states are easier to learn in comparison to others. here, we propose a new generative energy-based representation of quantum many-body states derived from gibbs distributions used for modeling the thermal states of classical spin systems. based on the prior information on a family of quantum states, the energy function can be specified by a small number of parameters using an explicit low-degree polynomial or a generic parametric family such as neural nets, and can naturally include the known symmetries of the system. our results show that such a representation can be efficiently learned from data using exact algorithms in a form that enables the prediction of expectation values of physical observables. importantly, the structure of the learned energy function provides a natural explanation for the hardness of learning for a given class of quantum states.",,2023-04-08,,"['abhijith jayakumar', 'marc vuffray', 'andrey y. lokhov']",https://arxiv.org/pdf/2304.04058.pdf
525,2304.04059,towards open-scenario semi-supervised medical image classification,cs.cv,"semi-supervised learning (ssl) has attracted much attention since it reduces the expensive costs of collecting adequate well-labeled training data, especially for deep learning methods. however, traditional ssl is built upon an assumption that labeled and unlabeled data should be from the same distribution e.g., classes and domains. however, in practical scenarios, unlabeled data would be from unseen classes or unseen domains, and it is still challenging to exploit them by existing ssl methods. therefore, in this paper, we proposed a unified framework to leverage these unseen unlabeled data for open-scenario semi-supervised medical image classification. we first design a novel scoring mechanism, called dual-path outliers estimation, to identify samples from unseen classes. meanwhile, to extract unseen-domain samples, we then apply an effective variational autoencoder (vae) pre-training. after that, we conduct domain adaptation to fully exploit the value of the detected unseen-domain samples to boost semi-supervised training. we evaluated our proposed framework on dermatology and ophthalmology tasks. extensive experiments demonstrate our model can achieve superior classification performance in various medical ssl scenarios.",,2023-04-08,,"['lie ju', 'yicheng wu', 'wei feng', 'zhen yu', 'lin wang', 'zhuoting zhu', 'zongyuan ge']",https://arxiv.org/pdf/2304.04059.pdf
526,2304.04060,application of self-supervised learning to mica model for reconstructing   imperfect 3d facial structures,cs.cv,"in this study, we emphasize the integration of a pre-trained mica model with an imperfect face dataset, employing a self-supervised learning approach. we present an innovative method for regenerating flawed facial structures, yielding 3d printable outputs that effectively support physicians in their patient treatment process. our results highlight the model's capacity for concealing scars and achieving comprehensive facial reconstructions without discernible scarring. by capitalizing on pre-trained models and necessitating only a few hours of supplementary training, our methodology adeptly devises an optimal model for reconstructing damaged and imperfect facial features. harnessing contemporary 3d printing technology, we institute a standardized protocol for fabricating realistic, camouflaging mask models for patients in a laboratory environment.",,2023-04-08,,"['phuong d. nguyen', 'thinh d. le', 'duong q. nguyen', 'binh nguyen', 'h. nguyen-xuan']",https://arxiv.org/pdf/2304.04060.pdf
527,2304.04062,predicting multiple sclerosis disease severity with multimodal deep   neural networks,cs.lg cs.ai,"multiple sclerosis (ms) is a chronic disease developed in human brain and spinal cord, which can cause permanent damage or deterioration of the nerves. the severity of ms disease is monitored by the expanded disability status scale (edss), composed of several functional sub-scores. early and accurate classification of ms disease severity is critical for slowing down or preventing disease progression via applying early therapeutic intervention strategies. recent advances in deep learning and the wide use of electronic health records (ehr) creates opportunities to apply data-driven and predictive modeling tools for this goal. previous studies focusing on using single-modal machine learning and deep learning algorithms were limited in terms of prediction accuracy due to the data insufficiency or model simplicity. in this paper, we proposed an idea of using patients' multimodal longitudinal and longitudinal ehr data to predict multiple sclerosis disease severity at the hospital visit. this work has two important contributions. first, we describe a pilot effort to leverage structured ehr data, neuroimaging data and clinical notes to build a multi-modal deep learning framework to predict patient's ms disease severity. the proposed pipeline demonstrates up to 25% increase in terms of the area under the area under the receiver operating characteristic curve (auroc) compared to models using single-modal data. second, the study also provides insights regarding the amount useful signal embedded in each data modality with respect to ms disease prediction, which may improve data collection processes.",,2023-04-08,,"['kai zhang', 'john a. lincoln', 'xiaoqian jiang', 'elmer v. bernstam', 'shayan shams']",https://arxiv.org/pdf/2304.04062.pdf
528,2304.04066,a barrier-lyapunov actor-critic reinforcement learning approach for safe   and stable control,eess.sy cs.lg cs.ro cs.sy,"reinforcement learning (rl) has demonstrated impressive performance in various areas such as video games and robotics. however, ensuring safety and stability, which are two critical properties from a control perspective, remains a significant challenge when using rl to control real-world systems. in this paper, we first provide definitions of safety and stability for the rl system, and then combine the control barrier function (cbf) and control lyapunov function (clf) methods with the actor-critic method in rl to propose a barrier-lyapunov actor-critic (blac) framework which helps maintain the aforementioned safety and stability for the system. in this framework, cbf constraints for safety and clf constraint for stability are constructed based on the data sampled from the replay buffer, and the augmented lagrangian method is used to update the parameters of the rl-based controller. furthermore, an additional backup controller is introduced in case the rl-based controller cannot provide valid control signals when safety and stability constraints cannot be satisfied simultaneously. simulation results show that this framework yields a controller that can help the system approach the desired state and cause fewer violations of safety constraints compared to baseline algorithms.",,2023-04-08,,"['liqun zhao', 'konstantinos gatsis', 'antonis papachristodoulou']",https://arxiv.org/pdf/2304.04066.pdf
529,2304.04068,word-level persian lipreading dataset,cs.cv,"lip-reading has made impressive progress in recent years, driven by advances in deep learning. nonetheless, the prerequisite such advances is a suitable dataset. this paper provides a new in-the-wild dataset for persian word-level lipreading containing 244,000 videos from approximately 1,800 speakers. we evaluated the state-of-the-art method in this field and used a novel approach for word-level lip-reading. in this method, we used the av-hubert model for feature extraction and obtained significantly better performance on our dataset.",10.1109/iccke57176.2022.9960105,2023-04-08,,"['javad peymanfard', 'ali lashini', 'samin heydarian', 'hossein zeinali', 'nasser mozayani']",https://arxiv.org/pdf/2304.04068.pdf
530,2304.04077,deep prototypical-parts ease morphological kidney stone identification   and are competitively robust to photometric perturbations,cs.cv,"identifying the type of kidney stones can allow urologists to determine their cause of formation, improving the prescription of appropriate treatments to diminish future relapses. currently, the associated ex-vivo diagnosis (known as morpho-constitutional analysis, mca) is time-consuming, expensive and requires a great deal of experience, as it requires a visual analysis component that is highly operator dependant. recently, machine learning methods have been developed for in-vivo endoscopic stone recognition. deep learning (dl) based methods outperform non-dl methods in terms of accuracy but lack explainability. despite this trade-off, when it comes to making high-stakes decisions, it's important to prioritize understandable computer-aided diagnosis (cadx) that suggests a course of action based on reasonable evidence, rather than a model prescribing a course of action. in this proposal, we learn prototypical parts (pps) per kidney stone subtype, which are used by the dl model to generate an output classification. using pps in the classification task enables case-based reasoning explanations for such output, thus making the model interpretable. in addition, we modify global visual characteristics to describe their relevance to the pps and the sensitivity of our model's performance. with this, we provide explanations with additional information at the sample, class and model levels in contrast to previous works. although our implementation's average accuracy is lower than state-of-the-art (sota) non-interpretable dl models by 1.5 %, our models perform 2.8% better on perturbed images with a lower standard deviation, without adversarial training. thus, learning pps has the potential to create more robust dl models.",,2023-04-08,,"['daniel flores-araiza', 'francisco lopez-tiro', 'jonathan el-beze', 'jacques hubert', 'miguel gonzalez-mendoza', 'gilberto ochoa-ruiz', 'christian daul']",https://arxiv.org/pdf/2304.04077.pdf
531,2304.04086,marl-idr: multi-agent reinforcement learning for incentive-based   residential demand response,eess.sy cs.sy,"this paper presents a decentralized multi-agent reinforcement learning (marl) approach to an incentive-based demand response (dr) program, which aims to maintain the capacity limits of the electricity grid and prevent grid congestion by financially incentivizing residential consumers to reduce their energy consumption. the proposed approach addresses the key challenge of coordinating heterogeneous preferences and requirements from multiple participants while preserving their privacy and minimizing financial costs for the aggregator. the participant agents use a novel disjunctively constrained knapsack problem optimization to curtail or shift the requested household appliances based on the selected demand reduction. through case studies with electricity data from $25$ households, the proposed approach effectively reduced energy consumption's peak-to-average ratio (par) by $14.48$% compared to the original par while fully preserving participant privacy. this approach has the potential to significantly improve the efficiency and reliability of the electricity grid, making it an important contribution to the management of renewable energy resources and the growing electricity demand.",,2023-04-08,,"['jasper van tilburg', 'luciano c. siebert', 'jochen l. cremer']",https://arxiv.org/pdf/2304.04086.pdf
532,2304.04087,interpretable multi labeled bengali toxic comments classification using   deep learning,cs.cl cs.ai cs.lg,"this paper presents a deep learning-based pipeline for categorizing bengali toxic comments, in which at first a binary classification model is used to determine whether a comment is toxic or not, and then a multi-label classifier is employed to determine which toxicity type the comment belongs to. for this purpose, we have prepared a manually labeled dataset consisting of 16,073 instances among which 8,488 are toxic and any toxic comment may correspond to one or more of the six toxic categories - vulgar, hate, religious, threat, troll, and insult simultaneously. long short term memory (lstm) with bert embedding achieved 89.42% accuracy for the binary classification task while as a multi-label classifier, a combination of convolutional neural network and bi-directional long short term memory (cnn-bilstm) with attention mechanism achieved 78.92% accuracy and 0.86 as weighted f1-score. to explain the predictions and interpret the word feature importance during classification by the proposed models, we utilized local interpretable model-agnostic explanations (lime) framework. we have made our dataset public and can be accessed at - https://github.com/deepu099cse/multi-labeled-bengali-toxic-comments-classification",,2023-04-08,,"['tanveer ahmed belal', 'g. m. shahariar', 'md. hasanul kabir']",https://arxiv.org/pdf/2304.04087.pdf
533,2304.04090,pdviz: a visual analytics approach for state policy data,cs.hc,"sub-national governments across the united states implement a variety of policies to address large societal problems and needs. many policies are picked up or adopted in other states. this process is called policy diffusion and allows researchers to analyze and compare social, political, and contextual characteristics that lead to adopting certain policies, as well as the efficacy of these policies once adopted. in this paper, we introduce pdviz, a visual analytics approach for social scientists to dynamically analyze the policy diffusion history and underlying patterns. it is designed for analyzing and answering a list of research questions and tasks posed by social scientists in prior work. to evaluate our system, we present two usage scenarios and conduct interviews with domain experts in political science. the interviews highlight that pdviz provides the result of policy diffusion patterns that align with their domain knowledge as well as the potential to be a learning tool for students and researchers to understand the concept of policy diffusion.",10.1111/cgf.14732,2023-04-08,2023-04-12,"['dongyun han', 'abdullah-al-raihan nayeem', 'jason windett', 'isaac cho']",https://arxiv.org/pdf/2304.04090.pdf
534,2304.04091,best arm identification with fairness constraints on subpopulations,cs.lg cs.cy stat.ml,"we formulate, analyze and solve the problem of best arm identification with fairness constraints on subpopulations (baics). standard best arm identification problems aim at selecting an arm that has the largest expected reward where the expectation is taken over the entire population. the baics problem requires that an selected arm must be fair to all subpopulations (e.g., different ethnic groups, age groups, or customer types) by satisfying constraints that the expected reward conditional on every subpopulation needs to be larger than some thresholds. the baics problem aims at correctly identify, with high confidence, the arm with the largest expected reward from all arms that satisfy subpopulation constraints. we analyze the complexity of the baics problem by proving a best achievable lower bound on the sample complexity with closed-form representation. we then design an algorithm and prove that the algorithm's sample complexity matches with the lower bound in terms of order. a brief account of numerical experiments are conducted to illustrate the theoretical findings.",,2023-04-08,,"['yuhang wu', 'zeyu zheng', 'tingyu zhu']",https://arxiv.org/pdf/2304.04091.pdf
535,2304.04095,a simple proof of the mixing of metropolis-adjusted langevin algorithm   under smoothness and isoperimetry,stat.ml cs.cc cs.lg stat.co,"we study the mixing time of metropolis-adjusted langevin algorithm (mala) for sampling a target density on $\mathbb{r}^d$. we assume that the target density satisfies $\psi_\mu$-isoperimetry and that the operator norm and trace of its hessian are bounded by $l$ and $\upsilon$ respectively. our main result establishes that, from a warm start, to achieve $\epsilon$-total variation distance to the target density, mala mixes in $o\left(\frac{(l\upsilon)^{\frac12}}{\psi_\mu^2} \log\left(\frac{1}{\epsilon}\right)\right)$ iterations. notably, this result holds beyond the log-concave sampling setting and the mixing time depends on only $\upsilon$ rather than its upper bound $l d$. in the $m$-strongly logconcave and $l$-log-smooth sampling setting, our bound recovers the previous minimax mixing bound of mala~\cite{wu2021minimax}.",,2023-04-08,,"['yuansi chen', 'khashayar gatmiry']",https://arxiv.org/pdf/2304.04095.pdf
536,2304.04103,tc-vae: uncovering out-of-distribution data generative factors,cs.lg cs.ai cs.it math.it,"uncovering data generative factors is the ultimate goal of disentanglement learning. although many works proposed disentangling generative models able to uncover the underlying generative factors of a dataset, so far no one was able to uncover ood generative factors (i.e., factors of variations that are not explicitly shown on the dataset). moreover, the datasets used to validate these models are synthetically generated using a balanced mixture of some predefined generative factors, implicitly assuming that generative factors are uniformly distributed across the datasets. however, real datasets do not present this property. in this work we analyse the effect of using datasets with unbalanced generative factors, providing qualitative and quantitative results for widely used generative models. moreover, we propose tc-vae, a generative model optimized using a lower bound of the joint total correlation between the learned latent representations and the input data. we show that the proposed model is able to uncover ood generative factors on different datasets and outperforms on average the related baselines in terms of downstream disentanglement metrics.",,2023-04-08,2023-04-10,"['cristian meo', 'anirudh goyal', 'justin dauwels']",https://arxiv.org/pdf/2304.04103.pdf
537,2304.04106,medgen3d: a deep generative framework for paired 3d image and mask   generation,eess.iv cs.cv,"acquiring and annotating sufficient labeled data is crucial in developing accurate and robust learning-based models, but obtaining such data can be challenging in many medical image segmentation tasks. one promising solution is to synthesize realistic data with ground-truth mask annotations. however, no prior studies have explored generating complete 3d volumetric images with masks. in this paper, we present medgen3d, a deep generative framework that can generate paired 3d medical images and masks. first, we represent the 3d medical data as 2d sequences and propose the multi-condition diffusion probabilistic model (mc-dpm) to generate multi-label mask sequences adhering to anatomical geometry. then, we use an image sequence generator and semantic diffusion refiner conditioned on the generated mask sequences to produce realistic 3d medical images that align with the generated masks. our proposed framework guarantees accurate alignment between synthetic images and segmentation maps. experiments on 3d thoracic ct and brain mri datasets show that our synthetic data is both diverse and faithful to the original data, and demonstrate the benefits for downstream segmentation tasks. we anticipate that medgen3d's ability to synthesize paired 3d medical images and masks will prove valuable in training deep learning models for medical imaging tasks.",,2023-04-08,,"['kun han', 'yifeng xiong', 'chenyu you', 'pooya khosravi', 'shanlin sun', 'xiangyi yan', 'james duncan', 'xiaohui xie']",https://arxiv.org/pdf/2304.04106.pdf
538,2304.04117,no code ai: automatic generation of function block diagrams from   documentation and associated heuristic for context-aware ml algorithm   training,cs.se cs.sy eess.sy,industrial process engineering and plc program development have traditionally favored function block diagram (fbd) programming over classical imperative style programming like the object oriented and functional programming paradigms. the increasing momentum in the adoption and trial of ideas now classified as 'no code' or 'low code' alongside the mainstream success of statistical learning theory or the so-called machine learning is redefining the way in which we structure programs for the digital machine to execute. a principal focus of 'no code' is deriving executable programs directly from a set of requirement documents or any other documentation that defines consumer or customer expectation. we present a method for generating function block diagram (fbd) programs as either the intermediate or final artifact that can be executed by a target system from a set of requirement documents using a constrained selection algorithm that draws from the top line of an associated recommender system. the results presented demonstrate that this type of no-code generative model is a viable option for industrial process design.,,2023-04-08,,"['oluwatosin ogundare', 'gustavo quiros araya', 'yassine qamsane']",https://arxiv.org/pdf/2304.04117.pdf
539,2304.04125,training neural networks for execution on approximate hardware,cs.lg cs.ar,"approximate computing methods have shown great potential for deep learning. due to the reduced hardware costs, these methods are especially suitable for inference tasks on battery-operated devices that are constrained by their power budget. however, approximate computing hasn't reached its full potential due to the lack of work on training methods. in this work, we discuss training methods for approximate hardware. we demonstrate how training needs to be specialized for approximate hardware, and propose methods to speed up the training process by up to 18x.",,2023-04-08,,"['tianmu li', 'shurui li', 'puneet gupta']",https://arxiv.org/pdf/2304.04125.pdf
540,2304.04128,"learning agile, vision-based drone flight: from simulation to reality",cs.ro,"we present our latest research in learning deep sensorimotor policies for agile, vision-based quadrotor flight. we show methodologies for the successful transfer of such policies from simulation to the real world. in addition, we discuss the open research questions that still need to be answered to improve the agility and robustness of autonomous drones toward human-pilot performance.",,2023-04-08,,"['davide scaramuzza', 'elia kaufmann']",https://arxiv.org/pdf/2304.04128.pdf
541,2304.04135,propheter: prophetic teacher guided long-tailed distribution learning,cs.cv,"the problem of deep long-tailed learning, a prevalent challenge in the realm of generic visual recognition, persists in a multitude of real-world applications. to tackle the heavily-skewed dataset issue in long-tailed classification, prior efforts have sought to augment existing deep models with the elaborate class-balancing strategies, such as class rebalancing, data augmentation, and module improvement. despite the encouraging performance, the limited class knowledge of the tailed classes in the training dataset still bottlenecks the performance of the existing deep models. in this paper, we propose an innovative long-tailed learning paradigm that breaks the bottleneck by guiding the learning of deep networks with external prior knowledge. this is specifically achieved by devising an elaborated ``prophetic'' teacher, termed as ``propheter'', that aims to learn the potential class distributions. the target long-tailed prediction model is then optimized under the instruction of the well-trained ``propheter'', such that the distributions of different classes are as distinguishable as possible from each other. experiments on eight long-tailed benchmarks across three architectures demonstrate that the proposed prophetic paradigm acts as a promising solution to the challenge of limited class knowledge in long-tailed datasets. our code and model can be found in the supplementary material.",,2023-04-08,,"['wenxiang xu', 'linyun zhou', 'lin chen', 'lechao cheng', 'jie lei', 'zunlei feng', 'mingli song']",https://arxiv.org/pdf/2304.04135.pdf
542,2304.04137,rd-dpp: rate-distortion theory meets determinantal point process to   diversify learning data samples,cs.lg,"in some practical learning tasks, such as traffic video analysis, the number of available training samples is restricted by different factors, such as limited communication bandwidth and computation power; therefore, it is imperative to select diverse data samples that contribute the most to the quality of the learning system. one popular approach to selecting diverse samples is determinantal point process (dpp). however, it suffers from a few known drawbacks, such as restriction of the number of samples to the rank of the similarity matrix, and not being customizable for specific learning tasks (e.g., multi-level classification tasks). in this paper, we propose a new way of measuring task-oriented diversity based on the rate-distortion (rd) theory, appropriate for multi-level classification. to this end, we establish a fundamental relationship between dpp and rd theory, which led to designing rd-dpp, an rd-based value function to evaluate the diversity gain of data samples. we also observe that the upper bound of the diversity of data selected by dpp has a universal trend of phase transition that quickly approaches its maximum point, then slowly converges to its final limits, meaning that dpp is beneficial only at the beginning of sample accumulation. we use this fact to design a bi-modal approach for sequential data selection.",,2023-04-08,,"['xiwen chen', 'huayu li', 'rahul amin', 'abolfazl razi']",https://arxiv.org/pdf/2304.04137.pdf
543,2304.04140,semantic human parsing via scalable semantic transfer over multiple   label domains,cs.cv,"this paper presents scalable semantic transfer (sst), a novel training paradigm, to explore how to leverage the mutual benefits of the data from different label domains (i.e. various levels of label granularity) to train a powerful human parsing network. in practice, two common application scenarios are addressed, termed universal parsing and dedicated parsing, where the former aims to learn homogeneous human representations from multiple label domains and switch predictions by only using different segmentation heads, and the latter aims to learn a specific domain prediction while distilling the semantic knowledge from other domains. the proposed sst has the following appealing benefits: (1) it can capably serve as an effective training scheme to embed semantic associations of human body parts from multiple label domains into the human representation learning process; (2) it is an extensible semantic transfer framework without predetermining the overall relations of multiple label domains, which allows continuously adding human parsing datasets to promote the training. (3) the relevant modules are only used for auxiliary training and can be removed during inference, eliminating the extra reasoning cost. experimental results demonstrate sst can effectively achieve promising universal human parsing performance as well as impressive improvements compared to its counterparts on three human parsing benchmarks (i.e., pascal-person-part, atr, and cihp). code is available at https://github.com/yangjie-cv/sst.",,2023-04-08,,"['jie yang', 'chaoqun wang', 'zhen li', 'junle wang', 'ruimao zhang']",https://arxiv.org/pdf/2304.04140.pdf
544,2304.04142,slideflow: deep learning for digital histopathology with real-time   whole-slide visualization,q-bio.qm cs.cv eess.iv,"deep learning methods have emerged as powerful tools for analyzing histopathological images, but current methods are often specialized for specific domains and software environments, and few open-source options exist for deploying models in an interactive interface. experimenting with different deep learning approaches typically requires switching software libraries and reprocessing data, reducing the feasibility and practicality of experimenting with new architectures. we developed a flexible deep learning library for histopathology called slideflow, a package which supports a broad array of deep learning methods for digital pathology and includes a fast whole-slide interface for deploying trained models. slideflow includes unique tools for whole-slide image data processing, efficient stain normalization and augmentation, weakly-supervised whole-slide classification, uncertainty quantification, feature generation, feature space analysis, and explainability. whole-slide image processing is highly optimized, enabling whole-slide tile extraction at 40x magnification in 2.5 seconds per slide. the framework-agnostic data processing pipeline enables rapid experimentation with new methods built with either tensorflow or pytorch, and the graphical user interface supports real-time visualization of slides, predictions, heatmaps, and feature space characteristics on a variety of hardware devices, including arm-based devices such as the raspberry pi.",,2023-04-08,,"['james m. dolezal', 'sara kochanny', 'emma dyer', 'andrew srisuwananukorn', 'matteo sacco', 'frederick m. howard', 'anran li', 'prajval mohan', 'alexander t. pearson']",https://arxiv.org/pdf/2304.04142.pdf
545,2304.04147,fedpnn: one-shot federated classification via evolving clustering method   and probabilistic neural network hybrid,cs.lg cs.ai,"protecting data privacy is paramount in the fields such as finance, banking, and healthcare. federated learning (fl) has attracted widespread attention due to its decentralized, distributed training and the ability to protect the privacy while obtaining a global shared model. however, fl presents challenges such as communication overhead, and limited resource capability. this motivated us to propose a two-stage federated learning approach toward the objective of privacy protection, which is a first-of-its-kind study as follows: (i) during the first stage, the synthetic dataset is generated by employing two different distributions as noise to the vanilla conditional tabular generative adversarial neural network (ctgan) resulting in modified ctgan, and (ii) in the second stage, the federated probabilistic neural network (fedpnn) is developed and employed for building globally shared classification model. we also employed synthetic dataset metrics to check the quality of the generated synthetic dataset. further, we proposed a meta-clustering algorithm whereby the cluster centers obtained from the clients are clustered at the server for training the global model. despite pnn being a one-pass learning classifier, its complexity depends on the training data size. therefore, we employed a modified evolving clustering method (ecm), another one-pass algorithm to cluster the training data thereby increasing the speed further. moreover, we conducted sensitivity analysis by varying dthr, a hyperparameter of ecm at the server and client, one at a time. the effectiveness of our approach is validated on four finance and medical datasets.",,2023-04-08,,"['polaki durga prasad', 'yelleti vivek', 'vadlamani ravi']",https://arxiv.org/pdf/2304.04147.pdf
546,2304.04150,robopianist: a benchmark for high-dimensional robot control,cs.ro cs.ai,"we introduce a new benchmarking suite for high-dimensional control, targeted at testing high spatial and temporal precision, coordination, and planning, all with an underactuated system frequently making-and-breaking contacts. the proposed challenge is mastering the piano through bi-manual dexterity, using a pair of simulated anthropomorphic robot hands. we call it robopianist, and the initial version covers a broad set of 150 variable-difficulty songs. we investigate both model-free and model-based methods on the benchmark, characterizing their performance envelopes. we observe that while certain existing methods, when well-tuned, can achieve impressive levels of performance in certain aspects, there is significant room for improvement. robopianist provides a rich quantitative benchmarking environment, with human-interpretable results, high ease of expansion by simply augmenting the repertoire with new songs, and opportunities for further research, including in multi-task learning, zero-shot generalization, multimodal (sound, vision, touch) learning, and imitation. supplementary information, including videos of our control policies, can be found at https://kzakka.com/robopianist/",,2023-04-08,,"['kevin zakka', 'laura smith', 'nimrod gileadi', 'taylor howell', 'xue bin peng', 'sumeet singh', 'yuval tassa', 'pete florence', 'andy zeng', 'pieter abbeel']",https://arxiv.org/pdf/2304.04150.pdf
547,2304.04152,continual graph convolutional network for text classification,cs.cl,"graph convolutional network (gcn) has been successfully applied to capture global non-consecutive and long-distance semantic information for text classification. however, while gcn-based methods have shown promising results in offline evaluations, they commonly follow a seen-token-seen-document paradigm by constructing a fixed document-token graph and cannot make inferences on new documents. it is a challenge to deploy them in online systems to infer steaming text data. in this work, we present a continual gcn model (contgcn) to generalize inferences from observed documents to unobserved documents. concretely, we propose a new all-token-any-document paradigm to dynamically update the document-token graph in every batch during both the training and testing phases of an online system. moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update contgcn in a label-free manner. a 3-month a/b test on huawei public opinion analysis system shows contgcn achieves 8.86% performance gain compared with state-of-the-art methods. offline experiments on five public datasets also show contgcn can improve inference quality. the source code will be released at https://github.com/jyonn/contgcn.",,2023-04-08,,"['tiandeng wu', 'qijiong liu', 'yi cao', 'yao huang', 'xiao-ming wu', 'jiandong ding']",https://arxiv.org/pdf/2304.04152.pdf
548,2304.04158,does continual learning equally forget all parameters?,cs.lg,"distribution shift (e.g., task or domain shift) in continual learning (cl) usually results in catastrophic forgetting of neural networks. although it can be alleviated by repeatedly replaying buffered data, the every-step replay is time-consuming. in this paper, we study which modules in neural networks are more prone to forgetting by investigating their training dynamics during cl. our proposed metrics show that only a few modules are more task-specific and sensitively alter between tasks, while others can be shared across tasks as common knowledge. hence, we attribute forgetting mainly to the former and find that finetuning them only on a small buffer at the end of any cl method can bring non-trivial improvement. due to the small number of finetuned parameters, such ``forgetting prioritized finetuning (fpf)'' is efficient in computation. we further propose a more efficient and simpler method that entirely removes the every-step replay and replaces them by only $k$-times of fpf periodically triggered during cl. surprisingly, this ``$k$-fpf'' performs comparably to fpf and outperforms the sota cl methods but significantly reduces their computational overhead and cost. in experiments on several benchmarks of class- and domain-incremental cl, fpf consistently improves existing cl methods by a large margin, and $k$-fpf further excels in efficiency without degrading the accuracy. we also empirically studied the impact of buffer size, epochs per task, and finetuning modules on the cost and accuracy of our methods.",,2023-04-09,,"['haiyan zhao', 'tianyi zhou', 'guodong long', 'jing jiang', 'chengqi zhang']",https://arxiv.org/pdf/2304.04158.pdf
549,2304.04161,detection of covid19 in chest x-ray images using transfer learning,eess.iv cs.cv,"covid19 is a highly contagious disease infected millions of people worldwide. with limited testing components, screening tools such as chest radiography can assist the clinicians in the diagnosis and assessing the progress of disease. the performance of deep learning-based systems for diagnosis of covid-19 disease in radiograph images has been encouraging. this paper investigates the concept of transfer learning using two of the most well-known vggnet architectures, namely vgg-16 and vgg-19. the classifier block and hyperparameters are fine-tuned to adopt the models for automatic detection of covid-19 in chest x-ray images. we generated two different datasets to evaluate the performance of the proposed system for the identification of positive covid-19 instances in a multiclass and binary classification problems. the experimental outcome demonstrates the usefulness of transfer learning for small-sized datasets particularly in the field of medical imaging, not only to prevent over-fitting and convergence problems but also to attain optimal classification performance as well.",,2023-04-09,,['zanoby n. khan'],https://arxiv.org/pdf/2304.04161.pdf
550,2304.04162,design of two-level incentive mechanisms for hierarchical federated   learning,cs.gt cs.dc cs.lg,"hierarchical federated learning (hfl) is a distributed machine learning paradigm tailored for multi-tiered computation architectures, which supports massive access of devices' models simultaneously. to enable efficient hfl, it is crucial to design suitable incentive mechanisms to ensure that devices actively participate in local training. however, there are few studies on incentive mechanism design for hfl. in this paper, we design two-level incentive mechanisms for the hfl with a two-tiered computing structure to encourage the participation of entities in each tier in the hfl training. in the lower-level game, we propose a coalition formation game to joint optimize the edge association and bandwidth allocation problem, and obtain efficient coalition partitions by the proposed preference rule, which can be proven to be stable by exact potential game. in the upper-level game, we design the stackelberg game algorithm, which not only determines the optimal number of edge aggregations for edge servers to maximize their utility, but also optimize the unit reward provided for the edge aggregation performance to ensure the interests of cloud servers. furthermore, numerical results indicate that the proposed algorithms can achieve better performance than the benchmark schemes.",,2023-04-09,,"['shunfeng chu', 'jun li', 'kang wei', 'yuwen qian', 'kunlun wang', 'feng shu', 'wen chen']",https://arxiv.org/pdf/2304.04162.pdf
551,2304.04164,gradient sparsification for efficient wireless federated learning with   differential privacy,cs.dc cs.ai cs.cr,"federated learning (fl) enables distributed clients to collaboratively train a machine learning model without sharing raw data with each other. however, it suffers the leakage of private information from uploading models. in addition, as the model size grows, the training latency increases due to limited transmission bandwidth and the model performance degrades while using differential privacy (dp) protection. in this paper, we propose a gradient sparsification empowered fl framework over wireless channels, in order to improve training efficiency without sacrificing convergence performance. specifically, we first design a random sparsification algorithm to retain a fraction of the gradient elements in each client's local training, thereby mitigating the performance degradation induced by dp and and reducing the number of transmission parameters over wireless channels. then, we analyze the convergence bound of the proposed algorithm, by modeling a non-convex fl problem. next, we formulate a time-sequential stochastic optimization problem for minimizing the developed convergence bound, under the constraints of transmit power, the average transmitting delay, as well as the client's dp requirement. utilizing the lyapunov drift-plus-penalty framework, we develop an analytical solution to the optimization problem. extensive experiments have been implemented on three real life datasets to demonstrate the effectiveness of our proposed algorithm. we show that our proposed algorithms can fully exploit the interworking between communication and computation to outperform the baselines, i.e., random scheduling, round robin and delay-minimization algorithms.",,2023-04-09,,"['kang wei', 'jun li', 'chuan ma', 'ming ding', 'haitao zhao', 'wen chen', 'hongbo zhu']",https://arxiv.org/pdf/2304.04164.pdf
552,2304.04166,experience-based evolutionary algorithms for expensive optimization,cs.ne cs.lg,"optimization algorithms are very different from human optimizers. a human being would gain more experiences through problem-solving, which helps her/him in solving a new unseen problem. yet an optimization algorithm never gains any experiences by solving more problems. in recent years, efforts have been made towards endowing optimization algorithms with some abilities of experience learning, which is regarded as experience-based optimization. in this paper, we argue that hard optimization problems could be tackled efficiently by making better use of experiences gained in related problems. we demonstrate our ideas in the context of expensive optimization, where we aim to find a near-optimal solution to an expensive optimization problem with as few fitness evaluations as possible. to achieve this, we propose an experience-based surrogate-assisted evolutionary algorithm (saea) framework to enhance the optimization efficiency of expensive problems, where experiences are gained across related expensive tasks via a novel meta-learning method. these experiences serve as the task-independent parameters of a deep kernel learning surrogate, then the solutions sampled from the target task are used to adapt task-specific parameters for the surrogate. with the help of experience learning, competitive regression-based surrogates can be initialized using only 1$d$ solutions from the target task ($d$ is the dimension of the decision space). our experimental results on expensive multi-objective and constrained optimization problems demonstrate that experiences gained from related tasks are beneficial for the saving of evaluation budgets on the target problem.",,2023-04-09,,"['xunzhao yu', 'yan wang', 'ling zhu', 'dimitar filev', 'xin yao']",https://arxiv.org/pdf/2304.04166.pdf
553,2304.04169,slowcal-sgd: slow query points improve local-sgd for stochastic convex   optimization,cs.lg math.oc,"we consider distributed learning scenarios where m machines interact with a parameter server along several communication rounds in order to minimize a joint objective function. focusing on the heterogeneous case, where different machines may draw samples from different data-distributions, we design the first local update method that provably benefits over the two most prominent distributed baselines: namely minibatch-sgd and local-sgd. key to our approach is a slow querying technique that we customize to the distributed setting, which in turn enables a better mitigation of the bias caused by local updates.",,2023-04-09,,['kfir y. levy'],https://arxiv.org/pdf/2304.04169.pdf
554,2304.04171,learning to tokenize for generative retrieval,cs.ir,"conventional document retrieval techniques are mainly based on the index-retrieve paradigm. it is challenging to optimize pipelines based on this paradigm in an end-to-end manner. as an alternative, generative retrieval represents documents as identifiers (docid) and retrieves documents by generating docids, enabling end-to-end modeling of document retrieval tasks. however, it is an open question how one should define the document identifiers. current approaches to the task of defining document identifiers rely on fixed rule-based docids, such as the title of a document or the result of clustering bert embeddings, which often fail to capture the complete semantic information of a document. we propose genret, a document tokenization learning method to address the challenge of defining document identifiers for generative retrieval. genret learns to tokenize documents into short discrete representations (i.e., docids) via a discrete auto-encoding approach. three components are included in genret: (i) a tokenization model that produces docids for documents; (ii) a reconstruction model that learns to reconstruct a document based on a docid; and (iii) a sequence-to-sequence retrieval model that generates relevant document identifiers directly for a designated query. by using an auto-encoding framework, genret learns semantic docids in a fully end-to-end manner. we also develop a progressive training scheme to capture the autoregressive nature of docids and to stabilize training. we conduct experiments on the nq320k, ms marco, and beir datasets to assess the effectiveness of genret. genret establishes the new state-of-the-art on the nq320k dataset. especially, compared to generative retrieval baselines, genret can achieve significant improvements on the unseen documents. genret also outperforms comparable baselines on ms marco and beir, demonstrating the method's generalizability.",,2023-04-09,,"['weiwei sun', 'lingyong yan', 'zheng chen', 'shuaiqiang wang', 'haichao zhu', 'pengjie ren', 'zhumin chen', 'dawei yin', 'maarten de rijke', 'zhaochun ren']",https://arxiv.org/pdf/2304.04171.pdf
555,2304.04172,$\mu^2$-sgd: stable stochastic optimization via a double momentum   mechanism,cs.lg math.oc,"we consider stochastic convex optimization problems where the objective is an expectation over smooth functions. for this setting we suggest a novel gradient estimate that combines two recent mechanism that are related to notion of momentum. then, we design an sgd-style algorithm as well as an accelerated version that make use of this new estimator, and demonstrate the robustness of these new approaches to the choice of the learning rate. concretely, we show that these approaches obtain the optimal convergence rates for both noiseless and noisy case with the same choice of fixed learning rate. moreover, for the noisy case we show that these approaches achieve the same optimal bound for a very wide range of learning rates.",,2023-04-09,,['kfir y. levy'],https://arxiv.org/pdf/2304.04172.pdf
556,2304.04175,token boosting for robust self-supervised visual transformer   pre-training,cs.cv,"learning with large-scale unlabeled data has become a powerful tool for pre-training visual transformers (vts). however, prior works tend to overlook that, in real-world scenarios, the input data may be corrupted and unreliable. pre-training vts on such corrupted data can be challenging, especially when we pre-train via the masked autoencoding approach, where both the inputs and masked ``ground truth"" targets can potentially be unreliable in this case. to address this limitation, we introduce the token boosting module (tbm) as a plug-and-play component for vts that effectively allows the vt to learn to extract clean and robust features during masked autoencoding pre-training. we provide theoretical analysis to show how tbm improves model pre-training with more robust and generalizable representations, thus benefiting downstream tasks. we conduct extensive experiments to analyze tbm's effectiveness, and results on four corrupted datasets demonstrate that tbm consistently improves performance on downstream tasks.",,2023-04-09,2023-04-12,"['tianjiao li', 'lin geng foo', 'ping hu', 'xindi shang', 'hossein rahmani', 'zehuan yuan', 'jun liu']",https://arxiv.org/pdf/2304.04175.pdf
557,2304.04179,sparse dense fusion for 3d object detection,cs.cv,"with the prevalence of multimodal learning, camera-lidar fusion has gained popularity in 3d object detection. although multiple fusion approaches have been proposed, they can be classified into either sparse-only or dense-only fashion based on the feature representation in the fusion module. in this paper, we analyze them in a common taxonomy and thereafter observe two challenges: 1) sparse-only solutions preserve 3d geometric prior and yet lose rich semantic information from the camera, and 2) dense-only alternatives retain the semantic continuity but miss the accurate geometric information from lidar. by analyzing these two formulations, we conclude that the information loss is inevitable due to their design scheme. to compensate for the information loss in either manner, we propose sparse dense fusion (sdf), a complementary framework that incorporates both sparse-fusion and dense-fusion modules via the transformer architecture. such a simple yet effective sparse-dense fusion structure enriches semantic texture and exploits spatial structure information simultaneously. through our sdf strategy, we assemble two popular methods with moderate performance and outperform baseline by 4.3% in map and 2.5% in nds, ranking first on the nuscenes benchmark. extensive ablations demonstrate the effectiveness of our method and empirically align our analysis.",,2023-04-09,,"['yulu gao', 'chonghao sima', 'shaoshuai shi', 'shangzhe di', 'si liu', 'hongyang li']",https://arxiv.org/pdf/2304.04179.pdf
558,2304.04187,similarity-aware multimodal prompt learning for fake news detection,cs.cl,"the standard paradigm for fake news detection mainly utilizes text information to model the truthfulness of news. however, the discourse of online fake news is typically subtle and it requires expert knowledge to use textual information to debunk fake news. recently, studies focusing on multimodal fake news detection have outperformed text-only methods. recent approaches utilizing the pre-trained model to extract unimodal features, or fine-tuning the pre-trained model directly, have become a new paradigm for detecting fake news. again, this paradigm either requires a large number of training instances, or updates the entire set of pre-trained model parameters, making real-world fake news detection impractical. furthermore, traditional multimodal methods fuse the cross-modal features directly without considering that the uncorrelated semantic representation might inject noise into the multimodal features. this paper proposes a similarity-aware multimodal prompt learning (sample) framework. first, we incorporate prompt learning into multimodal fake news detection. prompt learning, which only tunes prompts with a frozen language model, can reduce memory usage significantly and achieve comparable performances, compared with fine-tuning. we analyse three prompt templates with a soft verbalizer to detect fake news. in addition, we introduce the similarity-aware fusing method to adaptively fuse the intensity of multimodal representation and mitigate the noise injection via uncorrelated cross-modal features. for evaluation, sample surpasses the f1 and the accuracies of previous works on two benchmark multimodal datasets, demonstrating the effectiveness of the proposed method in detecting fake news. in addition, sample also is superior to other approaches regardless of few-shot and data-rich settings.",,2023-04-09,,"['ye jiang', 'xiaomin yu', 'yimin wang', 'xiaoman xu', 'xingyi song', 'diana maynard']",https://arxiv.org/pdf/2304.04187.pdf
559,2304.04193,extractive summarization via chatgpt for faithful summary generation,cs.cl,"extractive summarization is a crucial task in natural language processing that aims to condense long documents into shorter versions by directly extracting sentences. the recent introduction of chatgpt has attracted significant interest in the nlp community due to its remarkable performance on a wide range of downstream tasks. however, concerns regarding factuality and faithfulness have hindered its practical applications for summarization systems. this paper first presents a thorough evaluation of chatgpt's performance on extractive summarization and compares it with traditional fine-tuning methods on various benchmark datasets. our experimental analysis reveals that chatgpt's extractive summarization performance is still inferior to existing supervised systems in terms of rouge scores. in addition, we explore the effectiveness of in-context learning and chain-of-thought reasoning for enhancing its performance. furthermore, we find that applying an extract-then-generate pipeline with chatgpt yields significant performance improvements over abstractive baselines in terms of summary faithfulness. these observations highlight potential directions for enhancing chatgpt's capabilities for faithful text summarization tasks using two-stage approaches.",,2023-04-09,,"['haopeng zhang', 'xiao liu', 'jiawei zhang']",https://arxiv.org/pdf/2304.04193.pdf
560,2304.04200,dsmnet: deep high-precision 3d surface modeling from sparse point cloud   frames,cs.cv cs.ro,"existing point cloud modeling datasets primarily express the modeling precision by pose or trajectory precision rather than the point cloud modeling effect itself. under this demand, we first independently construct a set of lidar system with an optical stage, and then we build a hpmb dataset based on the constructed lidar system, a high-precision, multi-beam, real-world dataset. second, we propose an modeling evaluation method based on hpmb for object-level modeling to overcome this limitation. in addition, the existing point cloud modeling methods tend to generate continuous skeletons of the global environment, hence lacking attention to the shape of complex objects. to tackle this challenge, we propose a novel learning-based joint framework, dsmnet, for high-precision 3d surface modeling from sparse point cloud frames. dsmnet comprises density-aware point cloud registration (pcr) and geometry-aware point cloud sampling (pcs) to effectively learn the implicit structure feature of sparse point clouds. extensive experiments demonstrate that dsmnet outperforms the state-of-the-art methods in pcs and pcr on multi-view partial point cloud (mvp) database. furthermore, the experiments on the open source kitti and our proposed hpmb datasets show that dsmnet can be generalized as a post-processing of simultaneous localization and mapping (slam), thereby improving modeling precision in environments with sparse point clouds.",,2023-04-09,,"['changjie qiu', 'zhiyong wang', 'xiuhong lin', 'yu zang', 'cheng wang', 'weiquan liu']",https://arxiv.org/pdf/2304.04200.pdf
561,2304.04205,shape-erased feature learning for visible-infrared person   re-identification,cs.cv,"due to the modality gap between visible and infrared images with high visual ambiguity, learning \textbf{diverse} modality-shared semantic concepts for visible-infrared person re-identification (vi-reid) remains a challenging problem. body shape is one of the significant modality-shared cues for vi-reid. to dig more diverse modality-shared cues, we expect that erasing body-shape-related semantic concepts in the learned features can force the reid model to extract more and other modality-shared features for identification. to this end, we propose shape-erased feature learning paradigm that decorrelates modality-shared features in two orthogonal subspaces. jointly learning shape-related feature in one subspace and shape-erased features in the orthogonal complement achieves a conditional mutual information maximization between shape-erased feature and identity discarding body shape information, thus enhancing the diversity of the learned representation explicitly. extensive experiments on sysu-mm01, regdb, and hitsz-vcm datasets demonstrate the effectiveness of our method.",,2023-04-09,,"['jiawei feng', 'ancong wu', 'wei-shi zheng']",https://arxiv.org/pdf/2304.04205.pdf
562,2304.04218,automated prompting for non-overlapping cross-domain sequential   recommendation,cs.ir,"cross-domain recommendation (cr) has been extensively studied in recent years to alleviate the data sparsity issue in recommender systems by utilizing different domain information. in this work, we focus on the more general non-overlapping cross-domain sequential recommendation (ncsr) scenario. ncsr is challenging because there are no overlapped entities (e.g., users and items) between domains, and there is only users' implicit feedback and no content information. previous cr methods cannot solve ncsr well, since (1) they either need extra content to align domains or need explicit domain alignment constraints to reduce the domain discrepancy from domain-invariant features, (2) they pay more attention to users' explicit feedback (i.e., users' rating data) and cannot well capture their sequential interaction patterns, (3) they usually do a single-target cross-domain recommendation task and seldom investigate the dual-target ones. considering the above challenges, we propose prompt learning-based cross-domain recommender (plcr), an automated prompting-based recommendation framework for the ncsr task. specifically, to address the challenge (1), plcr resorts to learning domain-invariant and domain-specific representations via its prompt learning component, where the domain alignment constraint is discarded. for challenges (2) and (3), plcr introduces a pre-trained sequence encoder to learn users' sequential interaction patterns, and conducts a dual-learning target with a separation constraint to enhance recommendations in both domains. our empirical study on two sub-collections of amazon demonstrates the advance of plcr compared with some related sota methods.",,2023-04-09,,"['lei guo', 'chunxiao wang', 'xinhua wang', 'lei zhu', 'hongzhi yin']",https://arxiv.org/pdf/2304.04218.pdf
563,2304.04220,towards active learning for action spotting in association football   videos,cs.cv,"association football is a complex and dynamic sport, with numerous actions occurring simultaneously in each game. analyzing football videos is challenging and requires identifying subtle and diverse spatio-temporal patterns. despite recent advances in computer vision, current algorithms still face significant challenges when learning from limited annotated data, lowering their performance in detecting these patterns. in this paper, we propose an active learning framework that selects the most informative video samples to be annotated next, thus drastically reducing the annotation effort and accelerating the training of action spotting models to reach the highest accuracy at a faster pace. our approach leverages the notion of uncertainty sampling to select the most challenging video clips to train on next, hastening the learning process of the algorithm. we demonstrate that our proposed active learning framework effectively reduces the required training data for accurate action spotting in football videos. we achieve similar performances for action spotting with netvlad++ on soccernet-v2, using only one-third of the dataset, indicating significant capabilities for reducing annotation time and improving data efficiency. we further validate our approach on two new datasets that focus on temporally localizing actions of headers and passes, proving its effectiveness across different action semantics in football. we believe our active learning framework for action spotting would support further applications of action spotting algorithms and accelerate annotation campaigns in the sports domain.",,2023-04-09,,"['silvio giancola', 'anthony cioppa', 'julia georgieva', 'johsan billingham', 'andreas serner', 'kerry peek', 'bernard ghanem', 'marc van droogenbroeck']",https://arxiv.org/pdf/2304.04220.pdf
564,2304.04222,ciliate: towards fairer class-based incremental learning by dataset and   training refinement,cs.lg cs.ai cs.cy cs.se,"due to the model aging problem, deep neural networks (dnns) need updates to adjust them to new data distributions. the common practice leverages incremental learning (il), e.g., class-based incremental learning (cil) that updates output labels, to update the model with new data and a limited number of old data. this avoids heavyweight training (from scratch) using conventional methods and saves storage space by reducing the number of old data to store. but it also leads to poor performance in fairness. in this paper, we show that cil suffers both dataset and algorithm bias problems, and existing solutions can only partially solve the problem. we propose a novel framework, ciliate, that fixes both dataset and algorithm bias in cil. it features a novel differential analysis guided dataset and training refinement process that identifies unique and important samples overlooked by existing cil and enforces the model to learn from them. through this process, ciliate improves the fairness of cil by 17.03%, 22.46%, and 31.79% compared to state-of-the-art methods, icarl, bic, and wa, respectively, based on our evaluation on three popular datasets and widely used resnet models.",,2023-04-09,,"['xuanqi gao', 'juan zhai', 'shiqing ma', 'chao shen', 'yufei chen', 'shiwei wang']",https://arxiv.org/pdf/2304.04222.pdf
565,2304.04228,unsupervised multi-criteria adversarial detection in deep image   retrieval,cs.cv cs.ir,"the vulnerability in the algorithm supply chain of deep learning has imposed new challenges to image retrieval systems in the downstream. among a variety of techniques, deep hashing is gaining popularity. as it inherits the algorithmic backend from deep learning, a handful of attacks are recently proposed to disrupt normal image retrieval. unfortunately, the defense strategies in softmax classification are not readily available to be applied in the image retrieval domain. in this paper, we propose an efficient and unsupervised scheme to identify unique adversarial behaviors in the hamming space. in particular, we design three criteria from the perspectives of hamming distance, quantization loss and denoising to defend against both untargeted and targeted attacks, which collectively limit the adversarial space. the extensive experiments on four datasets demonstrate 2-23% improvements of detection rates with minimum computational overhead for real-time image queries.",,2023-04-09,,"['yanru xiao', 'cong wang', 'xing gao']",https://arxiv.org/pdf/2304.04228.pdf
566,2304.04231,crowdclip: unsupervised crowd counting via vision-language model,cs.cv,"supervised crowd counting relies heavily on costly manual labeling, which is difficult and expensive, especially in dense scenes. to alleviate the problem, we propose a novel unsupervised framework for crowd counting, named crowdclip. the core idea is built on two observations: 1) the recent contrastive pre-trained vision-language model (clip) has presented impressive performance on various downstream tasks; 2) there is a natural mapping between crowd patches and count text. to the best of our knowledge, crowdclip is the first to investigate the vision language knowledge to solve the counting problem. specifically, in the training stage, we exploit the multi-modal ranking loss by constructing ranking text prompts to match the size-sorted crowd patches to guide the image encoder learning. in the testing stage, to deal with the diversity of image patches, we propose a simple yet effective progressive filtering strategy to first select the highly potential crowd patches and then map them into the language space with various counting intervals. extensive experiments on five challenging datasets demonstrate that the proposed crowdclip achieves superior performance compared to previous unsupervised state-of-the-art counting methods. notably, crowdclip even surpasses some popular fully-supervised methods under the cross-dataset setting. the source code will be available at https://github.com/dk-liang/crowdclip.",,2023-04-09,,"['dingkang liang', 'jiahao xie', 'zhikang zou', 'xiaoqing ye', 'wei xu', 'xiang bai']",https://arxiv.org/pdf/2304.04231.pdf
567,2304.04234,variational operator learning: a unified paradigm for training neural   operators and solving partial differential equations,cs.lg cs.na math.na,"based on the variational method, we propose a novel paradigm that provides a unified framework of training neural operators and solving partial differential equations (pdes) with the variational form, which we refer to as the variational operator learning (vol). we first derive the functional approximation of the system from the node solution prediction given by neural operators, and then conduct the variational operation by automatic differentiation, constructing a forward-backward propagation loop to derive the residual of the linear system. one or several update steps of the steepest decent method (sd) and the conjugate gradient method (cg) are provided in every iteration as a cheap yet effective update for training the neural operators. experimental results show the proposed vol can learn a variety of solution operators in pdes of the steady heat transfer and the variable stiffness elasticity with satisfactory results and small error. the proposed vol achieves nearly label-free training. only five to ten labels are used for the output distribution-shift session in all experiments. generalization benefits of the vol are investigated and discussed.",,2023-04-09,,"['tengfei xu', 'dachuan liu', 'peng hao', 'bo wang']",https://arxiv.org/pdf/2304.04234.pdf
568,2304.04237,slide-transformer: hierarchical vision transformer with local   self-attention,cs.cv,"self-attention mechanism has been a key factor in the recent progress of vision transformer (vit), which enables adaptive feature extraction from global contexts. however, existing self-attention methods either adopt sparse global attention or window attention to reduce the computation complexity, which may compromise the local feature learning or subject to some handcrafted designs. in contrast, local attention, which restricts the receptive field of each query to its own neighboring pixels, enjoys the benefits of both convolution and self-attention, namely local inductive bias and dynamic feature selection. nevertheless, current local attention modules either use inefficient im2col function or rely on specific cuda kernels that are hard to generalize to devices without cuda support. in this paper, we propose a novel local attention module, slide attention, which leverages common convolution operations to achieve high efficiency, flexibility and generalizability. specifically, we first re-interpret the column-based im2col function from a new row-based perspective and use depthwise convolution as an efficient substitution. on this basis, we propose a deformed shifting module based on the re-parameterization technique, which further relaxes the fixed key/value positions to deformed features in the local region. in this way, our module realizes the local attention paradigm in both efficient and flexible manner. extensive experiments show that our slide attention module is applicable to a variety of advanced vision transformer models and compatible with various hardware devices, and achieves consistently improved performances on comprehensive benchmarks. code is available at https://github.com/leaplabthu/slide-transformer.",,2023-04-09,,"['xuran pan', 'tianzhu ye', 'zhuofan xia', 'shiji song', 'gao huang']",https://arxiv.org/pdf/2304.04237.pdf
569,2304.04240,data-driven multinomial random forest,stat.ml cs.lg,"in this article, we strengthen the proof methods of some previously weakly consistent variants of random forests into strongly consistent proof methods, and improve the data utilization of these variants, in order to obtain better theoretical properties and experimental performance. in addition, based on the multinomial random forest (mrf) and bernoulli random forest (brf), we propose a data-driven multinomial random forest (dmrf) algorithm, which has lower complexity than mrf and higher complexity than brf while satisfying strong consistency. it has better performance in classification and regression problems than previous rf variants that only satisfy weak consistency, and in most cases even surpasses standard random forest. to the best of our knowledge, dmrf is currently the most excellent strongly consistent rf variant with low algorithm complexity",,2023-04-09,,"['junhao chen', 'xueli wang']",https://arxiv.org/pdf/2304.04240.pdf
570,2304.04248,curricular object manipulation in lidar-based object detection,cs.cv,"this paper explores the potential of curriculum learning in lidar-based 3d object detection by proposing a curricular object manipulation (com) framework. the framework embeds the curricular training strategy into both the loss design and the augmentation process. for the loss design, we propose the comloss to dynamically predict object-level difficulties and emphasize objects of different difficulties based on training stages. on top of the widely-used augmentation technique called gt-aug in lidar detection tasks, we propose a novel comaug strategy which first clusters objects in ground-truth database based on well-designed heuristics. group-level difficulties rather than individual ones are then predicted and updated during training for stable results. model performance and generalization capabilities can be improved by sampling and augmenting progressively more difficult objects into the training samples. extensive experiments and ablation studies reveal the superior and generality of the proposed framework. the code is available at https://github.com/zzy816/com.",,2023-04-09,,"['ziyue zhu', 'qiang meng', 'xiao wang', 'ke wang', 'liujiang yan', 'jian yang']",https://arxiv.org/pdf/2304.04248.pdf
571,2304.04250,editable user profiles for controllable text recommendation,cs.ir cs.cl cs.hc cs.lg,"methods for making high-quality recommendations often rely on learning latent representations from interaction data. these methods, while performant, do not provide ready mechanisms for users to control the recommendation they receive. our work tackles this problem by proposing lace, a novel concept value bottleneck model for controllable text recommendations. lace represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents and learns personalized representations of the concepts based on user documents. this concept based user profile is then leveraged to make recommendations. the design of our model affords control over the recommendations through a number of intuitive interactions with a transparent user profile. we first establish the quality of recommendations obtained from lace in an offline evaluation on three recommendation tasks spanning six datasets in warm-start, cold-start, and zero-shot setups. next, we validate the controllability of lace under simulated user interactions. finally, we implement lace in an interactive controllable recommender system and conduct a user study to demonstrate that users are able to improve the quality of recommendations they receive through interactions with an editable user profile.",,2023-04-09,,"['sheshera mysore', 'mahmood jasim', 'andrew mccallum', 'hamed zamani']",https://arxiv.org/pdf/2304.04250.pdf
572,2304.04258,"a note on ""efficient task-specific data valuation for nearest neighbor   algorithms""",stat.ml cs.lg,"data valuation is a growing research field that studies the influence of individual data points for machine learning (ml) models. data shapley, inspired by cooperative game theory and economics, is an effective method for data valuation. however, it is well-known that the shapley value (sv) can be computationally expensive. fortunately, jia et al. (2019) showed that for k-nearest neighbors (knn) models, the computation of data shapley is surprisingly simple and efficient.   in this note, we revisit the work of jia et al. (2019) and propose a more natural and interpretable utility function that better reflects the performance of knn models. we derive the corresponding calculation procedure for the data shapley of knn classifiers/regressors with the new utility functions. our new approach, dubbed soft-label knn-sv, achieves the same time complexity as the original method. we further provide an efficient approximation algorithm for soft-label knn-sv based on locality sensitive hashing (lsh). our experimental results demonstrate that soft-label knn-sv outperforms the original method on most datasets in the task of mislabeled data detection, making it a better baseline for future work on data valuation.",,2023-04-09,,"['jiachen t. wang', 'ruoxi jia']",https://arxiv.org/pdf/2304.04258.pdf
573,2304.04259,clvos23: a long video object segmentation dataset for continual learning,cs.cv cs.lg,"continual learning in real-world scenarios is a major challenge. a general continual learning model should have a constant memory size and no predefined task boundaries, as is the case in semi-supervised video object segmentation (vos), where continual learning challenges particularly present themselves in working on long video sequences. in this article, we first formulate the problem of semi-supervised vos, specifically online vos, as a continual learning problem, and then secondly provide a public vos dataset, clvos23, focusing on continual learning. finally, we propose and implement a regularization-based continual learning approach on lwl, an existing online vos baseline, to demonstrate the efficacy of continual learning when applied to online vos and to establish a clvos23 baseline. we apply the proposed baseline to the long videos dataset as well as to two short video vos datasets, davis16 and davis17. to the best of our knowledge, this is the first time that vos has been defined and addressed as a continual learning problem.",,2023-04-09,,"['amir nazemi', 'zeyad moustafa', 'paul fieguth']",https://arxiv.org/pdf/2304.04259.pdf
574,2304.04271,embarrassingly simple mixup for time-series,cs.lg cs.ai,"labeling time series data is an expensive task because of domain expertise and dynamic nature of the data. hence, we often have to deal with limited labeled data settings. data augmentation techniques have been successfully deployed in domains like computer vision to exploit the use of existing labeled data. we adapt one of the most commonly used technique called mixup, in the time series domain. our proposed, mixup++ and latentmixup++, use simple modifications to perform interpolation in raw time series and classification model's latent space, respectively. we also extend these methods with semi-supervised learning to exploit unlabeled data. we observe significant improvements of 1\% - 15\% on time series classification on two public datasets, for both low labeled data as well as high labeled data regimes, with latentmixup++.",,2023-04-09,,"['karan aggarwal', 'jaideep srivastava']",https://arxiv.org/pdf/2304.04271.pdf
575,2304.04273,multimodal brain-computer interface for in-vehicle driver cognitive load   measurement: dataset and baselines,cs.lg cs.hc eess.sp,"through this paper, we introduce a novel driver cognitive load assessment dataset, cl-drive, which contains electroencephalogram (eeg) signals along with other physiological signals such as electrocardiography (ecg) and electrodermal activity (eda) as well as eye tracking data. the data was collected from 21 subjects while driving in an immersive vehicle simulator, in various driving conditions, to induce different levels of cognitive load in the subjects. the tasks consisted of 9 complexity levels for 3 minutes each. each driver reported their subjective cognitive load every 10 seconds throughout the experiment. the dataset contains the subjective cognitive load recorded as ground truth. in this paper, we also provide benchmark classification results for different machine learning and deep learning models for both binary and ternary label distributions. we followed 2 evaluation criteria namely 10-fold and leave-one-subject-out (loso). we have trained our models on both hand-crafted features as well as on raw data.",,2023-04-09,,"['prithila angkan', 'behnam behinaein', 'zunayed mahmud', 'anubhav bhatti', 'dirk rodenburg', 'paul hungler', 'ali etemad']",https://arxiv.org/pdf/2304.04273.pdf
576,2304.04282,higher-order uncoupled dynamics do not lead to nash equilibrium --   except when they do,cs.gt,"the framework of multi-agent learning explores the dynamics of how individual agent strategies evolve in response to the evolving strategies of other agents. of particular interest is whether or not agent strategies converge to well known solution concepts such as nash equilibrium (ne). most ``fixed order'' learning dynamics restrict an agent's underlying state to be its own strategy. in ``higher order'' learning, agent dynamics can include auxiliary states that can capture phenomena such as path dependencies. we introduce higher-order gradient play dynamics that resemble projected gradient ascent with auxiliary states. the dynamics are ``payoff based'' in that each agent's dynamics depend on its own evolving payoff. while these payoffs depend on the strategies of other agents in a game setting, agent dynamics do not depend explicitly on the nature of the game or the strategies of other agents. in this sense, dynamics are ``uncoupled'' since an agent's dynamics do not depend explicitly on the utility functions of other agents. we first show that for any specific game with an isolated completely mixed-strategy ne, there exist higher-order gradient play dynamics that lead (locally) to that ne, both for the specific game and nearby games with perturbed utility functions. conversely, we show that for any higher-order gradient play dynamics, there exists a game with a unique isolated completely mixed-strategy ne for which the dynamics do not lead to ne. these results build on prior work that showed that uncoupled fixed-order learning cannot lead to ne in certain instances, whereas higher-order variants can. finally, we consider the mixed-strategy equilibrium associated with coordination games. while higher-order gradient play can converge to such equilibria, we show such dynamics must be inherently internally unstable.",,2023-04-09,2023-04-12,"['sarah a. toonsi', 'jeff s. shamma']",https://arxiv.org/pdf/2304.04282.pdf
577,2304.04290,distributed conditional gan (discgan) for synthetic healthcare data   generation,cs.lg cs.ai,"in this paper, we propose a distributed generative adversarial networks (discgans) to generate synthetic tabular data specific to the healthcare domain. while using gans to generate images has been well studied, little to no attention has been given to generation of tabular data. modeling distributions of discrete and continuous tabular data is a non-trivial task with high utility. we applied discgan to model non-gaussian multi-modal healthcare data. we generated 249,000 synthetic records from original 2,027 eicu dataset. we evaluated the performance of the model using machine learning efficacy, the kolmogorov-smirnov (ks) test for continuous variables and chi-squared test for discrete variables. our results show that discgan was able to generate data with distributions similar to the real data.",,2023-04-09,,"['david fuentes', 'diana mcspadden', 'sodiq adewole']",https://arxiv.org/pdf/2304.04290.pdf
578,2304.04291,foramvit-gan: exploring new paradigms in deep learning for   micropaleontological image analysis,cs.cv eess.iv,"micropaleontology in geosciences focuses on studying the evolution of microfossils (e.g., foraminifera) through geological records to reconstruct past environmental and climatic conditions. this field heavily relies on visual recognition of microfossil features, making it suitable for computer vision technology, specifically deep convolutional neural networks (cnns), to automate and optimize microfossil identification and classification. however, the application of deep learning in micropaleontology is hindered by limited availability of high-quality, high-resolution labeled fossil images and the significant manual labeling effort required by experts. to address these challenges, we propose a novel deep learning workflow combining hierarchical vision transformers with style-based generative adversarial network algorithms to efficiently acquire and synthetically generate realistic high-resolution labeled datasets of micropaleontology in large volumes. our study shows that this workflow can generate high-resolution images with a high signal-to-noise ratio (39.1 db) and realistic synthetic images with a frechet inception distance similarity score of 14.88. additionally, our workflow provides a large volume of self-labeled datasets for model benchmarking and various downstream visual tasks, including fossil classification and segmentation. for the first time, we performed few-shot semantic segmentation of different foraminifera chambers on both generated and synthetic images with high accuracy. this novel meta-learning approach is only possible with the availability of high-resolution, high-volume labeled datasets. our deep learning-based workflow shows promise in advancing and optimizing micropaleontological research and other visual-dependent geological analyses.",,2023-04-09,,"['ivan ferreira-chacua', 'ardiansyah koeshidayatullah']",https://arxiv.org/pdf/2304.04291.pdf
579,2304.04292,proof generation for cdcl solvers using gauss-jordan elimination,cs.lo,"traditional boolean satisfiability (sat) solvers based on the conflict-driven clause-learning (cdcl) framework fare poorly on formulas involving large numbers of parity constraints. the cryptominisat solver augments cdcl with gauss-jordan elimination to greatly improve performance on these formulas. integrating the tbuddy proof-generating bdd library into cryptominisat enables it to generate unsatisfiability proofs when using gauss-jordan elimination. these proofs are compatible with standard, clausal proof frameworks.",,2023-04-09,,"['mate soos', 'randal e. bryant']",https://arxiv.org/pdf/2304.04292.pdf
580,2304.04300,class-imbalanced learning on graphs: a survey,cs.lg cs.ai,"the rapid advancement in data-driven research has increased the demand for effective graph data analysis. however, real-world data often exhibits class imbalance, leading to poor performance of machine learning models. to overcome this challenge, class-imbalanced learning on graphs (cilg) has emerged as a promising solution that combines the strengths of graph representation learning and class-imbalanced learning. in recent years, significant progress has been made in cilg. anticipating that such a trend will continue, this survey aims to offer a comprehensive understanding of the current state-of-the-art in cilg and provide insights for future research directions. concerning the former, we introduce the first taxonomy of existing work and its connection to existing imbalanced learning literature. concerning the latter, we critically analyze recent work in cilg and discuss urgent lines of inquiry within the topic. moreover, we provide a continuously maintained reading list of papers and code at https://github.com/yihongma/cilg-papers.",,2023-04-09,,"['yihong ma', 'yijun tian', 'nuno moniz', 'nitesh v. chawla']",https://arxiv.org/pdf/2304.04300.pdf
581,2304.04307,priorcvae: scalable mcmc parameter inference with bayesian deep   generative modelling,stat.ml cs.lg,"in applied fields where the speed of inference and model flexibility are crucial, the use of bayesian inference for models with a stochastic process as their prior, e.g. gaussian processes (gps) is ubiquitous. recent literature has demonstrated that the computational bottleneck caused by gp priors or their finite realizations can be encoded using deep generative models such as variational autoencoders (vaes), and the learned generators can then be used instead of the original priors during markov chain monte carlo (mcmc) inference in a drop-in manner. while this approach enables fast and highly efficient inference, it loses information about the stochastic process hyperparameters, and, as a consequence, makes inference over hyperparameters impossible and the learned priors indistinct. we propose to resolve this issue and disentangle the learned priors by conditioning the vae on stochastic process hyperparameters. this way, the hyperparameters are encoded alongside gp realisations and can be explicitly estimated at the inference stage. we believe that the new method, termed priorcvae, will be a useful tool among approximate inference approaches and has the potential to have a large impact on spatial and spatiotemporal inference in crucial real-life applications. code showcasing priorcvae can be found on github: https://github.com/elizavetasemenova/priorcvae",,2023-04-09,2023-04-12,"['elizaveta semenova', 'max cairney-leeming', 'seth flaxman']",https://arxiv.org/pdf/2304.04307.pdf
582,2304.04309,large language models for business process management: opportunities and   challenges,cs.se,"large language models are deep learning models with a large number of parameters. the models made noticeable progress on a large number of tasks, and as a consequence allowing them to serve as valuable and versatile tools for a diverse range of applications. their capabilities also offer opportunities for business process management, however, these opportunities have not yet been systematically investigated. in this paper, we address this research problem by foregrounding various management tasks of the bpm lifecycle. we investigate six research directions highlighting problems that need to be addressed when using large language models, including usage guidelines for practitioners.",,2023-04-09,,"['maxim vidgof', 'stefan bachhofner', 'jan mendling']",https://arxiv.org/pdf/2304.04309.pdf
583,2304.04312,theoretical characterization of the generalization performance of   overfitted meta-learning,cs.lg,"meta-learning has arisen as a successful method for improving training performance by training over many similar tasks, especially with deep neural networks (dnns). however, the theoretical understanding of when and why overparameterized models such as dnns can generalize well in meta-learning is still limited. as an initial step towards addressing this challenge, this paper studies the generalization performance of overfitted meta-learning under a linear regression model with gaussian features. in contrast to a few recent studies along the same line, our framework allows the number of model parameters to be arbitrarily larger than the number of features in the ground truth signal, and hence naturally captures the overparameterized regime in practical deep meta-learning. we show that the overfitted min $\ell_2$-norm solution of model-agnostic meta-learning (maml) can be beneficial, which is similar to the recent remarkable findings on ``benign overfitting'' and ``double descent'' phenomenon in the classical (single-task) linear regression. however, due to the uniqueness of meta-learning such as task-specific gradient descent inner training and the diversity/fluctuation of the ground-truth signals among training tasks, we find new and interesting properties that do not exist in single-task linear regression. we first provide a high-probability upper bound (under reasonable tightness) on the generalization error, where certain terms decrease when the number of features increases. our analysis suggests that benign overfitting is more significant and easier to observe when the noise and the diversity/fluctuation of the ground truth of each training task are large. under this circumstance, we show that the overfitted min $\ell_2$-norm solution can achieve an even lower generalization error than the underparameterized solution.",,2023-04-09,,"['peizhong ju', 'yingbin liang', 'ness b. shroff']",https://arxiv.org/pdf/2304.04312.pdf
584,2304.04321,arnold: a benchmark for language-grounded task learning with continuous   states in realistic 3d scenes,cs.ai cs.cl cs.cv cs.ro,"understanding the continuous states of objects is essential for task learning and planning in the real world. however, most existing task learning benchmarks assume discrete(e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. furthermore, state discretization limits a robot's ability to follow human instructions based on the grounding of actions and states. to tackle these challenges, we present arnold, a benchmark that evaluates language-grounded task learning with continuous states in realistic 3d scenes. arnold is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. to promote language-instructed learning, we provide expert demonstrations with template-generated language descriptions. we assess task performance by utilizing the latest language-conditioned policy learning models. our results indicate that current models for language-conditioned manipulations continue to experience significant challenges in novel goal-state generalizations, scene generalizations, and object generalizations. these findings highlight the need to develop new algorithms that address this gap and underscore the potential for further research in this area. see our project page at: https://arnold-benchmark.github.io",,2023-04-09,,"['ran gong', 'jiangyong huang', 'yizhou zhao', 'haoran geng', 'xiaofeng gao', 'qingyang wu', 'wensi ai', 'ziheng zhou', 'demetri terzopoulos', 'song-chun zhu', 'baoxiong jia', 'siyuan huang']",https://arxiv.org/pdf/2304.04321.pdf
585,2304.04325,self-supervised learning of object segmentation from unlabeled rgb-d   videos,cs.cv cs.ro,"this work proposes a self-supervised learning system for segmenting rigid objects in rgb images. the proposed pipeline is trained on unlabeled rgb-d videos of static objects, which can be captured with a camera carried by a mobile robot. a key feature of the self-supervised training process is a graph-matching algorithm that operates on the over-segmentation output of the point cloud that is reconstructed from each video. the graph matching, along with point cloud registration, is able to find reoccurring object patterns across videos and combine them into 3d object pseudo labels, even under occlusions or different viewing angles. projected 2d object masks from 3d pseudo labels are used to train a pixel-wise feature extractor through contrastive learning. during online inference, a clustering method uses the learned features to cluster foreground pixels into object segments. experiments highlight the method's effectiveness on both real and synthetic video datasets, which include cluttered scenes of tabletop objects. the proposed method outperforms existing unsupervised methods for object segmentation by a large margin.",,2023-04-09,,"['shiyang lu', 'yunfu deng', 'abdeslam boularias', 'kostas bekris']",https://arxiv.org/pdf/2304.04325.pdf
586,2304.04326,homogenizing non-iid datasets via in-distribution knowledge distillation   for decentralized learning,cs.lg cs.dc,"decentralized learning enables serverless training of deep neural networks (dnns) in a distributed manner on multiple nodes. this allows for the use of large datasets, as well as the ability to train with a wide variety of data sources. however, one of the key challenges with decentralized learning is heterogeneity in the data distribution across the nodes. in this paper, we propose in-distribution knowledge distillation (idkd) to address the challenge of heterogeneous data distribution. the goal of idkd is to homogenize the data distribution across the nodes. while such data homogenization can be achieved by exchanging data among the nodes sacrificing privacy, idkd achieves the same objective using a common public dataset across nodes without breaking the privacy constraint. this public dataset is different from the training dataset and is used to distill the knowledge from each node and communicate it to its neighbors through the generated labels. with traditional knowledge distillation, the generalization of the distilled model is reduced because all the public dataset samples are used irrespective of their similarity to the local dataset. thus, we introduce an out-of-distribution (ood) detector at each node to label a subset of the public dataset that maps close to the local training data distribution. finally, only labels corresponding to these subsets are exchanged among the nodes and with appropriate label averaging each node is finetuned on these data subsets along with its local data. our experiments on multiple image classification datasets and graph topologies show that the proposed idkd scheme is more effective than traditional knowledge distillation and achieves state-of-the-art generalization performance on heterogeneously distributed data with minimal communication overhead.",,2023-04-09,,"['deepak ravikumar', 'gobinda saha', 'sai aparna aketi', 'kaushik roy']",https://arxiv.org/pdf/2304.04326.pdf
587,2304.04330,pretrained embeddings for e-commerce machine learning: when it fails and   why?,cs.lg,"the use of pretrained embeddings has become widespread in modern e-commerce machine learning (ml) systems. in practice, however, we have encountered several key issues when using pretrained embedding in a real-world production system, many of which cannot be fully explained by current knowledge. unfortunately, we find that there is a lack of a thorough understanding of how pre-trained embeddings work, especially their intrinsic properties and interactions with downstream tasks. consequently, it becomes challenging to make interactive and scalable decisions regarding the use of pre-trained embeddings in practice.   our investigation leads to two significant discoveries about using pretrained embeddings in e-commerce applications. firstly, we find that the design of the pretraining and downstream models, particularly how they encode and decode information via embedding vectors, can have a profound impact. secondly, we establish a principled perspective of pre-trained embeddings via the lens of kernel analysis, which can be used to evaluate their predictability, interactively and scalably. these findings help to address the practical challenges we faced and offer valuable guidance for successful adoption of pretrained embeddings in real-world production. our conclusions are backed by solid theoretical reasoning, benchmark experiments, as well as online testings.",10.1145/3543873.3587669,2023-04-09,,"['da xu', 'bo yang']",https://arxiv.org/pdf/2304.04330.pdf
588,2304.04336,"split, merge, and refine: fitting tight bounding boxes via learned   over-segmentation and iterative search",cs.cv,"we present a novel framework for finding a set of tight bounding boxes of a 3d shape via neural-network-based over-segmentation and iterative merging and refinement. achieving tight bounding boxes of a shape while guaranteeing the complete boundness is an essential task for efficient geometric operations and unsupervised semantic part detection, but previous methods fail to achieve both full coverage and tightness. neural-network-based methods are not suitable for these goals due to the non-differentiability of the objective, and also classic iterative search methods suffer from their sensitivity to the initialization. we demonstrate that the best integration of the learning-based and iterative search methods can achieve the bounding boxes with both properties. we employ an existing unsupervised segmentation network to split the shape and obtain over-segmentation. then, we apply hierarchical merging with our novel tightness-aware merging and stopping criteria. to overcome the sensitivity to the initialization, we also refine the bounding box parameters in a game setup with a soft reward function promoting a wider exploration. lastly, we further improve the bounding boxes with a mcts-based multi-action space exploration. our experimental results demonstrate the full coverage, tightness, and the adequate number of bounding boxes of our method.",,2023-04-09,2023-04-10,"['chanhyeok park', 'minhyuk sung']",https://arxiv.org/pdf/2304.04336.pdf
589,2304.04341,regret distribution in stochastic bandits: optimal trade-off between   expectation and tail risk,stat.ml cs.lg math.st stat.me stat.th,"we study the trade-off between expectation and tail risk for regret distribution in the stochastic multi-armed bandit problem. we fully characterize the interplay among three desired properties for policy design: worst-case optimality, instance-dependent consistency, and light-tailed risk. we show how the order of expected regret exactly affects the decaying rate of the regret tail probability for both the worst-case and instance-dependent scenario. a novel policy is proposed to characterize the optimal regret tail probability for any regret threshold. concretely, for any given $\alpha\in[1/2, 1)$ and $\beta\in[0, \alpha]$, our policy achieves a worst-case expected regret of $\tilde o(t^\alpha)$ (we call it $\alpha$-optimal) and an instance-dependent expected regret of $\tilde o(t^\beta)$ (we call it $\beta$-consistent), while enjoys a probability of incurring an $\tilde o(t^\delta)$ regret ($\delta\geq\alpha$ in the worst-case scenario and $\delta\geq\beta$ in the instance-dependent scenario) that decays exponentially with a polynomial $t$ term. such decaying rate is proved to be best achievable. moreover, we discover an intrinsic gap of the optimal tail rate under the instance-dependent scenario between whether the time horizon $t$ is known a priori or not. interestingly, when it comes to the worst-case scenario, this gap disappears. finally, we extend our proposed policy design to (1) a stochastic multi-armed bandit setting with non-stationary baseline rewards, and (2) a stochastic linear bandit setting. our results reveal insights on the trade-off between regret expectation and regret tail risk for both worst-case and instance-dependent scenarios, indicating that more sub-optimality and inconsistency leave space for more light-tailed risk of incurring a large regret, and that knowing the planning horizon in advance can make a difference on alleviating tail risks.",,2023-04-09,,"['david simchi-levi', 'zeyu zheng', 'feng zhu']",https://arxiv.org/pdf/2304.04341.pdf
590,2304.04343,certifiable black-box attack: ensuring provably successful attack for   adversarial examples,cs.lg cs.cr,"black-box adversarial attacks have shown strong potential to subvert machine learning models. existing black-box adversarial attacks craft the adversarial examples by iteratively querying the target model and/or leveraging the transferability of a local surrogate model. whether such attack can succeed remains unknown to the adversary when empirically designing the attack. in this paper, to our best knowledge, we take the first step to study a new paradigm of adversarial attacks -- certifiable black-box attack that can guarantee the attack success rate of the crafted adversarial examples. specifically, we revise the randomized smoothing to establish novel theories for ensuring the attack success rate of the adversarial examples. to craft the adversarial examples with the certifiable attack success rate (casr) guarantee, we design several novel techniques, including a randomized query method to query the target model, an initialization method with smoothed self-supervised perturbation to derive certifiable adversarial examples, and a geometric shifting method to reduce the perturbation size of the certifiable adversarial examples for better imperceptibility. we have comprehensively evaluated the performance of the certifiable black-box attack on cifar10 and imagenet datasets against different levels of defenses. both theoretical and experimental results have validated the effectiveness of the proposed certifiable attack.",,2023-04-09,,"['hanbin hong', 'yuan hong']",https://arxiv.org/pdf/2304.04343.pdf
591,2304.04353,exponentially improved efficient machine learning for quantum many-body   states with provable guarantees,quant-ph cs.lg physics.data-an,"solving the ground state and the ground-state properties of quantum many-body systems is generically a hard task for classical algorithms. for a family of hamiltonians defined on an $m$-dimensional space of physical parameters, the ground state and its properties at an arbitrary parameter configuration can be predicted via a machine learning protocol up to a prescribed prediction error $\varepsilon$, provided that a sample set (of size $n$) of the states can be efficiently prepared and measured. in a recent work [huang et al., science 377, eabk3333 (2022)], a rigorous guarantee for such an generalization was proved. unfortunately, an exponential scaling, $n = m^{ {\cal{o}} \left(\frac{1}{\varepsilon} \right) }$, was found to be universal for generic gapped hamiltonians. this result applies to the situation where the dimension of the parameter space is large while the scaling with the accuracy is not an urgent factor, not entering the realm of more precise learning and prediction. in this work, we consider an alternative scenario, where $m$ is a finite, not necessarily large constant while the scaling with the prediction error becomes the central concern. by exploiting physical constraints and positive good kernels for predicting the density matrix, we rigorously obtain an exponentially improved sample complexity, $n = \mathrm{poly} \left(\varepsilon^{-1}, n, \log \frac{1}{\delta}\right)$, where $\mathrm{poly}$ denotes a polynomial function; $n$ is the number of qubits in the system, and ($1-\delta$) is the probability of success. moreover, if restricted to learning ground-state properties with strong locality assumptions, the number of samples can be further reduced to $n = \mathrm{poly} \left(\varepsilon^{-1}, \log \frac{n}{\delta}\right)$. this provably rigorous result represents a significant improvement and an indispensable extension of the existing work.",,2023-04-09,,"['yanming che', 'clemens gneiting', 'franco nori']",https://arxiv.org/pdf/2304.04353.pdf
592,2304.04354,vit-calibrator: decision stream calibration for vision transformer,cs.cv,"a surge of interest has emerged in utilizing transformers in diverse vision tasks owing to its formidable performance. however, existing approaches primarily focus on optimizing internal model architecture designs that often entail significant trial and error with high burdens. in this work, we propose a new paradigm dubbed decision stream calibration that boosts the performance of general vision transformers. to achieve this, we shed light on the information propagation mechanism in the learning procedure by exploring the correlation between different tokens and the relevance coefficient of multiple dimensions. upon further analysis, it was discovered that 1) the final decision is associated with tokens of foreground targets, while token features of foreground target will be transmitted into the next layer as much as possible, and the useless token features of background area will be eliminated gradually in the forward propagation. 2) each category is solely associated with specific sparse dimensions in the tokens. based on the discoveries mentioned above, we designed a two-stage calibration scheme, namely vit-calibrator, including token propagation calibration stage and dimension propagation calibration stage. extensive experiments on commonly used datasets show that the proposed approach can achieve promising results. the source codes are given in the supplements.",,2023-04-09,,"['lin chen', 'zhijie jia', 'tian qiu', 'lechao cheng', 'jie lei', 'zunlei feng', 'mingli song']",https://arxiv.org/pdf/2304.04354.pdf
593,2304.04356,eagle: end-to-end deep reinforcement learning based autonomous control   of ptz cameras,cs.cv cs.lg cs.sy eess.sy,"existing approaches for autonomous control of pan-tilt-zoom (ptz) cameras use multiple stages where object detection and localization are performed separately from the control of the ptz mechanisms. these approaches require manual labels and suffer from performance bottlenecks due to error propagation across the multi-stage flow of information. the large size of object detection neural networks also makes prior solutions infeasible for real-time deployment in resource-constrained devices. we present an end-to-end deep reinforcement learning (rl) solution called eagle to train a neural network policy that directly takes images as input to control the ptz camera. training reinforcement learning is cumbersome in the real world due to labeling effort, runtime environment stochasticity, and fragile experimental setups. we introduce a photo-realistic simulation framework for training and evaluation of ptz camera control policies. eagle achieves superior camera control performance by maintaining the object of interest close to the center of captured images at high resolution and has up to 17% more tracking duration than the state-of-the-art. eagle policies are lightweight (90x fewer parameters than yolo5s) and can run on embedded camera platforms such as raspberry pi (33 fps) and jetson nano (38 fps), facilitating real-time ptz tracking for resource-constrained environments. with domain randomization, eagle policies trained in our simulator can be transferred directly to real-world scenarios.",,2023-04-09,,"['sandeep singh sandha', 'bharathan balaji', 'luis garcia', 'mani srivastava']",https://arxiv.org/pdf/2304.04356.pdf
594,2304.04366,learning residual model of model predictive control via random forests   for autonomous driving,cs.ro cs.lg cs.sy eess.sy,"one major issue in learning-based model predictive control (mpc) for autonomous driving is the contradiction between the system model's prediction accuracy and computation efficiency. the more situations a system model covers, the more complex it is, along with highly nonlinear and nonconvex properties. these issues make the optimization too complicated to solve and render real-time control impractical.to address these issues, we propose a hierarchical learning residual model which leverages random forests and linear regression.the learned model consists of two levels. the low level uses linear regression to fit the residues, and the high level uses random forests to switch different linear models. meanwhile, we adopt the linear dynamic bicycle model with error states as the nominal model.the switched linear regression model is added to the nominal model to form the system model. it reformulates the learning-based mpc as a quadratic program (qp) problem and optimization solvers can effectively solve it. experimental path tracking results show that the driving vehicle's prediction accuracy and tracking accuracy are significantly improved compared with the nominal mpc.compared with the state-of-the-art gaussian process-based nonlinear model predictive control (gp-nmpc), our method gets better performance on tracking accuracy while maintaining a lower computation consumption.",,2023-04-09,,"['kang zhao', 'jianru xue', 'xiangning meng', 'gengxin li', 'mengsen wu']",https://arxiv.org/pdf/2304.04366.pdf
595,2304.04370,openagi: when llm meets domain experts,cs.ai cs.cl cs.lg,"human intelligence has the remarkable ability to assemble basic skills into complex ones so as to solve complex tasks. this ability is equally important for artificial intelligence (ai), and thus, we assert that in addition to the development of large, comprehensive intelligent models, it is equally crucial to equip such models with the capability to harness various domain-specific expert models for complex task-solving in the pursuit of artificial general intelligence (agi). recent developments in large language models (llms) have demonstrated remarkable learning and reasoning abilities, making them promising as a controller to select, synthesize, and execute external models to solve complex tasks. in this project, we develop openagi, an open-source agi research platform, specifically designed to offer complex, multi-step tasks and accompanied by task-specific datasets, evaluation metrics, and a diverse range of extensible models. openagi formulates complex tasks as natural language queries, serving as input to the llm. the llm subsequently selects, synthesizes, and executes models provided by openagi to address the task. furthermore, we propose a reinforcement learning from task feedback (rltf) mechanism, which uses the task-solving result as feedback to improve the llm's task-solving ability. thus, the llm is responsible for synthesizing various external models for solving complex tasks, while rltf provides feedback to improve its task-solving ability, enabling a feedback loop for self-improving ai. we believe that the paradigm of llms operating various expert models for complex task-solving is a promising approach towards agi. to facilitate the community's long-term improvement and evaluation of agi's ability, we open-source the code, benchmark, and evaluation methods of the openagi project at https://github.com/agiresearch/openagi.",,2023-04-09,2023-04-12,"['yingqiang ge', 'wenyue hua', 'jianchao ji', 'juntao tan', 'shuyuan xu', 'yongfeng zhang']",https://arxiv.org/pdf/2304.04370.pdf
596,2304.04377,delving into e-commerce product retrieval with vision-language   pre-training,cs.ir,"e-commerce search engines comprise a retrieval phase and a ranking phase, where the first one returns a candidate product set given user queries. recently, vision-language pre-training, combining textual information with visual clues, has been popular in the application of retrieval tasks. in this paper, we propose a novel v+l pre-training method to solve the retrieval problem in taobao search. we design a visual pre-training task based on contrastive learning, outperforming common regression-based visual pre-training tasks. in addition, we adopt two negative sampling schemes, tailored for the large-scale retrieval task. besides, we introduce the details of the online deployment of our proposed method in real-world situations. extensive offline/online experiments demonstrate the superior performance of our method on the retrieval task. our proposed method is employed as one retrieval channel of taobao search and serves hundreds of millions of users in real time.",,2023-04-10,,"['xiaoyang zheng', 'fuyu lv', 'zilong wang', 'qingwen liu', 'xiaoyi zeng']",https://arxiv.org/pdf/2304.04377.pdf
597,2304.04385,on robustness in multimodal learning,cs.lg,"multimodal learning is defined as learning over multiple heterogeneous input modalities such as video, audio, and text. in this work, we are concerned with understanding how models behave as the type of modalities differ between training and deployment, a situation that naturally arises in many applications of multimodal learning to hardware platforms. we present a multimodal robustness framework to provide a systematic analysis of common multimodal representation learning methods. further, we identify robustness short-comings of these approaches and propose two intervention techniques leading to $1.5\times$-$4\times$ robustness improvements on three datasets, audioset, kinetics-400 and imagenet-captions. finally, we demonstrate that these interventions better utilize additional modalities, if present, to achieve competitive results of $44.2$ map on audioset 20k.",,2023-04-10,2023-04-10,"['brandon mckinzie', 'joseph cheng', 'vaishaal shankar', 'yinfei yang', 'jonathon shlens', 'alexander toshev']",https://arxiv.org/pdf/2304.04385.pdf
598,2304.04386,generating adversarial attacks in the latent space,cs.lg cs.cr cs.cv,"adversarial attacks in the input (pixel) space typically incorporate noise margins such as $l_1$ or $l_{\infty}$-norm to produce imperceptibly perturbed data that confound deep learning networks. such noise margins confine the magnitude of permissible noise. in this work, we propose injecting adversarial perturbations in the latent (feature) space using a generative adversarial network, removing the need for margin-based priors. experiments on mnist, cifar10, fashion-mnist, cifar100 and stanford dogs datasets support the effectiveness of the proposed method in generating adversarial attacks in the latent space while ensuring a high degree of visual realism with respect to pixel-based adversarial attack methods.",,2023-04-10,,"['nitish shukla', 'sudipta banerjee']",https://arxiv.org/pdf/2304.04386.pdf
599,2304.04389,deep active alignment of knowledge graph entities and schemata,cs.db cs.ai,"knowledge graphs (kgs) store rich facts about the real world. in this paper, we study kg alignment, which aims to find alignment between not only entities but also relations and classes in different kgs. alignment at the entity level can cross-fertilize alignment at the schema level. we propose a new kg alignment approach, called daakg, based on deep learning and active learning. with deep learning, it learns the embeddings of entities, relations and classes, and jointly aligns them in a semi-supervised manner. with active learning, it estimates how likely an entity, relation or class pair can be inferred, and selects the best batch for human labeling. we design two approximation algorithms for efficient solution to batch selection. our experiments on benchmark datasets show the superior accuracy and generalization of daakg and validate the effectiveness of all its modules.",,2023-04-10,,"['jiacheng huang', 'zequn sun', 'qijin chen', 'xiaozhou xu', 'weijun ren', 'wei hu']",https://arxiv.org/pdf/2304.04389.pdf
600,2304.04391,cafin: centrality aware fairness inducing in-processing for unsupervised   representation learning on graphs,cs.lg cs.ai cs.cy,"unsupervised representation learning on (large) graphs has received significant attention in the research community due to the compactness and richness of the learned embeddings and the abundance of unlabelled graph data. when deployed, these node representations must be generated with appropriate fairness constraints to minimize bias induced by them on downstream tasks. consequently, group and individual fairness notions for graph learning algorithms have been investigated for specific downstream tasks. one major limitation of these fairness notions is that they do not consider the connectivity patterns in the graph leading to varied node influence (or centrality power). in this paper, we design a centrality-aware fairness framework for inductive graph representation learning algorithms. we propose cafin (centrality aware fairness inducing in-processing), an in-processing technique that leverages graph structure to improve graphsage's representations - a popular framework in the unsupervised inductive setting. we demonstrate the efficacy of cafin in the inductive setting on two popular downstream tasks - link prediction and node classification. empirically, they consistently minimize the disparity in fairness between groups across datasets (varying from 18 to 80% reduction in imparity, a measure of group fairness) from different domains while incurring only a minimal performance cost.",,2023-04-10,,"['arvindh arun', 'aakash aanegola', 'amul agrawal', 'ramasuri narayanam', 'ponnurangam kumaraguru']",https://arxiv.org/pdf/2304.04391.pdf
601,2304.04395,instance neural radiance field,cs.cv,"this paper presents one of the first learning-based nerf 3d instance segmentation pipelines, dubbed as instance neural radiance field, or instance nerf. taking a nerf pretrained from multi-view rgb images as input, instance nerf can learn 3d instance segmentation of a given scene, represented as an instance field component of the nerf model. to this end, we adopt a 3d proposal-based mask prediction network on the sampled volumetric features from nerf, which generates discrete 3d instance masks. the coarse 3d mask prediction is then projected to image space to match 2d segmentation masks from different views generated by existing panoptic segmentation models, which are used to supervise the training of the instance field. notably, beyond generating consistent 2d segmentation maps from novel views, instance nerf can query instance information at any 3d point, which greatly enhances nerf object segmentation and manipulation. our method is also one of the first to achieve such results without ground-truth instance information during inference. experimented on synthetic and real-world nerf datasets with complex indoor scenes, instance nerf surpasses previous nerf segmentation works and competitive 2d segmentation methods in segmentation performance on unseen views. see the demo video at https://youtu.be/ww9bme73coi.",,2023-04-10,,"['benran hu', 'junkai huang', 'yichen liu', 'yu-wing tai', 'chi-keung tang']",https://arxiv.org/pdf/2304.04395.pdf
602,2304.04398,ransomware detection and classification strategies,cs.cr,"ransomware uses encryption methods to make data inaccessible to legitimate users. to date a wide range of ransomware families have been developed and deployed, causing immense damage to governments, corporations, and private users. as these cyberthreats multiply, researchers have proposed a range of ransomware detection and classification schemes. most of these methods use advanced machine learning techniques to process and analyze real-world ransomware binaries and action sequences. hence this paper presents a survey of this critical space and classifies existing solutions into several categories, i.e., including network-based, host-based, forensic characterization, and authorship attribution. key facilities and tools for ransomware analysis are also presented along with open challenges.",,2023-04-10,,"['aldin vehabovic', 'nasir ghani', 'elias bou-harb', 'jorge crichigno', 'aysegul yayimli']",https://arxiv.org/pdf/2304.04398.pdf
603,2304.04399,cavl: learning contrastive and adaptive representations of vision and   language,cs.cv cs.ai cs.lg cs.mm,"visual and linguistic pre-training aims to learn vision and language representations together, which can be transferred to visual-linguistic downstream tasks. however, there exists semantic confusion between language and vision during the pre-training stage. moreover, current pre-trained models tend to take lots of computation resources for fine-tuning when transferred to downstream tasks. in this work, we present a simple but effective approach for learning contrastive and adaptive representations of vision and language, namely cavl. specifically, we introduce a pair-wise contrastive loss to learn alignments between the whole sentence and each image in the same batch during the pre-training process. at the fine-tuning stage, we introduce two lightweight adaptation networks to reduce model parameters and increase training speed for saving computation resources. we evaluate our cavl on six main downstream tasks, including visual question answering (vqa), visual commonsense reasoning (vcr), natural language for visual reasoning (nlvr), region-to-phrase grounding (rpg), text-to-image retrieval (tir), and zero-shot text-to-image retrieval (zs-tir). compared to baselines, we achieve superior performance and reduce the fine-tuning time by a large margin (in particular, 76.17%). extensive experiments and ablation studies demonstrate the efficiency of contrastive pre-training and adaptive fine-tuning proposed in our cavl.",,2023-04-10,,"['shentong mo', 'jingfei xia', 'ihor markevych']",https://arxiv.org/pdf/2304.04399.pdf
604,2304.04400,identity-guided collaborative learning for cloth-changing person   reidentification,cs.cv,"cloth-changing person reidentification (reid) is a newly emerging research topic that is aimed at addressing the issues of large feature variations due to cloth-changing and pedestrian view/pose changes. although significant progress has been achieved by introducing extra information (e.g., human contour sketching information, human body keypoints, and 3d human information), cloth-changing person reid is still challenging due to impressionable pedestrian representations. moreover, human semantic information and pedestrian identity information are not fully explored. to solve these issues, we propose a novel identity-guided collaborative learning scheme (igcl) for cloth-changing person reid, where the human semantic is fully utilized and the identity is unchangeable to guide collaborative learning. first, we design a novel clothing attention degradation stream to reasonably reduce the interference caused by clothing information where clothing attention and mid-level collaborative learning are employed. second, we propose a human semantic attention and body jigsaw stream to highlight the human semantic information and simulate different poses of the same identity. in this way, the extraction features not only focus on human semantic information that is unrelated to the background but also are suitable for pedestrian pose variations. moreover, a pedestrian identity enhancement stream is further proposed to enhance the identity importance and extract more favorable identity robust features. most importantly, all these streams are jointly explored in an end-to-end unified framework, and the identity is utilized to guide the optimization. extensive experiments on five public clothing person reid datasets demonstrate that the proposed igcl significantly outperforms sota methods and that the extracted feature is more robust, discriminative, and clothing-irrelevant.",,2023-04-10,,"['zan gao', 'shenxun wei', 'weili guan', 'lei zhu', 'meng wang', 'shenyong chen']",https://arxiv.org/pdf/2304.04400.pdf
605,2304.04403,h2rbox-v2: boosting hbox-supervised oriented object detection via   symmetric learning,cs.cv cs.ai,"with the increasing demand for oriented object detection e.g. in autonomous driving and remote sensing, the oriented annotation has become a labor-intensive work. to make full use of existing horizontally annotated datasets and reduce the annotation cost, a weakly-supervised detector h2rbox for learning the rotated box (rbox) from the horizontal box (hbox) has been proposed and received great attention. this paper presents a new version, h2rbox-v2, to further bridge the gap between hbox-supervised and rbox-supervised oriented object detection. while exploiting axisymmetry via flipping and rotating consistencies is available through our theoretical analysis, h2rbox-v2, using a weakly-supervised branch similar to h2rbox, is embedded with a novel self-supervised branch that learns orientations from the symmetry inherent in the image of objects. complemented by modules to cope with peripheral issues, e.g. angular periodicity, a stable and effective solution is achieved. to our knowledge, h2rbox-v2 is the first symmetry-supervised paradigm for oriented object detection. compared to h2rbox, our method is less susceptible to low annotation quality and insufficient training data, which in such cases is expected to give a competitive performance much closer to fully-supervised oriented object detectors. specifically, the performance comparison between h2rbox-v2 and rotated fcos on dota-v1.0/1.5/2.0 is 72.31%/64.76%/50.33% vs. 72.44%/64.53%/51.77%, 89.66% vs. 88.99% on hrsc, and 42.27% vs. 41.25% on fair1m.",,2023-04-10,2023-04-11,"['yi yu', 'xue yang', 'qingyun li', 'yue zhou', 'gefan zhang', 'feipeng da', 'junchi yan']",https://arxiv.org/pdf/2304.04403.pdf
606,2304.04407,coool: a learning-to-rank approach for sql hint recommendations,cs.db,"query optimization is a pivotal part of every database management system (dbms) since it determines the efficiency of query execution. numerous works have introduced machine learning (ml) techniques to cost modeling, cardinality estimation, and end-to-end learned optimizer, but few of them are proven practical due to long training time, lack of interpretability, and integration cost. a recent study provides a practical method to optimize queries by recommending per-query hints but it suffers from two inherited problems. first, it follows the regression framework to predict the absolute latency of each query plan, which is very challenging because the latencies of query plans for a certain query may span multiple orders of magnitude. second, it requires training a model for each dataset, which restricts the application of the trained models in practice. in this paper, we propose coool to predict cost orders of query plans to cooperate with dbms by learning-to-rank. instead of estimating absolute costs, coool uses ranking-based approaches to compute relative ranking scores of the costs of query plans. we show that coool is theoretically valid to distinguish query plans with different latencies. we implement coool on postgresql, and extensive experiments on join-order-benchmark and tpc-h data demonstrate that coool outperforms postgresql and state-of-the-art methods on single-dataset tasks as well as a unified model for multiple-dataset tasks. our experiments also shed some light on why coool outperforms regression approaches from the representation learning perspective, which may guide future research.",,2023-04-10,,"['xianghong xu', 'zhibing zhao', 'tieying zhang', 'rong kang', 'luming sun', 'jianjun chen']",https://arxiv.org/pdf/2304.04407.pdf
607,2304.04408,pcr: proxy-based contrastive replay for online class-incremental   continual learning,cs.cv cs.ai cs.lg,"online class-incremental continual learning is a specific task of continual learning. it aims to continuously learn new classes from data stream and the samples of data stream are seen only once, which suffers from the catastrophic forgetting issue, i.e., forgetting historical knowledge of old classes. existing replay-based methods effectively alleviate this issue by saving and replaying part of old data in a proxy-based or contrastive-based replay manner. although these two replay manners are effective, the former would incline to new classes due to class imbalance issues, and the latter is unstable and hard to converge because of the limited number of samples. in this paper, we conduct a comprehensive analysis of these two replay manners and find that they can be complementary. inspired by this finding, we propose a novel replay-based method called proxy-based contrastive replay (pcr). the key operation is to replace the contrastive samples of anchors with corresponding proxies in the contrastive-based way. it alleviates the phenomenon of catastrophic forgetting by effectively addressing the imbalance issue, as well as keeps a faster convergence of the model. we conduct extensive experiments on three real-world benchmark datasets, and empirical results consistently demonstrate the superiority of pcr over various state-of-the-art methods.",,2023-04-10,,"['huiwei lin', 'baoquan zhang', 'shanshan feng', 'xutao li', 'yunming ye']",https://arxiv.org/pdf/2304.04408.pdf
608,2304.04410,differentially private numerical vector analyses in the local and   shuffle model,cs.cr,"numerical vector aggregation plays a crucial role in privacy-sensitive applications, such as distributed gradient estimation in federated learning and statistical analysis of key-value data. in the context of local differential privacy, this study provides a tight minimax error bound of $o(\frac{ds}{n\epsilon^2})$, where $d$ represents the dimension of the numerical vector and $s$ denotes the number of non-zero entries. by converting the conditional/unconditional numerical mean estimation problem into a frequency estimation problem, we develop an optimal and efficient mechanism called collision. in contrast, existing methods exhibit sub-optimal error rates of $o(\frac{d^2}{n\epsilon^2})$ or $o(\frac{ds^2}{n\epsilon^2})$. specifically, for unconditional mean estimation, we leverage the negative correlation between two frequencies in each dimension and propose the coco mechanism, which further reduces estimation errors for mean values compared to collision. moreover, to surpass the error barrier in local privacy, we examine privacy amplification in the shuffle model for the proposed mechanisms and derive precisely tight amplification bounds. our experiments validate and compare our mechanisms with existing approaches, demonstrating significant error reductions for frequency estimation and mean estimation on numerical vectors.",,2023-04-10,,"['shaowei wang', 'jin li', 'yuntong li', 'jin li', 'wei yang', 'hongyang yan']",https://arxiv.org/pdf/2304.04410.pdf
609,2304.04415,meta compositional referring expression segmentation,cs.cv,"referring expression segmentation aims to segment an object described by a language expression from an image. despite the recent progress on this task, existing models tackling this task may not be able to fully capture semantics and visual representations of individual concepts, which limits their generalization capability, especially when handling novel compositions of learned concepts. in this work, through the lens of meta learning, we propose a meta compositional referring expression segmentation (mcres) framework to enhance model compositional generalization performance. specifically, to handle various levels of novel compositions, our framework first uses training data to construct a virtual training set and multiple virtual testing sets, where data samples in each virtual testing set contain a level of novel compositions w.r.t. the virtual training set. then, following a novel meta optimization scheme to optimize the model to obtain good testing performance on the virtual testing sets after training on the virtual training set, our framework can effectively drive the model to better capture semantics and visual representations of individual concepts, and thus obtain robust generalization performance even when handling novel compositions. extensive experiments on three benchmark datasets demonstrate the effectiveness of our framework.",,2023-04-10,2023-04-12,"['li xu', 'mark he huang', 'xindi shang', 'zehuan yuan', 'ying sun', 'jun liu']",https://arxiv.org/pdf/2304.04415.pdf
610,2304.04420,feature representation learning with adaptive displacement generation   and transformer fusion for micro-expression recognition,cs.cv,"micro-expressions are spontaneous, rapid and subtle facial movements that can neither be forged nor suppressed. they are very important nonverbal communication clues, but are transient and of low intensity thus difficult to recognize. recently deep learning based methods have been developed for micro-expression (me) recognition using feature extraction and fusion techniques, however, targeted feature learning and efficient feature fusion still lack further study according to the me characteristics. to address these issues, we propose a novel framework feature representation learning with adaptive displacement generation and transformer fusion (frl-dgt), in which a convolutional displacement generation module (dgm) with self-supervised learning is used to extract dynamic features from onset/apex frames targeted to the subsequent me recognition task, and a well-designed transformer fusion mechanism composed of three transformer-based fusion modules (local, global fusions based on au regions and full-face fusion) is applied to extract the multi-level informative features after dgm for the final me prediction. the extensive experiments with solid leave-one-subject-out (loso) evaluation results have demonstrated the superiority of our proposed frl-dgt to state-of-the-art methods.",,2023-04-10,,"['zhijun zhai', 'jianhui zhao', 'chengjiang long', 'wenju xu', 'shuangjiang he', 'huijuan zhao']",https://arxiv.org/pdf/2304.04420.pdf
611,2304.04421,local-global temporal difference learning for satellite video   super-resolution,cs.cv,"optical-flow-based and kernel-based approaches have been widely explored for temporal compensation in satellite video super-resolution (vsr). however, these techniques involve high computational consumption and are prone to fail under complex motions. in this paper, we proposed to exploit the well-defined temporal difference for efficient and robust temporal compensation. to fully utilize the temporal information within frames, we separately modeled the short-term and long-term temporal discrepancy since they provide distinctive complementary properties. specifically, a short-term temporal difference module is designed to extract local motion representations from residual maps between adjacent frames, which provides more clues for accurate texture representation. meanwhile, the global dependency in the entire frame sequence is explored via long-term difference learning. the differences between forward and backward segments are incorporated and activated to modulate the temporal feature, resulting in holistic global compensation. besides, we further proposed a difference compensation unit to enrich the interaction between the spatial distribution of the target frame and compensated results, which helps maintain spatial consistency while refining the features to avoid misalignment. extensive objective and subjective evaluation of five mainstream satellite videos demonstrates that the proposed method performs favorably for satellite vsr. code will be available at \url{https://github.com/xy-boy/tdmvsr}",,2023-04-10,,"['yi xiao', 'qiangqiang yuan', 'kui jiang', 'xianyu jin', 'jiang he', 'liangpei zhang', 'chia-wen lin']",https://arxiv.org/pdf/2304.04421.pdf
612,2304.04441,self-training with dual uncertainty for semi-supervised medical image   segmentation,cs.cv cs.lg,"in the field of semi-supervised medical image segmentation, the shortage of labeled data is the fundamental problem. how to effectively learn image features from unlabeled images to improve segmentation accuracy is the main research direction in this field. traditional self-training methods can partially solve the problem of insufficient labeled data by generating pseudo labels for iterative training. however, noise generated due to the model's uncertainty during training directly affects the segmentation results. therefore, we added sample-level and pixel-level uncertainty to stabilize the training process based on the self-training framework. specifically, we saved several moments of the model during pre-training, and used the difference between their predictions on unlabeled samples as the sample-level uncertainty estimate for that sample. then, we gradually add unlabeled samples from easy to hard during training. at the same time, we added a decoder with different upsampling methods to the segmentation network and used the difference between the outputs of the two decoders as pixel-level uncertainty. in short, we selectively retrained unlabeled samples and assigned pixel-level uncertainty to pseudo labels to optimize the self-training process. we compared the segmentation results of our model with five semi-supervised approaches on the public 2017 acdc dataset and 2018 prostate dataset. our proposed method achieves better segmentation performance on both datasets under the same settings, demonstrating its effectiveness, robustness, and potential transferability to other medical image segmentation tasks. keywords: medical image segmentation, semi-supervised learning, self-training, uncertainty estimation",,2023-04-10,,"['zhanhong qiu', 'haitao gan', 'ming shi', 'zhongwei huang', 'zhi yang']",https://arxiv.org/pdf/2304.04441.pdf
613,2304.04442,monte carlo linear clustering with single-point supervision is enough   for infrared small target detection,cs.cv,"single-frame infrared small target (sirst) detection aims at separating small targets from clutter backgrounds on infrared images. recently, deep learning based methods have achieved promising performance on sirst detection, but at the cost of a large amount of training data with expensive pixel-level annotations. to reduce the annotation burden, we propose the first method to achieve sirst detection with single-point supervision. the core idea of this work is to recover the per-pixel mask of each target from the given single point label by using clustering approaches, which looks simple but is indeed challenging since targets are always insalient and accompanied with background clutters. to handle this issue, we introduce randomness to the clustering process by adding noise to the input images, and then obtain much more reliable pseudo masks by averaging the clustered results. thanks to this ""monte carlo"" clustering approach, our method can accurately recover pseudo masks and thus turn arbitrary fully supervised sirst detection networks into weakly supervised ones with only single point annotation. experiments on four datasets demonstrate that our method can be applied to existing sirst detection networks to achieve comparable performance with their fully supervised counterparts, which reveals that single-point supervision is strong enough for sirst detection. our code will be available at: https://github.com/yeren123455/sirst-single-point-supervision.",,2023-04-10,,"['boyang li', 'yingqian wang', 'longguang wang', 'fei zhang', 'ting liu', 'zaiping lin', 'wei an', 'yulan guo']",https://arxiv.org/pdf/2304.04442.pdf
614,2304.04443,approximation of nonlinear functionals using deep relu networks,stat.ml cs.lg,"in recent years, functional neural networks have been proposed and studied in order to approximate nonlinear continuous functionals defined on $l^p([-1, 1]^s)$ for integers $s\ge1$ and $1\le p<\infty$. however, their theoretical properties are largely unknown beyond universality of approximation or the existing analysis does not apply to the rectified linear unit (relu) activation function. to fill in this void, we investigate here the approximation power of functional deep neural networks associated with the relu activation function by constructing a continuous piecewise linear interpolation under a simple triangulation. in addition, we establish rates of approximation of the proposed functional deep relu networks under mild regularity conditions. finally, our study may also shed some light on the understanding of functional data learning algorithms.",,2023-04-10,,"['linhao song', 'jun fan', 'di-rong chen', 'ding-xuan zhou']",https://arxiv.org/pdf/2304.04443.pdf
615,2304.04450,sustainable edge computing: challenges and future directions,cs.dc,"an increasing amount of data is being injected into the network from iot (internet of things) applications. many of these applications, developed to improve society's quality of life, are latency-critical and inject large amounts of data into the network. these requirements of iot applications trigger the emergence of edge computing paradigm. currently, data centers are responsible for a global energy use between 2% and 3%. however, this trend is difficult to maintain, as bringing computing infrastructures closer to the edge of the network comes with its own set of challenges for energy efficiency. in this paper, we propose our approach for the sustainability of future computing infrastructures to provide (i) an energy-efficient and economically viable deployment, (ii) a fault-tolerant automated operation, and (iii) a collaborative resource management to improve resource efficiency. we identify the main limitations of applying cloud-based approaches close to the data sources and present the research challenges to edge sustainability arising from these constraints. we propose two-phase immersion cooling, formal modeling, machine learning, and energy-centric federated management as edge-enabling technologies. we present our early results towards the sustainability of an edge infrastructure to demonstrate the benefits of our approach for future computing environments and deployments.",,2023-04-10,,"['patricia arroba', 'rajkumar buyya', 'rom√°n c√°rdenas', 'jos√© l. risco-mart√≠n', 'jos√© m. moya']",https://arxiv.org/pdf/2304.04450.pdf
616,2304.04455,bayesian optimization for sparse neural networks with trainable   activation functions,cs.lg cs.ai stat.me,"in the literature on deep neural networks, there is considerable interest in developing activation functions that can enhance neural network performance. in recent years, there has been renewed scientific interest in proposing activation functions that can be trained throughout the learning process, as they appear to improve network performance, especially by reducing overfitting. in this paper, we propose a trainable activation function whose parameters need to be estimated. a fully bayesian model is developed to automatically estimate from the learning data both the model weights and activation function parameters. an mcmc-based optimization scheme is developed to build the inference. the proposed method aims to solve the aforementioned problems and improve convergence time by using an efficient sampling scheme that guarantees convergence to the global maximum. the proposed scheme is tested on three datasets with three different cnns. promising results demonstrate the usefulness of our proposed approach in improving model accuracy due to the proposed activation function and bayesian estimation of the parameters.",,2023-04-10,,"['mohamed fakhfakh', 'lotfi chaari']",https://arxiv.org/pdf/2304.04455.pdf
617,2304.04468,toward cohort intelligence: a universal cohort representation learning   framework for electronic health record analysis,cs.lg cs.ai,"electronic health records (ehr) are generated from clinical routine care recording valuable information of broad patient populations, which provide plentiful opportunities for improving patient management and intervention strategies in clinical practice. to exploit the enormous potential of ehr data, a popular ehr data analysis paradigm in machine learning is ehr representation learning, which first leverages the individual patient's ehr data to learn informative representations by a backbone, and supports diverse health-care downstream tasks grounded on the representations. unfortunately, such a paradigm fails to access the in-depth analysis of patients' relevance, which is generally known as cohort studies in clinical practice. specifically, patients in the same cohort tend to share similar characteristics, implying their resemblance in medical conditions such as symptoms or diseases. in this paper, we propose a universal cohort representation learning (core) framework to augment ehr utilization by leveraging the fine-grained cohort information among patients. in particular, core first develops an explicit patient modeling task based on the prior knowledge of patients' diagnosis codes, which measures the latent relevance among patients to adaptively divide the cohorts for each patient. based on the constructed cohorts, core recodes the pre-extracted ehr data representation from intra- and inter-cohort perspectives, yielding augmented ehr data representation learning. core is readily applicable to diverse backbone models, serving as a universal plug-in framework to infuse cohort information into healthcare methods for boosted performance. we conduct an extensive experimental evaluation on two real-world datasets, and the experimental results demonstrate the effectiveness and generalizability of core.",,2023-04-10,2023-04-12,"['changshuo liu', 'wenqiao zhang', 'beng chin ooi', 'james wei luen yip', 'lingze zeng', 'kaiping zheng']",https://arxiv.org/pdf/2304.04468.pdf
618,2304.04480,on the existence of highly organized communities in networks of locally   interacting agents,cs.cr cs.dm,"in this paper we investigate phenomena of spontaneous emergence or purposeful formation of highly organized structures in networks of related agents. we show that the formation of large organized structures requires exponentially large, in the size of the structures, networks. our approach is based on kolmogorov, or descriptional, complexity of networks viewed as finite size strings. we apply this approach to the study of the emergence or formation of simple organized, hierarchical, structures based on sierpinski graphs and we prove a ramsey type theorem that bounds the number of vertices in kolmogorov random graphs that contain sierpinski graphs as subgraphs. moreover, we show that sierpinski graphs encompass close-knit relationships among their vertices that facilitate fast spread and learning of information when agents in their vertices are engaged in pairwise interactions modelled as two person games. finally, we generalize our findings for any organized structure with succinct representations. our work can be deployed, in particular, to study problems related to the security of networks by identifying conditions which enable or forbid the formation of sufficiently large insider subnetworks with malicious common goal to overtake the network or cause disruption of its operation.",,2023-04-10,,"['v. liagkou', 'p. e. nastou', 'p. spirakis', 'y. c. stamatiou']",https://arxiv.org/pdf/2304.04480.pdf
619,2304.04496,defeenet: consecutive 3d human motion prediction with deviation feedback,cs.cv,"let us rethink the real-world scenarios that require human motion prediction techniques, such as human-robot collaboration. current works simplify the task of predicting human motions into a one-off process of forecasting a short future sequence (usually no longer than 1 second) based on a historical observed one. however, such simplification may fail to meet practical needs due to the neglect of the fact that motion prediction in real applications is not an isolated ``observe then predict'' unit, but a consecutive process composed of many rounds of such unit, semi-overlapped along the entire sequence. as time goes on, the predicted part of previous round has its corresponding ground truth observable in the new round, but their deviation in-between is neither exploited nor able to be captured by existing isolated learning fashion. in this paper, we propose defeenet, a simple yet effective network that can be added on existing one-off prediction models to realize deviation perception and feedback when applied to consecutive motion prediction task. at each prediction round, the deviation generated by previous unit is first encoded by our defeenet, and then incorporated into the existing predictor to enable a deviation-aware prediction manner, which, for the first time, allows for information transmit across adjacent prediction units. we design two versions of defeenet as mlp-based and gru-based, respectively. on human3.6m and more complicated babel, experimental results indicate that our proposed network improves consecutive human motion prediction performance regardless of the basic model.",,2023-04-10,,"['xiaoning sun', 'huaijiang sun', 'bin li', 'dong wei', 'weiqing li', 'jianfeng lu']",https://arxiv.org/pdf/2304.04496.pdf
620,2304.04497,graph neural network-aided exploratory learning for community detection   with unknown topology,cs.si cs.ir cs.lg cs.ne cs.ni,"in social networks, the discovery of community structures has received considerable attention as a fundamental problem in various network analysis tasks. however, due to privacy concerns or access restrictions, the network structure is often unknown, thereby rendering established community detection approaches ineffective without costly network topology acquisition. to tackle this challenge, we present meta-code, a novel end-to-end solution for detecting overlapping communities in networks with unknown topology via exploratory learning aided by easy-to-collect node metadata. specifically, meta-code consists of three iterative steps in addition to the initial network inference step: 1) node-level community-affiliation embeddings based on graph neural networks (gnns) trained by our new reconstruction loss, 2) network exploration via community affiliation-based node queries, and 3) network inference using an edge connectivity-based siamese neural network model from the explored network. through comprehensive evaluations using five real-world datasets, we demonstrate that meta-code exhibits (a) its superiority over benchmark community detection methods, (b) empirical evaluations as well as theoretical findings to see the effectiveness of our node query, (c) the influence of each module, and (d) its computational efficiency.",,2023-04-10,,"['yu hou', 'cong tran', 'ming li', 'won-yong shin']",https://arxiv.org/pdf/2304.04497.pdf
621,2304.04507,hist2rna: an efficient deep learning architecture to predict gene   expression from breast cancer histopathology images,cs.cv,"gene expression can be used to subtype breast cancer with improved prediction of risk of recurrence and treatment responsiveness over that obtained using routine immunohistochemistry (ihc). however, in the clinic, molecular profiling is primarily used for er+ cancer and is costly and tissue destructive, requires specialized platforms and takes several weeks to obtain a result. deep learning algorithms can effectively extract morphological patterns in digital histopathology images to predict molecular phenotypes quickly and cost-effectively. we propose a new, computationally efficient approach called hist2rna inspired by bulk rna-sequencing techniques to predict the expression of 138 genes (incorporated from six commercially available molecular profiling tests), including luminal pam50 subtype, from hematoxylin and eosin (h&e) stained whole slide images (wsis). the training phase involves the aggregation of extracted features for each patient from a pretrained model to predict gene expression at the patient level using annotated h&e images from the cancer genome atlas (tcga, n=335). we demonstrate successful gene prediction on a held-out test set (n=160, corr=0.82 across patients, corr=0.29 across genes) and perform exploratory analysis on an external tissue microarray (tma) dataset (n=498) with known ihc and survival information. our model is able to predict gene expression and luminal pam50 subtype (luminal a versus luminal b) on the tma dataset with prognostic significance for overall survival in univariate analysis (c-index=0.56, hazard ratio=2.16, p<0.005), and independent significance in multivariate analysis incorporating standard clinicopathological variables (c-index=0.65, hazard ratio=1.85, p<0.005).",,2023-04-10,,"['raktim kumar mondol', 'ewan k. a. millar', 'peter h graham', 'lois browne', 'arcot sowmya', 'erik meijering']",https://arxiv.org/pdf/2304.04507.pdf
622,2304.04512,defense-prefix for preventing typographic attacks on clip,cs.cv,"vision-language pre-training models (vlps) have exhibited revolutionary improvements in various vision-language tasks. in vlp, some adversarial attacks fool a model into false or absurd classifications. previous studies addressed these attacks by fine-tuning the model or changing its architecture. however, these methods risk losing the original model's performance and are difficult to apply to downstream tasks. in particular, their applicability to other tasks has not been considered. in this study, we addressed the reduction of the impact of typographic attacks on clip without changing the model parameters. to achieve this, we expand the idea of ``prefix learning'' and introduce our simple yet effective method: defense-prefix (dp), which inserts the dp token before a class name to make words ``robust'' against typographic attacks. our method can be easily applied to downstream tasks, such as object detection, because the proposed method is independent of the model parameters. our method significantly improves the accuracy of classification tasks for typographic attack datasets, while maintaining the zero-shot capabilities of the model. in addition, we leverage our proposed method for object detection, demonstrating its high applicability and effectiveness. the codes and datasets will be publicly available.",,2023-04-10,,"['hiroki azuma', 'yusuke matsui']",https://arxiv.org/pdf/2304.04512.pdf
623,2304.04514,detclipv2: scalable open-vocabulary object detection pre-training via   word-region alignment,cs.cv,"this paper presents detclipv2, an efficient and scalable training framework that incorporates large-scale image-text pairs to achieve open-vocabulary object detection (ovd). unlike previous ovd frameworks that typically rely on a pre-trained vision-language model (e.g., clip) or exploit image-text pairs via a pseudo labeling process, detclipv2 directly learns the fine-grained word-region alignment from massive image-text pairs in an end-to-end manner. to accomplish this, we employ a maximum word-region similarity between region proposals and textual words to guide the contrastive objective. to enable the model to gain localization capability while learning broad concepts, detclipv2 is trained with a hybrid supervision from detection, grounding and image-text pair data under a unified data formulation. by jointly training with an alternating scheme and adopting low-resolution input for image-text pairs, detclipv2 exploits image-text pair data efficiently and effectively: detclipv2 utilizes 13x more image-text pairs than detclip with a similar training time and improves performance. with 13m image-text pairs for pre-training, detclipv2 demonstrates superior open-vocabulary detection performance, e.g., detclipv2 with swin-t backbone achieves 40.4% zero-shot ap on the lvis benchmark, which outperforms previous works glip/glipv2/detclip by 14.4/11.4/4.5% ap, respectively, and even beats its fully-supervised counterpart by a large margin.",,2023-04-10,,"['lewei yao', 'jianhua han', 'xiaodan liang', 'dan xu', 'wei zhang', 'zhenguo li', 'hang xu']",https://arxiv.org/pdf/2304.04514.pdf
624,2304.04515,sood: towards semi-supervised oriented object detection,cs.cv,"semi-supervised object detection (ssod), aiming to explore unlabeled data for boosting object detectors, has become an active task in recent years. however, existing ssod approaches mainly focus on horizontal objects, leaving multi-oriented objects that are common in aerial images unexplored. this paper proposes a novel semi-supervised oriented object detection model, termed sood, built upon the mainstream pseudo-labeling framework. towards oriented objects in aerial scenes, we design two loss functions to provide better supervision. focusing on the orientations of objects, the first loss regularizes the consistency between each pseudo-label-prediction pair (includes a prediction and its corresponding pseudo label) with adaptive weights based on their orientation gap. focusing on the layout of an image, the second loss regularizes the similarity and explicitly builds the many-to-many relation between the sets of pseudo-labels and predictions. such a global consistency constraint can further boost semi-supervised learning. our experiments show that when trained with the two proposed losses, sood surpasses the state-of-the-art ssod methods under various settings on the dota-v1.5 benchmark. the code will be available at https://github.com/hamperdredes/sood.",,2023-04-10,,"['wei hua', 'dingkang liang', 'jingyu li', 'xiaolong liu', 'zhikang zou', 'xiaoqing ye', 'xiang bai']",https://arxiv.org/pdf/2304.04515.pdf
625,2304.04527,deep reinforcement learning with importance weighted a3c for qoe   enhancement in video delivery services,cs.mm,"adaptive bitrate (abr) algorithms are used to adapt the video bitrate based on the network conditions to improve the overall video quality of experience (qoe). recently, reinforcement learning (rl) and asynchronous advantage actor-critic (a3c) methods have been used to generate adaptive bit rate algorithms and they have been shown to improve the overall qoe as compared to fixed rule abr algorithms. however, a common issue in the a3c methods is the lag between behaviour policy and target policy. as a result, the behaviour and the target policies are no longer synchronized which results in suboptimal updates. in this work, we present alisa: an actor-learner architecture with importance sampling for efficient learning in abr algorithms. alisa incorporates importance sampling weights to give more weightage to relevant experience to address the lag issues with the existing a3c methods. we present the design and implementation of alisa, and compare its performance to state-of-the-art video rate adaptation algorithms including vanilla a3c implemented in the pensieve framework and other fixed-rule schedulers like bb, bola, and rb. our results show that alisa improves average qoe by up to 25%-48% higher average qoe than pensieve, and even more when compared to fixed-rule schedulers.",,2023-04-10,,"['mandan naresh', 'paresh saxena', 'manik gupta']",https://arxiv.org/pdf/2304.04527.pdf
626,2304.04529,fan: fatigue-aware network for click-through rate prediction in   e-commerce recommendation,cs.ir cs.hc cs.lg,"since clicks usually contain heavy noise, increasing research efforts have been devoted to modeling implicit negative user behaviors (i.e., non-clicks). however, they either rely on explicit negative user behaviors (e.g., dislikes) or simply treat non-clicks as negative feedback, failing to learn negative user interests comprehensively. in such situations, users may experience fatigue because of seeing too many similar recommendations. in this paper, we propose fatigue-aware network (fan), a novel ctr model that directly perceives user fatigue from non-clicks. specifically, we first apply fourier transformation to the time series generated from non-clicks, obtaining its frequency spectrum which contains comprehensive information about user fatigue. then the frequency spectrum is modulated by category information of the target item to model the bias that both the upper bound of fatigue and users' patience is different for different categories. moreover, a gating network is adopted to model the confidence of user fatigue and an auxiliary task is designed to guide the learning of user fatigue, so we can obtain a well-learned fatigue representation and combine it with user interests for the final ctr prediction. experimental results on real-world datasets validate the superiority of fan and online a/b tests also show fan outperforms representative ctr models significantly.",,2023-04-10,,"['ming li', 'naiyin liu', 'xiaofeng pan', 'yang huang', 'ningning li', 'yingmin su', 'chengjun mao', 'bo cao']",https://arxiv.org/pdf/2304.04529.pdf
627,2304.04537,deepfake detection of occluded images using a patch-based approach,cs.cv,"deepfake involves the use of deep learning and artificial intelligence techniques to produce or change video and image contents typically generated by gans. moreover, it can be misused and leads to fictitious news, ethical and financial crimes, and also affects the performance of facial recognition systems. thus, detection of real or fake images is significant specially to authenticate originality of people's images or videos. one of the most important challenges in this topic is obstruction that decreases the system precision. in this study, we present a deep learning approach using the entire face and face patches to distinguish real/fake images in the presence of obstruction with a three-path decision: first entire-face reasoning, second a decision based on the concatenation of feature vectors of face patches, and third a majority vote decision based on these features. to test our approach, new datasets including real and fake images are created. for producing fake images, stylegan and stylegan2 are trained by ffhq images and also stargan and pggan are trained by celeba images. the celeba and ffhq datasets are used as real images. the proposed approach reaches higher results in early epochs than other methods and increases the sota results by 0.4\%-7.9\% in the different built data-sets. also, we have shown in experimental results that weighing the patches may improve accuracy.",,2023-04-10,,"['mahsa soleimani', 'ali nazari', 'mohsen ebrahimi moghaddam']",https://arxiv.org/pdf/2304.04537.pdf
628,2304.04539,uatta-eb: uncertainty-aware test-time augmented ensemble of berts for   classifying common mental illnesses on social media posts,cs.cl cs.ai cs.lg,"given the current state of the world, because of existing situations around the world, millions of people suffering from mental illnesses feel isolated and unable to receive help in person. psychological studies have shown that our state of mind can manifest itself in the linguistic features we use to communicate. people have increasingly turned to online platforms to express themselves and seek help with their conditions. deep learning methods have been commonly used to identify and analyze mental health conditions from various sources of information, including social media. still, they face challenges, including a lack of reliability and overconfidence in predictions resulting in the poor calibration of the models. to solve these issues, we propose uatta-eb: uncertainty-aware test-time augmented ensembling of berts for producing reliable and well-calibrated predictions to classify six possible types of mental illnesses- none, depression, anxiety, bipolar disorder, adhd, and ptsd by analyzing unstructured user data on reddit.",,2023-04-10,,"['pratinav seth', 'mihir agarwal']",https://arxiv.org/pdf/2304.04539.pdf
629,2304.04549,towards a blockchain-based software engineering education,cs.se,"blockchain technologies for rewards in education are gaining attraction as a promising approach to motivate student learning and promote academic achievement. by providing tangible rewards for educational attainment and engagement, such as digital tokens, educators can motivate learners to take a more active role in their learning and increase their sense of ownership and responsibility for their academic outcomes. in this context, this work proposes the software engineering skill (ses) token as a way of rewarding students in order to improve their experiences in software engineering education (see). we performed a proof of concept and conclude that ses token can be deployed in a platform to support see.",,2023-04-04,,"['filipe fernandes', 'cl√°udia werner']",https://arxiv.org/pdf/2304.04549.pdf
630,2304.04553,two steps forward and one behind: rethinking time series forecasting   with deep learning,cs.lg cs.ai,"the transformer is a highly successful deep learning model that has revolutionised the world of artificial neural networks, first in natural language processing and later in computer vision. this model is based on the attention mechanism and is able to capture complex semantic relationships between a variety of patterns present in the input data. precisely because of these characteristics, the transformer has recently been exploited for time series forecasting problems, assuming its natural adaptability to the domain of continuous numerical series. despite the acclaimed results in the literature, some works have raised doubts about the robustness of this approach. in this paper, we further investigate the effectiveness of transformer-based models applied to the domain of time series forecasting, demonstrate their limitations, and propose a set of alternative models that are better performing and significantly less complex. in particular, we empirically show how simplifying this forecasting model almost always leads to an improvement, reaching the state of the art among transformer-based architectures. we also propose shallow models without the attention mechanism, which compete with the overall state of the art in long time series forecasting, and demonstrate their ability to accurately predict extremely long windows. we show how it is always necessary to use a simple baseline to verify the effectiveness of one's models, and finally we conclude the paper with a reflection on recent research paths and the desire to follow trends and apply the latest model even where it may not be necessary.",,2023-04-10,,"['riccardo ughi', 'eugenio lomurno', 'matteo matteucci']",https://arxiv.org/pdf/2304.04553.pdf
631,2304.04556,attention: marginal probability is all you need?,cs.lg cs.ai cs.ne,"attention mechanisms are a central property of cognitive systems allowing them to selectively deploy cognitive resources in a flexible manner. attention has been long studied in the neurosciences and there are numerous phenomenological models that try to capture its core properties. recently attentional mechanisms have become a dominating architectural choice of machine learning and are the central innovation of transformers. the dominant intuition and formalism underlying their development has drawn on ideas of keys and queries in database management systems. in this work, we propose an alternative bayesian foundation for attentional mechanisms and show how this unifies different attentional architectures in machine learning. this formulation allows to to identify commonality across different attention ml architectures as well as suggest a bridge to those developed in neuroscience. we hope this work will guide more sophisticated intuitions into the key properties of attention architectures and suggest new ones.",,2023-04-07,,"['ryan singh', 'christopher l. buckley']",https://arxiv.org/pdf/2304.04556.pdf
632,2304.04579,coherent concept-based explanations in medical image and its application   to skin lesion diagnosis,cs.cv,"early detection of melanoma is crucial for preventing severe complications and increasing the chances of successful treatment. existing deep learning approaches for melanoma skin lesion diagnosis are deemed black-box models, as they omit the rationale behind the model prediction, compromising the trustworthiness and acceptability of these diagnostic methods. attempts to provide concept-based explanations are based on post-hoc approaches, which depend on an additional model to derive interpretations. in this paper, we propose an inherently interpretable framework to improve the interpretability of concept-based models by incorporating a hard attention mechanism and a coherence loss term to assure the visual coherence of concept activations by the concept encoder, without requiring the supervision of additional annotations. the proposed framework explains its decision in terms of human-interpretable concepts and their respective contribution to the final prediction, as well as a visual interpretation of the locations where the concept is present in the image. experiments on skin image datasets demonstrate that our method outperforms existing black-box and concept-based models for skin lesion classification.",,2023-04-10,,"['cristiano patr√≠cio', 'jo√£o c. neves', 'lu√≠s f. teixeira']",https://arxiv.org/pdf/2304.04579.pdf
633,2304.04581,reconstruction-driven dynamic refinement based unsupervised domain   adaptation for joint optic disc and cup segmentation,eess.iv cs.cv,"glaucoma is one of the leading causes of irreversible blindness. segmentation of optic disc (od) and optic cup (oc) on fundus images is a crucial step in glaucoma screening. although many deep learning models have been constructed for this task, it remains challenging to train an od/oc segmentation model that could be deployed successfully to different healthcare centers. the difficulties mainly comes from the domain shift issue, i.e., the fundus images collected at these centers usually vary greatly in the tone, contrast, and brightness. to address this issue, in this paper, we propose a novel unsupervised domain adaptation (uda) method called reconstruction-driven dynamic refinement network (rdr-net), where we employ a due-path segmentation backbone for simultaneous edge detection and region prediction and design three modules to alleviate the domain gap. the reconstruction alignment (ra) module uses a variational auto-encoder (vae) to reconstruct the input image and thus boosts the image representation ability of the network in a self-supervised way. it also uses a style-consistency constraint to force the network to retain more domain-invariant information. the low-level feature refinement (lfr) module employs input-specific dynamic convolutions to suppress the domain-variant information in the obtained low-level features. the prediction-map alignment (pma) module elaborates the entropy-driven adversarial learning to encourage the network to generate source-like boundaries and regions. we evaluated our rdr-net against state-of-the-art solutions on four public fundus image datasets. our results indicate that rdr-net is superior to competing models in both segmentation performance and generalization ability",,2023-04-10,,"['ziyang chen', 'yongsheng pan', 'yong xia']",https://arxiv.org/pdf/2304.04581.pdf
634,2304.04589,hyperspectral image super-resolution via dual-domain network based on   hybrid convolution,cs.cv eess.iv,"since the number of incident energies is limited, it is difficult to directly acquire hyperspectral images (hsi) with high spatial resolution. considering the high dimensionality and correlation of hsi, super-resolution (sr) of hsi remains a challenge in the absence of auxiliary high-resolution images. furthermore, it is very important to extract the spatial features effectively and make full use of the spectral information. this paper proposes a novel hsi super-resolution algorithm, termed dual-domain network based on hybrid convolution (srdnet). specifically, a dual-domain network is designed to fully exploit the spatial-spectral and frequency information among the hyper-spectral data. to capture inter-spectral self-similarity, a self-attention learning mechanism (hsl) is devised in the spatial domain. meanwhile the pyramid structure is applied to increase the acceptance field of attention, which further reinforces the feature representation ability of the network. moreover, to further improve the perceptual quality of hsi, a frequency loss(hfl) is introduced to optimize the model in the frequency domain. the dynamic weighting mechanism drives the network to gradually refine the generated frequency and excessive smoothing caused by spatial loss. finally, in order to better fully obtain the mapping relationship between high-resolution space and low-resolution space, a hybrid module of 2d and 3d units with progressive upsampling strategy is utilized in our method. experiments on a widely used benchmark dataset illustrate that the proposed srdnet method enhances the texture information of hsi and is superior to state-of-the-art methods.",,2023-04-10,2023-04-10,"['tingting liu', 'yuan liu', 'chuncheng zhang', 'xiubao sui', 'qian chen']",https://arxiv.org/pdf/2304.04589.pdf
635,2304.04591,"for pre-trained vision models in motor control, not all policy learning   methods are created equal",cs.cv cs.ro,"in recent years, increasing attention has been directed to leveraging pre-trained vision models for motor control. while existing works mainly emphasize the importance of this pre-training phase, the arguably equally important role played by downstream policy learning during control-specific fine-tuning is often neglected. it thus remains unclear if pre-trained vision models are consistent in their effectiveness under different control policies. to bridge this gap in understanding, we conduct a comprehensive study on 14 pre-trained vision models using 3 distinct classes of policy learning methods, including reinforcement learning (rl), imitation learning through behavior cloning (bc), and imitation learning with a visual reward function (vrf). our study yields a series of intriguing results, including the discovery that the effectiveness of pre-training is highly dependent on the choice of the downstream policy learning algorithm. we show that conventionally accepted evaluation based on rl methods is highly variable and therefore unreliable, and further advocate for using more robust methods like vrf and bc. to facilitate more universal evaluations of pre-trained models and their policy learning methods in the future, we also release a benchmark of 21 tasks across 3 different environments alongside our work.",,2023-04-10,,"['yingdong hu', 'renhao wang', 'li erran li', 'yang gao']",https://arxiv.org/pdf/2304.04591.pdf
636,2304.04597,accelerated deep self-supervised ptycho-laminography for   three-dimensional nanoscale imaging of integrated circuits,eess.iv cs.lg physics.optics,"three-dimensional inspection of nanostructures such as integrated circuits is important for security and reliability assurance. two scanning operations are required: ptychographic to recover the complex transmissivity of the specimen; and rotation of the specimen to acquire multiple projections covering the 3d spatial frequency domain. two types of rotational scanning are possible: tomographic and laminographic. for flat, extended samples, for which the full 180 degree coverage is not possible, the latter is preferable because it provides better coverage of the 3d spatial frequency domain compared to limited-angle tomography. it is also because the amount of attenuation through the sample is approximately the same for all projections. however, both techniques are time consuming because of extensive acquisition and computation time. here, we demonstrate the acceleration of ptycho-laminographic reconstruction of integrated circuits with 16-times fewer angular samples and 4.67-times faster computation by using a physics-regularized deep self-supervised learning architecture. we check the fidelity of our reconstruction against a densely sampled reconstruction that uses full scanning and no learning. as already reported elsewhere [zhou and horstmeyer, opt. express, 28(9), pp. 12872-12896], we observe improvement of reconstruction quality even over the densely sampled reconstruction, due to the ability of the self-supervised learning kernel to fill the missing cone.",,2023-04-10,,"['iksung kang', 'yi jiang', 'mirko holler', 'manuel guizar-sicairos', 'a. f. j. levi', 'jeffrey klug', 'stefan vogt', 'george barbastathis']",https://arxiv.org/pdf/2304.04597.pdf
637,2304.04598,in-situ crack and keyhole pore detection in laser directed energy   deposition through acoustic signal and deep learning,cs.sd eess.as eess.sp,"cracks and keyhole pores are detrimental defects in alloys produced by laser directed energy deposition (lded). laser-material interaction sound may hold information about underlying complex physical events such as crack propagation and pores formation. however, due to the noisy environment and intricate signal content, acoustic-based monitoring in lded has received little attention. this paper proposes a novel acoustic-based in-situ defect detection strategy in lded. the key contribution of this study is to develop an in-situ acoustic signal denoising, feature extraction, and sound classification pipeline that incorporates convolutional neural networks (cnn) for online defect prediction. microscope images are used to identify locations of the cracks and keyhole pores within a part. the defect locations are spatiotemporally registered with acoustic signal. various acoustic features corresponding to defect-free regions, cracks, and keyhole pores are extracted and analysed in time-domain, frequency-domain, and time-frequency representations. the cnn model is trained to predict defect occurrences using the mel-frequency cepstral coefficients (mfccs) of the lasermaterial interaction sound. the cnn model is compared to various classic machine learning models trained on the denoised acoustic dataset and raw acoustic dataset. the validation results shows that the cnn model trained on the denoised dataset outperforms others with the highest overall accuracy (89%), keyhole pore prediction accuracy (93%), and auc-roc score (98%). furthermore, the trained cnn model can be deployed into an in-house developed software platform for online quality monitoring. the proposed strategy is the first study to use acoustic signals with deep learning for insitu defect detection in lded process.",10.1016/j.addma.2023.103547,2023-04-10,,"['lequn chen', 'xiling yao', 'chaolin tan', 'weiyang he', 'jinlong su', 'fei weng', 'youxiang chew', 'nicholas poh huat ng', 'seung ki moon']",https://arxiv.org/pdf/2304.04598.pdf
638,2304.04600,rotation-scale equivariant steerable filters,cs.cv,"incorporating either rotation equivariance or scale equivariance into cnns has proved to be effective in improving models' generalization performance. however, jointly integrating rotation and scale equivariance into cnns has not been widely explored. digital histology imaging of biopsy tissue can be captured at arbitrary orientation and magnification and stored at different resolutions, resulting in cells appearing in different scales. when conventional cnns are applied to histopathology image analysis, the generalization performance of models is limited because 1) a part of the parameters of filters are trained to fit rotation transformation, thus decreasing the capability of learning other discriminative features; 2) fixed-size filters trained on images at a given scale fail to generalize to those at different scales. to deal with these issues, we propose the rotation-scale equivariant steerable filter (rsesf), which incorporates steerable filters and scale-space theory. the rsesf contains copies of filters that are linear combinations of gaussian filters, whose direction is controlled by directional derivatives and whose scale parameters are trainable but constrained to span disjoint scales in successive layers of the network. extensive experiments on two gland segmentation datasets demonstrate that our method outperforms other approaches, with much fewer trainable parameters and fewer gpu resources required. the source code is available at: https://github.com/ynulonger/rsesf.",,2023-04-10,,"['yilong yang', 'srinandan dasmahapatra', 'sasan mahmoodi']",https://arxiv.org/pdf/2304.04600.pdf
639,2304.04602,learning a universal human prior for dexterous manipulation from human   preference,cs.ro cs.hc cs.lg,"generating human-like behavior on robots is a great challenge especially in dexterous manipulation tasks with robotic hands. even in simulation with no sample constraints, scripting controllers is intractable due to high degrees of freedom, and manual reward engineering can also be hard and lead to non-realistic motions. leveraging the recent progress on reinforcement learning from human feedback (rlhf), we propose a framework to learn a universal human prior using direct human preference feedback over videos, for efficiently tuning the rl policy on 20 dual-hand robot manipulation tasks in simulation, without a single human demonstration. one task-agnostic reward model is trained through iteratively generating diverse polices and collecting human preference over the trajectories; it is then applied for regularizing the behavior of polices in the fine-tuning stage. our method empirically demonstrates more human-like behaviors on robot hands in diverse tasks including even unseen tasks, indicating its generalization capability.",,2023-04-10,,"['zihan ding', 'yuanpei chen', 'allen z. ren', 'shixiang shane gu', 'hao dong', 'chi jin']",https://arxiv.org/pdf/2304.04602.pdf
640,2304.04606,localise to segment: crop to improve organ at risk segmentation accuracy,eess.iv cs.cv,"increased organ at risk segmentation accuracy is required to reduce cost and complications for patients receiving radiotherapy treatment. some deep learning methods for the segmentation of organs at risk use a two stage process where a localisation network first crops an image to the relevant region and then a locally specialised network segments the cropped organ of interest. we investigate the accuracy improvements brought about by such a localisation stage by comparing to a single-stage baseline network trained on full resolution images. we find that localisation approaches can improve both training time and stability and a two stage process involving both a localisation and organ segmentation network provides a significant increase in segmentation accuracy for the spleen, pancreas and heart from the medical segmentation decathlon dataset. we also observe increased benefits of localisation for smaller organs. source code that recreates the main results is available at \href{https://github.com/abe404/localise_to_segment}{this https url}.",,2023-04-10,,"['abraham george smith', 'denis kutn√°r', 'ivan richter vogelius', 'sune darkner', 'jens petersen']",https://arxiv.org/pdf/2304.04606.pdf
641,2304.04610,attention at semeval-2023 task 10: explainable detection of online   sexism (edos),cs.cl,"in this paper, we have worked on interpretability, trust, and understanding of the decisions made by models in the form of classification tasks. the task is divided into 3 subtasks. the first task consists of determining binary sexism detection. the second task describes the category of sexism. the third task describes a more fine-grained category of sexism. our work explores solving these tasks as a classification problem by fine-tuning transformer-based architecture. we have performed several experiments with our architecture, including combining multiple transformers, using domain adaptive pretraining on the unlabelled dataset provided by reddit and gab, joint learning, and taking different layers of transformers as input to a classification head. our system (with team name attention) was able to achieve a macro f1 score of 0.839 for task a, 0.5835 macro f1 score for task b and 0.3356 macro f1 score for task c at the codalab semeval competition. later we improved the accuracy of task b to 0.6228 and task c to 0.3693 in the test set.",,2023-04-10,,"['debashish roy', 'manish shrivastava']",https://arxiv.org/pdf/2304.04610.pdf
642,2304.04612,mixed-precision random projection for randnla on tensor cores,cs.dc,"random projection can reduce the dimension of data while capturing its structure and is a fundamental tool for machine learning, signal processing, and information retrieval, which deal with a large amount of data today. randnla (randomized numerical linear algebra) leverages random projection to reduce the computational complexity of low-rank decomposition of tensors and solve least-square problems. while the computation of the random projection is a simple matrix multiplication, its asymptotic computational complexity is typically larger than other operations in a randnla algorithm. therefore, various studies propose methods for reducing its computational complexity. we propose a fast mixed-precision random projection method on nvidia gpus using tensor cores for single-precision tensors. we exploit the fact that the random matrix requires less precision, and develop a highly optimized matrix multiplication between fp32 and fp16 matrices -- shgemm (single and half-precision gemm) -- on tensor cores, where the random matrix is stored in fp16. our method can compute randomized svd 1.28 times faster and random projection high order svd 1.75 times faster than baseline single-precision implementations while maintaining accuracy.",,2023-04-10,,"['hiroyuki ootomo', 'rio yokota']",https://arxiv.org/pdf/2304.04612.pdf
643,2304.04614,hst-mrf: heterogeneous swin transformer with multi-receptive field for   medical image segmentation,cs.cv,"the transformer has been successfully used in medical image segmentation due to its excellent long-range modeling capabilities. however, patch segmentation is necessary when building a transformer class model. this process may disrupt the tissue structure in medical images, resulting in the loss of relevant information. in this study, we proposed a heterogeneous swin transformer with multi-receptive field (hst-mrf) model based on u-shaped networks for medical image segmentation. the main purpose is to solve the problem of loss of structural information caused by patch segmentation using transformer by fusing patch information under different receptive fields. the heterogeneous swin transformer (hst) is the core module, which achieves the interaction of multi-receptive field patch information through heterogeneous attention and passes it to the next stage for progressive learning. we also designed a two-stage fusion module, multimodal bilinear pooling (mbp), to assist hst in further fusing multi-receptive field information and combining low-level and high-level semantic information for accurate localization of lesion regions. in addition, we developed adaptive patch embedding (ape) and soft channel attention (sca) modules to retain more valuable information when acquiring patch embedding and filtering channel features, respectively, thereby improving model segmentation quality. we evaluated hst-mrf on multiple datasets for polyp and skin lesion segmentation tasks. experimental results show that our proposed method outperforms state-of-the-art models and can achieve superior performance. furthermore, we verified the effectiveness of each module and the benefits of multi-receptive field segmentation in reducing the loss of structural information through ablation experiments.",,2023-04-10,,"['xiaofei huang', 'hongfang gong', 'jin zhang']",https://arxiv.org/pdf/2304.04614.pdf
644,2304.04615,a survey on recent teacher-student learning studies,cs.lg stat.ml,"knowledge distillation is a method of transferring the knowledge from a complex deep neural network (dnn) to a smaller and faster dnn, while preserving its accuracy. recent variants of knowledge distillation include teaching assistant distillation, curriculum distillation, mask distillation, and decoupling distillation, which aim to improve the performance of knowledge distillation by introducing additional components or by changing the learning process. teaching assistant distillation involves an intermediate model called the teaching assistant, while curriculum distillation follows a curriculum similar to human education. mask distillation focuses on transferring the attention mechanism learned by the teacher, and decoupling distillation decouples the distillation loss from the task loss. overall, these variants of knowledge distillation have shown promising results in improving the performance of knowledge distillation.",,2023-04-10,,['minghong gao'],https://arxiv.org/pdf/2304.04615.pdf
645,2304.04616,automated reading passage generation with openai's large language model,cs.cl cs.ai,"the widespread usage of computer-based assessments and individualized learning platforms has resulted in an increased demand for the rapid production of high-quality items. automated item generation (aig), the process of using item models to generate new items with the help of computer technology, was proposed to reduce reliance on human subject experts at each step of the process. aig has been used in test development for some time. still, the use of machine learning algorithms has introduced the potential to improve the efficiency and effectiveness of the process greatly. the approach presented in this paper utilizes openai's latest transformer-based language model, gpt-3, to generate reading passages. existing reading passages were used in carefully engineered prompts to ensure the ai-generated text has similar content and structure to a fourth-grade reading passage. for each prompt, we generated multiple passages, the final passage was selected according to the lexile score agreement with the original passage. in the final round, the selected passage went through a simple revision by a human editor to ensure the text was free of any grammatical and factual errors. all ai-generated passages, along with original passages were evaluated by human judges according to their coherence, appropriateness to fourth graders, and readability.",,2023-04-10,,"['ummugul bezirhan', 'matthias von davier']",https://arxiv.org/pdf/2304.04616.pdf
646,2304.04620,federated incremental semantic segmentation,cs.cv,"federated learning-based semantic segmentation (fss) has drawn widespread attention via decentralized training on local clients. however, most fss models assume categories are fixed in advance, thus heavily undergoing forgetting on old categories in practical applications where local clients receive new categories incrementally while have no memory storage to access old classes. moreover, new clients collecting novel classes may join in the global training of fss, which further exacerbates catastrophic forgetting. to surmount the above challenges, we propose a forgetting-balanced learning (fbl) model to address heterogeneous forgetting on old classes from both intra-client and inter-client aspects. specifically, under the guidance of pseudo labels generated via adaptive class-balanced pseudo labeling, we develop a forgetting-balanced semantic compensation loss and a forgetting-balanced relation consistency loss to rectify intra-client heterogeneous forgetting of old categories with background shift. it performs balanced gradient propagation and relation consistency distillation within local clients. moreover, to tackle heterogeneous forgetting from inter-client aspect, we propose a task transition monitor. it can identify new classes under privacy protection and store the latest old global model for relation distillation. qualitative experiments reveal large improvement of our model against comparison methods. the code is available at https://github.com/jiahuadong/fiss.",,2023-04-10,,"['jiahua dong', 'duzhen zhang', 'yang cong', 'wei cong', 'henghui ding', 'dengxin dai']",https://arxiv.org/pdf/2304.04620.pdf
647,2304.04624,nf-atlas: multi-volume neural feature fields for large scale lidar   mapping,cs.ro,"lidar mapping has been a long-standing problem in robotics. recent progress in neural implicit representation has brought new opportunities to robotic mapping. in this paper, we propose the multi-volume neural feature fields, called nf-atlas, which bridge the neural feature volumes with pose graph optimization. by regarding the neural feature volume as pose graph nodes and the relative pose between volumes as pose graph edges, the entire neural feature field becomes both locally rigid and globally elastic. locally, the neural feature volume employs a sparse feature octree and a small mlp to encode the submap sdf with an option of semantics. learning the map using this structure allows for end-to-end solving of maximum a posteriori (map) based probabilistic mapping. globally, the map is built volume by volume independently, avoiding catastrophic forgetting when mapping incrementally. furthermore, when a loop closure occurs, with the elastic pose graph based representation, only updating the origin of neural volumes is required without remapping. finally, these functionalities of nf-atlas are validated. thanks to the sparsity and the optimization based formulation, nf-atlas shows competitive performance in terms of accuracy, efficiency and memory usage on both simulation and real-world datasets.",,2023-04-10,,"['xuan yu', 'yili liu', 'sitong mao', 'shunbo zhou', 'rong xiong', 'yiyi liao', 'yue wang']",https://arxiv.org/pdf/2304.04624.pdf
648,2304.04625,reinforcement learning-based black-box model inversion attacks,cs.lg cs.cr cs.cv,"model inversion attacks are a type of privacy attack that reconstructs private data used to train a machine learning model, solely by accessing the model. recently, white-box model inversion attacks leveraging generative adversarial networks (gans) to distill knowledge from public datasets have been receiving great attention because of their excellent attack performance. on the other hand, current black-box model inversion attacks that utilize gans suffer from issues such as being unable to guarantee the completion of the attack process within a predetermined number of query accesses or achieve the same level of performance as white-box attacks. to overcome these limitations, we propose a reinforcement learning-based black-box model inversion attack. we formulate the latent space search as a markov decision process (mdp) problem and solve it with reinforcement learning. our method utilizes the confidence scores of the generated images to provide rewards to an agent. finally, the private data can be reconstructed using the latent vectors found by the agent trained in the mdp. the experiment results on various datasets and models demonstrate that our attack successfully recovers the private information of the target model by achieving state-of-the-art attack performance. we emphasize the importance of studies on privacy-preserving machine learning by proposing a more advanced black-box model inversion attack.",,2023-04-10,,"['gyojin han', 'jaehyun choi', 'haeil lee', 'junmo kim']",https://arxiv.org/pdf/2304.04625.pdf
649,2304.04637,improving abr performance for short video streaming using multi-agent   reinforcement learning with expert guidance,cs.mm eess.iv,"in the realm of short video streaming, popular adaptive bitrate (abr) algorithms developed for classical long video applications suffer from catastrophic failures because they are tuned to solely adapt bitrates. instead, short video adaptive bitrate (sabr) algorithms have to properly determine which video at which bitrate level together for content prefetching, without sacrificing the users' quality of experience (qoe) and yielding noticeable bandwidth wastage jointly. unfortunately, existing sabr methods are inevitably entangled with slow convergence and poor generalization. thus, in this paper, we propose incendio, a novel sabr framework that applies multi-agent reinforcement learning (marl) with expert guidance to separate the decision of video id and video bitrate in respective buffer management and bitrate adaptation agents to maximize the system-level utilized score modeled as a compound function of qoe and bandwidth wastage metrics. to train incendio, it is first initialized by imitating the hand-crafted expert rules and then fine-tuned through the use of marl. results from extensive experiments indicate that incendio outperforms the current state-of-the-art sabr algorithm with a 53.2% improvement measured by the utility score while maintaining low training complexity and inference time.",,2023-04-10,,"['yueheng li', 'qianyuan zheng', 'zicheng zhang', 'hao chen', 'zhan ma']",https://arxiv.org/pdf/2304.04637.pdf
650,2304.04640,"neurobench: advancing neuromorphic computing through collaborative, fair   and representative benchmarking",cs.ai,"the field of neuromorphic computing holds great promise in terms of advancing computing efficiency and capabilities by following brain-inspired principles. however, the rich diversity of techniques employed in neuromorphic research has resulted in a lack of clear standards for benchmarking, hindering effective evaluation of the advantages and strengths of neuromorphic methods compared to traditional deep-learning-based methods. this paper presents a collaborative effort, bringing together members from academia and the industry, to define benchmarks for neuromorphic computing: neurobench. the goals of neurobench are to be a collaborative, fair, and representative benchmark suite developed by the community, for the community. in this paper, we discuss the challenges associated with benchmarking neuromorphic solutions, and outline the key features of neurobench. we believe that neurobench will be a significant step towards defining standards that can unify the goals of neuromorphic computing and drive its technological progress. please visit neurobench.ai for the latest updates on the benchmark tasks and metrics.",,2023-04-10,,"['jason yik', 'soikat hasan ahmed', 'zergham ahmed', 'brian anderson', 'andreas g. andreou', 'chiara bartolozzi', 'arindam basu', 'douwe den blanken', 'petrut bogdan', 'sander bohte', 'younes bouhadjar', 'sonia buckley', 'gert cauwenberghs', 'federico corradi', 'guido de croon', 'andreea danielescu', 'anurag daram', 'mike davies', 'yigit demirag', 'jason eshraghian', 'jeremy forest', 'steve furber', 'michael furlong', 'aditya gilra', 'giacomo indiveri', 'siddharth joshi', 'vedant karia', 'lyes khacef', 'james c. knight', 'laura kriener', 'rajkumar kubendran', 'dhireesha kudithipudi', 'gregor lenz', 'rajit manohar', 'christian mayr', 'konstantinos michmizos', 'dylan muir', 'emre neftci', 'thomas nowotny', 'fabrizio ottati', 'ayca ozcelikkale', 'noah pacik-nelson', 'priyadarshini panda', 'sun pao-sheng', 'melika payvand', 'christian pehle', 'mihai a. petrovici', 'christoph posch', 'alpha renner', 'yulia sandamirskaya', 'clemens js schaefer', 'andr√© van schaik', 'johannes schemmel', 'catherine schuman', 'jae-sun seo', 'sumit bam shrestha', 'manolis sifalakis', 'amos sironi', 'kenneth stewart', 'terrence c. stewart', 'philipp stratmann', 'guangzhi tang', 'jonathan timcheck', 'marian verhelst', 'craig m. vineyard', 'bernhard vogginger', 'amirreza yousefzadeh', 'biyan zhou', 'fatima tuz zohora', 'charlotte frenkel', 'vijay janapa reddi']",https://arxiv.org/pdf/2304.04640.pdf
651,2304.04641,probably approximately correct federated learning,cs.lg cs.ai,"federated learning (fl) is a new distributed learning paradigm, with privacy, utility, and efficiency as its primary pillars. existing research indicates that it is unlikely to simultaneously attain infinitesimal privacy leakage, utility loss, and efficiency. therefore, how to find an optimal trade-off solution is the key consideration when designing the fl algorithm. one common way is to cast the trade-off problem as a multi-objective optimization problem, i.e., the goal is to minimize the utility loss and efficiency reduction while constraining the privacy leakage not exceeding a predefined value. however, existing multi-objective optimization frameworks are very time-consuming, and do not guarantee the existence of the pareto frontier, this motivates us to seek a solution to transform the multi-objective problem into a single-objective problem because it is more efficient and easier to be solved. to this end, we propose fedpac, a unified framework that leverages pac learning to quantify multiple objectives in terms of sample complexity, such quantification allows us to constrain the solution space of multiple objectives to a shared dimension, so that it can be solved with the help of a single-objective optimization algorithm. specifically, we provide the results and detailed analyses of how to quantify the utility loss, privacy leakage, privacy-utility-efficiency trade-off, as well as the cost of the attacker from the pac learning perspective.",,2023-04-10,2023-04-13,"['xiaojin zhang', 'anbu huang', 'lixin fan', 'kai chen', 'qiang yang']",https://arxiv.org/pdf/2304.04641.pdf
652,2304.04646,ecg-cl: a comprehensive electrocardiogram interpretation method based on   continual learning,eess.sp cs.lg,"electrocardiogram (ecg) monitoring is one of the most powerful technique of cardiovascular disease (cvd) early identification, and the introduction of intelligent wearable ecg devices has enabled daily monitoring. however, due to the need for professional expertise in the ecgs interpretation, general public access has once again been restricted, prompting the need for the development of advanced diagnostic algorithms. classic rule-based algorithms are now completely outperformed by deep learning based methods. but the advancement of smart diagnostic algorithms is hampered by issues like small dataset, inconsistent data labeling, inefficient use of local and global ecg information, memory and inference time consuming deployment of multiple models, and lack of information transfer between tasks. we propose a multi-resolution model that can sustain high-resolution low-level semantic information throughout, with the help of the development of low-resolution high-level semantic information, by capitalizing on both local morphological information and global rhythm information. from the perspective of effective data leverage and inter-task knowledge transfer, we develop a parameter isolation based ecg continual learning (ecg-cl) approach. we evaluated our model's performance on four open-access datasets by designing segmentation-to-classification for cross-domain incremental learning, minority-to-majority class for category incremental learning, and small-to-large sample for task incremental learning. our approach is shown to successfully extract informative morphological and rhythmic features from ecg segmentation, leading to higher quality classification results. from the perspective of intelligent wearable applications, the possibility of a comprehensive ecg interpretation algorithm based on single-lead ecgs is also confirmed.",,2023-04-10,,"['hongxiang gao', 'xingyao wang', 'zhenghua chen', 'min wu', 'jianqing li', 'chengyu liu']",https://arxiv.org/pdf/2304.04646.pdf
653,2304.04653,do we train on test data? the impact of near-duplicates on license plate   recognition,cs.cv,"this work draws attention to the large fraction of near-duplicates in the training and test sets of datasets widely adopted in license plate recognition (lpr) research. these duplicates refer to images that, although different, show the same license plate. our experiments, conducted on the two most popular datasets in the field, show a substantial decrease in recognition rate when six well-known models are trained and tested under fair splits, that is, in the absence of duplicates in the training and test sets. moreover, in one of the datasets, the ranking of models changed considerably when they were trained and tested under duplicate-free splits. these findings suggest that such duplicates have significantly biased the evaluation and development of deep learning-based models for lpr. the list of near-duplicates we have found and proposals for fair splits are publicly available for further research at https://raysonlaroca.github.io/supp/lpr-train-on-test/",,2023-04-10,,"['rayson laroca', 'valter estevam', 'alceu s. britto', 'rodrigo minetto', 'david menotti']",https://arxiv.org/pdf/2304.04653.pdf
654,2304.04660,uncertainty-driven trajectory truncation for model-based offline   reinforcement learning,cs.lg cs.ai,"equipped with the trained environmental dynamics, model-based offline reinforcement learning (rl) algorithms can often successfully learn good policies from fixed-sized datasets, even some datasets with poor quality. unfortunately, however, it can not be guaranteed that the generated samples from the trained dynamics model are reliable (e.g., some synthetic samples may lie outside of the support region of the static dataset). to address this issue, we propose trajectory truncation with uncertainty (tatu), which adaptively truncates the synthetic trajectory if the accumulated uncertainty along the trajectory is too large. we theoretically show the performance bound of tatu to justify its benefits. to empirically show the advantages of tatu, we first combine it with two classical model-based offline rl algorithms, mopo and combo. furthermore, we integrate tatu with several off-the-shelf model-free offline rl algorithms, e.g., bcq. experimental results on the d4rl benchmark show that tatu significantly improves their performance, often by a large margin.",,2023-04-10,,"['junjie zhang', 'jiafei lyu', 'xiaoteng ma', 'jiangpeng yan', 'jun yang', 'le wan', 'xiu li']",https://arxiv.org/pdf/2304.04660.pdf
655,2304.04662,selformer: molecular representation learning via selfies language models,q-bio.qm cs.lg,"automated computational analysis of the vast chemical space is critical for numerous fields of research such as drug discovery and material science. representation learning techniques have recently been employed with the primary objective of generating compact and informative numerical expressions of complex data. one approach to efficiently learn molecular representations is processing string-based notations of chemicals via natural language processing (nlp) algorithms. majority of the methods proposed so far utilize smiles notations for this purpose; however, smiles is associated with numerous problems related to validity and robustness, which may prevent the model from effectively uncovering the knowledge hidden in the data. in this study, we propose selformer, a transformer architecture-based chemical language model that utilizes a 100% valid, compact and expressive notation, selfies, as input, in order to learn flexible and high-quality molecular representations. selformer is pre-trained on two million drug-like compounds and fine-tuned for diverse molecular property prediction tasks. our performance evaluation has revealed that, selformer outperforms all competing methods, including graph learning-based approaches and smiles-based chemical language models, on predicting aqueous solubility of molecules and adverse drug reactions. we also visualized molecular representations learned by selformer via dimensionality reduction, which indicated that even the pre-trained model can discriminate molecules with differing structural properties. we shared selformer as a programmatic tool, together with its datasets and pre-trained models. overall, our research demonstrates the benefit of using the selfies notations in the context of chemical language modeling and opens up new possibilities for the design and discovery of novel drug candidates with desired features.",,2023-04-10,,"['atakan y√ºksel', 'erva ulusoy', 'atabey √ºnl√º', 'gamze deniz', 'tunca doƒüan']",https://arxiv.org/pdf/2304.04662.pdf
656,2304.04664,inductive biases in deep learning models for weather prediction,physics.ao-ph cs.lg,"deep learning has recently gained immense popularity in the earth sciences as it enables us to formulate purely data-driven models of complex earth system processes. deep learning-based weather prediction (dlwp) models have made significant progress in the last few years, achieving forecast skills comparable to established numerical weather prediction (nwp) models with comparatively lesser computational costs. in order to train accurate, reliable, and tractable dlwp models with several millions of parameters, the model design needs to incorporate suitable inductive biases that encode structural assumptions about the data and modelled processes. when chosen appropriately, these biases enable faster learning and better generalisation to unseen data. although inductive biases play a crucial role in successful dlwp models, they are often not stated explicitly and how they contribute to model performance remains unclear. here, we review and analyse the inductive biases of six state-of-the-art dlwp models, involving a deeper look at five key design elements: input data, forecasting objective, loss components, layered design of the deep learning architectures, and optimisation methods. we show how the design choices made in each of the five design elements relate to structural assumptions. given recent developments in the broader dl community, we anticipate that the future of dlwp will likely see a wider use of foundation models -- large models pre-trained on big databases with self-supervised learning -- combined with explicit physics-informed inductive biases that allow the models to provide competitive forecasts even at the more challenging subseasonal-to-seasonal scales.",,2023-04-06,,"['jannik thuemmel', 'matthias karlbauer', 'sebastian otte', 'christiane zarfl', 'georg martius', 'nicole ludwig', 'thomas scholten', 'ulrich friedrich', 'volker wulfmeyer', 'bedartha goswami', 'martin v. butz']",https://arxiv.org/pdf/2304.04664.pdf
657,2304.04668,mermaide: learning to align learners using model-based meta-learning,cs.lg,"we study how a principal can efficiently and effectively intervene on the rewards of a previously unseen learning agent in order to induce desirable outcomes. this is relevant to many real-world settings like auctions or taxation, where the principal may not know the learning behavior nor the rewards of real people. moreover, the principal should be few-shot adaptable and minimize the number of interventions, because interventions are often costly. we introduce mermaide, a model-based meta-learning framework to train a principal that can quickly adapt to out-of-distribution agents with different learning strategies and reward functions. we validate this approach step-by-step. first, in a stackelberg setting with a best-response agent, we show that meta-learning enables quick convergence to the theoretically known stackelberg equilibrium at test time, although noisy observations severely increase the sample complexity. we then show that our model-based meta-learning approach is cost-effective in intervening on bandit agents with unseen explore-exploit strategies. finally, we outperform baselines that use either meta-learning or agent behavior modeling, in both $0$-shot and $k=1$-shot settings with partial agent information.",,2023-04-10,,"['arundhati banerjee', 'soham phade', 'stefano ermon', 'stephan zheng']",https://arxiv.org/pdf/2304.04668.pdf
658,2304.04672,deep image matting: a comprehensive survey,cs.cv,"image matting refers to extracting precise alpha matte from natural images, and it plays a critical role in various downstream applications, such as image editing. despite being an ill-posed problem, traditional methods have been trying to solve it for decades. the emergence of deep learning has revolutionized the field of image matting and given birth to multiple new techniques, including automatic, interactive, and referring image matting. this paper presents a comprehensive review of recent advancements in image matting in the era of deep learning. we focus on two fundamental sub-tasks: auxiliary input-based image matting, which involves user-defined input to predict the alpha matte, and automatic image matting, which generates results without any manual intervention. we systematically review the existing methods for these two tasks according to their task settings and network structures and provide a summary of their advantages and disadvantages. furthermore, we introduce the commonly used image matting datasets and evaluate the performance of representative matting methods both quantitatively and qualitatively. finally, we discuss relevant applications of image matting and highlight existing challenges and potential opportunities for future research. we also maintain a public repository to track the rapid development of deep image matting at https://github.com/jizhizili/matting-survey.",,2023-04-10,,"['jizhizi li', 'jing zhang', 'dacheng tao']",https://arxiv.org/pdf/2304.04672.pdf
659,2304.04673,regional deep atrophy: a self-supervised learning method to   automatically identify regions associated with alzheimer's disease   progression from longitudinal mri,q-bio.nc cs.ai,"longitudinal assessment of brain atrophy, particularly in the hippocampus, is a well-studied biomarker for neurodegenerative diseases, such as alzheimer's disease (ad). in clinical trials, estimation of brain progressive rates can be applied to track therapeutic efficacy of disease modifying treatments. however, most state-of-the-art measurements calculate changes directly by segmentation and/or deformable registration of mri images, and may misreport head motion or mri artifacts as neurodegeneration, impacting their accuracy. in our previous study, we developed a deep learning method deepatrophy that uses a convolutional neural network to quantify differences between longitudinal mri scan pairs that are associated with time. deepatrophy has high accuracy in inferring temporal information from longitudinal mri scans, such as temporal order or relative inter-scan interval. deepatrophy also provides an overall atrophy score that was shown to perform well as a potential biomarker of disease progression and treatment efficacy. however, deepatrophy is not interpretable, and it is unclear what changes in the mri contribute to progression measurements. in this paper, we propose regional deep atrophy (rda), which combines the temporal inference approach from deepatrophy with a deformable registration neural network and attention mechanism that highlights regions in the mri image where longitudinal changes are contributing to temporal inference. rda has similar prediction accuracy as deepatrophy, but its additional interpretability makes it more acceptable for use in clinical settings, and may lead to more sensitive biomarkers for disease monitoring in clinical trials of early ad.",,2023-04-10,,"['mengjin dong', 'long xie', 'sandhitsu r. das', 'jiancong wang', 'laura e. m. wisse', 'robin deflores', 'david a. wolk', 'paul a. yushkevich']",https://arxiv.org/pdf/2304.04673.pdf
660,2304.04679,fairpilot: an explorative system for hyperparameter tuning through the   lens of fairness,cs.lg,"despite the potential benefits of machine learning (ml) in high-risk decision-making domains, the deployment of ml is not accessible to practitioners, and there is a risk of discrimination. to establish trust and acceptance of ml in such domains, democratizing ml tools and fairness consideration are crucial. in this paper, we introduce fairpilot, an interactive system designed to promote the responsible development of ml models by exploring a combination of various models, different hyperparameters, and a wide range of fairness definitions. we emphasize the challenge of selecting the ``best"" ml model and demonstrate how fairpilot allows users to select a set of evaluation criteria and then displays the pareto frontier of models and hyperparameters as an interactive map. fairpilot is the first system to combine these features, offering a unique opportunity for users to responsibly choose their model.",,2023-04-10,,"['francesco di carlo', 'nazanin nezami', 'hadis anahideh', 'abolfazl asudeh']",https://arxiv.org/pdf/2304.04679.pdf
661,2304.04687,learning to detect touches on cluttered tables,cs.cv cs.hc,"we present a novel self-contained camera-projector tabletop system with a lamp form-factor that brings digital intelligence to our tables. we propose a real-time, on-device, learning-based touch detection algorithm that makes any tabletop interactive. the top-down configuration and learning-based algorithm makes our method robust to the presence of clutter, a main limitation of existing camera-projector tabletop systems. our research prototype enables a set of experiences that combine hand interactions and objects present on the table. a video can be found at https://youtu.be/helc_c25fg8.",,2023-04-10,,"['norberto adrian goussies', 'kenji hata', 'shruthi prabhakara', 'abhishek amit', 'tony aube', 'carl cepress', 'diana chang', 'li-te cheng', 'horia stefan ciurdar', 'mike cleron', 'chelsey fleming', 'ashwin ganti', 'divyansh garg', 'niloofar gheissari', 'petra luna grutzik', 'david hendon', 'daniel iglesia', 'jin kim', 'stuart kyle', 'chris larosa', 'roman lewkow', 'peter f mcdermott', 'chris melancon', 'paru nackeeran', 'neal norwitz', 'ali rahimi', 'brett rampata', 'carlos sobrinho', 'george sung', 'natalie zauhar', 'palash nandy']",https://arxiv.org/pdf/2304.04687.pdf
662,2304.04688,interaction-aware prompting for zero-shot spatio-temporal action   detection,cs.cv cs.ai,"the goal of spatial-temporal action detection is to determine the time and place where each person's action occurs in a video and classify the corresponding action category. most of the existing methods adopt fully-supervised learning, which requires a large amount of training data, making it very difficult to achieve zero-shot learning. in this paper, we propose to utilize a pre-trained visual-language model to extract the representative image and text features, and model the relationship between these features through different interaction modules to obtain the interaction feature. in addition, we use this feature to prompt each label to obtain more appropriate text features. finally, we calculate the similarity between the interaction feature and the text feature for each label to determine the action category. our experiments on j-hmdb and ucf101-24 datasets demonstrate that the proposed interaction module and prompting make the visual-language features better aligned, thus achieving excellent accuracy for zero-shot spatio-temporal action detection. the code will be released upon acceptance.",,2023-04-10,2023-04-11,"['wei-jhe huang', 'jheng-hsien yeh', 'gueter josmy faure', 'min-hung chen', 'shang-hong lai']",https://arxiv.org/pdf/2304.04688.pdf
663,2304.04697,brain-inspired spiking neural network for online unsupervised time   series prediction,cs.ne cs.ai cs.lg eess.sp,"energy and data-efficient online time series prediction for predicting evolving dynamical systems are critical in several fields, especially edge ai applications that need to update continuously based on streaming data. however, current dnn-based supervised online learning models require a large amount of training data and cannot quickly adapt when the underlying system changes. moreover, these models require continuous retraining with incoming data making them highly inefficient. to solve these issues, we present a novel continuous learning-based unsupervised recurrent spiking neural network model (clursnn), trained with spike timing dependent plasticity (stdp). clursnn makes online predictions by reconstructing the underlying dynamical system using random delay embedding by measuring the membrane potential of neurons in the recurrent layer of the rsnn with the highest betweenness centrality. we also use topological data analysis to propose a novel methodology using the wasserstein distance between the persistence homologies of the predicted and observed time series as a loss function. we show that the proposed online time series prediction methodology outperforms state-of-the-art dnn models when predicting an evolving lorenz63 dynamical system.",,2023-04-10,,"['biswadeep chakraborty', 'saibal mukhopadhyay']",https://arxiv.org/pdf/2304.04697.pdf
664,2304.04700,achieving long-term fairness in submodular maximization through   randomization,cs.ds cs.ai cs.lg,"submodular function optimization has numerous applications in machine learning and data analysis, including data summarization which aims to identify a concise and diverse set of data points from a large dataset. it is important to implement fairness-aware algorithms when dealing with data items that may contain sensitive attributes like race or gender, to prevent biases that could lead to unequal representation of different groups. with this in mind, we investigate the problem of maximizing a monotone submodular function while meeting group fairness constraints. unlike previous studies in this area, we allow for randomized solutions, with the objective being to calculate a distribution over feasible sets such that the expected number of items selected from each group is subject to constraints in the form of upper and lower thresholds, ensuring that the representation of each group remains balanced in the long term. here a set is considered feasible if its size does not exceed a constant value of $b$. our research includes the development of a series of approximation algorithms for this problem.",,2023-04-10,,"['shaojie tang', 'jing yuan', 'twumasi mensah-boateng']",https://arxiv.org/pdf/2304.04700.pdf
665,2304.04703,transfer learning for low-resource sentiment analysis,cs.cl,"sentiment analysis is the process of identifying and extracting subjective information from text. despite the advances to employ cross-lingual approaches in an automatic way, the implementation and evaluation of sentiment analysis systems require language-specific data to consider various sociocultural and linguistic peculiarities. in this paper, the collection and annotation of a dataset are described for sentiment analysis of central kurdish. we explore a few classical machine learning and neural network-based techniques for this task. additionally, we employ an approach in transfer learning to leverage pretrained models for data augmentation. we demonstrate that data augmentation achieves a high f$_1$ score and accuracy despite the difficulty of the task.",,2023-04-10,,"['razhan hameed', 'sina ahmadi', 'fatemeh daneshfar']",https://arxiv.org/pdf/2304.04703.pdf
666,2304.04705,arc-based traffic assignment: equilibrium characterization and learning,eess.sy cs.sy,"arc-based traffic assignment models (tams) are a popular framework for modeling traffic network congestion generated by self-interested travelers who sequentially select arcs based on their perceived latency on the network. however, existing arc-based tams either assign travelers to cyclic paths, or do not extend to networks with bi-directional arcs (or edges) between nodes. to overcome these difficulties, we propose a new modeling framework for stochastic arc-based tams. given a traffic network with bidirectional arcs, we replicate its arcs and nodes to construct a directed acyclic graph (dag), which we call the condensed dag (codag) representation. self-interested travelers sequentially select arcs on the codag representation to reach their destination. we show that the associated equilibrium flow, which we call the condensed dag equilibrium, exists, is unique, and can be characterized as a strictly convex optimization problem. moreover, we propose a discrete-time dynamical system that captures a natural adaptation rule employed by self-interested travelers to learn about the emergent congestion on the network. we show that the arc flows generated by this adaptation rule converges to a neighborhood of condensed dag equilibrium. to our knowledge, our work is the first to study learning and adaptation in an arc-based tam. finally, we present numerical results that corroborate our theoretical results.",,2023-04-10,2023-04-12,"['chih-yuan chiu', 'chinmay maheshwari', 'pan-yang su', 'shankar sastry']",https://arxiv.org/pdf/2304.04705.pdf
667,2304.04711,using logs data to identify when software engineers experience flow or   focused work,cs.hc,"beyond self-report data, we lack reliable and non-intrusive methods for identifying flow. however, taking a step back and acknowledging that flow occurs during periods of focus gives us the opportunity to make progress towards measuring flow by isolating focused work. here, we take a mixed-methods approach to design a logs-based metric that leverages machine learning and a comprehensive collection of logs data to identify periods of related actions (indicating focus), and validate this metric against self-reported time in focus or flow using diary data and quarterly survey data. our results indicate that we can determine when software engineers at a large technology company experience focused work which includes instances of flow. this metric speaks to engineering work, but can be leveraged in other domains to non-disruptively measure when people experience focus. future research can build upon this work to identify signals associated with other facets of flow.",,2023-04-10,,"['adam brown', ""sarah d'angelo"", 'ben holtz', 'ciera jaspen', 'collin green']",https://arxiv.org/pdf/2304.04711.pdf
668,2304.04716,respect: reinforcement learning based edge scheduling on pipelined coral   edge tpus,cs.ar cs.ai cs.lg,"deep neural networks (dnns) have substantial computational and memory requirements, and the compilation of its computational graphs has a great impact on the performance of resource-constrained (e.g., computation, i/o, and memory-bound) edge computing systems. while efficient execution of their computational graph requires an effective scheduling algorithm, generating the optimal scheduling solution is a challenging np-hard problem. furthermore, the complexity of scheduling dnn computational graphs will further increase on pipelined multi-core systems considering memory communication cost, as well as the increasing size of dnns. using the synthetic graph for the training dataset, this work presents a reinforcement learning (rl) based scheduling framework respect, which learns the behaviors of optimal optimization algorithms and generates near-optimal scheduling results with short solving runtime overhead. our framework has demonstrated up to $\sim2.5\times$ real-world on-chip inference runtime speedups over the commercial compiler with ten popular imagenet models deployed on the physical coral edge tpus system. moreover, compared to the exact optimization methods, the proposed rl scheduling improves the scheduling optimization runtime by up to 683$\times$ speedups compared to the commercial compiler and matches the exact optimal solutions with up to 930$\times$ speedups. finally, we perform a comprehensive generalizability test, which demonstrates respect successfully imitates optimal solving behaviors from small synthetic graphs to large real-world dnns computational graphs.",,2023-04-10,,"['jiaqi yin', 'yingjie li', 'daniel robinson', 'cunxi yu']",https://arxiv.org/pdf/2304.04716.pdf
669,2304.04718,investigating graph structure information for entity alignment with   dangling cases,cs.cl,"entity alignment (ea) aims to discover the equivalent entities in different knowledge graphs (kgs), which play an important role in knowledge engineering. recently, ea with dangling entities has been proposed as a more realistic setting, which assumes that not all entities have corresponding equivalent entities. in this paper, we focus on this setting. some work has explored this problem by leveraging translation api, pre-trained word embeddings, and other off-the-shelf tools. however, these approaches over-rely on the side information (e.g., entity names), and fail to work when the side information is absent. on the contrary, they still insufficiently exploit the most fundamental graph structure information in kg. to improve the exploitation of the structural information, we propose a novel entity alignment framework called weakly-optimal graph contrastive learning (wogcl), which is refined on three dimensions : (i) model. we propose a novel gated graph attention network to capture local and global graph structure similarity. (ii) training. two learning objectives: contrastive learning and optimal transport learning are designed to obtain distinguishable entity representations via the optimal transport plan. (iii) inference. in the inference phase, a pagerank-based method is proposed to calculate higher-order structural similarity. extensive experiments on two dangling benchmarks demonstrate that our wogcl outperforms the current state-of-the-art methods with pure structural information in both traditional (relaxed) and dangling (consolidated) settings. the code will be public soon.",,2023-04-10,,"['jin xu', 'yangning li', 'xiangjin xie', 'yinghui li', 'niu hu', 'haitao zheng', 'yong jiang']",https://arxiv.org/pdf/2304.04718.pdf
670,2304.04724,when does metropolized hamiltonian monte carlo provably outperform   metropolis-adjusted langevin algorithm?,stat.co cs.cc stat.ml,"we analyze the mixing time of metropolized hamiltonian monte carlo (hmc) with the leapfrog integrator to sample from a distribution on $\mathbb{r}^d$ whose log-density is smooth, has lipschitz hessian in frobenius norm and satisfies isoperimetry. we bound the gradient complexity to reach $\epsilon$ error in total variation distance from a warm start by $\tilde o(d^{1/4}\text{polylog}(1/\epsilon))$ and demonstrate the benefit of choosing the number of leapfrog steps to be larger than 1. to surpass previous analysis on metropolis-adjusted langevin algorithm (mala) that has $\tilde{o}(d^{1/2}\text{polylog}(1/\epsilon))$ dimension dependency in wu et al. (2022), we reveal a key feature in our proof that the joint distribution of the location and velocity variables of the discretization of the continuous hmc dynamics stays approximately invariant. this key feature, when shown via induction over the number of leapfrog steps, enables us to obtain estimates on moments of various quantities that appear in the acceptance rate control of metropolized hmc. moreover, to deal with another bottleneck on the hmc proposal distribution overlap control in the literature, we provide a new approach to upper bound the kullback-leibler divergence between push-forwards of the gaussian distribution through hmc dynamics initialized at two different points. notably, our analysis does not require log-concavity or independence of the marginals, and only relies on an isoperimetric inequality. to illustrate the applicability of our result, several examples of natural functions that fall into our framework are discussed.",,2023-04-10,,"['yuansi chen', 'khashayar gatmiry']",https://arxiv.org/pdf/2304.04724.pdf
671,2304.04734,modularizing and assembling cognitive map learners via hyperdimensional   computing,cs.ne,"biological organisms must learn how to control their own bodies to achieve deliberate locomotion, that is, predict their next body position based on their current position and selected action. such learning is goal-agnostic with respect to maximizing (minimizing) an environmental reward (penalty) signal. a cognitive map learner (cml) is a collection of three separate yet collaboratively trained artificial neural networks which learn to construct representations for the node states and edge actions of an arbitrary bidirectional graph. in so doing, a cml learns how to traverse the graph nodes; however, the cml does not learn when and why to move from one node state to another. this work created cmls with node states expressed as high dimensional vectors suitable for hyperdimensional computing (hdc), a form of symbolic machine learning (ml). in so doing, graph knowledge (cml) was segregated from target node selection (hdc), allowing each ml approach to be trained independently. the first approach used hdc to engineer an arbitrary number of hierarchical cmls, where each graph node state specified target node states for the next lower level cmls to traverse to. second, an hdc-based stimulus-response experience model was demonstrated per cml. because hypervectors may be in superposition with each other, multiple experience models were added together and run in parallel without any retraining. lastly, a cml-hdc ml unit was modularized: trained with proxy symbols such that arbitrary, application-specific stimulus symbols could be operated upon without retraining either cml or hdc model. these methods provide a template for engineering heterogenous ml systems.",,2023-04-10,,['nathan mcdonald'],https://arxiv.org/pdf/2304.04734.pdf
672,2304.04740,reflected diffusion models,stat.ml cs.lg,"score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. however, for complex tasks, numerical error can compound and result in highly unnatural samples. previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. to incorporate data constraints in a principled manner, we present reflected diffusion models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. our approach learns the perturbed score function through a generalized score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ode sampling. we also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected sdes. on standard image benchmarks, our method is competitive with or surpasses the state of the art and, for classifier-free guidance, our approach enables fast exact sampling with odes and produces more faithful samples under high guidance weight.",,2023-04-10,2023-04-13,"['aaron lou', 'stefano ermon']",https://arxiv.org/pdf/2304.04740.pdf
673,2304.04745,ambiguous medical image segmentation using diffusion models,cs.cv,"collective insights from a group of experts have always proven to outperform an individual's best diagnostic for clinical tasks. for the task of medical image segmentation, existing research on ai-based alternatives focuses more on developing models that can imitate the best individual rather than harnessing the power of expert groups. in this paper, we introduce a single diffusion model-based approach that produces multiple plausible outputs by learning a distribution over group insights. our proposed model generates a distribution of segmentation masks by leveraging the inherent stochastic sampling process of diffusion using only minimal additional learning. we demonstrate on three different medical image modalities- ct, ultrasound, and mri that our model is capable of producing several possible variants while capturing the frequencies of their occurrences. comprehensive results show that our proposed approach outperforms existing state-of-the-art ambiguous segmentation networks in terms of accuracy while preserving naturally occurring variation. we also propose a new metric to evaluate the diversity as well as the accuracy of segmentation predictions that aligns with the interest of clinical practice of collective insights.",,2023-04-10,,"['aimon rahman', 'jeya maria jose valanarasu', 'ilker hacihaliloglu', 'vishal m patel']",https://arxiv.org/pdf/2304.04745.pdf
674,2304.04748,exploring effective factors for improving visual in-context learning,cs.cv,"the in-context learning (icl) is to understand a new task via a few demonstrations (aka. prompt) and predict new inputs without tuning the models. while it has been widely studied in nlp, it is still a relatively new area of research in computer vision. to reveal the factors influencing the performance of visual in-context learning, this paper shows that prompt selection and prompt fusion are two major factors that have a direct impact on the inference performance of visual context learning. prompt selection is the process of identifying the most appropriate prompt or example to help the model understand new tasks. this is important because providing the model with relevant prompts can help it learn more effectively and efficiently. prompt fusion involves combining knowledge from different positions within the large-scale visual model. by doing this, the model can leverage the diverse knowledge stored in different parts of the model to improve its performance on new tasks. based these findings, we propose a simple framework prompt-self for visual in-context learning. specifically, we first use the pixel-level retrieval method to select a suitable prompt, and then use different prompt fusion methods to activate all the knowledge stored in the large-scale model, and finally ensemble the prediction results obtained from different prompt fusion methods to obtain the final prediction results. and we conduct extensive experiments on single-object segmentation and detection tasks to demonstrate the effectiveness of prompt-self. remarkably, the prompt-self has outperformed oslsm based meta-learning in 1-shot segmentation for the first time. this indicated the great potential of visual in-context learning. the source code and models will be available at \url{https://github.com/syp2ysy/prompt-self}.",,2023-04-10,,"['yanpeng sun', 'qiang chen', 'jian wang', 'jingdong wang', 'zechao li']",https://arxiv.org/pdf/2304.04748.pdf
675,2304.04751,deephive: a multi-agent reinforcement learning approach for automated   discovery of swarm-based optimization policies,cs.ai,"we present an approach for designing swarm-based optimizers for the global optimization of expensive black-box functions. in the proposed approach, the problem of finding efficient optimizers is framed as a reinforcement learning problem, where the goal is to find optimization policies that require a few function evaluations to converge to the global optimum. the state of each agent within the swarm is defined as its current position and function value within a design space and the agents learn to take favorable actions that maximize reward, which is based on the final value of the objective function. the proposed approach is tested on various benchmark optimization functions and compared to the performance of other global optimization strategies. furthermore, the effect of changing the number of agents, as well as the generalization capabilities of the trained agents are investigated. the results show superior performance compared to the other optimizers, desired scaling when the number of agents is varied, and acceptable performance even when applied to unseen functions. on a broader scale, the results show promise for the rapid development of domain-specific optimizers.",,2023-03-29,,"['eloghosa ikponmwoba', 'ope owoyele']",https://arxiv.org/pdf/2304.04751.pdf
676,2304.04752,a practitioner's guide to bayesian inference in pharmacometrics using   pumas,stat.ap cs.lg cs.ms stat.co,"this paper provides a comprehensive tutorial for bayesian practitioners in pharmacometrics using pumas workflows. we start by giving a brief motivation of bayesian inference for pharmacometrics highlighting limitations in existing software that pumas addresses. we then follow by a description of all the steps of a standard bayesian workflow for pharmacometrics using code snippets and examples. this includes: model definition, prior selection, sampling from the posterior, prior and posterior simulations and predictions, counter-factual simulations and predictions, convergence diagnostics, visual predictive checks, and finally model comparison with cross-validation. finally, the background and intuition behind many advanced concepts in bayesian statistics are explained in simple language. this includes many important ideas and precautions that users need to keep in mind when performing bayesian analysis. many of the algorithms, codes, and ideas presented in this paper are highly applicable to clinical research and statistical learning at large but we chose to focus our discussions on pharmacometrics in this paper to have a narrower scope in mind and given the nature of pumas as a software primarily for pharmacometricians.",,2023-03-31,,"['mohamed tarek', 'jose storopoli', 'casey davis', 'chris elrod', 'julius krumbiegel', 'chris rackauckas', 'vijay ivaturi']",https://arxiv.org/pdf/2304.04752.pdf
677,2304.04753,$\textit{e-uber}$: a crowdsourcing platform for electric vehicle-based   ride- and energy-sharing,cs.ai cs.gt cs.hc cs.lg cs.sy eess.sy,"the sharing-economy-based business model has recently seen success in the transportation and accommodation sectors with companies like uber and airbnb. there is growing interest in applying this model to energy systems, with modalities like peer-to-peer (p2p) energy trading, electric vehicles (ev)-based vehicle-to-grid (v2g), vehicle-to-home (v2h), vehicle-to-vehicle (v2v), and battery swapping technology (bst). in this work, we exploit the increasing diffusion of evs to realize a crowdsourcing platform called e-uber that jointly enables ride-sharing and energy-sharing through v2g and bst. e-uber exploits spatial crowdsourcing, reinforcement learning, and reverse auction theory. specifically, the platform uses reinforcement learning to understand the drivers' preferences towards different ride-sharing and energy-sharing tasks. based on these preferences, a personalized list is recommended to each driver through cmab-based algorithm for task recommendation system (cars). drivers bid on their preferred tasks in their list in a reverse auction fashion. then e-uber solves the task assignment optimization problem that minimizes cost and guarantees v2g energy requirement. we prove that this problem is np-hard and introduce a bipartite matching-inspired heuristic, bipartite matching-based winner selection (bmw), that has polynomial time complexity. results from experiments using real data from nyc taxi trips and energy consumption show that e-uber performs close to the optimum and finds better solutions compared to a state-of-the-art approach",,2023-03-31,,"['ashutosh timilsina', 'simone silvestri']",https://arxiv.org/pdf/2304.04753.pdf
678,2304.04754,por\'ownanie metod detekcji zaj\k{e}to\'sci widma radiowego z   wykorzystaniem uczenia federacyjnego z oraz bez w\k{e}z{\l}a centralnego,cs.ni cs.lg,"dynamic spectrum access systems typically require information about the spectrum occupancy and thus the presence of other users in order to make a spectrum al-location decision for a new device. simple methods of spectrum occupancy detection are often far from reliable, hence spectrum occupancy detection algorithms supported by machine learning or artificial intelligence are often and successfully used. to protect the privacy of user data and to reduce the amount of control data, an interesting approach is to use federated machine learning. this paper compares two approaches to system design using federated machine learning: with and without a central node.",10.15199/59.2022.4.72,2023-03-31,,['≈Çukasz ku≈Çacz'],https://arxiv.org/pdf/2304.04754.pdf
679,2304.04755,a novel two-level causal inference framework for on-road vehicle quality   issues diagnosis,cs.ai cs.lg,"in the automotive industry, the full cycle of managing in-use vehicle quality issues can take weeks to investigate. the process involves isolating root causes, defining and implementing appropriate treatments, and refining treatments if needed. the main pain-point is the lack of a systematic method to identify causal relationships, evaluate treatment effectiveness, and direct the next actionable treatment if the current treatment was deemed ineffective. this paper will show how we leverage causal machine learning (ml) to speed up such processes. a real-word data set collected from on-road vehicles will be used to demonstrate the proposed framework. open challenges for vehicle quality applications will also be discussed.",,2023-03-31,,"['qian wang', 'huanyi shui', 'thi tu trinh tran', 'milad zafar nezhad', 'devesh upadhyay', 'kamran paynabar', 'anqi he']",https://arxiv.org/pdf/2304.04755.pdf
680,2304.04757,a new perspective on building efficient and expressive 3d equivariant   graph neural networks,cs.lg cs.ai,"geometric deep learning enables the encoding of physical symmetries in modeling 3d objects. despite rapid progress in encoding 3d symmetries into graph neural networks (gnns), a comprehensive evaluation of the expressiveness of these networks through a local-to-global analysis lacks today. in this paper, we propose a local hierarchy of 3d isomorphism to evaluate the expressive power of equivariant gnns and investigate the process of representing global geometric information from local patches. our work leads to two crucial modules for designing expressive and efficient geometric gnns; namely local substructure encoding (lse) and frame transition encoding (fte). to demonstrate the applicability of our theory, we propose leftnet which effectively implements these modules and achieves state-of-the-art performance on both scalar-valued and vector-valued molecular property prediction tasks. we further point out the design space for future developments of equivariant graph neural networks. our codes are available at \url{https://github.com/yuanqidu/leftnet}.",,2023-04-07,,"['weitao du', 'yuanqi du', 'limei wang', 'dieqiao feng', 'guifeng wang', 'shuiwang ji', 'carla gomes', 'zhi-ming ma']",https://arxiv.org/pdf/2304.04757.pdf
681,2304.04761,connecting fairness in machine learning with public health equity,cs.lg cs.ai cs.cy,"machine learning (ml) has become a critical tool in public health, offering the potential to improve population health, diagnosis, treatment selection, and health system efficiency. however, biases in data and model design can result in disparities for certain protected groups and amplify existing inequalities in healthcare. to address this challenge, this study summarizes seminal literature on ml fairness and presents a framework for identifying and mitigating biases in the data and model. the framework provides guidance on incorporating fairness into different stages of the typical ml pipeline, such as data processing, model design, deployment, and evaluation. to illustrate the impact of biases in data on ml models, we present examples that demonstrate how systematic biases can be amplified through model predictions. these case studies suggest how the framework can be used to prevent these biases and highlight the need for fair and equitable ml models in public health. this work aims to inform and guide the use of ml in public health towards a more ethical and equitable outcome for all populations.",,2023-04-08,,['shaina raza'],https://arxiv.org/pdf/2304.04761.pdf
682,2304.04766,non-linear estimation using the weighted average consensus-based   unscented filtering for various vehicles dynamics towards autonomous   sensorless design,eess.sy cs.sy,"the concerns to autonomous vehicles have been becoming more intriguing in coping with the more environmentally dynamics non-linear systems under some constraints and disturbances. these vehicles connect not only to the self-instruments yet to the neighborhoods components, making the diverse interconnected communications which should be handled locally to ease the computation and to fasten the decision. to deal with those interconnected networks, the distributed estimation to reach the untouched states, pursuing sensorless design, is approached, initiated by the construction of the modified pseudo measurement which, due to approximation, led to the weighted average consensus calculation within unscented filtering along with the bounded estimation errors. moreover, the tested vehicles are also associated to certain robust control scenarios subject to noise and disturbance with some stability analysis to ensure the usage of the proposed estimation algorithm. the numerical instances are presented along with the performances of the control and estimation method. the results affirms the effectiveness of the method with limited error deviation compared to the other centralized and distributed filtering. beyond these, the further research would be the directed sensorless design and fault-tolerant learning control subject to faults to negate the failures.",10.18196/jrc.v4i1.16164,2023-04-08,,"['bambang l. widjiantoro', 'moh kamalul wafi', 'katherin indriawati']",https://arxiv.org/pdf/2304.04766.pdf
683,2304.04774,ddrf: denoising diffusion model for remote sensing image fusion,cs.cv cs.ai eess.iv,"denosing diffusion model, as a generative model, has received a lot of attention in the field of image generation recently, thanks to its powerful generation capability. however, diffusion models have not yet received sufficient research in the field of image fusion. in this article, we introduce diffusion model to the image fusion field, treating the image fusion task as image-to-image translation and designing two different conditional injection modulation modules (i.e., style transfer modulation and wavelet modulation) to inject coarse-grained style information and fine-grained high-frequency and low-frequency information into the diffusion unet, thereby generating fused images. in addition, we also discussed the residual learning and the selection of training objectives of the diffusion model in the image fusion task. extensive experimental results based on quantitative and qualitative assessments compared with benchmarks demonstrates state-of-the-art results and good generalization performance in image fusion tasks. finally, it is hoped that our method can inspire other works and gain insight into this field to better apply the diffusion model to image fusion tasks. code shall be released for better reproducibility.",,2023-04-10,,"['zihan cao', 'shiqi cao', 'xiao wu', 'junming hou', 'ran ran', 'liang-jian deng']",https://arxiv.org/pdf/2304.04774.pdf
684,2304.04776,deep photonic networks with arbitrary and broadband functionality,cs.et physics.optics,"growing application space in optical communications, computing, and sensing continues to drive the need for high-performance integrated photonic components. designing these on-chip systems with complex and application-specific functionality requires beyond what is possible with physical intuition, for which machine learning-based design methods have recently become popular. however, as the expensive computational requirements for physically accurate device simulations last a critical challenge, these methods typically remain limited in scalability and the optical design degrees of freedom they can provide for application-specific and arbitrary photonic integrated circuits. here, we introduce a highly-scalable, physics-informed framework for the design of on-chip optical systems with arbitrary functionality based on a deep photonic network of custom-designed mach-zehnder interferometers. using this framework, we design ultra-broadband power splitters and a spectral duplexer, each in less than two minutes, and demonstrate state-of-the-art experimental performance with less than 0.66 db insertion loss and over 120 nm of 1-db bandwidth for all devices. our presented framework provides an essential tool with a tractable path towards the systematic design of large-scale photonic systems with custom and broadband power, phase, and dispersion profiles for use in multi-band optical applications including high-throughput communications, quantum information processing, and medical/biological sensing.",,2023-04-10,,"['ali najjar amiri', 'aycan deniz vit', 'kazim gorgulu', 'emir salih magden']",https://arxiv.org/pdf/2304.04776.pdf
685,2304.04778,first-order methods for stochastic variational inequality problems with   function constraints,math.oc cs.lg,"the monotone variational inequality (vi) is an important problem in machine learning. in numerous instances, the vi problems are accompanied by function constraints which can possibly be data-driven, making the projection operator challenging to compute. in this paper, we present novel first-order methods for function constrained vi (fcvi) problem under various settings, including smooth or nonsmooth problems with a stochastic operator and/or stochastic constraints. first, we introduce the~{\texttt{opconex}} method and its stochastic variants, which employ extrapolation of the operator and constraint evaluations to update the variables and the lagrangian multipliers. these methods achieve optimal operator or sample complexities when the fcvi problem is either (i) deterministic nonsmooth, or (ii) stochastic, including smooth or nonsmooth stochastic constraints. notably, our algorithms are simple single-loop procedures and do not require the knowledge of lagrange multipliers to attain these complexities. second, to obtain the optimal operator complexity for smooth deterministic problems, we present a novel single-loop adaptive lagrangian extrapolation~(\texttt{adlagex}) method that can adaptively search for and explicitly bound the lagrange multipliers. furthermore, we show that all of our algorithms can be easily extended to saddle point problems with coupled function constraints, hence achieving similar complexity results for the aforementioned cases. to our best knowledge, many of these complexities are obtained for the first time in the literature.",,2023-04-10,,"['digvijay boob', 'qi deng']",https://arxiv.org/pdf/2304.04778.pdf
686,2304.04779,graphmae2: a decoding-enhanced masked self-supervised graph learner,cs.lg,"graph self-supervised learning (ssl), including contrastive and generative approaches, offers great potential to address the fundamental challenge of label scarcity in real-world graph data. among both sets of graph ssl techniques, the masked graph autoencoders (e.g., graphmae)--one type of generative method--have recently produced promising results. the idea behind this is to reconstruct the node features (or structures)--that are randomly masked from the input--with the autoencoder architecture. however, the performance of masked feature reconstruction naturally relies on the discriminability of the input features and is usually vulnerable to disturbance in the features. in this paper, we present a masked self-supervised learning framework graphmae2 with the goal of overcoming this issue. the idea is to impose regularization on feature reconstruction for graph ssl. specifically, we design the strategies of multi-view random re-mask decoding and latent representation prediction to regularize the feature reconstruction. the multi-view random re-mask decoding is to introduce randomness into reconstruction in the feature space, while the latent representation prediction is to enforce the reconstruction in the embedding space. extensive experiments show that graphmae2 can consistently generate top results on various public datasets, including at least 2.45% improvements over state-of-the-art baselines on ogbn-papers100m with 111m nodes and 1.6b edges.",,2023-04-10,,"['zhenyu hou', 'yufei he', 'yukuo cen', 'xiao liu', 'yuxiao dong', 'evgeny kharlamov', 'jie tang']",https://arxiv.org/pdf/2304.04779.pdf
687,2304.04782,reinforcement learning from passive data via latent intentions,cs.lg cs.ai stat.ml,"passive observational data, such as human videos, is abundant and rich in information, yet remains largely untapped by current rl methods. perhaps surprisingly, we show that passive data, despite not having reward or action labels, can still be used to learn features that accelerate downstream rl. our approach learns from passive data by modeling intentions: measuring how the likelihood of future outcomes change when the agent acts to achieve a particular task. we propose a temporal difference learning objective to learn about intentions, resulting in an algorithm similar to conventional rl, but which learns entirely from passive data. when optimizing this objective, our agent simultaneously learns representations of states, of policies, and of possible outcomes in an environment, all from raw observational data. both theoretically and empirically, this scheme learns features amenable for value prediction for downstream tasks, and our experiments demonstrate the ability to learn from many forms of passive data, including cross-embodiment video data and youtube videos.",,2023-04-10,,"['dibya ghosh', 'chethan bhateja', 'sergey levine']",https://arxiv.org/pdf/2304.04782.pdf
688,2304.04784,criticality versus uniformity in deep neural networks,cs.lg stat.ml,"deep feedforward networks initialized along the edge of chaos exhibit exponentially superior training ability as quantified by maximum trainable depth. in this work, we explore the effect of saturation of the tanh activation function along the edge of chaos. in particular, we determine the line of uniformity in phase space along which the post-activation distribution has maximum entropy. this line intersects the edge of chaos, and indicates the regime beyond which saturation of the activation function begins to impede training efficiency. our results suggest that initialization along the edge of chaos is a necessary but not sufficient condition for optimal trainability.",,2023-04-10,,"['aleksandar bukva', 'jurriaan de gier', 'kevin t. grosvenor', 'ro jefferson', 'koenraad schalm', 'eliot schwander']",https://arxiv.org/pdf/2304.04784.pdf
689,2304.04794,stochastic domain wall-magnetic tunnel junction artificial neurons for   noise-resilient spiking neural networks,cs.ne cond-mat.mes-hall,"the spatiotemporal nature of neuronal behavior in spiking neural networks (snns) make snns promising for edge applications that require high energy efficiency. to realize snns in hardware, spintronic neuron implementations can bring advantages of scalability and energy efficiency. domain wall (dw) based magnetic tunnel junction (mtj) devices are well suited for probabilistic neural networks given their intrinsic integrate-and-fire behavior with tunable stochasticity. here, we present a scaled dw-mtj neuron with voltage-dependent firing probability. the measured behavior was used to simulate a snn that attains accuracy during learning compared to an equivalent, but more complicated, multi-weight (mw) dw-mtj device. the validation accuracy during training was also shown to be comparable to an ideal leaky integrate and fire (lif) device. however, during inference, the binary dw-mtj neuron outperformed the other devices after gaussian noise was introduced to the fashion-mnist classification task. this work shows that dw-mtj devices can be used to construct noise-resilient networks suitable for neuromorphic computing on the edge.",,2023-04-10,,"['thomas leonard', 'samuel liu', 'harrison jin', 'jean anne c. incorvia']",https://arxiv.org/pdf/2304.04794.pdf
690,2304.04797,rapid: enabling fast online policy learning in dynamic public cloud   environments,cs.lg cs.dc cs.sy eess.sy,"resource sharing between multiple workloads has become a prominent practice among cloud service providers, motivated by demand for improved resource utilization and reduced cost of ownership. effective resource sharing, however, remains an open challenge due to the adverse effects that resource contention can have on high-priority, user-facing workloads with strict quality of service (qos) requirements. although recent approaches have demonstrated promising results, those works remain largely impractical in public cloud environments since workloads are not known in advance and may only run for a brief period, thus prohibiting offline learning and significantly hindering online learning. in this paper, we propose rapid, a novel framework for fast, fully-online resource allocation policy learning in highly dynamic operating environments. rapid leverages lightweight qos predictions, enabled by domain-knowledge-inspired techniques for sample efficiency and bias reduction, to decouple control from conventional feedback sources and guide policy learning at a rate orders of magnitude faster than prior work. evaluation on a real-world server platform with representative cloud workloads confirms that rapid can learn stable resource allocation policies in minutes, as compared with hours in prior state-of-the-art, while improving qos by 9.0x and increasing best-effort workload performance by 19-43%.",,2023-04-10,,"['drew penney', 'bin li', 'lizhong chen', 'jaroslaw j. sydir', 'anna drewek-ossowicka', 'ramesh illikkal', 'charlie tai', 'ravi iyer', 'andrew herdrich']",https://arxiv.org/pdf/2304.04797.pdf
691,2304.04807,deep-learning based measurement of planetary radial velocities in the   presence of stellar variability,astro-ph.ep astro-ph.im astro-ph.sr cs.lg,"we present a deep-learning based approach for measuring small planetary radial velocities in the presence of stellar variability. we use neural networks to reduce stellar rv jitter in three years of harps-n sun-as-a-star spectra. we develop and compare dimensionality-reduction and data splitting methods, as well as various neural network architectures including single line cnns, an ensemble of single line cnns, and a multi-line cnn. we inject planet-like rvs into the spectra and use the network to recover them. we find that the multi-line cnn is able to recover planets with 0.2 m/s semi-amplitude, 50 day period, with 8.8% error in the amplitude and 0.7% in the period. this approach shows promise for mitigating stellar rv variability and enabling the detection of small planetary rvs with unprecedented precision.",,2023-04-10,2023-04-12,"['ian colwell', 'virisha timmaraju', 'alexander wise']",https://arxiv.org/pdf/2304.04807.pdf
692,2304.04812,scallop: a language for neurosymbolic programming,cs.pl cs.ai cs.lg,"we present scallop, a language which combines the benefits of deep learning and logical reasoning. scallop enables users to write a wide range of neurosymbolic applications and train them in a data- and compute-efficient manner. it achieves these goals through three key features: 1) a flexible symbolic representation that is based on the relational data model; 2) a declarative logic programming language that is based on datalog and supports recursion, aggregation, and negation; and 3) a framework for automatic and efficient differentiable reasoning that is based on the theory of provenance semirings. we evaluate scallop on a suite of eight neurosymbolic applications from the literature. our evaluation demonstrates that scallop is capable of expressing algorithmic reasoning in diverse and challenging ai tasks, provides a succinct interface for machine learning programmers to integrate logical domain knowledge, and yields solutions that are comparable or superior to state-of-the-art models in terms of accuracy. furthermore, scallop's solutions outperform these models in aspects such as runtime and data efficiency, interpretability, and generalizability.",,2023-04-10,,"['ziyang li', 'jiani huang', 'mayur naik']",https://arxiv.org/pdf/2304.04812.pdf
693,2304.04814,lcdctcnn: lung cancer diagnosis of ct scan images using cnn based model,eess.iv cs.cv cs.lg,"the most deadly and life-threatening disease in the world is lung cancer. though early diagnosis and accurate treatment are necessary for lowering the lung cancer mortality rate. a computerized tomography (ct) scan-based image is one of the most effective imaging techniques for lung cancer detection using deep learning models. in this article, we proposed a deep learning model-based convolutional neural network (cnn) framework for the early detection of lung cancer using ct scan images. we also have analyzed other models for instance inception v3, xception, and resnet-50 models to compare with our proposed model. we compared our models with each other considering the metrics of accuracy, area under curve (auc), recall, and loss. after evaluating the model's performance, we observed that cnn outperformed other models and has been shown to be promising compared to traditional methods. it achieved an accuracy of 92%, auc of 98.21%, recall of 91.72%, and loss of 0.328.",,2023-04-10,,"['muntasir mamun', 'md ishtyaq mahmud', 'mahabuba meherin', 'ahmed abdelgawad']",https://arxiv.org/pdf/2304.04814.pdf
694,2304.04819,"advances in cybercrime prediction: a survey of machine, deep, transfer,   and adaptive learning techniques",cs.lg cs.ai cs.cr cs.cv,"cybercrime is a growing threat to organizations and individuals worldwide, with criminals using increasingly sophisticated techniques to breach security systems and steal sensitive data. in recent years, machine learning, deep learning, and transfer learning techniques have emerged as promising tools for predicting cybercrime and preventing it before it occurs. this paper aims to provide a comprehensive survey of the latest advancements in cybercrime prediction using above mentioned techniques, highlighting the latest research related to each approach. for this purpose, we reviewed more than 150 research articles and discussed around 50 most recent and relevant research articles. we start the review by discussing some common methods used by cyber criminals and then focus on the latest machine learning techniques and deep learning techniques, such as recurrent and convolutional neural networks, which were effective in detecting anomalous behavior and identifying potential threats. we also discuss transfer learning, which allows models trained on one dataset to be adapted for use on another dataset, and then focus on active and reinforcement learning as part of early-stage algorithmic research in cybercrime prediction. finally, we discuss critical innovations, research gaps, and future research opportunities in cybercrime prediction. overall, this paper presents a holistic view of cutting-edge developments in cybercrime prediction, shedding light on the strengths and limitations of each method and equipping researchers and practitioners with essential insights, publicly available datasets, and resources necessary to develop efficient cybercrime prediction systems.",,2023-04-10,,"['lavanya elluri', 'varun mandalapu', 'piyush vyas', 'nirmalya roy']",https://arxiv.org/pdf/2304.04819.pdf
695,2304.04822,robust body exposure (robe): a graph-based dynamics modeling approach to   manipulating blankets over people,cs.ro,"robotic caregivers could potentially improve the quality of life of many who require physical assistance. however, in order to assist individuals who are lying in bed, robots must be capable of dealing with a significant obstacle: the blanket or sheet that will almost always cover the person's body. we propose a method for targeted bedding manipulation over people lying supine in bed where we first learn a model of the cloth's dynamics. then, we optimize over this model to uncover a given target limb using information about human body shape and pose that only needs to be provided at run-time. we show how this approach enables greater robustness to variation relative to geometric and reinforcement learning baselines via a number of generalization evaluations in simulation and in the real world. we further evaluate our approach in a human study with 12 participants where we demonstrate that a mobile manipulator can adapt to real variation in human body shape, size, pose, and blanket configuration to uncover target body parts without exposing the rest of the body. source code and supplementary materials are available online.",,2023-04-10,,"['kavya puthuveetil', 'sasha wald', 'atharva pusalkar', 'pratyusha karnati', 'zackory erickson']",https://arxiv.org/pdf/2304.04822.pdf
696,2304.04824,gradient-based uncertainty attribution for explainable bayesian deep   learning,cs.lg cs.cv cs.it math.it stat.ml,"predictions made by deep learning models are prone to data perturbations, adversarial attacks, and out-of-distribution inputs. to build a trusted ai system, it is therefore critical to accurately quantify the prediction uncertainties. while current efforts focus on improving uncertainty quantification accuracy and efficiency, there is a need to identify uncertainty sources and take actions to mitigate their effects on predictions. therefore, we propose to develop explainable and actionable bayesian deep learning methods to not only perform accurate uncertainty quantification but also explain the uncertainties, identify their sources, and propose strategies to mitigate the uncertainty impacts. specifically, we introduce a gradient-based uncertainty attribution method to identify the most problematic regions of the input that contribute to the prediction uncertainty. compared to existing methods, the proposed ua-backprop has competitive accuracy, relaxed assumptions, and high efficiency. moreover, we propose an uncertainty mitigation strategy that leverages the attribution results as attention to further improve the model performance. both qualitative and quantitative evaluations are conducted to demonstrate the effectiveness of our proposed methods.",,2023-04-10,,"['hanjing wang', 'dhiraj joshi', 'shiqiang wang', 'qiang ji']",https://arxiv.org/pdf/2304.04824.pdf
697,2304.04839,mhfit: mobile health data for predicting athletics fitness using machine   learning,cs.lg cs.cy,"mobile phones and other electronic gadgets or devices have aided in collecting data without the need for data entry. this paper will specifically focus on mobile health data. mobile health data use mobile devices to gather clinical health data and track patient vitals in real-time. our study is aimed to give decisions for small or big sports teams on whether one athlete good fit or not for a particular game with the compare several machine learning algorithms to predict human behavior and health using the data collected from mobile devices and sensors placed on patients. in this study, we have obtained the dataset from a similar study done on mhealth. the dataset contains vital signs recordings of ten volunteers from different backgrounds. they had to perform several physical activities with a sensor placed on their bodies. our study used 5 machine learning algorithms (xgboost, naive bayes, decision tree, random forest, and logistic regression) to analyze and predict human health behavior. xgboost performed better compared to the other machine learning algorithms and achieved 95.2% accuracy, 99.5% in sensitivity, 99.5% in specificity, and 99.66% in f1 score. our research indicated a promising future in mhealth being used to predict human behavior and further research and exploration need to be done for it to be available for commercial use specifically in the sports industry.",,2023-04-10,,"['jonayet miah', 'muntasir mamun', 'md minhazur rahman', 'md ishtyaq mahmyd', 'asm mohaimenul islam', 'sabbir ahmed']",https://arxiv.org/pdf/2304.04839.pdf
698,2304.04842,deploying machine learning models to ahead-of-time runtime on edge using   microtvm,cs.lg,"in the past few years, more and more ai applications have been applied to edge devices. however, models trained by data scientists with machine learning frameworks, such as pytorch or tensorflow, can not be seamlessly executed on edge. in this paper, we develop an end-to-end code generator parsing a pre-trained model to c source libraries for the backend using microtvm, a machine learning compiler framework extension addressing inference on bare metal devices. an analysis shows that specific compute-intensive operators can be easily offloaded to the dedicated accelerator with a universal modular accelerator (uma) interface, while others are processed in the cpu cores. by using the automatically generated ahead-of-time c runtime, we conduct a hand gesture recognition experiment on an arm cortex m4f core.",,2023-04-10,,"['chen liu', 'matthias jobst', 'liyuan guo', 'xinyue shi', 'johannes partzsch', 'christian mayr']",https://arxiv.org/pdf/2304.04842.pdf
699,2304.04854,ipinns: incremental learning for physics-informed neural networks,cs.lg cs.na math.na,"physics-informed neural networks (pinns) have recently become a powerful tool for solving partial differential equations (pdes). however, finding a set of neural network parameters that lead to fulfilling a pde can be challenging and non-unique due to the complexity of the loss landscape that needs to be traversed. although a variety of multi-task learning and transfer learning approaches have been proposed to overcome these issues, there is no incremental training procedure for pinns that can effectively mitigate such training challenges. we propose incremental pinns (ipinns) that can learn multiple tasks (equations) sequentially without additional parameters for new tasks and improve performance for every equation in the sequence. our approach learns multiple pdes starting from the simplest one by creating its own subnetwork for each pde and allowing each subnetwork to overlap with previously learned subnetworks. we demonstrate that previous subnetworks are a good initialization for a new equation if pdes share similarities. we also show that ipinns achieve lower prediction error than regular pinns for two different scenarios: (1) learning a family of equations (e.g., 1-d convection pde); and (2) learning pdes resulting from a combination of processes (e.g., 1-d reaction-diffusion pde). the ability to learn all problems with a single network together with learning more complex pdes with better generalization than regular pinns will open new avenues in this field.",,2023-04-10,,"['aleksandr dekhovich', 'marcel h. f. sluiter', 'david m. j. tax', 'miguel a. bessa']",https://arxiv.org/pdf/2304.04854.pdf
700,2304.04858,simulated annealing in early layers leads to better generalization,cs.lg cs.cv,"recently, a number of iterative learning methods have been introduced to improve generalization. these typically rely on training for longer periods of time in exchange for improved generalization. llf (later-layer-forgetting) is a state-of-the-art method in this category. it strengthens learning in early layers by periodically re-initializing the last few layers of the network. our principal innovation in this work is to use simulated annealing in early layers (seal) of the network in place of re-initialization of later layers. essentially, later layers go through the normal gradient descent process, while the early layers go through short stints of gradient ascent followed by gradient descent. extensive experiments on the popular tiny-imagenet dataset benchmark and a series of transfer learning and few-shot learning tasks show that we outperform llf by a significant margin. we further show that, compared to normal training, llf features, although improving on the target task, degrade the transfer learning performance across all datasets we explored. in comparison, our method outperforms llf across the same target datasets by a large margin. we also show that the prediction depth of our method is significantly lower than that of llf and normal training, indicating on average better prediction performance.",,2023-04-10,,"['amirmohammad sarfi', 'zahra karimpour', 'muawiz chaudhary', 'nasir m. khalid', 'mirco ravanelli', 'sudhir mudur', 'eugene belilovsky']",https://arxiv.org/pdf/2304.04858.pdf
701,2304.04870,dass good: explainable data mining of spatial cohort data,cs.hc cs.lg,"developing applicable clinical machine learning models is a difficult task when the data includes spatial information, for example, radiation dose distributions across adjacent organs at risk. we describe the co-design of a modeling system, dass, to support the hybrid human-machine development and validation of predictive models for estimating long-term toxicities related to radiotherapy doses in head and neck cancer patients. developed in collaboration with domain experts in oncology and data mining, dass incorporates human-in-the-loop visual steering, spatial data, and explainable ai to augment domain knowledge with automatic data mining. we demonstrate dass with the development of two practical clinical stratification models and report feedback from domain experts. finally, we describe the design lessons learned from this collaborative experience.",,2023-04-10,,"['andrew wentzel', 'carla floricel', 'guadalupe canahuate', 'mohamed a. naser', 'abdallah s. mohamed', 'clifton david fuller', 'lisanne van dijk', 'g. elisabeta marai']",https://arxiv.org/pdf/2304.04870.pdf
702,2304.04873,socioeconomicmag meets a platform for ses-diverse college students: a   case study,cs.hc,"emerging research shows that individual differences in how people use technology sometimes cluster by socioeconomic status (ses) and that when technology is not socioeconomically inclusive, low-ses individuals may abandon it. to understand how to improve technology's ses-inclusivity, we present a multi-phase case study on socioeconomicmag (sesmag), an emerging inspection method for socio+economic inclusivity. in our 16-month case study, a software team developing a learning management platform used sesmag to evaluate and then to improve their platform's ses-inclusivity. the results showed that (1) the practitioners identified ses-inclusivity bugs in 76% of the features they evaluated; (2) these inclusivity bugs actually arise among low-ses college students; and (3) the sesmag process pointed ways towards fixing these bugs. finally, (4) a user study with ses-diverse college students showed that the platform's ses-inclusivity eradicated 45-54% of the bugs; for some types of bugs, the bug instance eradication rate was 80% or higher.",,2023-04-10,,"['puja agarwal', 'divya prem', 'christopher bogart', 'abrar fallatah', 'aileen abril castro-guzman', 'pannapat chanpaisaeng', 'stella doehring', 'margaret burnett', 'anita sarma']",https://arxiv.org/pdf/2304.04873.pdf
703,2304.04874,imagecaptioner$^2$: image captioner for image captioning bias   amplification assessment,cs.cv cs.ai cs.lg,"most pre-trained learning systems are known to suffer from bias, which typically emerges from the data, the model, or both. measuring and quantifying bias and its sources is a challenging task and has been extensively studied in image captioning. despite the significant effort in this direction, we observed that existing metrics lack consistency in the inclusion of the visual signal. in this paper, we introduce a new bias assessment metric, dubbed $imagecaptioner^2$, for image captioning. instead of measuring the absolute bias in the model or the data, $imagecaptioner^2$ pay more attention to the bias introduced by the model w.r.t the data bias, termed bias amplification. unlike the existing methods, which only evaluate the image captioning algorithms based on the generated captions only, $imagecaptioner^2$ incorporates the image while measuring the bias. in addition, we design a formulation for measuring the bias of generated captions as prompt-based image captioning instead of using language classifiers. finally, we apply our $imagecaptioner^2$ metric across 11 different image captioning architectures on three different datasets, i.e., ms-coco caption dataset, artemis v1, and artemis v2, and on three different protected attributes, i.e., gender, race, and emotions. consequently, we verify the effectiveness of our $imagecaptioner^2$ metric by proposing anonymousbench, which is a novel human evaluation paradigm for bias metrics. our metric shows significant superiority over the recent bias metric; lic, in terms of human alignment, where the correlation scores are 80% and 54% for our metric and lic, respectively. the code is available at https://eslambakr.github.io/imagecaptioner2.github.io/.",,2023-04-10,,"['eslam mohamed bakr', 'pengzhan sun', 'li erran li', 'mohamed elhoseiny']",https://arxiv.org/pdf/2304.04874.pdf
704,2304.04884,multi-sample consensus driven unsupervised normal estimation for 3d   point clouds,cs.cv,"deep normal estimators have made great strides on synthetic benchmarks. unfortunately, their performance dramatically drops on the real scan data since they are supervised only on synthetic datasets. the point-wise annotation of ground truth normals is vulnerable to inefficiency and inaccuracies, which totally makes it impossible to build perfect real datasets for supervised deep learning. to overcome the challenge, we propose a multi-sample consensus paradigm for unsupervised normal estimation. the paradigm consists of multi-candidate sampling, candidate rejection, and mode determination. the latter two are driven by neighbor point consensus and candidate consensus respectively. two primary implementations of the paradigm, msune and msune-net, are proposed. msune minimizes a candidate consensus loss in mode determination. as a robust optimization method, it outperforms the cutting-edge supervised deep learning methods on real data at the cost of longer runtime for sampling enough candidate normals for each query point. msune-net, the first unsupervised deep normal estimator as far as we know, significantly promotes the multi-sample consensus further. it transfers the three online stages of msune to offline training. thereby its inference time is 100 times faster. besides that, more accurate inference is achieved, since the candidates of query points from similar patches can form a sufficiently large candidate set implicitly in msune-net. comprehensive experiments demonstrate that the two proposed unsupervised methods are noticeably superior to some supervised deep normal estimators on the most common synthetic dataset. more importantly, they show better generalization ability and outperform all the sota conventional and deep methods on three real datasets: nyuv2, kitti, and a dataset from pcv [1].",,2023-04-10,,"['jie zhang', 'minghui nie', 'junjie cao', 'jian liu', 'ligang liu']",https://arxiv.org/pdf/2304.04884.pdf
705,2304.04896,neural network predicts ion concentration profiles under nanoconfinement,cs.lg physics.chem-ph,"modeling the ion concentration profile in nanochannel plays an important role in understanding the electrical double layer and electroosmotic flow. due to the non-negligible surface interaction and the effect of discrete solvent molecules, molecular dynamics (md) simulation is often used as an essential tool to study the behavior of ions under nanoconfinement. despite the accuracy of md simulation in modeling nanoconfinement systems, it is computationally expensive. in this work, we propose neural network to predict ion concentration profiles in nanochannels with different configurations, including channel widths, ion molarity, and ion types. by modeling the ion concentration profile as a probability distribution, our neural network can serve as a much faster surrogate model for md simulation with high accuracy. we further demonstrate the superior prediction accuracy of neural network over xgboost. lastly, we demonstrated that neural network is flexible in predicting ion concentration profiles with different bin sizes. overall, our deep learning model is a fast, flexible, and accurate surrogate model to predict ion concentration profiles in nanoconfinement.",,2023-04-10,,"['zhonglin cao', 'yuyang wang', 'cooper lorsung', 'amir barati farimani']",https://arxiv.org/pdf/2304.04896.pdf
706,2304.04901,bounding box annotation with visible status,cs.cv cs.mm,"training deep-learning-based vision systems requires the manual annotation of a significant amount of data to optimize several parameters of the deep convolutional neural networks. such manual annotation is highly time-consuming and labor-intensive. to reduce this burden, a previous study presented a fully automated annotation approach that does not require any manual intervention. the proposed method associates a visual marker with an object and captures it in the same image. however, because the previous method relied on moving the object within the capturing range using a fixed-point camera, the collected image dataset was limited in terms of capturing viewpoints. to overcome this limitation, this study presents a mobile application-based free-viewpoint image-capturing method. with the proposed application, users can collect multi-view image datasets automatically that are annotated with bounding boxes by moving the camera. however, capturing images through human involvement is laborious and monotonous. therefore, we propose gamified application features to track the progress of the collection status. our experiments demonstrated that using the gamified mobile application for bounding box annotation, with visible collection progress status, can motivate users to collect multi-view object image datasets with less mental workload and time pressure in an enjoyable manner, leading to increased engagement.",,2023-04-10,,"['takuya kiyokawa', 'naoki shirakura', 'hiroki katayama', 'keita tomochika', 'jun takamatsu']",https://arxiv.org/pdf/2304.04901.pdf
707,2304.04902,weakly supervised intracranial hemorrhage segmentation using head-wise   gradient-infused self-attention maps from a swin transformer in categorical   learning,cs.cv,"intracranial hemorrhage (ich) is a life-threatening medical emergency caused by various factors. timely and precise diagnosis of ich is crucial for administering effective treatment and improving patient survival rates. while deep learning techniques have emerged as the leading approach for medical image analysis and processing, the most commonly employed supervised learning often requires large, high-quality annotated datasets that can be costly to obtain, particularly for pixel/voxel-wise image segmentation. to address this challenge and facilitate ich treatment decisions, we proposed a novel weakly supervised ich segmentation method that leverages a hierarchical combination of head-wise gradient-infused self-attention maps obtained from a swin transformer. the transformer is trained using an ich classification task with categorical labels. to build and validate the proposed technique, we used two publicly available clinical ct datasets, namely rsna 2019 brain ct hemorrhage and physionet. additionally, we conducted an exploratory study comparing two learning strategies - binary classification and full ich subtyping - to assess their impact on self-attention and our weakly supervised ich segmentation framework. the proposed algorithm was compared against the popular u-net with full supervision, as well as a similar weakly supervised approach using grad-cam for ich segmentation. with a mean dice score of 0.47, our technique achieved similar ich segmentation performance as the u-net and outperformed the grad-cam based approach, demonstrating the excellent potential of the proposed framework in challenging medical image segmentation tasks.",,2023-04-10,,"['amirhossein rasoulian', 'soorena salari', 'yiming xiao']",https://arxiv.org/pdf/2304.04902.pdf
708,2304.04906,survey on leveraging uncertainty estimation towards trustworthy deep   neural networks: the case of reject option and post-training processing,cs.lg cs.cv,"although neural networks (especially deep neural networks) have achieved \textit{better-than-human} performance in many fields, their real-world deployment is still questionable due to the lack of awareness about the limitation in their knowledge. to incorporate such awareness in the machine learning model, prediction with reject option (also known as selective classification or classification with abstention) has been proposed in literature. in this paper, we present a systematic review of the prediction with the reject option in the context of various neural networks. to the best of our knowledge, this is the first study focusing on this aspect of neural networks. moreover, we discuss different novel loss functions related to the reject option and post-training processing (if any) of network output for generating suitable measurements for knowledge awareness of the model. finally, we address the application of the rejection option in reducing the prediction time for the real-time problems and present a comprehensive summary of the techniques related to the reject option in the context of extensive variety of neural networks. our code is available on github: \url{https://github.com/mehedihasantutul/reject_option}",,2023-04-10,,"['mehedi hasan', 'moloud abdar', 'abbas khosravi', 'uwe aickelin', ""pietro lio'"", 'ibrahim hossain', 'ashikur rahman', 'saeid nahavandi']",https://arxiv.org/pdf/2304.04906.pdf
709,2304.04907,improving vision-and-language navigation by generating future-view image   semantics,cs.cv cs.ai cs.cl cs.lg,"vision-and-language navigation (vln) is the task that requires an agent to navigate through the environment based on natural language instructions. at each step, the agent takes the next action by selecting from a set of navigable locations. in this paper, we aim to take one step further and explore whether the agent can benefit from generating the potential future view during navigation. intuitively, humans will have an expectation of how the future environment will look like, based on the natural language instructions and surrounding views, which will aid correct navigation. hence, to equip the agent with this ability to generate the semantics of future navigation views, we first propose three proxy tasks during the agent's in-domain pre-training: masked panorama modeling (mpm), masked trajectory modeling (mtm), and action prediction with image generation (apig). these three objectives teach the model to predict missing views in a panorama (mpm), predict missing steps in the full trajectory (mtm), and generate the next view based on the full instruction and navigation history (apig), respectively. we then fine-tune the agent on the vln task with an auxiliary loss that minimizes the difference between the view semantics generated by the agent and the ground truth view semantics of the next step. empirically, our vln-sig achieves the new state-of-the-art on both the room-to-room dataset and the cvdn dataset. we further show that our agent learns to fill in missing patches in future views qualitatively, which brings more interpretability over agents' predicted actions. lastly, we demonstrate that learning to predict future view semantics also enables the agent to have better performance on longer paths.",,2023-04-10,,"['jialu li', 'mohit bansal']",https://arxiv.org/pdf/2304.04907.pdf
710,2304.04911,real-time model-free deep reinforcement learning for force control of a   series elastic actuator,cs.lg cs.ro cs.sy eess.sy,"many state-of-the art robotic applications utilize series elastic actuators (seas) with closed-loop force control to achieve complex tasks such as walking, lifting, and manipulation. model-free pid control methods are more prone to instability due to nonlinearities in the sea where cascaded model-based robust controllers can remove these effects to achieve stable force control. however, these model-based methods require detailed investigations to characterize the system accurately. deep reinforcement learning (drl) has proved to be an effective model-free method for continuous control tasks, where few works deal with hardware learning. this paper describes the training process of a drl policy on hardware of an sea pendulum system for tracking force control trajectories from 0.05 - 0.35 hz at 50 n amplitude using the proximal policy optimization (ppo) algorithm. safety mechanisms are developed and utilized for training the policy for 12 hours (overnight) without an operator present within the full 21 hours training period. the tracking performance is evaluated showing improvements of $25$ n in mean absolute error when comparing the first 18 min. of training to the full 21 hours for a 50 n amplitude, 0.1 hz sinusoid desired force trajectory. finally, the drl policy exhibits better tracking and stability margins when compared to a model-free pid controller for a 50 n chirp force trajectory.",,2023-04-10,,"['ruturaj sambhus', 'aydin gokce', 'stephen welch', 'connor w. herron', 'alexander leonessa']",https://arxiv.org/pdf/2304.04911.pdf
711,2304.04912,financial time series forecasting using cnn and transformer,cs.lg cs.ai econ.em q-fin.cp,"time series forecasting is important across various domains for decision-making. in particular, financial time series such as stock prices can be hard to predict as it is difficult to model short-term and long-term temporal dependencies between data points. convolutional neural networks (cnn) are good at capturing local patterns for modeling short-term dependencies. however, cnns cannot learn long-term dependencies due to the limited receptive field. transformers on the other hand are capable of learning global context and long-term dependencies. in this paper, we propose to harness the power of cnns and transformers to model both short-term and long-term dependencies within a time series, and forecast if the price would go up, down or remain the same (flat) in the future. in our experiments, we demonstrated the success of the proposed method in comparison to commonly adopted statistical and deep learning methods on forecasting intraday stock price change of s&p 500 constituents.",,2023-04-10,,"['zhen zeng', 'rachneet kaur', 'suchetha siddagangappa', 'saba rahimi', 'tucker balch', 'manuela veloso']",https://arxiv.org/pdf/2304.04912.pdf
712,2304.04916,a data-driven state aggregation approach for dynamic discrete choice   models,cs.lg stat.ml,"we study dynamic discrete choice models, where a commonly studied problem involves estimating parameters of agent reward functions (also known as ""structural"" parameters), using agent behavioral data. maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality. in this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. our method works in two stages. in the first stage, we use a flexible inverse reinforcement learning approach to estimate agent q-functions. we use these estimated q-functions, along with a clustering algorithm, to select a subset of states that are the most pivotal for driving changes in q-functions. in the second stage, with these selected ""aggregated"" states, we conduct maximum likelihood estimation using a commonly used nested fixed-point algorithm. the proposed two-stage approach mitigates the curse of dimensionality by reducing the problem dimension. theoretically, we derive finite-sample bounds on the associated estimation error, which also characterize the trade-off of computational complexity, estimation error, and sample complexity. we demonstrate the empirical performance of the algorithm in two classic dynamic discrete choice estimation applications.",,2023-04-10,,"['sinong geng', 'houssam nassif', 'carlos a. manzanares']",https://arxiv.org/pdf/2304.04916.pdf
713,2304.04918,explicit and implicit semantic ranking framework,cs.ir cs.ai,"the core challenge in numerous real-world applications is to match an inquiry to the best document from a mutable and finite set of candidates. existing industry solutions, especially latency-constrained services, often rely on similarity algorithms that sacrifice quality for speed. in this paper we introduce a generic semantic learning-to-rank framework, self-training semantic cross-attention ranking (srank). this transformer-based framework uses linear pairwise loss with mutable training batch sizes and achieves quality gains and high efficiency, and has been applied effectively to show gains on two industry tasks at microsoft over real-world large-scale data sets: smart reply (sr) and ambient clinical intelligence (aci). in smart reply, $srank$ assists live customers with technical support by selecting the best reply from predefined solutions based on consumer and support agent messages. it achieves 11.7% gain in offline top-one accuracy on the sr task over the previous system, and has enabled 38.7% time reduction in composing messages in telemetry recorded since its general release in january 2021. in the aci task, srank selects relevant historical physician templates that serve as guidance for a text summarization model to generate higher quality medical notes. it achieves 35.5% top-one accuracy gain, along with 46% relative rouge-l gain in generated medical notes.",10.1145/3543873.3584621,2023-04-10,,"['xiaofeng zhu', 'thomas lin', 'vishal anand', 'matthew calderwood', 'eric clausen-brown', 'gord lueck', 'wen-wai yim', 'cheng wu']",https://arxiv.org/pdf/2304.04918.pdf
714,2304.04932,robust dequantization of the quantum singular value transformation and   quantum machine learning algorithms,quant-ph cs.ds cs.lg,"several quantum algorithms for linear algebra problems, and in particular quantum machine learning problems, have been ""dequantized"" in the past few years. these dequantization results typically hold when classical algorithms can access the data via length-squared sampling. in this work we investigate how robust these dequantization results are. we introduce the notion of approximate length-squared sampling, where classical algorithms are only able to sample from a distribution close to the ideal distribution in total variation distance. while quantum algorithms are natively robust against small perturbations, current techniques in dequantization are not. our main technical contribution is showing how many techniques from randomized linear algebra can be adapted to work under this weaker assumption as well. we then use these techniques to show that the recent low-rank dequantization framework by chia, gily\'en, li, lin, tang and wang (jacm 2022) and the dequantization framework for sparse matrices by gharibian and le gall (stoc 2022), which are both based on the quantum singular value transformation, can be generalized to the case of approximate length-squared sampling access to the input. we also apply these results to obtain a robust dequantization of many quantum machine learning algorithms, including quantum algorithms for recommendation systems, supervised clustering and low-rank matrix inversion.",,2023-04-10,,['fran√ßois le gall'],https://arxiv.org/pdf/2304.04932.pdf
715,2304.04933,reinforcement learning tutor better supported lower performers in a math   task,cs.ai cs.cl,"resource limitations make it hard to provide all students with one of the most effective educational interventions: personalized instruction. reinforcement learning could be a key tool to reduce the development cost and improve the effectiveness of, intelligent tutoring software that aims to provide the right support, at the right time, to a student. here we illustrate that deep reinforcement learning can be used to provide adaptive pedagogical support to students learning about the concept of volume in a narrative storyline software. using explainable artificial intelligence tools, we also extracted interpretable insights about the pedagogical policy learned, and we demonstrate that the resulting policy had similar performance in a different student population. most importantly, in both studies the reinforcement-learning narrative system had the largest benefit for those students with the lowest initial pretest scores, suggesting the opportunity for ai to adapt and provide support for those most in need.",,2023-04-10,,"['sherry ruan', 'allen nie', 'william steenbergen', 'jiayu he', 'jq zhang', 'meng guo', 'yao liu', 'kyle dang nguyen', 'catherine y wang', 'rui ying', 'james a landay', 'emma brunskill. sherry ruan', 'allen nie', 'william steenbergen', 'jiayu he', 'jq zhang', 'meng guo', 'yao liu', 'kyle dang nguyen', 'catherine y wang', 'rui ying', 'james a landay', 'emma brunskill']",https://arxiv.org/pdf/2304.04933.pdf
716,2304.04934,model sparsification can simplify machine unlearning,cs.lg,"recent data regulations necessitate machine unlearning (mu): the removal of the effect of specific examples from the model. while exact unlearning is possible by conducting a model retraining with the remaining data from scratch, its computational cost has led to the development of approximate but efficient unlearning schemes. beyond data-centric mu solutions, we advance mu through a novel model-based viewpoint: sparsification via weight pruning. our results in both theory and practice indicate that model sparsity can boost the multi-criteria unlearning performance of an approximate unlearner, closing the approximation gap, while continuing to be efficient. with this insight, we develop two new sparsity-aware unlearning meta-schemes, termed `prune first, then unlearn' and `sparsity-aware unlearning'. extensive experiments show that our findings and proposals consistently benefit mu in various scenarios, including class-wise data scrubbing, random data scrubbing, and backdoor data forgetting. one highlight is the 77% unlearning efficacy gain of fine-tuning (one of the simplest approximate unlearning methods) in the proposed sparsity-aware unlearning paradigm. codes are available at https://github.com/optml-group/unlearn-sparse.",,2023-04-10,2023-04-13,"['jinghan jia', 'jiancheng liu', 'parikshit ram', 'yuguang yao', 'gaowen liu', 'yang liu', 'pranay sharma', 'sijia liu']",https://arxiv.org/pdf/2304.04934.pdf
717,2304.04935,sentence-level relation extraction via contrastive learning with   descriptive relation prompts,cs.cl,"sentence-level relation extraction aims to identify the relation between two entities for a given sentence. the existing works mostly focus on obtaining a better entity representation and adopting a multi-label classifier for relation extraction. a major limitation of these works is that they ignore background relational knowledge and the interrelation between entity types and candidate relations. in this work, we propose a new paradigm, contrastive learning with descriptive relation prompts(ctl-drp), to jointly consider entity information, relational knowledge and entity type restrictions. in particular, we introduce an improved entity marker and descriptive relation prompts when generating contextual embedding, and utilize contrastive learning to rank the restricted candidate relations. the ctl-drp obtains a competitive f1-score of 76.7% on tacred. furthermore, the new presented paradigm achieves f1-scores of 85.8% and 91.6% on tacrev and re-tacred respectively, which are both the state-of-the-art performance.",,2023-04-10,,"['jiewen zheng', 'ze chen']",https://arxiv.org/pdf/2304.04935.pdf
718,2304.04947,conditional adapters: parameter-efficient transfer learning with fast   inference,cs.cl,"we propose conditional adapter (coda), a parameter-efficient transfer learning method that also improves inference efficiency. coda generalizes beyond standard adapter approaches to enable a new way of balancing speed and accuracy using conditional computation. starting with an existing dense pretrained model, coda adds sparse activation together with a small number of new parameters and a light-weight training phase. our experiments demonstrate that the coda approach provides an unexpectedly efficient way to transfer knowledge. across a variety of language, vision, and speech tasks, coda achieves a 2x to 8x inference speed-up compared to the state-of-the-art adapter approach with moderate to no accuracy loss and the same parameter efficiency.",,2023-04-10,,"['tao lei', 'junwen bai', 'siddhartha brahma', 'joshua ainslie', 'kenton lee', 'yanqi zhou', 'nan du', 'vincent y. zhao', 'yuexin wu', 'bo li', 'yu zhang', 'ming-wei chang']",https://arxiv.org/pdf/2304.04947.pdf
719,2304.04950,reinforcement learning based minimum state-flipped control for the   reachability of boolean control networks,eess.sy cs.sy,"to realize reachability as well as reduce control costs of boolean control networks (bcns) with state-flipped control, a reinforcement learning based method is proposed to obtain flip kernels and the optimal policy with minimal flipping actions to realize reachability. the method proposed is model-free and of low computational complexity. in particular, q-learning (ql), fast ql, and small memory ql are proposed to find flip kernels. fast ql and small memory ql are two novel algorithms. specifically, fast ql, namely, ql combined with transfer-learning and special initial states, is of higher efficiency, and small memory ql is applicable to large-scale systems. meanwhile, we present a novel reward setting, under which the optimal policy with minimal flipping actions to realize reachability is the one of the highest returns. then, to obtain the optimal policy, we propose ql, and fast small memory ql for large-scale systems. specifically, on the basis of the small memory ql mentioned before, the fast small memory ql uses a changeable reward setting to speed up the learning efficiency while ensuring the optimality of the policy. for parameter settings, we give some system properties for reference. finally, two examples, which are a small-scale system and a large-scale one, are considered to verify the proposed method.",,2023-04-10,,"['jingjie ni', 'fangfei li']",https://arxiv.org/pdf/2304.04950.pdf
720,2304.04959,adatt: adaptive task-to-task fusion network for multitask learning in   recommendations,cs.ir,"multi-task learning (mtl) aims at enhancing the performance and efficiency of machine learning models by training them on multiple tasks simultaneously. however, mtl research faces two challenges: 1) modeling the relationships between tasks to effectively share knowledge between them, and 2) jointly learning task-specific and shared knowledge. in this paper, we present a novel model adaptive task-to-task fusion network (adatt) to address both challenges. adatt is a deep fusion network built with task specific and optional shared fusion units at multiple levels. by leveraging a residual mechanism and gating mechanism for task-to-task fusion, these units adaptively learn shared knowledge and task specific knowledge. to evaluate the performance of adatt, we conduct experiments on a public benchmark and an industrial recommendation dataset using various task groups. results demonstrate adatt can significantly outperform existing state-of-the-art baselines.",,2023-04-11,,"['danwei li', 'zhengyu zhang', 'siyang yuan', 'mingze gao', 'weilin zhang', 'chaofei yang', 'xi liu', 'jiyan yang']",https://arxiv.org/pdf/2304.04959.pdf
721,2304.04960,panoramic image-to-image translation,cs.cv,"in this paper, we tackle the challenging task of panoramic image-to-image translation (pano-i2i) for the first time. this task is difficult due to the geometric distortion of panoramic images and the lack of a panoramic image dataset with diverse conditions, like weather or time. to address these challenges, we propose a panoramic distortion-aware i2i model that preserves the structure of the panoramic images while consistently translating their global style referenced from a pinhole image. to mitigate the distortion issue in naive 360 panorama translation, we adopt spherical positional embedding to our transformer encoders, introduce a distortion-free discriminator, and apply sphere-based rotation for augmentation and its ensemble. we also design a content encoder and a style encoder to be deformation-aware to deal with a large domain gap between panoramas and pinhole images, enabling us to work on diverse conditions of pinhole images. in addition, considering the large discrepancy between panoramas and pinhole images, our framework decouples the learning procedure of the panoramic reconstruction stage from the translation stage. we show distinct improvements over existing i2i models in translating the streetlearn dataset in the daytime into diverse conditions. the code will be publicly available online for our community.",,2023-04-11,,"['soohyun kim', 'junho kim', 'taekyung kim', 'hwan heo', 'seungryong kim', 'jiyoung lee', 'jin-hwa kim']",https://arxiv.org/pdf/2304.04960.pdf
722,2304.04966,computer vision-aided intelligent monitoring of coffee: towards   sustainable coffee production,cs.cv,"coffee which is prepared from the grinded roasted seeds of harvested coffee cherries, is one of the most consumed beverage and traded commodity, globally. to manually monitor the coffee field regularly, and inform about plant and soil health, as well as estimate yield and harvesting time, is labor-intensive, time-consuming and error-prone. some recent studies have developed sensors for estimating coffee yield at the time of harvest, however a more inclusive and applicable technology to remotely monitor multiple parameters of the field and estimate coffee yield and quality even at pre-harvest stage, was missing. following precision agriculture approach, we employed machine learning algorithm yolo, for image processing of coffee plant. in this study, the latest version of the state-of-the-art algorithm yolov7 was trained with 324 annotated images followed by its evaluation with 82 unannotated images as test data. next, as an innovative approach for annotating the training data, we trained k-means models which led to machine-generated color classes of coffee fruit and could thus characterize the informed objects in the image. finally, we attempted to develop an ai-based handy mobile application which would not only efficiently predict harvest time, estimate coffee yield and quality, but also inform about plant health. resultantly, the developed model efficiently analyzed the test data with a mean average precision of 0.89. strikingly, our innovative semi-supervised method with an mean average precision of 0.77 for multi-class mode surpassed the supervised method with mean average precision of only 0.60, leading to faster and more accurate annotation. the mobile application we designed based on the developed code, was named coffeapp, which possesses multiple features of analyzing fruit from the image taken by phone camera with in field and can thus track fruit ripening in real time.",,2023-04-11,,"['francisco eron', 'muhammad noman', 'raphael ricon de oliveira', 'deigo de souza marques', 'rafael serapilha durelli', 'andre pimenta freire', 'antonio chalfun junior']",https://arxiv.org/pdf/2304.04966.pdf
723,2304.04970,gril: a $2$-parameter persistence based vectorization for machine   learning,cs.lg cs.ai cs.cg math.at,"$1$-parameter persistent homology, a cornerstone in topological data analysis (tda), studies the evolution of topological features such as connected components and cycles hidden in data. it has been applied to enhance the representation power of deep learning models, such as graph neural networks (gnns). to enrich the representations of topological features, here we propose to study $2$-parameter persistence modules induced by bi-filtration functions. in order to incorporate these representations into machine learning models, we introduce a novel vector representation called generalized rank invariant landscape \textsc{gril} for $2$-parameter persistence modules. we show that this vector representation is $1$-lipschitz stable and differentiable with respect to underlying filtration functions and can be easily integrated into machine learning models to augment encoding topological features. we present an algorithm to compute the vector representation efficiently. we also test our methods on synthetic and benchmark graph datasets, and compare the results with previous vector representations of $1$-parameter and $2$-parameter persistence modules.",,2023-04-11,,"['cheng xin', 'soham mukherjee', 'shreyas n. samaga', 'tamal k. dey']",https://arxiv.org/pdf/2304.04970.pdf
724,2304.04972,federated learning with classifier shift for class imbalance,cs.lg,"federated learning aims to learn a global model collaboratively while the training data belongs to different clients and is not allowed to be exchanged. however, the statistical heterogeneity challenge on non-iid data, such as class imbalance in classification, will cause client drift and significantly reduce the performance of the global model. this paper proposes a simple and effective approach named fedshift which adds the shift on the classifier output during the local training phase to alleviate the negative impact of class imbalance. we theoretically prove that the classifier shift in fedshift can make the local optimum consistent with the global optimum and ensure the convergence of the algorithm. moreover, our experiments indicate that fedshift significantly outperforms the other state-of-the-art federated learning approaches on various datasets regarding accuracy and communication efficiency.",,2023-04-11,,"['yunheng shen', 'haoxiang wang', 'hairong lv']",https://arxiv.org/pdf/2304.04972.pdf
725,2304.04974,wav2code: restore clean speech representations via codebook lookup for   noise-robust asr,eess.as cs.lg cs.sd,"automatic speech recognition (asr) has gained a remarkable success thanks to recent advances of deep learning, but it usually degrades significantly under real-world noisy conditions. recent works introduce speech enhancement (se) as front-end to improve speech quality, which is proved effective but may not be optimal for downstream asr due to speech distortion problem. based on that, latest works combine se and currently popular self-supervised learning (ssl) to alleviate distortion and improve noise robustness. despite the effectiveness, the speech distortion caused by conventional se still cannot be completely eliminated. in this paper, we propose a self-supervised framework named wav2code to implement a generalized se without distortions for noise-robust asr. first, in pre-training stage the clean speech representations from ssl model are sent to lookup a discrete codebook via nearest-neighbor feature matching, the resulted code sequence are then exploited to reconstruct the original clean representations, in order to store them in codebook as prior. second, during finetuning we propose a transformer-based code predictor to accurately predict clean codes by modeling the global dependency of input noisy representations, which enables discovery and restoration of high-quality clean representations without distortions. furthermore, we propose an interactive feature fusion network to combine original noisy and the restored clean representations to consider both fidelity and quality, resulting in even more informative features for downstream asr. finally, experiments on both synthetic and real noisy datasets demonstrate that wav2code can solve the speech distortion and improve asr performance under various noisy conditions, resulting in stronger robustness.",,2023-04-11,,"['yuchen hu', 'chen chen', 'qiushi zhu', 'eng siong chng']",https://arxiv.org/pdf/2304.04974.pdf
726,2304.04976,partitioner selection with ease to optimize distributed graph processing,cs.dc,"for distributed graph processing on massive graphs, a graph is partitioned into multiple equally-sized parts which are distributed among machines in a compute cluster. in the last decade, many partitioning algorithms have been developed which differ from each other with respect to the partitioning quality, the run-time of the partitioning and the type of graph for which they work best. the plethora of graph partitioning algorithms makes it a challenging task to select a partitioner for a given scenario. different studies exist that provide qualitative insights into the characteristics of graph partitioning algorithms that support a selection. however, in order to enable automatic selection, a quantitative prediction of the partitioning quality, the partitioning run-time and the run-time of subsequent graph processing jobs is needed. in this paper, we propose a machine learning-based approach to provide such a quantitative prediction for different types of edge partitioning algorithms and graph processing workloads. we show that training based on generated graphs achieves high accuracy, which can be further improved when using real-world data. based on the predictions, the automatic selection reduces the end-to-end run-time on average by 11.1% compared to a random selection, by 17.4% compared to selecting the partitioner that yields the lowest cut size, and by 29.1% compared to the worst strategy, respectively. furthermore, in 35.7% of the cases, the best strategy was selected.",,2023-04-11,,"['nikolai merkel', 'ruben mayer', 'tawkir ahmed fakir', 'hans-arno jacobsen']",https://arxiv.org/pdf/2304.04976.pdf
727,2304.04982,biological factor regulatory neural network,cs.lg cs.ai q-bio.qm,"genes are fundamental for analyzing biological systems and many recent works proposed to utilize gene expression for various biological tasks by deep learning models. despite their promising performance, it is hard for deep neural networks to provide biological insights for humans due to their black-box nature. recently, some works integrated biological knowledge with neural networks to improve the transparency and performance of their models. however, these methods can only incorporate partial biological knowledge, leading to suboptimal performance. in this paper, we propose the biological factor regulatory neural network (bfreg-nn), a generic framework to model relations among biological factors in cell systems. bfreg-nn starts from gene expression data and is capable of merging most existing biological knowledge into the model, including the regulatory relations among genes or proteins (e.g., gene regulatory networks (grn), protein-protein interaction networks (ppi)) and the hierarchical relations among genes, proteins and pathways (e.g., several genes/proteins are contained in a pathway). moreover, bfreg-nn also has the ability to provide new biologically meaningful insights because of its white-box characteristics. experimental results on different gene expression-based tasks verify the superiority of bfreg-nn compared with baselines. our case studies also show that the key insights found by bfreg-nn are consistent with the biological literature.",,2023-04-11,,"['xinnan dai', 'caihua shan', 'jie zheng', 'xiaoxiao li', 'dongsheng li']",https://arxiv.org/pdf/2304.04982.pdf
728,2304.04985,efficient feature description for small body relative navigation using   binary convolutional neural networks,cs.cv cs.ai,"missions to small celestial bodies rely heavily on optical feature tracking for characterization of and relative navigation around the target body. while techniques for feature tracking based on deep learning are a promising alternative to current human-in-the-loop processes, designing deep architectures that can operate onboard spacecraft is challenging due to onboard computational and memory constraints. this paper introduces a novel deep local feature description architecture that leverages binary convolutional neural network layers to significantly reduce computational and memory requirements. we train and test our models on real images of small bodies from legacy and ongoing missions and demonstrate increased performance relative to traditional handcrafted methods. moreover, we implement our models onboard a surrogate for the next-generation spacecraft processor and demonstrate feasible runtimes for online feature tracking.",,2023-04-11,,"['travis driver', 'panagiotis tsiotras']",https://arxiv.org/pdf/2304.04985.pdf
729,2304.05020,cooperative coevolution for non-separable large-scale black-box   optimization: convergence analyses and distributed accelerations,cs.ne,"given the ubiquity of non-separable optimization problems in real worlds, in this paper we analyze and extend the large-scale version of the well-known cooperative coevolution (cc), a divide-and-conquer optimization framework, on non-separable functions. first, we reveal empirical reasons of why decomposition-based methods are preferred or not in practice on some non-separable large-scale problems, which have not been clearly pointed out in many previous cc papers. then, we formalize cc to a continuous game model via simplification, but without losing its essential property. different from previous evolutionary game theory for cc, our new model provides a much simpler but useful viewpoint to analyze its convergence, since only the pure nash equilibrium concept is needed and more general fitness landscapes can be explicitly considered. based on convergence analyses, we propose a hierarchical decomposition strategy for better generalization, as for any decomposition there is a risk of getting trapped into a suboptimal nash equilibrium. finally, we use powerful distributed computing to accelerate it under the multi-level learning framework, which combines the fine-tuning ability from decomposition with the invariance property of cma-es. experiments on a set of high-dimensional functions validate both its search performance and scalability (w.r.t. cpu cores) on a clustering computing platform with 400 cpu cores.",,2023-04-11,,"['qiqi duan', 'chang shao', 'guochen zhou', 'haobin yang', 'qi zhao', 'yuhui shi']",https://arxiv.org/pdf/2304.05020.pdf
730,2304.05022,a deep analysis of transfer learning based breast cancer detection using   histopathology images,eess.iv cs.cv cs.lg,"breast cancer is one of the most common and dangerous cancers in women, while it can also afflict men. breast cancer treatment and detection are greatly aided by the use of histopathological images since they contain sufficient phenotypic data. a deep neural network (dnn) is commonly employed to improve accuracy and breast cancer detection. in our research, we have analyzed pre-trained deep transfer learning models such as resnet50, resnet101, vgg16, and vgg19 for detecting breast cancer using the 2453 histopathology images dataset. images in the dataset were separated into two categories: those with invasive ductal carcinoma (idc) and those without idc. after analyzing the transfer learning model, we found that resnet50 outperformed other models, achieving accuracy rates of 90.2%, area under curve (auc) rates of 90.0%, recall rates of 94.7%, and a marginal loss of 3.5%.",,2023-04-11,,"['md ishtyaq mahmud', 'muntasir mamun', 'ahmed abdelgawad']",https://arxiv.org/pdf/2304.05022.pdf
731,2304.05023,learning optimal fair scoring systems for multi-class classification,cs.lg cs.cy math.oc,"machine learning models are increasingly used for decision making, in particular in high-stakes applications such as credit scoring, medicine or recidivism prediction. however, there are growing concerns about these models with respect to their lack of interpretability and the undesirable biases they can generate or reproduce. while the concepts of interpretability and fairness have been extensively studied by the scientific community in recent years, few works have tackled the general multi-class classification problem under fairness constraints, and none of them proposes to generate fair and interpretable models for multi-class classification. in this paper, we use mixed-integer linear programming (milp) techniques to produce inherently interpretable scoring systems under sparsity and fairness constraints, for the general multi-class classification setup. our work generalizes the slim (supersparse linear integer models) framework that was proposed by rudin and ustun to learn optimal scoring systems for binary classification. the use of milp techniques allows for an easy integration of diverse operational constraints (such as, but not restricted to, fairness or sparsity), but also for the building of certifiably optimal models (or sub-optimal models with bounded optimality gap).",,2023-04-11,,"['julien rouzot', 'julien ferry', 'marie-jos√© huguet']",https://arxiv.org/pdf/2304.05023.pdf
732,2304.05027,triple sequence learning for cross-domain recommendation,cs.ir,"cross-domain recommendation (cdr) aims to leverage the users' behaviors in both source and target domains to improve the target domain's performance. conventional cdr methods typically explore the dual relations between the source and target domains' behavior sequences. however, they ignore modeling the third sequence of mixed behaviors that naturally reflects the user's global preference. to address this issue, we present a novel and model-agnostic triple sequence learning for cross-domain recommendation (tri-cdr) framework to jointly model the source, target, and mixed behavior sequences in cdr. specifically, tri-cdr independently models the hidden user representations for the source, target, and mixed behavior sequences, and proposes a triple cross-domain attention (tca) to emphasize the informative knowledge related to both user's target-domain preference and global interests in three sequences. to comprehensively learn the triple correlations, we design a novel triple contrastive learning (tcl) that jointly considers coarse-grained similarities and fine-grained distinctions among three sequences, ensuring the alignment while preserving the information diversity in multi-domain. we conduct extensive experiments and analyses on two real-world datasets with four domains. the significant improvements of tri-cdr with different sequential encoders on all datasets verify the effectiveness and universality. the source code will be released in the future.",,2023-04-11,,"['haokai ma', 'ruobing xie', 'lei meng', 'xin chen', 'xu zhang', 'leyu lin', 'jie zhou']",https://arxiv.org/pdf/2304.05027.pdf
733,2304.05040,unsupervised out-of-distribution detection for safer robotically-guided   retinal microsurgery,cs.cv eess.iv,"purpose: a fundamental problem in designing safe machine learning systems is identifying when samples presented to a deployed model differ from those observed at training time. detecting so-called out-of-distribution (ood) samples is crucial in safety-critical applications such as robotically-guided retinal microsurgery, where distances between the instrument and the retina are derived from sequences of 1d images that are acquired by an instrument-integrated optical coherence tomography (iioct) probe.   methods: this work investigates the feasibility of using an ood detector to identify when images from the iioct probe are inappropriate for subsequent machine learning-based distance estimation. we show how a simple ood detector based on the mahalanobis distance can successfully reject corrupted samples coming from real-world ex-vivo porcine eyes.   results: our results demonstrate that the proposed approach can successfully detect ood samples and help maintain the performance of the downstream task within reasonable levels. mahaad outperformed a supervised approach trained on the same kind of corruptions and achieved the best performance in detecting ood cases from a collection of iioct samples with real-world corruptions.   conclusion: the results indicate that detecting corrupted iioct data through ood detection is feasible and does not need prior knowledge of possible corruptions. consequently, mahaad could aid in ensuring patient safety during robotically-guided microsurgery by preventing deployed prediction models from estimating distances that put the patient at risk.",,2023-04-11,,"['alain jungo', 'lars doorenbos', 'tommaso da col', 'maarten beelen', 'martin zinkernagel', 'pablo m√°rquez-neila', 'raphael sznitman']",https://arxiv.org/pdf/2304.05040.pdf
734,2304.05047,semi-supervised relational contrastive learning,cs.cv,"disease diagnosis from medical images via supervised learning is usually dependent on tedious, error-prone, and costly image labeling by medical experts. alternatively, semi-supervised learning and self-supervised learning offer effectiveness through the acquisition of valuable insights from readily available unlabeled images. we present semi-supervised relational contrastive learning (srcl), a novel semi-supervised learning model that leverages self-supervised contrastive loss and sample relation consistency for the more meaningful and effective exploitation of unlabeled data. our experimentation with the srcl model explores both pre-train/fine-tune and joint learning of the pretext (contrastive learning) and downstream (diagnostic classification) tasks. we validate against the isic 2018 challenge benchmark skin lesion classification dataset and demonstrate the effectiveness of our semi-supervised method on varying amounts of labeled data.",,2023-04-11,,"['attiano purpura-pontoniere', 'adam wang', 'demetri terzopoulos', 'abdullah-al-zubaer imran']",https://arxiv.org/pdf/2304.05047.pdf
735,2304.05055,a comprehensive survey on deep graph representation learning,cs.lg cs.ai cs.ir,"graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. however, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. with the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages over shallow (traditional) methods, there exist a large number of deep graph representation learning techniques have been proposed in the past decade, especially graph neural networks. in this survey, we conduct a comprehensive survey on current deep graph representation learning algorithms by proposing a new taxonomy of existing state-of-the-art literature. specifically, we systematically summarize the essential components of graph representation learning and categorize existing approaches by the ways of graph neural network architectures and the most recent advanced learning paradigms. moreover, this survey also provides the practical and promising applications of deep graph representation learning. last but not least, we state new perspectives and suggest challenging directions which deserve further investigations in the future.",,2023-04-11,,"['wei ju', 'zheng fang', 'yiyang gu', 'zequn liu', 'qingqing long', 'ziyue qiao', 'yifang qin', 'jianhao shen', 'fang sun', 'zhiping xiao', 'junwei yang', 'jingyang yuan', 'yusheng zhao', 'xiao luo', 'ming zhang']",https://arxiv.org/pdf/2304.05055.pdf
736,2304.05059,hyperbolic geometric graph representation learning for   hierarchy-imbalance node classification,cs.lg cs.si,"learning unbiased node representations for imbalanced samples in the graph has become a more remarkable and important topic. for the graph, a significant challenge is that the topological properties of the nodes (e.g., locations, roles) are unbalanced (topology-imbalance), other than the number of training labeled nodes (quantity-imbalance). existing studies on topology-imbalance focus on the location or the local neighborhood structure of nodes, ignoring the global underlying hierarchical properties of the graph, i.e., hierarchy. in the real-world scenario, the hierarchical structure of graph data reveals important topological properties of graphs and is relevant to a wide range of applications. we find that training labeled nodes with different hierarchical properties have a significant impact on the node classification tasks and confirm it in our experiments. it is well known that hyperbolic geometry has a unique advantage in representing the hierarchical structure of graphs. therefore, we attempt to explore the hierarchy-imbalance issue for node classification of graph neural networks with a novelty perspective of hyperbolic geometry, including its characteristics and causes. then, we propose a novel hyperbolic geometric hierarchy-imbalance learning framework, named hyperimba, to alleviate the hierarchy-imbalance issue caused by uneven hierarchy-levels and cross-hierarchy connectivity patterns of labeled nodes.extensive experimental results demonstrate the superior effectiveness of hyperimba for hierarchy-imbalance node classification tasks.",10.1145/3543507.3583403,2023-04-11,,"['xingcheng fu', 'yuecen wei', 'qingyun sun', 'haonan yuan', 'jia wu', 'hao peng', 'jianxin li']",https://arxiv.org/pdf/2304.05059.pdf
737,2304.05065,artificial intelligence based prediction on lung cancer risk factors   using deep learning,eess.iv cs.ai cs.cv q-bio.sc,"in this proposed work, we identified the significant research issues on lung cancer risk factors. capturing and defining symptoms at an early stage is one of the most difficult phases for patients. based on the history of patients records, we reviewed a number of current research studies on lung cancer and its various stages. we identified that lung cancer is one of the significant research issues in predicting the early stages of cancer disease. this research aimed to develop a model that can detect lung cancer with a remarkably high level of accuracy using the deep learning approach (convolution neural network). this method considers and resolves significant gaps in previous studies. we compare the accuracy levels and loss values of our model with vgg16, inceptionv3, and resnet50. we found that our model achieved an accuracy of 94% and a minimum loss of 0.1%. hence physicians can use our convolution neural network models for predicting lung cancer risk factors in the real world. moreover, this investigation reveals that squamous cell carcinoma, normal, adenocarcinoma, and large cell carcinoma are the most significant risk factors. in addition, the remaining attributes are also crucial for achieving the best performance.",10.11591/ijict.v12i2.pp188-194,2023-04-11,,"['muhammad sohaib', 'mary adewunmi']",https://arxiv.org/pdf/2304.05065.pdf
738,2304.05066,unbiased pairwise learning from implicit feedback for recommender   systems without biased variance control,cs.ir,"generally speaking, the model training for recommender systems can be based on two types of data, namely explicit feedback and implicit feedback. moreover, because of its general availability, we see wide adoption of implicit feedback data, such as click signal. there are mainly two challenges for the application of implicit feedback. first, implicit data just includes positive feedback. therefore, we are not sure whether the non-interacted items are really negative or positive but not displayed to the corresponding user. moreover, the relevance of rare items is usually underestimated since much fewer positive feedback of rare items is collected compared with popular ones. to tackle such difficulties, both pointwise and pairwise solutions are proposed before for unbiased relevance learning. as pairwise learning suits well for the ranking tasks, the previously proposed unbiased pairwise learning algorithm already achieves state-of-the-art performance. nonetheless, the existing unbiased pairwise learning method suffers from high variance. to get satisfactory performance, non-negative estimator is utilized for practical variance control but introduces additional bias. in this work, we propose an unbiased pairwise learning method, named upl, with much lower variance to learn a truly unbiased recommender model. extensive offline experiments on real world datasets and online a/b testing demonstrate the superior performance of our proposed method.",10.1145/3539618.3592077,2023-04-11,,"['yi ren', 'hongyan tang', 'jiangpeng rong', 'siwen zhu']",https://arxiv.org/pdf/2304.05066.pdf
739,2304.05071,fracture detection in pediatric wrist trauma x-ray images using yolov8   algorithm,cs.cv,"hospital emergency departments frequently receive lots of bone fracture cases, with pediatric wrist trauma fracture accounting for the majority of them. before pediatric surgeons perform surgery, they need to ask patients how the fracture occurred and analyze the fracture situation by interpreting x-ray images. the interpretation of x-ray images often requires a combination of techniques from radiologists and surgeons, which requires time-consuming specialized training. with the rise of deep learning in the field of computer vision, network models applying for fracture detection has become an important research topic. in this paper, yolov8 algorithm is used to train models on the grazpedwri-dx dataset, which includes x-ray images from 6,091 pediatric patients with wrist trauma. the experimental results show that yolov8 algorithm models have different advantages for different model sizes, with yolov8l model achieving the highest mean average precision (map 50) of 63.6\%, and yolov8n model achieving the inference time of 67.4ms per x-ray image on one single cpu with low computing power. in this way, we create ""fracture detection using yolov8 app"" to assist surgeons in interpreting x-ray images without the help of radiologists. our implementation code is released at https://github.com/ruiyangju/bone_fracture_detection_yolov8.",,2023-04-11,,"['rui-yang ju', 'weiming cai']",https://arxiv.org/pdf/2304.05071.pdf
740,2304.05073,a tale of sampling and estimation in discounted reinforcement learning,cs.lg,"the most relevant problems in discounted reinforcement learning involve estimating the mean of a function under the stationary distribution of a markov reward process, such as the expected return in policy evaluation, or the policy gradient in policy optimization. in practice, these estimates are produced through a finite-horizon episodic sampling, which neglects the mixing properties of the markov process. it is mostly unclear how this mismatch between the practical and the ideal setting affects the estimation, and the literature lacks a formal study on the pitfalls of episodic sampling, and how to do it optimally. in this paper, we present a minimax lower bound on the discounted mean estimation problem that explicitly connects the estimation error with the mixing properties of the markov process and the discount factor. then, we provide a statistical analysis on a set of notable estimators and the corresponding sampling procedures, which includes the finite-horizon estimators often used in practice. crucially, we show that estimating the mean by directly sampling from the discounted kernel of the markov process brings compelling statistical properties w.r.t. the alternative estimators, as it matches the lower bound without requiring a careful tuning of the episode horizon.",,2023-04-11,,"['alberto maria metelli', 'mirco mutti', 'marcello restelli']",https://arxiv.org/pdf/2304.05073.pdf
741,2304.05078,todynet: temporal dynamic graph neural network for multivariate time   series classification,cs.lg,"multivariate time series classification (mtsc) is an important data mining task, which can be effectively solved by popular deep learning technology. unfortunately, the existing deep learning-based methods neglect the hidden dependencies in different dimensions and also rarely consider the unique dynamic features of time series, which lack sufficient feature extraction capability to obtain satisfactory classification accuracy. to address this problem, we propose a novel temporal dynamic graph neural network (todynet) that can extract hidden spatio-temporal dependencies without undefined graph structure. it enables information flow among isolated but implicit interdependent variables and captures the associations between different time slots by dynamic graph mechanism, which further improves the classification performance of the model. meanwhile, the hierarchical representations of graphs cannot be learned due to the limitation of gnns. thus, we also design a temporal graph pooling layer to obtain a global graph-level representation for graph learning with learnable temporal parameters. the dynamic graph, graph information propagation, and temporal convolution are jointly learned in an end-to-end framework. the experiments on 26 uea benchmark datasets illustrate that the proposed todynet outperforms existing deep learning-based methods in the mtsc tasks.",,2023-04-11,,"['huaiyuan liu', 'xianzhang liu', 'donghua yang', 'zhiyu liang', 'hongzhi wang', 'yong cui', 'jun gu']",https://arxiv.org/pdf/2304.05078.pdf
742,2304.05080,investigating imbalances between sar and optical utilization for   multi-modal urban mapping,cs.cv eess.iv,"accurate urban maps provide essential information to support sustainable urban development. recent urban mapping methods use multi-modal deep neural networks to fuse synthetic aperture radar (sar) and optical data. however, multi-modal networks may rely on just one modality due to the greedy nature of learning. in turn, the imbalanced utilization of modalities can negatively affect the generalization ability of a network. in this paper, we investigate the utilization of sar and optical data for urban mapping. to that end, a dual-branch network architecture using intermediate fusion modules to share information between the uni-modal branches is utilized. a cut-off mechanism in the fusion modules enables the stopping of information flow between the branches, which is used to estimate the network's dependence on sar and optical data. while our experiments on the sen12 global urban mapping dataset show that good performance can be achieved with conventional sar-optical data fusion (f1 score = 0.682 $\pm$ 0.014), we also observed a clear under-utilization of optical data. therefore, future work is required to investigate whether a more balanced utilization of sar and optical data can lead to performance improvements.",,2023-04-11,,"['sebastian hafner', 'yifang ban', 'andrea nascetti']",https://arxiv.org/pdf/2304.05080.pdf
743,2304.05084,a self-attention knowledge domain adaptation network for commercial   lithium-ion batteries state-of-health estimation under shallow cycles,cs.lg eess.sp,"accurate state-of-health (soh) estimation is critical to guarantee the safety, efficiency and reliability of battery-powered applications. most soh estimation methods focus on the 0-100\% full state-of-charge (soc) range that has similar distributions. however, the batteries in real-world applications usually work in the partial soc range under shallow-cycle conditions and follow different degradation profiles with no labeled data available, thus making soh estimation challenging. to estimate shallow-cycle battery soh, a novel unsupervised deep transfer learning method is proposed to bridge different domains using self-attention distillation module and multi-kernel maximum mean discrepancy technique. the proposed method automatically extracts domain-variant features from charge curves to transfer knowledge from the large-scale labeled full cycles to the unlabeled shallow cycles. the calce and snl battery datasets are employed to verify the effectiveness of the proposed method to estimate the battery soh for different soc ranges, temperatures, and discharge rates. the proposed method achieves a root-mean-square error within 2\% and outperforms other transfer learning methods for different soc ranges. when applied to batteries with different operating conditions and from different manufacturers, the proposed method still exhibits superior soh estimation performance. the proposed method is the first attempt at accurately estimating battery soh under shallow-cycle conditions without needing a full-cycle characteristic test.",,2023-04-11,,"['xin chen', 'yuwen qin', 'weidong zhao', 'qiming yang', 'ningbo cai', 'kai wu']",https://arxiv.org/pdf/2304.05084.pdf
744,2304.05090,crowdsim2: an open synthetic benchmark for object detectors,cs.cv,"data scarcity has become one of the main obstacles to developing supervised models based on artificial intelligence in computer vision. indeed, deep learning-based models systematically struggle when applied in new scenarios never seen during training and may not be adequately tested in non-ordinary yet crucial real-world situations. this paper presents and publicly releases crowdsim2, a new synthetic collection of images suitable for people and vehicle detection gathered from a simulator based on the unity graphical engine. it consists of thousands of images gathered from various synthetic scenarios resembling the real world, where we varied some factors of interest, such as the weather conditions and the number of objects in the scenes. the labels are automatically collected and consist of bounding boxes that precisely localize objects belonging to the two object classes, leaving out humans from the annotation pipeline. we exploited this new benchmark as a testing ground for some state-of-the-art detectors, showing that our simulated scenarios can be a valuable tool for measuring their performances in a controlled environment.",10.5220/0011692500003417,2023-04-11,,"['pawe≈Ç foszner', 'agnieszka szczƒôsna', 'luca ciampi', 'nicola messina', 'adam cygan', 'bartosz bizo≈Ñ', 'micha≈Ç cogiel', 'dominik golba', 'el≈ºbieta macioszek', 'micha≈Ç staniszewski']",https://arxiv.org/pdf/2304.05090.pdf
745,2304.05091,actually sparse variational gaussian processes,stat.ml cs.lg,"gaussian processes (gps) are typically criticised for their unfavourable scaling in both computational and memory requirements. for large datasets, sparse gps reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. in practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse gps can become computationally expensive, limited by the number of inducing variables one can use. in this work, we propose a new class of inter-domain variational gp, constructed by projecting a gp onto a set of compactly supported b-spline basis functions. the key benefit of our approach is that the compact support of the b-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. this allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previous approaches failed.",,2023-04-11,,"['harry jake cunningham', 'daniel augusto de souza', 'so takao', 'mark van der wilk', 'marc peter deisenroth']",https://arxiv.org/pdf/2304.05091.pdf
746,2304.05099,feudal graph reinforcement learning,cs.lg,"we focus on learning composable policies to control a variety of physical agents with possibly different structures. among state-of-the-art methods, prominent approaches exploit graph-based representations and weight-sharing modular policies based on the message-passing framework. however, as shown by recent literature, message passing can create bottlenecks in information propagation and hinder global coordination. this drawback can become even more problematic in tasks where high-level planning is crucial. in fact, in similar scenarios, each modular policy - e.g., controlling a joint of a robot - would request to coordinate not only for basic locomotion but also achieve high-level goals, such as navigating a maze. a classical solution to avoid similar pitfalls is to resort to hierarchical decision-making. in this work, we adopt the feudal reinforcement learning paradigm to develop agents where control actions are the outcome of a hierarchical (pyramidal) message-passing process. in the proposed feudal graph reinforcement learning (fgrl) framework, high-level decisions at the top level of the hierarchy are propagated through a layered graph representing a hierarchy of policies. lower layers mimic the morphology of the physical system and upper layers can capture more abstract sub-modules. the purpose of this preliminary work is to formalize the framework and provide proof-of-concept experiments on benchmark environments (mujoco locomotion tasks). empirical evaluation shows promising results on both standard benchmarks and zero-shot transfer learning settings.",,2023-04-11,,"['tommaso marzi', 'arshjot khehra', 'andrea cini', 'cesare alippi']",https://arxiv.org/pdf/2304.05099.pdf
747,2304.05104,approaching test time augmentation in the context of uncertainty   calibration for deep neural networks,cs.cv,"with the rise of deep neural networks, machine learning systems are nowadays ubiquitous in a number of real-world applications, which bears the need for highly reliable models. this requires a thorough look not only at the accuracy of such systems, but also to their predictive uncertainty. hence, we propose a novel technique (with two different variations, named m-atta and v-atta) based on test time augmentation, to improve the uncertainty calibration of deep models for image classification. unlike other test time augmentation approaches, m/v-atta improves uncertainty calibration without affecting the model's accuracy, by leveraging an adaptive weighting system. we evaluate the performance of the technique with respect to different metrics of uncertainty calibration. empirical results, obtained on cifar-10, cifar-100, as well as on the benchmark aerial image dataset, indicate that the proposed approach outperforms state-of-the-art calibration techniques, while maintaining the baseline classification performance. code for m/v-atta available at: https://github.com/pedrormconde/mv-atta.",,2023-04-11,,"['pedro conde', 'tiago barros', 'rui l. lopes', 'cristiano premebida', 'urbano j. nunes']",https://arxiv.org/pdf/2304.05104.pdf
748,2304.05112,video event restoration based on keyframes for video anomaly detection,cs.cv,"video anomaly detection (vad) is a significant computer vision problem. existing deep neural network (dnn) based vad methods mostly follow the route of frame reconstruction or frame prediction. however, the lack of mining and learning of higher-level visual features and temporal context relationships in videos limits the further performance of these two approaches. inspired by video codec theory, we introduce a brand-new vad paradigm to break through these limitations: first, we propose a new task of video event restoration based on keyframes. encouraging dnn to infer missing multiple frames based on video keyframes so as to restore a video event, which can more effectively motivate dnn to mine and learn potential higher-level visual features and comprehensive temporal context relationships in the video. to this end, we propose a novel u-shaped swin transformer network with dual skip connections (ustn-dsc) for video event restoration, where a cross-attention and a temporal upsampling residual skip connection are introduced to further assist in restoring complex static and dynamic motion object features in the video. in addition, we propose a simple and effective adjacent frame difference loss to constrain the motion consistency of the video sequence. extensive experiments on benchmarks demonstrate that ustn-dsc outperforms most existing methods, validating the effectiveness of our method.",,2023-04-11,,"['zhiwei yang', 'jing liu', 'zhaoyang wu', 'peng wu', 'xiaotao liu']",https://arxiv.org/pdf/2304.05112.pdf
749,2304.05115,towards systematic intraday news screening: a liquidity-focused approach,q-fin.tr cs.lg q-fin.cp,"news can convey bearish or bullish views on financial assets. institutional investors need to evaluate automatically the implied news sentiment based on textual data. given the huge amount of news articles published each day, most of which are neutral, we present a systematic news screening method to identify the ``true'' impactful ones, aiming for more effective development of news sentiment learning methods. based on several liquidity-driven variables, including volatility, turnover, bid-ask spread, and book size, we associate each 5-min time bin to one of two specific liquidity modes. one represents the ``calm'' state at which the market stays for most of the time and the other, featured with relatively higher levels of volatility and trading volume, describes the regime driven by some exogenous events. then we focus on the moments where the liquidity mode switches from the former to the latter and consider the news articles published nearby impactful. we apply naive bayes on these filtered samples for news sentiment classification as an illustrative example. we show that the screened dataset leads to more effective feature capturing and thus superior performance on short-term asset return prediction compared to the original dataset.",,2023-04-11,,"['jianfei zhang', 'mathieu rosenbaum']",https://arxiv.org/pdf/2304.05115.pdf
750,2304.05116,evaluation of differentially constrained motion models for graph-based   trajectory prediction,cs.ro cs.ai cs.lg,"given their adaptability and encouraging performance, deep-learning models are becoming standard for motion prediction in autonomous driving. however, with great flexibility comes a lack of interpretability and possible violations of physical constraints. accompanying these data-driven methods with differentially-constrained motion models to provide physically feasible trajectories is a promising future direction. the foundation for this work is a previously introduced graph-neural-network-based model, mtp-go. the neural network learns to compute the inputs to an underlying motion model to provide physically feasible trajectories. this research investigates the performance of various motion models in combination with numerical solvers for the prediction task. the study shows that simpler models, such as low-order integrator models, are preferred over more complex ones, e.g., kinematic models, to achieve accurate predictions. further, the numerical solver can have a substantial impact on performance, advising against commonly used first-order methods like euler forward. instead, a second-order method like heun's can significantly improve predictions.",,2023-04-11,,"['theodor westny', 'joel oskarsson', 'bj√∂rn olofsson', 'erik frisk']",https://arxiv.org/pdf/2304.05116.pdf
751,2304.05124,online spatio-temporal learning with target projection,cs.ne cs.lg,"recurrent neural networks trained with the backpropagation through time (bptt) algorithm have led to astounding successes in various temporal tasks. however, bptt introduces severe limitations, such as the requirement to propagate information backwards through time, the weight symmetry requirement, as well as update-locking in space and time. these problems become roadblocks for ai systems where online training capabilities are vital. recently, researchers have developed biologically-inspired training algorithms, addressing a subset of those problems. in this work, we propose a novel learning algorithm called online spatio-temporal learning with target projection (osttp) that resolves all aforementioned issues of bptt. in particular, osttp equips a network with the capability to simultaneously process and learn from new incoming data, alleviating the weight symmetry and update-locking problems. we evaluate osttp on two temporal tasks, showcasing competitive performance compared to bptt. moreover, we present a proof-of-concept implementation of osttp on a memristive neuromorphic hardware system, demonstrating its versatility and applicability to resource-constrained ai devices.",,2023-04-11,,"['thomas ortner', 'lorenzo pes', 'joris gentinetta', 'charlotte frenkel', 'angeliki pantazi']",https://arxiv.org/pdf/2304.05124.pdf
752,2304.05127,improving performance of private federated models in medical image   analysis,cs.cr cs.cv cs.lg eess.iv,"federated learning (fl) is a distributed machine learning (ml) approach that allows data to be trained without being centralized. this approach is particularly beneficial for medical applications because it addresses some key challenges associated with medical data, such as privacy, security, and data ownership. on top of that, fl can improve the quality of ml models used in medical applications. medical data is often diverse and can vary significantly depending on the patient population, making it challenging to develop ml models that are accurate and generalizable. fl allows medical data to be used from multiple sources, which can help to improve the quality and generalizability of ml models. differential privacy (dp) is a go-to algorithmic tool to make this process secure and private. in this work, we show that the model performance can be further improved by employing local steps, a popular approach to improving the communication efficiency of fl, and tuning the number of communication rounds. concretely, given the privacy budget, we show an optimal number of local steps and communications rounds. we provide theoretical motivations further corroborated with experimental evaluations on real-world medical imaging tasks.",,2023-04-11,,"['xiangjian hou', 'sarit khirirat', 'mohammad yaqub', 'samuel horvath']",https://arxiv.org/pdf/2304.05127.pdf
753,2304.05133,neural network architectures,cs.lg math.oc,"these lecture notes provide an overview of neural network architectures from a mathematical point of view. especially, machine learning with neural networks is seen as an optimization problem. covered are an introduction to neural networks and the following architectures: feedforward neural network, convolutional neural network, resnet, and recurrent neural network.",,2023-04-11,,['evelyn herberg'],https://arxiv.org/pdf/2304.05133.pdf
754,2304.05135,recup-fl: reconciling utility and privacy in federated learning via   user-configurable privacy defense,cs.lg cs.cr,"federated learning (fl) provides a variety of privacy advantages by allowing clients to collaboratively train a model without sharing their private data. however, recent studies have shown that private information can still be leaked through shared gradients. to further minimize the risk of privacy leakage, existing defenses usually require clients to locally modify their gradients (e.g., differential privacy) prior to sharing with the server. while these approaches are effective in certain cases, they regard the entire data as a single entity to protect, which usually comes at a large cost in model utility. in this paper, we seek to reconcile utility and privacy in fl by proposing a user-configurable privacy defense, recup-fl, that can better focus on the user-specified sensitive attributes while obtaining significant improvements in utility over traditional defenses. moreover, we observe that existing inference attacks often rely on a machine learning model to extract the private information (e.g., attributes). we thus formulate such a privacy defense as an adversarial learning problem, where recup-fl generates slight perturbations that can be added to the gradients before sharing to fool adversary models. to improve the transferability to un-queryable black-box adversary models, inspired by the idea of meta-learning, recup-fl forms a model zoo containing a set of substitute models and iteratively alternates between simulations of the white-box and the black-box adversarial attack scenarios to generate perturbations. extensive experiments on four datasets under various adversarial settings (both attribute inference attack and data reconstruction attack) show that recup-fl can meet user-specified privacy constraints over the sensitive attributes while significantly improving the model utility compared with state-of-the-art privacy defenses.",10.1145/3579856.3582819,2023-04-11,,"['yue cui', 'syed irfan ali meerza', 'zhuohang li', 'luyang liu', 'jiaxin zhang', 'jian liu']",https://arxiv.org/pdf/2304.05135.pdf
755,2304.05137,modeling and design of heterogeneous hierarchical bioinspired spider web   structures using generative deep learning and additive manufacturing,cs.lg cond-mat.soft nlin.ao,"spider webs are incredible biological structures, comprising thin but strong silk filament and arranged into complex hierarchical architectures with striking mechanical properties (e.g., lightweight but high strength, achieving diverse mechanical responses). while simple 2d orb webs can easily be mimicked, the modeling and synthesis of 3d-based web structures remain challenging, partly due to the rich set of design features. here we provide a detailed analysis of the heterogenous graph structures of spider webs, and use deep learning as a way to model and then synthesize artificial, bio-inspired 3d web structures. the generative ai models are conditioned based on key geometric parameters (including average edge length, number of nodes, average node degree, and others). to identify graph construction principles, we use inductive representation sampling of large experimentally determined spider web graphs, to yield a dataset that is used to train three conditional generative models: 1) an analog diffusion model inspired by nonequilibrium thermodynamics, with sparse neighbor representation, 2) a discrete diffusion model with full neighbor representation, and 3) an autoregressive transformer architecture with full neighbor representation. all three models are scalable, produce complex, de novo bio-inspired spider web mimics, and successfully construct graphs that meet the design objectives. we further propose algorithm that assembles web samples produced by the generative models into larger-scale structures based on a series of geometric design targets, including helical and parametric shapes, mimicking, and extending natural design principles towards integration with diverging engineering objectives. several webs are manufactured using 3d printing and tested to assess mechanical properties.",,2023-04-11,,"['wei lu', 'nic a. lee', 'markus j. buehler']",https://arxiv.org/pdf/2304.05137.pdf
756,2304.05138,distributed event-triggered online learning for multi-agent system   control using gaussian process regression,eess.sy cs.sy,"for the cooperative control of multi-agent systems with unknown dynamics, data-driven methods are commonly employed to infer models from the collected data. due to the flexibility to model nonlinear functions and the existence of theoretical prediction error bound, gaussian process (gp) regression is widely used in such control problems. online learning, i.e. adding newly collected training data to the gp models, promises to improve control performance via improved predictions during the operation. in this paper, we propose a distributed event-triggered online learning algorithm for multi-agent system control. the proposed algorithm only employs locally available information from the neighbors and achieves a guaranteed overall control performance with desired tracking error bound. moreover, the exclusion of the zeno behavior for each agent is proved. finally, the effectiveness of the proposed event-triggered online learning is demonstrated in simulations.",,2023-04-11,,"['xiaobing dai', 'zewen yang', 'mengtian xu', 'sandra hirche']",https://arxiv.org/pdf/2304.05138.pdf
757,2304.05141,dexterous in-hand manipulation of slender cylindrical objects through   deep reinforcement learning with tactile sensing,cs.ro,"continuous in-hand manipulation is an important physical interaction skill, where tactile sensing provides indispensable contact information to enable dexterous manipulation of small objects. this work proposed a framework for end-to-end policy learning with tactile feedback and sim-to-real transfer, which achieved fine in-hand manipulation that controls the pose of a thin cylindrical object, such as a long stick, to track various continuous trajectories through multiple contacts of three fingertips of a dexterous robot hand with tactile sensor arrays. we estimated the central contact position between the stick and each fingertip from the high-dimensional tactile information and showed that the learned policies achieved effective manipulation performance with the processed tactile feedback. the policies were trained with deep reinforcement learning in simulation and successfully transferred to real-world experiments, using coordinated model calibration and domain randomization. we evaluated the effectiveness of tactile information via comparative studies and validated the sim-to-real performance through real-world experiments.",,2023-04-11,,"['wenbin hu', 'bidan huang', 'wang wei lee', 'sicheng yang', 'yu zheng', 'zhibin li']",https://arxiv.org/pdf/2304.05141.pdf
758,2304.05153,regression-based deep-learning predicts molecular biomarkers from   pathology slides,cs.cv cs.ai,"deep learning (dl) can predict biomarkers from cancer histopathology. several clinically approved applications use this technology. most approaches, however, predict categorical labels, whereas biomarkers are often continuous measurements. we hypothesized that regression-based dl outperforms classification-based dl. therefore, we developed and evaluated a new self-supervised attention-based weakly supervised regression method that predicts continuous biomarkers directly from images in 11,671 patients across nine cancer types. we tested our method for multiple clinically and biologically relevant biomarkers: homologous repair deficiency (hrd) score, a clinically used pan-cancer biomarker, as well as markers of key biological processes in the tumor microenvironment. using regression significantly enhances the accuracy of biomarker prediction, while also improving the interpretability of the results over classification. in a large cohort of colorectal cancer patients, regression-based prediction scores provide a higher prognostic value than classification-based scores. our open-source regression approach offers a promising alternative for continuous biomarker analysis in computational pathology.",,2023-04-11,,"['omar s. m. el nahhas', 'chiara m. l. loeffler', 'zunamys i. carrero', 'marko van treeck', 'fiona r. kolbinger', 'katherine j. hewitt', 'hannah s. muti', 'mara graziani', 'qinghe zeng', 'julien calderaro', 'nadina ortiz-br√ºchle', 'tanwei yuan', 'michael hoffmeister', 'hermann brenner', 'alexander brobeil', 'jorge s. reis-filho', 'jakob nikolas kather']",https://arxiv.org/pdf/2304.05153.pdf
759,2304.05163,self-supervision for medical image classification: state-of-the-art   performance with ~100 labeled training samples per class,cs.cv,"is self-supervised deep learning (dl) for medical image analysis already a serious alternative to the de facto standard of end-to-end trained supervised dl? we tackle this question for medical image classification, with a particular focus on one of the currently most limiting factors of the field: the (non-)availability of labeled data. based on three common medical imaging modalities (bone marrow microscopy, gastrointestinal endoscopy, dermoscopy) and publicly available data sets, we analyze the performance of self-supervised dl within the self-distillation with no labels (dino) framework. after learning an image representation without use of image labels, conventional machine learning classifiers are applied. the classifiers are fit using a systematically varied number of labeled data (1-1000 samples per class). exploiting the learned image representation, we achieve state-of-the-art classification performance for all three imaging modalities and data sets with only a fraction of between 1% and 10% of the available labeled data and about 100 labeled samples per class.",,2023-04-11,,"['maximilian nielsen', 'laura wenderoth', 'thilo sentker', 'ren√© werner']",https://arxiv.org/pdf/2304.05163.pdf
760,2304.05171,curriculum-based imitation of versatile skills,cs.lg,"learning skills by imitation is a promising concept for the intuitive teaching of robots. a common way to learn such skills is to learn a parametric model by maximizing the likelihood given the demonstrations. yet, human demonstrations are often multi-modal, i.e., the same task is solved in multiple ways which is a major challenge for most imitation learning methods that are based on such a maximum likelihood (ml) objective. the ml objective forces the model to cover all data, it prevents specialization in the context space and can cause mode-averaging in the behavior space, leading to suboptimal or potentially catastrophic behavior. here, we alleviate those issues by introducing a curriculum using a weight for each data point, allowing the model to specialize on data it can represent while incentivizing it to cover as much data as possible by an entropy bonus. we extend our algorithm to a mixture of (linear) experts (moe) such that the single components can specialize on local context regions, while the moe covers all data points. we evaluate our approach in complex simulated and real robot control tasks and show it learns from versatile human demonstrations and significantly outperforms current sota methods. a reference implementation can be found at https://github.com/intuitive-robots/ml-cur",,2023-04-11,,"['maximilian xiling li', 'onur celik', 'philipp becker', 'denis blessing', 'rudolf lioutikov', 'gerhard neumann']",https://arxiv.org/pdf/2304.05171.pdf
761,2304.05172,lrrnet: a novel representation learning guided fusion network for   infrared and visible images,cs.cv,"deep learning based fusion methods have been achieving promising performance in image fusion tasks. this is attributed to the network architecture that plays a very important role in the fusion process. however, in general, it is hard to specify a good fusion architecture, and consequently, the design of fusion networks is still a black art, rather than science. to address this problem, we formulate the fusion task mathematically, and establish a connection between its optimal solution and the network architecture that can implement it. this approach leads to a novel method proposed in the paper of constructing a lightweight fusion network. it avoids the time-consuming empirical network design by a trial-and-test strategy. in particular we adopt a learnable representation approach to the fusion task, in which the construction of the fusion network architecture is guided by the optimisation algorithm producing the learnable model. the low-rank representation (lrr) objective is the foundation of our learnable model. the matrix multiplications, which are at the heart of the solution are transformed into convolutional operations, and the iterative process of optimisation is replaced by a special feed-forward network. based on this novel network architecture, an end-to-end lightweight fusion network is constructed to fuse infrared and visible light images. its successful training is facilitated by a detail-to-semantic information loss function proposed to preserve the image details and to enhance the salient features of the source images. our experiments show that the proposed fusion network exhibits better fusion performance than the state-of-the-art fusion methods on public datasets. interestingly, our network requires a fewer training parameters than other existing methods.",,2023-04-11,,"['hui li', 'tianyang xu', 'xiao-jun wu', 'jiwen lu', 'josef kittler']",https://arxiv.org/pdf/2304.05172.pdf
762,2304.05173,improving image recognition by retrieving from web-scale image-text data,cs.cv cs.lg,"retrieval augmented models are becoming increasingly popular for computer vision tasks after their recent success in nlp problems. the goal is to enhance the recognition capabilities of the model by retrieving similar examples for the visual input from an external memory set. in this work, we introduce an attention-based memory module, which learns the importance of each retrieved example from the memory. compared to existing approaches, our method removes the influence of the irrelevant retrieved examples, and retains those that are beneficial to the input query. we also thoroughly study various ways of constructing the memory dataset. our experiments show the benefit of using a massive-scale memory dataset of 1b image-text pairs, and demonstrate the performance of different memory representations. we evaluate our method in three different classification tasks, namely long-tailed recognition, learning with noisy labels, and fine-grained classification, and show that it achieves state-of-the-art accuracies in imagenet-lt, places-lt and webvision datasets.",,2023-04-11,,"['ahmet iscen', 'alireza fathi', 'cordelia schmid']",https://arxiv.org/pdf/2304.05173.pdf
763,2304.05174,electricity demand forecasting with hybrid statistical and machine   learning algorithms: case study of ukraine,cs.lg stat.ap,"this article presents a novel hybrid approach using statistics and machine learning to forecast the national demand of electricity. as investment and operation of future energy systems require long-term electricity demand forecasts with hourly resolution, our mathematical model fills a gap in energy forecasting. the proposed methodology was constructed using hourly data from ukraine's electricity consumption ranging from 2013 to 2020. to this end, we analysed the underlying structure of the hourly, daily and yearly time series of electricity consumption. the long-term yearly trend is evaluated using macroeconomic regression analysis. the mid-term model integrates temperature and calendar regressors to describe the underlying structure, and combines arima and lstm ``black-box'' pattern-based approaches to describe the error term. the short-term model captures the hourly seasonality through calendar regressors and multiple arma models for the residual. results show that the best forecasting model is composed by combining multiple regression models and a lstm hybrid model for residual prediction. our hybrid model is very effective at forecasting long-term electricity consumption on an hourly resolution. in two years of out-of-sample forecasts with 17520 timesteps, it is shown to be within 96.83 \% accuracy.",,2023-04-11,,"['tatiana gonzalez grandon', 'johannes schwenzer', 'thomas steens', 'julia breuing']",https://arxiv.org/pdf/2304.05174.pdf
764,2304.05176,decoupling anomaly discrimination and representation learning:   self-supervised learning for anomaly detection on attributed graph,cs.lg cs.ai,"anomaly detection on attributed graphs is a crucial topic for its practical application. existing methods suffer from semantic mixture and imbalance issue because they mainly focus on anomaly discrimination, ignoring representation learning. it conflicts with the assortativity assumption that anomalous nodes commonly connect with normal nodes directly. additionally, there are far fewer anomalous nodes than normal nodes, indicating a long-tailed data distribution. to address these challenges, a unique algorithm,decoupled self-supervised learning foranomalydetection (dslad), is proposed in this paper. dslad is a self-supervised method with anomaly discrimination and representation learning decoupled for anomaly detection. dslad employs bilinear pooling and masked autoencoder as the anomaly discriminators. by decoupling anomaly discrimination and representation learning, a balanced feature space is constructed, in which nodes are more semantically discriminative, as well as imbalance issue can be resolved. experiments conducted on various six benchmark datasets reveal the effectiveness of dslad.",,2023-04-11,,"['yanming hu', 'chuan chen', 'bowen deng', 'yujing lai', 'hao lin', 'zibin zheng', 'jing bian']",https://arxiv.org/pdf/2304.05176.pdf
765,2304.05187,automatic gradient descent: deep learning without hyperparameters,cs.lg cs.ai cs.na cs.ne math.na stat.ml,"the architecture of a deep neural network is defined explicitly in terms of the number of layers, the width of each layer and the general network topology. existing optimisation frameworks neglect this information in favour of implicit architectural information (e.g. second-order methods) or architecture-agnostic distance functions (e.g. mirror descent). meanwhile, the most popular optimiser in practice, adam, is based on heuristics. this paper builds a new framework for deriving optimisation algorithms that explicitly leverage neural architecture. the theory extends mirror descent to non-convex composite objective functions: the idea is to transform a bregman divergence to account for the non-linear structure of neural architecture. working through the details for deep fully-connected networks yields automatic gradient descent: a first-order optimiser without any hyperparameters. automatic gradient descent trains both fully-connected and convolutional networks out-of-the-box and at imagenet scale. a pytorch implementation is available at https://github.com/jxbz/agd and also in appendix b. overall, the paper supplies a rigorous theoretical foundation for a next-generation of architecture-dependent optimisers that work automatically and without hyperparameters.",,2023-04-11,,"['jeremy bernstein', 'chris mingard', 'kevin huang', 'navid azizan', 'yisong yue']",https://arxiv.org/pdf/2304.05187.pdf
766,2304.05195,hpn: personalized federated hyperparameter optimization,cs.lg,"numerous research studies in the field of federated learning (fl) have attempted to use personalization to address the heterogeneity among clients, one of fl's most crucial and challenging problems. however, existing works predominantly focus on tailoring models. yet, due to the heterogeneity of clients, they may each require different choices of hyperparameters, which have not been studied so far. we pinpoint two challenges of personalized federated hyperparameter optimization (pfedhpo): handling the exponentially increased search space and characterizing each client without compromising its data privacy. to overcome them, we propose learning a \textsc{h}yper\textsc{p}arameter \textsc{n}etwork (hpn) fed with client encoding to decide personalized hyperparameters. the client encoding is calculated with a random projection-based procedure to protect each client's privacy. besides, we design a novel mechanism to debias the low-fidelity function evaluation samples for learning hpn. we conduct extensive experiments on fl tasks from various domains, demonstrating the superiority of hpn.",,2023-04-11,,"['anda cheng', 'zhen wang', 'yaliang li', 'jian cheng']",https://arxiv.org/pdf/2304.05195.pdf
767,2304.05198,multi-scale fusion fault diagnosis method based on two-dimensionaliztion   sequence in complex scenarios,cs.cv,"rolling bearings are critical components in rotating machinery, and their faults can cause severe damage. early detection of abnormalities is crucial to prevent catastrophic accidents. traditional and intelligent methods have been used to analyze time series data, but in real-life scenarios, sensor data is often noisy and cannot be accurately characterized in the time domain, leading to mode collapse in trained models. two-dimensionalization methods such as the gram angle field method (gaf) or interval sampling have been proposed, but they lack mathematical derivation and interpretability. this paper proposes an improved gaf combined with grayscale images for convolution scenarios. the main contributions include illustrating the feasibility of the approach in complex scenarios, widening the data set, and introducing an improved convolutional neural network method with a multi-scale feature fusion diffusion model and deep learning compression techniques for deployment in industrial scenarios.",,2023-04-11,,['weiyang jin'],https://arxiv.org/pdf/2304.05198.pdf
768,2304.05201,tinyreptile: tinyml with federated meta-learning,cs.lg cs.ai cs.dc,"tiny machine learning (tinyml) is a rapidly growing field aiming to democratize machine learning (ml) for resource-constrained microcontrollers (mcus). given the pervasiveness of these tiny devices, it is inherent to ask whether tinyml applications can benefit from aggregating their knowledge. federated learning (fl) enables decentralized agents to jointly learn a global model without sharing sensitive local data. however, a common global model may not work for all devices due to the complexity of the actual deployment environment and the heterogeneity of the data available on each device. in addition, the deployment of tinyml hardware has significant computational and communication constraints, which traditional ml fails to address. considering these challenges, we propose tinyreptile, a simple but efficient algorithm inspired by meta-learning and online learning, to collaboratively learn a solid initialization for a neural network (nn) across tiny devices that can be quickly adapted to a new device with respect to its data. we demonstrate tinyreptile on raspberry pi 4 and cortex-m4 mcu with only 256-kb ram. the evaluations on various tinyml use cases confirm a resource reduction and training time saving by at least two factors compared with baseline algorithms with comparable performance.",,2023-04-11,,"['haoyu ren', 'darko anicic', 'thomas a. runkler']",https://arxiv.org/pdf/2304.05201.pdf
769,2304.05207,cgxplain: rule-based deep neural network explanations using dual linear   programs,cs.lg cs.ai,"rule-based surrogate models are an effective and interpretable way to approximate a deep neural network's (dnn) decision boundaries, allowing humans to easily understand deep learning models. current state-of-the-art decompositional methods, which are those that consider the dnn's latent space to extract more exact rule sets, manage to derive rule sets at high accuracy. however, they a) do not guarantee that the surrogate model has learned from the same variables as the dnn (alignment), b) only allow to optimise for a single objective, such as accuracy, which can result in excessively large rule sets (complexity), and c) use decision tree algorithms as intermediate models, which can result in different explanations for the same dnn (stability). this paper introduces the cgx (column generation explainer) to address these limitations - a decompositional method using dual linear programming to extract rules from the hidden representations of the dnn. this approach allows to optimise for any number of objectives and empowers users to tweak the explanation model to their needs. we evaluate our results on a wide variety of tasks and show that cgx meets all three criteria, by having exact reproducibility of the explanation model that guarantees stability and reduces the rule set size by >80% (complexity) at equivalent or improved accuracy and fidelity across tasks (alignment).",,2023-04-11,,"['konstantin hemker', 'zohreh shams', 'mateja jamnik']",https://arxiv.org/pdf/2304.05207.pdf
770,2304.05219,banditq -- no-regret learning with guaranteed per-user rewards in   adversarial environments,cs.lg cs.pf,"classic online prediction algorithms, such as hedge, are inherently unfair by design, as they try to play the most rewarding arm as many times as possible while ignoring the sub-optimal arms to achieve sublinear regret. in this paper, we consider a fair online prediction problem in the adversarial setting with hard lower bounds on the rate of accrual of rewards for all arms. by combining elementary queueing theory with online learning, we propose a new online prediction policy, called banditq, that achieves the target rate constraints while achieving a regret of $o(t^{3/4})$ in the full-information setting. the design and analysis of banditq involve a novel use of the potential function method and are of independent interest.",,2023-04-11,,['abhishek sinha'],https://arxiv.org/pdf/2304.05219.pdf
771,2304.05223,"inhomogeneous graph trend filtering via a l2,0 cardinality penalty",cs.lg cs.si stat.ml,"we study estimation of piecewise smooth signals over a graph. we propose a $\ell_{2,0}$-norm penalized graph trend filtering (gtf) model to estimate piecewise smooth graph signals that exhibits inhomogeneous levels of smoothness across the nodes. we prove that the proposed gtf model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. we propose two methods to solve the proposed gtf model: a spectral decomposition method and a method based on simulated annealing. in the experiment on synthetic and real-world datasets, we show that the proposed gtf model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. we also show that the proposed gtf model can be solved more efficiently than existing models for the dataset with a large edge set.",,2023-04-11,,"['xiaoqing huang', 'andersen ang', 'jie zhang', 'yijie wang']",https://arxiv.org/pdf/2304.05223.pdf
772,2304.05232,lady and the tramp nextdoor: online manifestations of real-world   inequalities in the nextdoor social network,cs.si cs.lg,"from health to education, income impacts a huge range of life choices. many papers have leveraged data from online social networks to study precisely this. in this paper, we ask the opposite question: do different levels of income result in different online behaviors? we demonstrate it does. we present the first large-scale study of nextdoor, a popular location-based social network. we collect 2.6 million posts from 64,283 neighborhoods in the united states and 3,325 neighborhoods in the united kingdom, to examine whether online discourse reflects the income and income inequality of a neighborhood. we show that posts from neighborhoods with different income indeed differ, e.g. richer neighborhoods have a more positive sentiment and discuss crimes more, even though their actual crime rates are much lower. we then show that user-generated content can predict both income and inequality. we train multiple machine learning models and predict both income (r-square=0.841) and inequality (r-square=0.77).",,2023-04-11,,"['waleed iqbal', 'vahid ghafouri', 'gareth tyson', 'guillermo suarez-tangil', 'ignacio castro']",https://arxiv.org/pdf/2304.05232.pdf
773,2304.05238,diagnosing and augmenting feature representations in correctional   inverse reinforcement learning,cs.ro cs.sy eess.sy,"robots have been increasingly better at doing tasks for humans by learning from their feedback, but still often suffer from model misalignment due to missing or incorrectly learned features. when the features the robot needs to learn to perform its task are missing or do not generalize well to new settings, the robot will not be able to learn the task the human wants and, even worse, may learn a completely different and undesired behavior. prior work shows how the robot can detect when its representation is missing some feature and can, thus, ask the human to be taught about the new feature; however, these works do not differentiate between features that are completely missing and those that exist but do not generalize to new environments. in the latter case, the robot would detect misalignment and simply learn a new feature, leading to an arbitrarily growing feature representation that can, in turn, lead to spurious correlations and incorrect learning down the line. in this work, we propose separating the two sources of misalignment: we propose a framework for determining whether a feature the robot needs is incorrectly learned and does not generalize to new environment setups vs. is entirely missing from the robot's representation. once we detect the source of error, we show how the human can initiate the realignment process for the model: if the feature is missing, we follow prior work for learning new features; however, if the feature exists but does not generalize, we use data augmentation to expand its training and, thus, complete the correction. we demonstrate the proposed approach in experiments with a simulated 7dof robot manipulator and physical human corrections.",,2023-04-11,2023-04-13,"['in√™s louren√ßo', 'andreea bobu', 'cristian r. rojas', 'bo wahlberg']",https://arxiv.org/pdf/2304.05238.pdf
774,2304.05243,r-softmax: generalized softmax with controllable sparsity rate,cs.lg,"nowadays artificial neural network models achieve remarkable results in many disciplines. functions mapping the representation provided by the model to the probability distribution are the inseparable aspect of deep learning solutions. although softmax is a commonly accepted probability mapping function in the machine learning community, it cannot return sparse outputs and always spreads the positive probability to all positions. in this paper, we propose r-softmax, a modification of the softmax, outputting sparse probability distribution with controllable sparsity rate. in contrast to the existing sparse probability mapping functions, we provide an intuitive mechanism for controlling the output sparsity level. we show on several multi-label datasets that r-softmax outperforms other sparse alternatives to softmax and is highly competitive with the original softmax. we also apply r-softmax to the self-attention module of a pre-trained transformer language model and demonstrate that it leads to improved performance when fine-tuning the model on different natural language processing tasks.",,2023-04-11,2023-04-12,"['klaudia ba≈Çazy', '≈Çukasz struski', 'marek ≈õmieja', 'jacek tabor']",https://arxiv.org/pdf/2304.05243.pdf
775,2304.05246,openal: evaluation and interpretation of active learning strategies,cs.lg cs.ai cs.hc,"despite the vast body of literature on active learning (al), there is no comprehensive and open benchmark allowing for efficient and simple comparison of proposed samplers. additionally, the variability in experimental settings across the literature makes it difficult to choose a sampling strategy, which is critical due to the one-off nature of al experiments. to address those limitations, we introduce openal, a flexible and open-source framework to easily run and compare sampling al strategies on a collection of realistic tasks. the proposed benchmark is augmented with interpretability metrics and statistical analysis methods to understand when and why some samplers outperform others. last but not least, practitioners can easily extend the benchmark by submitting their own al samplers.",,2023-04-11,,"['w. jonas', 'a. abraham', 'l. dreyfus-schmidt']",https://arxiv.org/pdf/2304.05246.pdf
776,2304.05255,density map distillation for incremental object counting,cs.cv,"we investigate the problem of incremental learning for object counting, where a method must learn to count a variety of object classes from a sequence of datasets. a na\""ive approach to incremental object counting would suffer from catastrophic forgetting, where it would suffer from a dramatic performance drop on previous tasks. in this paper, we propose a new exemplar-free functional regularization method, called density map distillation (dmd). during training, we introduce a new counter head for each task and introduce a distillation loss to prevent forgetting of previous tasks. additionally, we introduce a cross-task adaptor that projects the features of the current backbone to the previous backbone. this projector allows for the learning of new features while the backbone retains the relevant features for previous tasks. finally, we set up experiments of incremental learning for counting new objects. results confirm that our method greatly reduces catastrophic forgetting and outperforms existing methods.",,2023-04-11,,"['chenshen wu', 'joost van de weijer']",https://arxiv.org/pdf/2304.05255.pdf
777,2304.05260,re-weighted softmax cross-entropy to control forgetting in federated   learning,cs.lg cs.ai,"in federated learning, a global model is learned by aggregating model updates computed at a set of independent client nodes, to reduce communication costs multiple gradient steps are performed at each node prior to aggregation. a key challenge in this setting is data heterogeneity across clients resulting in differing local objectives which can lead clients to overly minimize their own local objective, diverging from the global solution. we demonstrate that individual client models experience a catastrophic forgetting with respect to data from other clients and propose an efficient approach that modifies the cross-entropy objective on a per-client basis by re-weighting the softmax logits prior to computing the loss. this approach shields classes outside a client's label set from abrupt representation change and we empirically demonstrate it can alleviate client forgetting and provide consistent improvements to standard federated learning algorithms. our method is particularly beneficial under the most challenging federated learning settings where data heterogeneity is high and client participation in each round is low.",,2023-04-11,,"['gwen legate', 'lucas caccia', 'eugene belilovsky']",https://arxiv.org/pdf/2304.05260.pdf
778,2304.05263,prompt learning for news recommendation,cs.ir cs.ai,"some recent \textit{news recommendation} (nr) methods introduce a pre-trained language model (plm) to encode news representation by following the vanilla pre-train and fine-tune paradigm with carefully-designed recommendation-specific neural networks and objective functions. due to the inconsistent task objective with that of plm, we argue that their modeling paradigm has not well exploited the abundant semantic information and linguistic knowledge embedded in the pre-training process. recently, the pre-train, prompt, and predict paradigm, called \textit{prompt learning}, has achieved many successes in natural language processing domain. in this paper, we make the first trial of this new paradigm to develop a \textit{prompt learning for news recommendation} (prompt4nr) framework, which transforms the task of predicting whether a user would click a candidate news as a cloze-style mask-prediction task. specifically, we design a series of prompt templates, including discrete, continuous, and hybrid templates, and construct their corresponding answer spaces to examine the proposed prompt4nr framework. furthermore, we use the prompt ensembling to integrate predictions from multiple prompt templates. extensive experiments on the mind dataset validate the effectiveness of our prompt4nr with a set of new benchmark results.",10.1145/3539618.3591752,2023-04-11,,"['zizhuo zhang', 'bang wang']",https://arxiv.org/pdf/2304.05263.pdf
779,2304.05265,controllable textual inversion for personalized text-to-image generation,cs.cv cs.ai cs.cl cs.lg,"the recent large-scale generative modeling has attained unprecedented performance especially in producing high-fidelity images driven by text prompts. text inversion (ti), alongside the text-to-image model backbones, is proposed as an effective technique in personalizing the generation when the prompts contain user-defined, unseen or long-tail concept tokens. despite that, we find and show that the deployment of ti remains full of ""dark-magics"" -- to name a few, the harsh requirement of additional datasets, arduous human efforts in the loop and lack of robustness. in this work, we propose a much-enhanced version of ti, dubbed controllable textual inversion (coti), in resolving all the aforementioned problems and in turn delivering a robust, data-efficient and easy-to-use framework. the core to coti is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an active-learning paradigm. the extensive results show that coti significantly outperforms the prior ti-related approaches with a 26.05 decrease in the fid score and a 23.00% boost in the r-precision.",,2023-04-11,2023-04-12,"['jianan yang', 'haobo wang', 'ruixuan xiao', 'sai wu', 'gang chen', 'junbo zhao']",https://arxiv.org/pdf/2304.05265.pdf
780,2304.05271,automaton-guided curriculum generation for reinforcement learning agents,cs.ai,"despite advances in reinforcement learning, many sequential decision making tasks remain prohibitively expensive and impractical to learn. recently, approaches that automatically generate reward functions from logical task specifications have been proposed to mitigate this issue; however, they scale poorly on long-horizon tasks (i.e., tasks where the agent needs to perform a series of correct actions to reach the goal state, considering future transitions while choosing an action). employing a curriculum (a sequence of increasingly complex tasks) further improves the learning speed of the agent by sequencing intermediate tasks suited to the learning capacity of the agent. however, generating curricula from the logical specification still remains an unsolved problem. to this end, we propose agcl, automaton-guided curriculum learning, a novel method for automatically generating curricula for the target task in the form of directed acyclic graphs (dags). agcl encodes the specification in the form of a deterministic finite automaton (dfa), and then uses the dfa along with the object-oriented mdp (oomdp) representation to generate a curriculum as a dag, where the vertices correspond to tasks, and edges correspond to the direction of knowledge transfer. experiments in gridworld and physics-based simulated robotics domains show that the curricula produced by agcl achieve improved time-to-threshold performance on a complex sequential decision-making problem relative to state-of-the-art curriculum learning (e.g, teacher-student, self-play) and automaton-guided reinforcement learning baselines (e.g, q-learning for reward machines). further, we demonstrate that agcl performs well even in the presence of noise in the task's oomdp description, and also when distractor objects are present that are not modeled in the logical specification of the tasks' objectives.",,2023-04-11,,"['yash shukla', 'abhishek kulkarni', 'robert wright', 'alvaro velasquez', 'jivko sinapov']",https://arxiv.org/pdf/2304.05271.pdf
781,2304.05277,topology reasoning for driving scenes,cs.cv,"understanding the road genome is essential to realize autonomous driving. this highly intelligent problem contains two aspects - the connection relationship of lanes, and the assignment relationship between lanes and traffic elements, where a comprehensive topology reasoning method is vacant. on one hand, previous map learning techniques struggle in deriving lane connectivity with segmentation or laneline paradigms; or prior lane topology-oriented approaches focus on centerline detection and neglect the interaction modeling. on the other hand, the traffic element to lane assignment problem is limited in the image domain, leaving how to construct the correspondence from two views an unexplored challenge. to address these issues, we present toponet, the first end-to-end framework capable of abstracting traffic knowledge beyond conventional perception tasks. to capture the driving scene topology, we introduce three key designs: (1) an embedding module to incorporate semantic knowledge from 2d elements into a unified feature space; (2) a curated scene graph neural network to model relationships and enable feature interaction inside the network; (3) instead of transmitting messages arbitrarily, a scene knowledge graph is devised to differentiate prior knowledge from various types of the road genome. we evaluate toponet on the challenging scene understanding benchmark, openlane-v2, where our approach outperforms all previous works by a great margin on all perceptual and topological metrics. the code would be released soon.",,2023-04-11,,"['tianyu li', 'li chen', 'xiangwei geng', 'huijie wang', 'yang li', 'zhenbo liu', 'shengyin jiang', 'yuting wang', 'hang xu', 'chunjing xu', 'feng wen', 'ping luo', 'junchi yan', 'wei zhang', 'xiaogang wang', 'yu qiao', 'hongyang li']",https://arxiv.org/pdf/2304.05277.pdf
782,2304.05288,task difficulty aware parameter allocation & regularization for lifelong   learning,cs.lg cs.ai cs.cv,"parameter regularization or allocation methods are effective in overcoming catastrophic forgetting in lifelong learning. however, they solve all tasks in a sequence uniformly and ignore the differences in the learning difficulty of different tasks. so parameter regularization methods face significant forgetting when learning a new task very different from learned tasks, and parameter allocation methods face unnecessary parameter overhead when learning simple tasks. in this paper, we propose the parameter allocation & regularization (par), which adaptively select an appropriate strategy for each task from parameter allocation and regularization based on its learning difficulty. a task is easy for a model that has learned tasks related to it and vice versa. we propose a divergence estimation method based on the nearest-prototype distance to measure the task relatedness using only features of the new task. moreover, we propose a time-efficient relatedness-aware sampling-based architecture search strategy to reduce the parameter overhead for allocation. experimental results on multiple benchmarks demonstrate that, compared with sotas, our method is scalable and significantly reduces the model's redundancy while improving the model's performance. further qualitative analysis indicates that par obtains reasonable task-relatedness.",,2023-04-11,,"['wenjin wang', 'yunqing hu', 'qianglong chen', 'yin zhang']",https://arxiv.org/pdf/2304.05288.pdf
783,2304.05292,mc-vivit: multi-branch classifier-vivit to detect mild cognitive   impairment in older adults using facial videos,cs.cv cs.ai cs.lg,"deep machine learning models including convolutional neural networks (cnn) have been successful in the detection of mild cognitive impairment (mci) using medical images, questionnaires, and videos. this paper proposes a novel multi-branch classifier-video vision transformer (mc-vivit) model to distinguish mci from those with normal cognition by analyzing facial features. the data comes from the i-conect, a behavioral intervention trial aimed at improving cognitive function by providing frequent video chats. mc-vivit extracts spatiotemporal features of videos in one branch and augments representations by the mc module. the i-conect dataset is challenging as the dataset is imbalanced containing hard-easy and positive-negative samples, which impedes the performance of mc-vivit. we propose a loss function for hard-easy and positive-negative samples (hp loss) by combining focal loss and ad-corre loss to address the imbalanced problem. our experimental results on the i-conect dataset show the great potential of mc-vivit in predicting mci with a high accuracy of 90.63\% accuracy on some of the interview videos.",,2023-04-11,,"['jian sun', 'hiroko h. dodge', 'mohammad h. mahoor']",https://arxiv.org/pdf/2304.05292.pdf
784,2304.05294,selecting robust features for machine learning applications using   multidata causal discovery,stat.ml cs.lg physics.ao-ph physics.comp-ph,"robust feature selection is vital for creating reliable and interpretable machine learning (ml) models. when designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. to mitigate this issue, we introduce a multidata (m) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. this approach uses the causal discovery algorithms pc1 or pcmci that are implemented in the tigramite python package. these algorithms utilize conditional independence tests to infer parts of the causal graph. our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ml models (multiple linear regression, random forest) that predict the targets. we apply our framework to the statistical intensity prediction of western pacific tropical cyclones (tc), for which it is often difficult to accurately choose drivers and their dimensionality reduction (time lags, vertical levels, and area-averaging). using more stringent significance thresholds in the conditional independence tests helps eliminate spurious causal relationships, thus helping the ml model generalize better to unseen tc cases. m-pc1 with a reduced number of features outperforms m-pcmci, non-causal ml, and other feature selection methods (lagged correlation, random), even slightly outperforming feature selection based on explainable artificial intelligence. the optimal causal drivers obtained from our causal feature selection help improve our understanding of underlying relationships and suggest new potential drivers of tc intensification.",,2023-04-11,2023-04-12,"['saranya ganesh s.', 'tom beucler', 'frederick iat-hin tam', 'milton s. gomez', 'jakob runge', 'andreas gerhardus']",https://arxiv.org/pdf/2304.05294.pdf
785,2304.05295,a comprehensive study on object detection techniques in unconstrained   environments,cs.cv cs.lg,"object detection is a crucial task in computer vision that aims to identify and localize objects in images or videos. the recent advancements in deep learning and convolutional neural networks (cnns) have significantly improved the performance of object detection techniques. this paper presents a comprehensive study of object detection techniques in unconstrained environments, including various challenges, datasets, and state-of-the-art approaches. additionally, we present a comparative analysis of the methods and highlight their strengths and weaknesses. finally, we provide some future research directions to further improve object detection in unconstrained environments.",,2023-04-11,,['hrishitva patel'],https://arxiv.org/pdf/2304.05295.pdf
786,2304.05302,rrhf: rank responses to align language models with human feedback   without tears,cs.cl,"reinforcement learning from human feedback (rlhf) facilitates the alignment of large language models with human preferences, significantly enhancing the quality of interactions between humans and these models. instructgpt implements rlhf through several stages, including supervised fine-tuning (sft), reward model training, and proximal policy optimization (ppo). ppo, however, is sensitive to hyperparameters and requires a minimum of four models in its standard implementation, which makes it hard to train. in contrast, we propose a novel learning paradigm called rrhf, which scores responses generated by different sampling policies and learns to align them with human preferences through ranking loss. rrhf can efficiently align language model output probabilities with human preferences as robust as fine-tuning and it only needs 1 to 2 models during tuning. in addition, rrhf can be considered an extension of sft and reward models while being simpler than ppo in terms of coding, model counts, and hyperparameters. the entire alignment process can be accomplished within a single rrhf training session. we evaluate rrhf using llama and alpaca on helpful and harmless data, demonstrating performance comparable to ppo.",,2023-04-11,,"['zheng yuan', 'hongyi yuan', 'chuanqi tan', 'wei wang', 'songfang huang', 'fei huang']",https://arxiv.org/pdf/2304.05302.pdf
787,2304.05303,elvis: empowering locality of vision language pre-training with   intra-modal similarity,cs.cv cs.cl,"deep learning has shown great potential in assisting radiologists in reading chest x-ray (cxr) images, but its need for expensive annotations for improving performance prevents widespread clinical application. visual language pre-training (vlp) can alleviate the burden and cost of annotation by leveraging routinely generated reports for radiographs, which exist in large quantities as well as in paired form (imagetext pairs). additionally, extensions to localization-aware vlps are being proposed to address the needs of accurate localization of abnormalities for cad in cxr. however, we find that the formulation proposed by locality-aware vlp literatures actually leads to loss in spatial relationships required for downstream localization tasks. therefore, we propose empowering locality of vlp with intra-modal similarity, elvis, a vlp aware of intra-modal locality, to better preserve the locality within radiographs or reports, which enhances the ability to comprehend location references in text reports. our locality-aware vlp method significantly outperforms state-of-the art baselines in multiple segmentation tasks and the ms-cxr phrase grounding task. qualitatively, elvis is able to focus well on regions of interest described in the report text compared to prior approaches, allowing for enhanced interpretability.",,2023-04-11,,"['sumin seo', 'jaewoong shin', 'jaewoo kang', 'tae soo kim', 'thijs kooi']",https://arxiv.org/pdf/2304.05303.pdf
788,2304.05305,generative modeling via hierarchical tensor sketching,math.na cs.lg cs.na stat.ml,we propose a hierarchical tensor-network approach for approximating high-dimensional probability density via empirical distribution. this leverages randomized singular value decomposition (svd) techniques and involves solving linear equations for tensor cores in this tensor network. the complexity of the resulting algorithm scales linearly in the dimension of the high-dimensional density. an analysis of estimation error demonstrates the effectiveness of this method through several numerical experiments.,,2023-04-11,,"['yifan peng', 'yian chen', 'e. miles stoudenmire', 'yuehaw khoo']",https://arxiv.org/pdf/2304.05305.pdf
789,2304.05309,the efficacy potential of cyber security advice as presented in news   articles,cs.hc,"cyber security advice is a broad church: it is thematically expansive, comprising expert texts, user-generated data consumed by individual users via informal learning, and much in-between. while there is evidence that cyber security news articles play a role in disseminating cyber security advice, the nature and extent of that role are not clear. we present a corpus of cyber security advice generated from mainstream news articles. the work was driven by two research objectives. the first objective was to ascertain what kind of actionable advice is being disseminated; the second was to explore ways of determining the efficacy potential of news-mediated security advice. the results show an increase in the generation of cyber security news articles, together with increases in vocabulary complexity and reading difficulty. we argue that these could present challenges for vulnerable users. we believe that this corpus and the accompanying analysis have the potential to inform future efforts to quantify and improve the efficacy potential of security advice dissemination.",,2023-04-11,,"['mark quinlan', 'aaron ceross', 'andrew simpson']",https://arxiv.org/pdf/2304.05309.pdf
790,2304.05312,fingerprint liveness detection using minutiae-independent dense sampling   of local patches,cs.cy,"fingerprint recognition and matching is a common form of user authentication. while a fingerprint is unique to each individual, authentication is vulnerable when an attacker can forge a copy of the fingerprint (spoof). to combat these spoofed fingerprints, spoof detection and liveness detection algorithms are currently being researched as countermeasures to this security vulnerability. this paper introduces a fingerprint anti-spoofing mechanism using machine learning.",,2023-04-11,,"['riley kiefer', 'jacob stevens', 'ashok patel']",https://arxiv.org/pdf/2304.05312.pdf
791,2304.05325,mining the characteristics of jupyter notebooks in data science projects,cs.se,"nowadays, numerous industries have exceptional demand for skills in data science, such as data analysis, data mining, and machine learning. the computational notebook (e.g., jupyter notebook) is a well-known data science tool adopted in practice. kaggle and github are two platforms where data science communities are used for knowledge-sharing, skill-practicing, and collaboration. while tutorials and guidelines for novice data science are available on both platforms, there is a low number of jupyter notebooks that received high numbers of votes from the community. the high-voted notebook is considered well-documented, easy to understand, and applies the best data science and software engineering practices. in this research, we aim to understand the characteristics of high-voted jupyter notebooks on kaggle and the popular jupyter notebooks for data science projects on github. we plan to mine and analyse the jupyter notebooks on both platforms. we will perform exploratory analytics, data visualization, and feature importances to understand the overall structure of these notebooks and to identify common patterns and best-practice features separating the low-voted and high-voted notebooks. upon the completion of this research, the discovered insights can be applied as training guidelines for aspiring data scientists and machine learning practitioners looking to improve their performance from novice ranking jupyter notebook on kaggle to a deployable project on github.",,2023-04-11,,"['morakot choetkiertikul', 'apirak hoonlor', 'chaiyong ragkhitwetsagul', 'siripen pongpaichet', 'thanwadee sunetnanta', 'tasha settewong', 'vacharavich jiravatvanich', 'urisayar kaewpichai']",https://arxiv.org/pdf/2304.05325.pdf
792,2304.05332,emergent autonomous scientific research capabilities of large language   models,physics.chem-ph cs.cl,"transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. in this paper, we present an intelligent agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. we showcase the agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.",,2023-04-11,,"['daniil a. boiko', 'robert macknight', 'gabe gomes']",https://arxiv.org/pdf/2304.05332.pdf
793,2304.05339,deep-learning assisted detection and quantification of (oo)cysts of   giardia and cryptosporidium on smartphone microscopy images,eess.iv cs.cv cs.lg,"the consumption of microbial-contaminated food and water is responsible for the deaths of millions of people annually. smartphone-based microscopy systems are portable, low-cost, and more accessible alternatives for the detection of giardia and cryptosporidium than traditional brightfield microscopes. however, the images from smartphone microscopes are noisier and require manual cyst identification by trained technicians, usually unavailable in resource-limited settings. automatic detection of (oo)cysts using deep-learning-based object detection could offer a solution for this limitation. we evaluate the performance of three state-of-the-art object detectors to detect (oo)cysts of giardia and cryptosporidium on a custom dataset that includes both smartphone and brightfield microscopic images from vegetable samples. faster rcnn, retinanet, and you only look once (yolov8s) deep-learning models were employed to explore their efficacy and limitations. our results show that while the deep-learning models perform better with the brightfield microscopy image dataset than the smartphone microscopy image dataset, the smartphone microscopy predictions are still comparable to the prediction performance of non-experts.",,2023-04-11,,"['suprim nakarmi', 'sanam pudasaini', 'safal thapaliya', 'pratima upretee', 'retina shrestha', 'basant giri', 'bhanu bhakta neupane', 'bishesh khanal']",https://arxiv.org/pdf/2304.05339.pdf
794,2304.05341,bayesian optimization of catalysts with in-context learning,physics.chem-ph cs.lg,"large language models (llms) are able to do accurate classification with zero or only a few examples (in-context learning). we show a prompting system that enables regression with uncertainty for in-context learning with frozen llm (gpt-3, gpt-3.5, and gpt-4) models, allowing predictions without features or architecture tuning. by incorporating uncertainty, our approach enables bayesian optimization for catalyst or molecule optimization using natural language, eliminating the need for training or simulation. here, we performed the optimization using the synthesis procedure of catalysts to predict properties. working with natural language mitigates difficulty synthesizability since the literal synthesis procedure is the model's input. we showed that in-context learning could improve past a model context window (maximum number of tokens the model can process at once) as data is gathered via example selection, allowing the model to scale better. although our method does not outperform all baselines, it requires zero training, feature selection, and minimal computing while maintaining satisfactory performance. we also find gaussian process regression on text embeddings is strong at bayesian optimization. the code is available in our github repository: https://github.com/ur-whitelab/bo-lift",,2023-04-11,,"['mayk caldas ramos', 'shane s. michtavy', 'marc d. porosoff', 'andrew d. white']",https://arxiv.org/pdf/2304.05341.pdf
795,2304.05352,spot: sequential predictive modeling of clinical trial outcome with   meta-learning,cs.lg cs.ai,"clinical trials are essential to drug development but time-consuming, costly, and prone to failure. accurate trial outcome prediction based on historical trial data promises better trial investment decisions and more trial success. existing trial outcome prediction models were not designed to model the relations among similar trials, capture the progression of features and designs of similar trials, or address the skewness of trial data which causes inferior performance for less common trials.   to fill the gap and provide accurate trial outcome prediction, we propose sequential predictive modeling of clinical trial outcome (spot) that first identifies trial topics to cluster the multi-sourced trial data into relevant trial topics. it then generates trial embeddings and organizes them by topic and time to create clinical trial sequences. with the consideration of each trial sequence as a task, it uses a meta-learning strategy to achieve a point where the model can rapidly adapt to new tasks with minimal updates. in particular, the topic discovery module enables a deeper understanding of the underlying structure of the data, while sequential learning captures the evolution of trial designs and outcomes. this results in predictions that are not only more accurate but also more interpretable, taking into account the temporal patterns and unique characteristics of each trial topic. we demonstrate that spot wins over the prior methods by a significant margin on trial outcome benchmark data: with a 21.5\% lift on phase i, an 8.9\% lift on phase ii, and a 5.5\% lift on phase iii trials in the metric of the area under precision-recall curve (pr-auc).",,2023-04-07,,"['zifeng wang', 'cao xiao', 'jimeng sun']",https://arxiv.org/pdf/2304.05352.pdf
796,2304.05354,idml: incentivized decentralized machine learning,cs.lg cs.ai cs.dc,"with the rising emergence of decentralized and opportunistic approaches to machine learning, end devices are increasingly tasked with training deep learning models on-devices using crowd-sourced data that they collect themselves. these approaches are desirable from a resource consumption perspective and also from a privacy preservation perspective. when the devices benefit directly from the trained models, the incentives are implicit - contributing devices' resources are incentivized by the availability of the higher-accuracy model that results from collaboration. however, explicit incentive mechanisms must be provided when end-user devices are asked to contribute their resources (e.g., computation, communication, and data) to a task performed primarily for the benefit of others, e.g., training a model for a task that a neighbor device needs but the device owner is uninterested in. in this project, we propose a novel blockchain-based incentive mechanism for completely decentralized and opportunistic learning architectures. we leverage a smart contract not only for providing explicit incentives to end devices to participate in decentralized learning but also to create a fully decentralized mechanism to inspect and reflect on the behavior of the learning architecture.",,2023-04-10,,"['haoxiang yu', 'hsiao-yuan chen', 'sangsu lee', 'sriram vishwanath', 'xi zheng', 'christine julien']",https://arxiv.org/pdf/2304.05354.pdf
797,2304.05359,a comparative study between paired and unpaired image quality assessment   in low-dose ct denoising,eess.iv cs.cv,"the current deep learning approaches for low-dose ct denoising can be divided into paired and unpaired methods. the former involves the use of well-paired datasets, whilst the latter relaxes this constraint. the large availability of unpaired datasets has raised the interest in deepening unpaired denoising strategies that, in turn, need for robust evaluation techniques going beyond the qualitative evaluation. to this end, we can use quantitative image quality assessment scores that we divided into two categories, i.e., paired and unpaired measures. however, the interpretation of unpaired metrics is not straightforward, also because the consistency with paired metrics has not been fully investigated. to cope with this limitation, in this work we consider 15 paired and unpaired scores, which we applied to assess the performance of low-dose ct denoising. we perform an in-depth statistical analysis that not only studies the correlation between paired and unpaired metrics but also within each category. this brings out useful guidelines that can help researchers and practitioners select the right measure for their applications.",,2023-04-11,,"['francesco di feola', 'lorenzo tronchin', 'paolo soda']",https://arxiv.org/pdf/2304.05359.pdf
798,2304.05362,masil: towards maximum separable class representation for few shot class   incremental learning,cs.cv,"few shot class incremental learning (fscil) with few examples per class for each incremental session is the realistic setting of continual learning since obtaining large number of annotated samples is not feasible and cost effective. we present the framework masil as a step towards learning the maximal separable classifier. it addresses the common problem i.e forgetting of old classes and over-fitting to novel classes by learning the classifier weights to be maximally separable between classes forming a simplex equiangular tight frame. we propose the idea of concept factorization explaining the collapsed features for base session classes in terms of concept basis and use these to induce classifier simplex for few shot classes. we further adds fine tuning to reduce any error occurred during factorization and train the classifier jointly on base and novel classes without retaining any base class samples in memory. experimental results on miniimagenet, cifar-100 and cub-200 demonstrate that masil outperforms all the benchmarks.",,2023-04-08,,['anant khandelwal'],https://arxiv.org/pdf/2304.05362.pdf
799,2304.05364,diffusion models for constrained domains,cs.lg stat.ml,"denoising diffusion models are a recent class of generative models which achieve state-of-the-art results in many domains such as unconditional image generation and text-to-speech tasks. they consist of a noising process destroying the data and a backward stage defined as the time-reversal of the noising diffusion. building on their success, diffusion models have recently been extended to the riemannian manifold setting. yet, these riemannian diffusion models require geodesics to be defined for all times. while this setting encompasses many important applications, it does not include manifolds defined via a set of inequality constraints, which are ubiquitous in many scientific domains such as robotics and protein design. in this work, we introduce two methods to bridge this gap. first, we design a noising process based on the logarithmic barrier metric induced by the inequality constraints. second, we introduce a noising process based on the reflected brownian motion. as existing diffusion model techniques cannot be applied in this setting, we derive new tools to define such models in our framework. we empirically demonstrate the applicability of our methods to a number of synthetic and real-world tasks, including the constrained conformational modelling of protein backbones and robotic arms.",,2023-04-11,,"['nic fishman', 'leo klarner', 'valentin de bortoli', 'emile mathieu', 'michael hutchinson']",https://arxiv.org/pdf/2304.05364.pdf
800,2304.05365,did we personalize? assessing personalization by an online reinforcement   learning algorithm using resampling,cs.lg stat.ap stat.me stat.ml,"there is a growing interest in using reinforcement learning (rl) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). online rl is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. however, to decide whether the rl algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the rl algorithm is actually personalizing the treatments to its users. due to the stochasticity in the rl algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. we use a working definition of personalization and introduce a resampling-based methodology for investigating whether the personalization exhibited by the rl algorithm is an artifact of the rl algorithm stochasticity. we illustrate our methodology with a case study by analyzing the data from a physical activity clinical trial called heartsteps, which included the use of an online rl algorithm. we demonstrate how our approach enhances data-driven truth-in-advertising of algorithm personalization both across all users as well as within specific users in the study.",,2023-04-11,,"['susobhan ghosh', 'raphael kim', 'prasidh chhabria', 'raaz dwivedi', 'predrag klasjna', 'peng liao', 'kelly zhang', 'susan murphy']",https://arxiv.org/pdf/2304.05365.pdf
801,2304.05366,"the no free lunch theorem, kolmogorov complexity, and the role of   inductive biases in machine learning",cs.lg stat.ml,"no free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. while virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using kolmogorov complexity. notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. our experiments show that pre-trained and even randomly initialized language models prefer to generate low-complexity sequences. whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we explain how tasks that often require human intervention such as picking an appropriately sized model when labeled data is scarce or plentiful can be automated into a single learning algorithm. these observations justify the trend in deep learning of unifying seemingly disparate problems with an increasingly small set of machine learning models.",,2023-04-11,,"['micah goldblum', 'marc finzi', 'keefer rowan', 'andrew gordon wilson']",https://arxiv.org/pdf/2304.05366.pdf
802,2304.05368,are large language models ready for healthcare? a comparative study on   clinical language understanding,cs.cl cs.ai,"large language models (llms) have made significant progress in various domains, including healthcare. however, the specialized nature of clinical language understanding tasks presents unique challenges and limitations that warrant further investigation. in this study, we conduct a comprehensive evaluation of state-of-the-art llms, namely gpt-3.5, gpt-4, and bard, within the realm of clinical language understanding tasks. these tasks span a diverse range, including named entity recognition, relation extraction, natural language inference, semantic textual similarity, document classification, and question-answering. we also introduce a novel prompting strategy, self-questioning prompting (sqp), tailored to enhance llms' performance by eliciting informative questions and answers pertinent to the clinical scenarios at hand. our evaluation underscores the significance of task-specific learning strategies and prompting techniques for improving llms' effectiveness in healthcare-related tasks. additionally, our in-depth error analysis on the challenging relation extraction task offers valuable insights into error distribution and potential avenues for improvement using sqp. our study sheds light on the practical implications of employing llms in the specialized domain of healthcare, serving as a foundation for future research and the development of potential applications in healthcare settings.",,2023-04-09,2023-04-13,"['yuqing wang', 'yun zhao', 'linda petzold']",https://arxiv.org/pdf/2304.05368.pdf
803,2304.05369,a surprisingly simple technique to control the pretraining bias for   better transfer: expand or narrow your representation,cs.lg,"self-supervised learning (ssl) models rely on a pretext task to learn representations. because this pretext task differs from the downstream tasks used to evaluate the performance of these models, there is an inherent misalignment or pretraining bias. a commonly used trick in ssl, shown to make deep networks more robust to such bias, is the addition of a small projector (usually a 2 or 3 layer multi-layer perceptron) on top of a backbone network during training. in contrast to previous work that studied the impact of the projector architecture, we here focus on a simpler, yet overlooked lever to control the information in the backbone representation. we show that merely changing its dimensionality -- by changing only the size of the backbone's very last block -- is a remarkably effective technique to mitigate the pretraining bias. it significantly improves downstream transfer performance for both self-supervised and supervised pretrained models.",,2023-04-11,,"['florian bordes', 'samuel lavoie', 'randall balestriero', 'nicolas ballas', 'pascal vincent']",https://arxiv.org/pdf/2304.05369.pdf
804,2304.05370,overload: latency attacks on object detection for edge devices,cs.cv,"nowadays, the deployment of deep learning based applications on edge devices is an essential task owing to the increasing demands on intelligent services. however, the limited computing resources on edge nodes make the models vulnerable to attacks, such that the predictions made by models are unreliable. in this paper, we investigate latency attacks on deep learning applications. unlike common adversarial attacks for misclassification, the goal of latency attacks is to increase the inference time, which may stop applications from responding to the requests within a reasonable time. this kind of attack is ubiquitous for various applications, and we use object detection to demonstrate how such kind of attacks work. we also design a framework named overload to generate latency attacks at scale. our method is based on a newly formulated optimization problem and a novel technique, called spatial attention, to increase the inference time of object detection. we have conducted experiments using yolov5 models on nvidia nx. the experimental results show that with latency attacks, the inference time of a single image can be increased ten times longer in reference to the normal setting. moreover, comparing to existing methods, our attacking method is simpler and more effective.",,2023-04-11,2023-04-12,"['erh-chung chen', 'pin-yu chen', 'i-hsin chung', 'che-rung lee']",https://arxiv.org/pdf/2304.05370.pdf
805,2304.05387,most: multiple object localization with self-supervised transformers for   object discovery,cs.cv,"we tackle the challenging task of unsupervised object localization in this work. recently, transformers trained with self-supervised learning have been shown to exhibit object localization properties without being trained for this task. in this work, we present multiple object localization with self-supervised transformers (most) that uses features of transformers trained using self-supervised learning to localize multiple objects in real world images. most analyzes the similarity maps of the features using box counting; a fractal analysis tool to identify tokens lying on foreground patches. the identified tokens are then clustered together, and tokens of each cluster are used to generate bounding boxes on foreground regions. unlike recent state-of-the-art object localization methods, most can localize multiple objects per image and outperforms sota algorithms on several object localization and discovery benchmarks on pascal-voc 07, 12 and coco20k datasets. additionally, we show that most can be used for self-supervised pre-training of object detectors, and yields consistent improvements on fully, semi-supervised object detection and unsupervised region proposal generation.",,2023-04-11,,"['sai saketh rambhatla', 'ishan misra', 'rama chellappa', 'abhinav shrivastava']",https://arxiv.org/pdf/2304.05387.pdf
806,2304.05391,pinpointing why object recognition performance degrades across income   levels and geographies,cs.cv,"despite impressive advances in object-recognition, deep learning systems' performance degrades significantly across geographies and lower income levels raising pressing concerns of inequity. addressing such performance gaps remains a challenge, as little is understood about why performance degrades across incomes or geographies. we take a step in this direction by annotating images from dollar street, a popular benchmark of geographically and economically diverse images, labeling each image with factors such as color, shape, and background. these annotations unlock a new granular view into how objects differ across incomes and regions. we then use these object differences to pinpoint model vulnerabilities across incomes and regions. we study a range of modern vision models, finding that performance disparities are most associated with differences in texture, occlusion, and images with darker lighting. we illustrate how insights from our factor labels can surface mitigations to improve models' performance disparities. as an example, we show that mitigating a model's vulnerability to texture can improve performance on the lower income level. we release all the factor annotations along with an interactive dashboard to facilitate research into more equitable vision systems.",,2023-04-11,,"['laura gustafson', 'megan richards', 'melissa hall', 'caner hazirbas', 'diane bouchacourt', 'mark ibrahim']",https://arxiv.org/pdf/2304.05391.pdf
807,2304.05396,sam.md: zero-shot medical image segmentation capabilities of the segment   anything model,eess.iv cs.cv cs.lg,"foundation models have taken over natural language processing and image generation domains due to the flexibility of prompting. with the recent introduction of the segment anything model (sam), this prompt-driven paradigm has entered image segmentation with a hitherto unexplored abundance of capabilities. the purpose of this paper is to conduct an initial evaluation of the out-of-the-box zero-shot capabilities of sam for medical image segmentation, by evaluating its performance on an abdominal ct organ segmentation task, via point or bounding box based prompting. we show that sam generalizes well to ct data, making it a potential catalyst for the advancement of semi-automatic segmentation tools for clinicians. we believe that this foundation model, while not reaching state-of-the-art segmentation performance in our investigations, can serve as a highly potent starting point for further adaptations of such models to the intricacies of the medical domain. keywords: medical image segmentation, sam, foundation models, zero-shot learning",,2023-04-10,,"['saikat roy', 'tassilo wald', 'gregor koehler', 'maximilian r. rokuss', 'nico disch', 'julius holzschuh', 'david zimmerer', 'klaus h. maier-hein']",https://arxiv.org/pdf/2304.05396.pdf
808,2304.05397,accelerating hybrid federated learning convergence under partial   participation,cs.dc cs.lg,"over the past few years, federated learning (fl) has become a popular distributed machine learning paradigm. fl involves a group of clients with decentralized data who collaborate to learn a common model under the coordination of a centralized server, with the goal of protecting clients' privacy by ensuring that local datasets never leave the clients and that the server only performs model aggregation. however, in realistic scenarios, the server may be able to collect a small amount of data that approximately mimics the population distribution and has stronger computational ability to perform the learning process. to address this, we focus on the hybrid fl framework in this paper. while previous hybrid fl work has shown that the alternative training of clients and server can increase convergence speed, it has focused on the scenario where clients fully participate and ignores the negative effect of partial participation. in this paper, we provide theoretical analysis of hybrid fl under clients' partial participation to validate that partial participation is the key constraint on convergence speed. we then propose a new algorithm called fedclg, which investigates the two-fold role of the server in hybrid fl. firstly, the server needs to process the training steps using its small amount of local datasets. secondly, the server's calculated gradient needs to guide the participated clients' training and the server's aggregation. we validate our theoretical findings through numerical experiments, which show that our proposed method fedclg outperforms state-of-the-art methods.",,2023-04-10,,"['jieming bian', 'lei wang', 'kun yang', 'cong shen', 'jie xu']",https://arxiv.org/pdf/2304.05397.pdf
809,2304.05398,forward-backward gaussian variational inference via jko in the   bures-wasserstein space,math.st cs.lg math.oc stat.th,"variational inference (vi) seeks to approximate a target distribution $\pi$ by an element of a tractable family of distributions. of key interest in statistics and machine learning is gaussian vi, which approximates $\pi$ by minimizing the kullback-leibler (kl) divergence to $\pi$ over the space of gaussians. in this work, we develop the (stochastic) forward-backward gaussian variational inference (fb-gvi) algorithm to solve gaussian vi. our approach exploits the composite structure of the kl divergence, which can be written as the sum of a smooth term (the potential) and a non-smooth term (the entropy) over the bures-wasserstein (bw) space of gaussians endowed with the wasserstein distance. for our proposed algorithm, we obtain state-of-the-art convergence guarantees when $\pi$ is log-smooth and log-concave, as well as the first convergence guarantees to first-order stationary solutions when $\pi$ is only log-smooth.",,2023-04-10,,"['michael diao', 'krishnakumar balasubramanian', 'sinho chewi', 'adil salim']",https://arxiv.org/pdf/2304.05398.pdf
810,2304.05402,boosting cross-task transferability of adversarial patches with visual   relations,cs.cv cs.cr cs.lg cs.mm,"the transferability of adversarial examples is a crucial aspect of evaluating the robustness of deep learning systems, particularly in black-box scenarios. although several methods have been proposed to enhance cross-model transferability, little attention has been paid to the transferability of adversarial examples across different tasks. this issue has become increasingly relevant with the emergence of foundational multi-task ai systems such as visual chatgpt, rendering the utility of adversarial samples generated by a single task relatively limited. furthermore, these systems often entail inferential functions beyond mere recognition-like tasks. to address this gap, we propose a novel visual relation-based cross-task adversarial patch generation method called vrap, which aims to evaluate the robustness of various visual tasks, especially those involving visual reasoning, such as visual question answering and image captioning. vrap employs scene graphs to combine object recognition-based deception with predicate-based relations elimination, thereby disrupting the visual reasoning information shared among inferential tasks. our extensive experiments demonstrate that vrap significantly surpasses previous methods in terms of black-box transferability across diverse visual reasoning tasks.",,2023-04-11,,"['tony ma', 'songze li', 'yisong xiao', 'shunchang liu']",https://arxiv.org/pdf/2304.05402.pdf
811,2304.05403,isolated sign language recognition based on tree structure skeleton   images,cs.cv,"sign language recognition (slr) systems aim to be embedded in video stream platforms to recognize the sign performed in front of a camera. slr research has taken advantage of recent advances in pose estimation models to use skeleton sequences estimated from videos instead of rgb information to predict signs. this approach can make har-related tasks less complex and more robust to diverse backgrounds, lightning conditions, and physical appearances. in this work, we explore the use of a spatio-temporal skeleton representation such as tree structure skeleton image (tssi) as an alternative input to improve the accuracy of skeleton-based models for slr. tssi converts a skeleton sequence into an rgb image where the columns represent the joints of the skeleton in a depth-first tree traversal order, the rows represent the temporal evolution of the joints, and the three channels represent the (x, y, z) coordinates of the joints. we trained a densenet-121 using this type of input and compared it with other skeleton-based deep learning methods using a large-scale american sign language (asl) dataset, wlasl. our model (sl-tssi-densenet) overcomes the state-of-the-art of other skeleton-based models. moreover, when including data augmentation our proposal achieves better results than both skeleton-based and rgb-based models. we evaluated the effectiveness of our model on the ankara university turkish sign language (tsl) dataset, autsl, and a mexican sign language (lsm) dataset. on the autsl dataset, the model achieves similar results to the state-of-the-art of other skeleton-based models. on the lsm dataset, the model achieves higher results than the baseline. code has been made available at: https://github.com/davidlainesv/sl-tssi-densenet.",,2023-04-09,,"['david laines', 'gissella bejarano', 'miguel gonzalez-mendoza', 'gilberto ochoa-ruiz']",https://arxiv.org/pdf/2304.05403.pdf
812,2304.05405,efficient automation of neural network design: a survey on   differentiable neural architecture search,cs.lg cs.ai cs.cv,"in the past few years, differentiable neural architecture search (dnas) rapidly imposed itself as the trending approach to automate the discovery of deep neural network architectures. this rise is mainly due to the popularity of darts, one of the first major dnas methods. in contrast with previous works based on reinforcement learning or evolutionary algorithms, dnas is faster by several orders of magnitude and uses fewer computational resources. in this comprehensive survey, we focus specifically on dnas and review recent approaches in this field. furthermore, we propose a novel challenge-based taxonomy to classify dnas methods. we also discuss the contributions brought to dnas in the past few years and its impact on the global nas field. finally, we conclude by giving some insights into future research directions for the dnas field.",,2023-04-11,,"['alexandre heuillet', 'ahmad nasser', 'hichem arioui', 'hedi tabia']",https://arxiv.org/pdf/2304.05405.pdf
813,2304.05417,the monet dataset: multimodal drone thermal dataset recorded in rural   scenarios,cs.cv,"we present monet, a new multimodal dataset captured using a thermal camera mounted on a drone that flew over rural areas, and recorded human and vehicle activities. we captured monet to study the problem of object localisation and behaviour understanding of targets undergoing large-scale variations and being recorded from different and moving viewpoints. target activities occur in two different land sites, each with unique scene structures and cluttered backgrounds. monet consists of approximately 53k images featuring 162k manually annotated bounding boxes. each image is timestamp-aligned with drone metadata that includes information about attitudes, speed, altitude, and gps coordinates. monet is different from previous thermal drone datasets because it features multimodal data, including rural scenes captured with thermal cameras containing both person and vehicle targets, along with trajectory information and metadata. we assessed the difficulty of the dataset in terms of transfer learning between the two sites and evaluated nine object detection algorithms to identify the open challenges associated with this type of data. project page: https://github.com/fabiopoiesi/monet_dataset.",,2023-04-11,,"['luigi riz', 'andrea caraffa', 'matteo bortolon', 'mohamed lamine mekhalfi', 'davide boscani', 'andr√© moura', 'jos√© antunes', 'andr√© dias', 'hugo silva', 'andreas leonidou', 'christos constantinides', 'christos keleshis', 'dante abate', 'fabio poiesi']",https://arxiv.org/pdf/2304.05417.pdf
814,2304.05430,transfer learning across heterogeneous features for efficient tensor   program generation,cs.pl cs.lg,"tuning tensor program generation involves searching for various possible program transformation combinations for a given program on target hardware to optimize the tensor program execution. it is already a complex process because of the massive search space and exponential combinations of transformations make auto-tuning tensor program generation more challenging, especially when we have a heterogeneous target. in this research, we attempt to address these problems by learning the joint neural network and hardware features and transferring them to the new target hardware. we extensively study the existing state-of-the-art dataset, tenset, perform comparative analysis on the test split strategies and propose methodologies to prune the dataset. we adopt an attention-inspired approach for tuning the tensor programs enabling them to embed neural network and hardware-specific features. our approach could prune the dataset up to 45\% of the baseline without compromising the pairwise comparison accuracy (pca). further, the proposed methodology can achieve on-par or improved mean inference time with 25%-40% of the baseline tuning time across different networks and target hardware.",,2023-04-11,,"['gaurav verma', 'siddhisanket raskar', 'zhen xie', 'abid m malik', 'murali emani', 'barbara chapman']",https://arxiv.org/pdf/2304.05430.pdf
815,2304.05444,collaborative machine learning model building with families using co-ml,cs.hc cs.lg,"existing novice-friendly machine learning (ml) modeling tools center around a solo user experience, where a single user collects only their own data to build a model. however, solo modeling experiences limit valuable opportunities for encountering alternative ideas and approaches that can arise when learners work together; consequently, it often precludes encountering critical issues in ml around data representation and diversity that can surface when different perspectives are manifested in a group-constructed data set. to address this issue, we created co-ml -- a tablet-based app for learners to collaboratively build ml image classifiers through an end-to-end, iterative model-building process. in this paper, we illustrate the feasibility and potential richness of collaborative modeling by presenting an in-depth case study of a family (two children 11 and 14-years-old working with their parents) using co-ml in a facilitated introductory ml activity at home. we share the co-ml system design and contribute a discussion of how using co-ml in a collaborative activity enabled beginners to collectively engage with dataset design considerations underrepresented in prior work such as data diversity, class imbalance, and data quality. we discuss how a distributed collaborative process, in which individuals can take on different model-building responsibilities, provides a rich context for children and adults to learn ml dataset design.",,2023-04-11,,"['tiffany tseng', 'jennifer king chen', 'mona abdelrahman', 'mary beth kery', 'fred hohman', 'adriana hilliard', 'r. benjamin shapiro']",https://arxiv.org/pdf/2304.05444.pdf
816,2304.05459,probabilistic reasoning at scale: trigger graphs to the rescue,cs.db,"the role of uncertainty in data management has become more prominent than ever before, especially because of the growing importance of machine learning-driven applications that produce large uncertain databases. a well-known approach to querying such databases is to blend rule-based reasoning with uncertainty. however, techniques proposed so far struggle with large databases. in this paper, we address this problem by presenting a new technique for probabilistic reasoning that exploits trigger graphs (tgs) -- a notion recently introduced for the non-probabilistic setting. the intuition is that tgs can effectively store a probabilistic model by avoiding an explicit materialization of the lineage and by grouping together similar derivations of the same fact. firstly, we show how tgs can be adapted to support the possible world semantics. then, we describe techniques for efficiently computing a probabilistic model, and formally establish the correctness of our approach. we also present an extensive empirical evaluation using a prototype called ltgs. our comparison against other leading engines shows that ltgs is not only faster, even against approximate reasoning techniques, but can also reason over probabilistic databases that existing engines cannot scale to.",10.1145/3588719,2023-04-11,,"['efthymia tsamoura', 'jaehun lee', 'jacopo urbani']",https://arxiv.org/pdf/2304.05459.pdf
817,2304.05462,evaluation of short range depth sonifications for visual-to-auditory   sensory substitution,cs.hc,"visual to auditory sensory substitution devices convert visual information into sound and can provide valuable assistance for blind people. recent iterations of these devices rely on depth sensors. rules for converting depth into sound (i.e. the sonifications) are often designed arbitrarily, with no strong evidence for choosing one over another. the purpose of this work is to compare and understand the effectiveness of five depth sonifications in order to assist the design process of future visual to auditory systems for blind people which rely on depth sensors. the frequency, amplitude and reverberation of the sound as well as the repetition rate of short high-pitched sounds and the signal-to-noise ratio of a mixture between pure sound and noise are studied. we conducted positioning experiments with twenty-eight sighted blindfolded participants. stage 1 incorporates learning phases followed by depth estimation tasks. stage 2 adds the additional challenge of azimuth estimation to the first stage's protocol. stage 3 tests learning retention by incorporating a 10-minute break before re-testing depth estimation. the best depth estimates in stage 1 were obtained with the sound frequency and the repetition rate of beeps. in stage 2, the beep repetition rate yielded the best depth estimation and no significant difference was observed for the azimuth estimation. results of stage 3 showed that the beep repetition rate was the easiest sonification to memorize. based on statistical analysis of the results, we discuss the effectiveness of each sonification and compare with other studies that encode depth into sounds. finally we provide recommendations for the design of depth encoding.",,2023-04-11,,"['louis comm√®re', 'jean rouat']",https://arxiv.org/pdf/2304.05462.pdf
818,2304.05464,uncrtaints: uncertainty quantification for cloud removal in optical   satellite time series,cs.cv eess.iv,"clouds and haze often occlude optical satellite images, hindering continuous, dense monitoring of the earth's surface. although modern deep learning methods can implicitly learn to ignore such occlusions, explicit cloud removal as pre-processing enables manual interpretation and allows training models when only few annotations are available. cloud removal is challenging due to the wide range of occlusion scenarios -- from scenes partially visible through haze, to completely opaque cloud coverage. furthermore, integrating reconstructed images in downstream applications would greatly benefit from trustworthy quality assessment. in this paper, we introduce uncrtaints, a method for multi-temporal cloud removal combining a novel attention-based architecture, and a formulation for multivariate uncertainty prediction. these two components combined set a new state-of-the-art performance in terms of image reconstruction on two public cloud removal datasets. additionally, we show how the well-calibrated predicted uncertainties enable a precise control of the reconstruction quality.",,2023-04-11,,"['patrick ebel', 'vivien sainte fare garnot', 'michael schmitt', 'jan dirk wegner', 'xiao xiang zhu']",https://arxiv.org/pdf/2304.05464.pdf
819,2304.05475,failure probability estimation and detection of failure surfaces via   adaptive sequential decomposition of the design domain,cs.ce math.pr,"we propose an algorithm for an optimal adaptive selection of points from the design domain of input random variables that are needed for an accurate estimation of failure probability and the determination of the boundary between safe and failure domains. the method is particularly useful when each evaluation of the performance function g(x) is very expensive and the function can be characterized as either highly nonlinear, noisy, or even discrete-state (e.g., binary). in such cases, only a limited number of calls is feasible, and gradients of g(x) cannot be used. the input design domain is progressively segmented by expanding and adaptively refining mesh-like lock-free geometrical structure. the proposed triangulation-based approach effectively combines the features of simulation and approximation methods. the algorithm performs two independent tasks: (i) the estimation of probabilities through an ingenious combination of deterministic cubature rules and the application of the divergence theorem and (ii) the sequential extension of the experimental design with new points. the sequential selection of points from the design domain for future evaluation of g(x) is carried out through a new learning function, which maximizes instantaneous information gain in terms of the probability classification that corresponds to the local region. the extension may be halted at any time, e.g., when sufficiently accurate estimations are obtained. due to the use of the exact geometric representation in the input domain, the algorithm is most effective for problems of a low dimension, not exceeding eight. the method can handle random vectors with correlated non-gaussian marginals. the estimation accuracy can be improved by employing a smooth surrogate model. finally, we define new factors of global sensitivity to failure based on the entire failure surface weighted by the density of the input random vector.",,2023-04-11,,"['aleksei gerasimov', 'miroslav vo≈ôechovsk√Ω']",https://arxiv.org/pdf/2304.05475.pdf
820,2304.05482,computational pathology: a survey review and the way forward,eess.iv cs.cv,"computational pathology (copath) is an interdisciplinary science that augments developments of computational approaches to analyze and model medical histopathology images. the main objective for copath is to develop infrastructure and workflows of digital diagnostics as an assistive cad system for clinical pathology facilitating transformational changes in the diagnosis and treatment of cancer diseases. with evergrowing developments in deep learning and computer vision algorithms, and the ease of the data flow from digital pathology, currently copath is witnessing a paradigm shift. despite the sheer volume of engineering and scientific works being introduced for cancer image analysis, there is still a considerable gap of adopting and integrating these algorithms in clinical practice. this raises a significant question regarding the direction and trends that are undertaken in copath. in this article we provide a comprehensive review of more than 700 papers to address the challenges faced in problem design all-the-way to the application and implementation viewpoints. we have catalogued each paper into a model-card by examining the key works and challenges faced to layout the current landscape in copath. we hope this helps the community to locate relevant works and facilitate understanding of the field's future directions. in a nutshell, we oversee the copath developments in cycle of stages which are required to be cohesively linked together to address the challenges associated with such multidisciplinary science. we overview this cycle from different perspectives of data-centric, model-centric, and application-centric problems. we finally sketch remaining challenges and provide directions for future technical developments and clinical integration of copath.",,2023-04-11,,"['mahdi s. hosseini', 'babak ehteshami bejnordi', 'vincent quoc-huy trinh', 'danial hasan', 'xingwen li', 'taehyo kim', 'haochen zhang', 'theodore wu', 'kajanan chinniah', 'sina maghsoudlou', 'ryan zhang', 'stephen yang', 'jiadai zhu', 'lyndon chan', 'samir khaki', 'andrei buin', 'fatemeh chaji', 'ala salehi', 'alejandra zambrano luna', 'bich ngoc nguyen', 'dimitris samaras', 'konstantinos n. plataniotis']",https://arxiv.org/pdf/2304.05482.pdf
821,2304.05489,user adaptive language learning chatbots with a curriculum,cs.cl,"along with the development of systems for natural language understanding and generation, dialog systems have been widely adopted for language learning and practicing. many current educational dialog systems perform chitchat, where the generated content and vocabulary are not constrained. however, for learners in a school setting, practice through dialog is more effective if it aligns with students' curriculum and focuses on textbook vocabulary. therefore, we adapt lexically constrained decoding to a dialog system, which urges the dialog system to include curriculum-aligned words and phrases in its generated utterances. we adopt a generative dialog system, blenderbot3, as our backbone model and evaluate our curriculum-based dialog system with middle school students learning english as their second language. the constrained words and phrases are derived from their textbooks, suggested by their english teachers. the evaluation result demonstrates that the dialog system with curriculum infusion improves students' understanding of target words and increases their interest in practicing english.",,2023-04-11,,"['kun qian', 'ryan shea', 'yu li', 'luke kutszik fryer', 'zhou yu']",https://arxiv.org/pdf/2304.05489.pdf
822,2304.05493,kgs: causal discovery using knowledge-guided greedy equivalence search,cs.ai,"learning causal relationships solely from observational data provides insufficient information about the underlying causal mechanism and the search space of possible causal graphs. as a result, often the search space can grow exponentially for approaches such as greedy equivalence search (ges) that uses a score-based approach to search the space of equivalence classes of graphs. prior causal information such as the presence or absence of a causal edge can be leveraged to guide the discovery process towards a more restricted and accurate search space. in this study, we present kgs, a knowledge-guided greedy score-based causal discovery approach that uses observational data and structural priors (causal edges) as constraints to learn the causal graph. kgs is a novel application of knowledge constraints that can leverage any of the following prior edge information between any two variables: the presence of a directed edge, the absence of an edge, and the presence of an undirected edge. we extensively evaluate kgs across multiple settings in both synthetic and benchmark real-world datasets. our experimental results demonstrate that structural priors of any type and amount are helpful and guide the search process towards an improved performance and early convergence.",,2023-04-11,,"['uzma hasan', 'md osman gani']",https://arxiv.org/pdf/2304.05493.pdf
823,2304.05495,communication efficient dnn partitioning-based federated learning,cs.dc,"efficiently running federated learning (fl) on resource-constrained devices is challenging since they are required to train computationally intensive deep neural networks (dnn) independently. dnn partitioning-based fl (dpfl) has been proposed as one mechanism to accelerate training where the layers of a dnn (or computation) are offloaded from the device to an edge server. however, this creates significant communication overheads since the activation and gradient need to be transferred between the device and the edge server during training. current techniques reduce the communication introduced by dnn partitioning using local loss-based methods. we demonstrate that these methods adversely impact accuracy and ignore the communication costs incurred when transmitting the activation from the device to the server. this paper proposes actionfed - a communication efficient framework for dpfl to accelerate training on resource-constrained devices. actionfed eliminates the transmission of the gradient by developing pre-trained initialization of the dnn model on the device for the first time. this reduces the accuracy degradation seen in local loss-based methods. in addition, actionfed proposes a novel replay buffer mechanism and implements a quantization-based compression technique to reduce the transmission of the activation. it is experimentally demonstrated that actionfed can reduce the communication cost by up to 15.77x and accelerates training by up to 3.87x when compared to vanilla dpfl.",,2023-04-11,,"['di wu', 'rehmat ullah', 'philip rodgers', 'peter kilpatrick', 'ivor spence', 'blesson varghese']",https://arxiv.org/pdf/2304.05495.pdf
824,2304.05498,graphganfed: a federated generative framework for graph-structured   molecules towards efficient drug discovery,cs.lg cs.ai,"recent advances in deep learning have accelerated its use in various applications, such as cellular image analysis and molecular discovery. in molecular discovery, a generative adversarial network (gan), which comprises a discriminator to distinguish generated molecules from existing molecules and a generator to generate new molecules, is one of the premier technologies due to its ability to learn from a large molecular data set efficiently and generate novel molecules that preserve similar properties. however, different pharmaceutical companies may be unwilling or unable to share their local data sets due to the geo-distributed and sensitive nature of molecular data sets, making it impossible to train gans in a centralized manner. in this paper, we propose a graph convolutional network in generative adversarial networks via federated learning (graphganfed) framework, which integrates graph convolutional neural network (gcn), gan, and federated learning (fl) as a whole system to generate novel molecules without sharing local data sets. in graphganfed, the discriminator is implemented as a gcn to better capture features from molecules represented as molecular graphs, and fl is used to train both the discriminator and generator in a distributive manner to preserve data privacy. extensive simulations are conducted based on the three bench-mark data sets to demonstrate the feasibility and effectiveness of graphganfed. the molecules generated by graphganfed can achieve high novelty (=100) and diversity (> 0.9). the simulation results also indicate that 1) a lower complexity discriminator model can better avoid mode collapse for a smaller data set, 2) there is a tradeoff among different evaluation metrics, and 3) having the right dropout ratio of the generator and discriminator can avoid mode collapse.",,2023-04-11,,"['daniel manu', 'jingjing yao', 'wuji liu', 'xiang sun']",https://arxiv.org/pdf/2304.05498.pdf
825,2304.05501,l3mvn: leveraging large language models for visual target navigation,cs.ro,"visual target navigation in unknown environments is a crucial problem in robotics. despite extensive investigation of classical and learning-based approaches in the past, robots lack common-sense knowledge about household objects and layouts. prior state-of-the-art approaches to this task rely on learning the priors during the training and typically require significant expensive resources and time for learning. to address this, we propose a new framework for visual target navigation that leverages large language models (llm) to impart common sense for object searching. specifically, we introduce two paradigms: (i) zero-shot and (ii) feed-forward approaches that use language to find the relevant frontier from the semantic map as a long-term goal and explore the environment efficiently. our analysis demonstrates the notable zero-shot generalization and transfer capabilities from the use of language. experiments on gibson and habitat-matterport 3d (hm3d) demonstrate that the proposed framework significantly outperforms existing map-based methods in terms of success rate and generalization. ablation analysis also indicates that the common-sense knowledge from the language model leads to more efficient semantic exploration. finally, we provide a real robot experiment to verify the applicability of our framework in real-world scenarios. the supplementary video and code can be accessed via the following link: https://sites.google.com/view/l3mvn.",,2023-04-11,,"['bangguo yu', 'hamidreza kasaei', 'ming cao']",https://arxiv.org/pdf/2304.05501.pdf
826,2304.05502,machine learning for structure-property relationships: scalability and   limitations,cond-mat.stat-mech cond-mat.mtrl-sci cs.lg,"we present a scalable machine learning (ml) framework for predicting intensive properties and particularly classifying phases of many-body systems. scalability and transferability are central to the unprecedented computational efficiency of ml methods. in general, linear-scaling computation can be achieved through the divide and conquer approach, and the locality of physical properties is key to partitioning the system into sub-domains that can be solved separately. based on the locality assumption, ml model is developed for the prediction of intensive properties of a finite-size block. predictions of large-scale systems can then be obtained by averaging results of the ml model from randomly sampled blocks of the system. we show that the applicability of this approach depends on whether the block-size of the ml model is greater than the characteristic length scale of the system. in particular, in the case of phase identification across a critical point, the accuracy of the ml prediction is limited by the diverging correlation length. the two-dimensional ising model is used to demonstrate the proposed framework. we obtain an intriguing scaling relation between the prediction accuracy and the ratio of ml block size over the spin-spin correlation length. implications for practical applications are also discussed.",,2023-04-11,,"['zhongzheng tian', 'sheng zhang', 'gia-wei chern']",https://arxiv.org/pdf/2304.05502.pdf
827,2304.05503,disthd: a learner-aware dynamic encoding method for hyperdimensional   classification,cs.lg cs.ai,"brain-inspired hyperdimensional computing (hdc) has been recently considered a promising learning approach for resource-constrained devices. however, existing approaches use static encoders that are never updated during the learning process. consequently, it requires a very high dimensionality to achieve adequate accuracy, severely lowering the encoding and training efficiency. in this paper, we propose disthd, a novel dynamic encoding technique for hdc adaptive learning that effectively identifies and regenerates dimensions that mislead the classification and compromise the learning quality. our proposed algorithm disthd successfully accelerates the learning process and achieves the desired accuracy with considerably lower dimensionality.",,2023-04-11,,"['junyao wang', 'sitao huang', 'mohsen imani']",https://arxiv.org/pdf/2304.05503.pdf
828,2304.05506,frontier semantic exploration for visual target navigation,cs.ro,"this work focuses on the problem of visual target navigation, which is very important for autonomous robots as it is closely related to high-level tasks. to find a special object in unknown environments, classical and learning-based approaches are fundamental components of navigation that have been investigated thoroughly in the past. however, due to the difficulty in the representation of complicated scenes and the learning of the navigation policy, previous methods are still not adequate, especially for large unknown scenes. hence, we propose a novel framework for visual target navigation using the frontier semantic policy. in this proposed framework, the semantic map and the frontier map are built from the current observation of the environment. using the features of the maps and object category, deep reinforcement learning enables to learn a frontier semantic policy which can be used to select a frontier cell as a long-term goal to explore the environment efficiently. experiments on gibson and habitat-matterport 3d (hm3d) demonstrate that the proposed framework significantly outperforms existing map-based methods in terms of success rate and efficiency. ablation analysis also indicates that the proposed approach learns a more efficient exploration policy based on the frontiers. a demonstration is provided to verify the applicability of applying our model to real-world transfer. the supplementary video and code can be accessed via the following link: https://sites.google.com/view/fsevn.",,2023-04-11,,"['bangguo yu', 'hamidreza kasaei', 'ming cao']",https://arxiv.org/pdf/2304.05506.pdf
829,2304.05509,control invariant set enhanced reinforcement learning for process   control: improved sampling efficiency and guaranteed stability,eess.sy cs.ai cs.lg cs.sy,"reinforcement learning (rl) is an area of significant research interest, and safe rl in particular is attracting attention due to its ability to handle safety-driven constraints that are crucial for real-world applications of rl algorithms. this work proposes a novel approach to rl training, called control invariant set (cis) enhanced rl, which leverages the benefits of cis to improve stability guarantees and sampling efficiency. the approach consists of two learning stages: offline and online. in the offline stage, cis is incorporated into the reward design, initial state sampling, and state reset procedures. in the online stage, rl is retrained whenever the state is outside of cis, which serves as a stability criterion. a backup table that utilizes the explicit form of cis is obtained to ensure the online stability. to evaluate the proposed approach, we apply it to a simulated chemical reactor. the results show a significant improvement in sampling efficiency during offline training and closed-loop stability in the online implementation.",,2023-04-11,,"['song bo', 'xunyuan yin', 'jinfeng liu']",https://arxiv.org/pdf/2304.05509.pdf
830,2304.05511,training large language models efficiently with sparsity and dataflow,cs.lg,"large foundation language models have shown their versatility in being able to be adapted to perform a wide variety of downstream tasks, such as text generation, sentiment analysis, semantic search etc. however, training such large foundational models is a non-trivial exercise that requires a significant amount of compute power and expertise from machine learning and systems experts. as models get larger, these demands are only increasing. sparsity is a promising technique to relieve the compute requirements for training. however, sparsity introduces new challenges in training the sparse model to the same quality as the dense counterparts. furthermore, sparsity drops the operation intensity and introduces irregular memory access patterns that makes it challenging to efficiently utilize compute resources. this paper demonstrates an end-to-end training flow on a large language model - 13 billion gpt - using sparsity and dataflow. the dataflow execution model and architecture enables efficient on-chip irregular memory accesses as well as native kernel fusion and pipelined parallelism that helps recover device utilization. we show that we can successfully train gpt 13b to the same quality as the dense gpt 13b model, while achieving an end-end speedup of 4.5x over dense a100 baseline.",,2023-04-11,,"['venkat srinivasan', 'darshan gandhi', 'urmish thakker', 'raghu prabhakar']",https://arxiv.org/pdf/2304.05511.pdf
831,2304.05516,echo of neighbors: privacy amplification for personalized private   federated learning with shuffle model,cs.cr cs.lg,"federated learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. different privacy levels regarding users' attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. personalized local differential privacy (pldp) is suitable for preserving users' varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. in this work, a general framework (apes) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model. to tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. the contributions are characterized by the ability of generating ""echos"" from the perturbation of each user, which is carefully measured by proposed methods neighbor divergence and clip-laplace mechanism. furthermore, we propose a refined framework (s-apes) with the post-sparsification technique to reduce privacy loss in high-dimension scenarios. to the best of our knowledge, the impact of shuffling on personalized local privacy is considered for the first time. we provide a strong privacy amplification effect, and the bound is tighter than the baseline result based on existing methods for uniform local privacy. experiments demonstrate that our frameworks ensure comparable or higher accuracy for the global model.",,2023-04-11,,"['yixuan liu', 'suyun zhao', 'li xiong', 'yuhan liu', 'hong chen']",https://arxiv.org/pdf/2304.05516.pdf
832,2304.05527,"black box variational inference with a deterministic objective: faster,   more accurate, and even more black box",cs.lg stat.me stat.ml,"automatic differentiation variational inference (advi) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. however, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. moreover, advi inherits the poor posterior uncertainty estimates of mean-field variational bayes (mfvb). we introduce ``deterministic advi'' (dadvi) to address these issues. dadvi replaces the intractable mfvb objective with a fixed monte carlo approximation, a technique known in the stochastic optimization literature as the ``sample average approximation'' (saa). by optimizing an approximate but deterministic objective, dadvi can use off-the-shelf second-order optimization, and, unlike standard mean-field advi, is amenable to more accurate posterior linear response (lr) covariance estimates. in contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, dadvi and the saa can perform well with relatively few samples even in very high dimensions, though we also show that such favorable results cannot extend to variational approximations that are too expressive relative to mean-field advi. we show on a variety of real-world problems that dadvi reliably finds good solutions with default settings (unlike advi) and, together with lr covariances, is typically faster and more accurate than standard advi.",,2023-04-11,,"['ryan giordano', 'martin ingram', 'tamara broderick']",https://arxiv.org/pdf/2304.05527.pdf
833,2304.05542,clclsa: cross-omics linked embedding with contrastive learning and self   attention for multi-omics integration with incomplete multi-omics data,cs.lg cs.ai q-bio.gn,"integration of heterogeneous and high-dimensional multi-omics data is becoming increasingly important in understanding genetic data. each omics technique only provides a limited view of the underlying biological process and integrating heterogeneous omics layers simultaneously would lead to a more comprehensive and detailed understanding of diseases and phenotypes. however, one obstacle faced when performing multi-omics data integration is the existence of unpaired multi-omics data due to instrument sensitivity and cost. studies may fail if certain aspects of the subjects are missing or incomplete. in this paper, we propose a deep learning method for multi-omics integration with incomplete data by cross-omics linked unified embedding with contrastive learning and self attention (clclsa). utilizing complete multi-omics data as supervision, the model employs cross-omics autoencoders to learn the feature representation across different types of biological data. the multi-omics contrastive learning, which is used to maximize the mutual information between different types of omics, is employed before latent feature concatenation. in addition, the feature-level self-attention and omics-level self-attention are employed to dynamically identify the most informative features for multi-omics data integration. extensive experiments were conducted on four public multi-omics datasets. the experimental results indicated that the proposed clclsa outperformed the state-of-the-art approaches for multi-omics data classification using incomplete multi-omics data.",,2023-04-11,,"['chen zhao', 'anqi liu', 'xiao zhang', 'xuewei cao', 'zhengming ding', 'qiuying sha', 'hui shen', 'hong-wen deng', 'weihua zhou']",https://arxiv.org/pdf/2304.05542.pdf
834,2304.05547,taxonomic class incremental learning,cs.lg cs.cv,"the problem of continual learning has attracted rising attention in recent years. however, few works have questioned the commonly used learning setup, based on a task curriculum of random class. this differs significantly from human continual learning, which is guided by taxonomic curricula. in this work, we propose the taxonomic class incremental learning (tcil) problem. in tcil, the task sequence is organized based on a taxonomic class tree. we unify existing approaches to cil and taxonomic learning as parameter inheritance schemes and introduce a new such scheme for the tcil learning. this enables the incremental transfer of knowledge from ancestor to descendant class of a class taxonomy through parameter inheritance. experiments on cifar-100 and imagenet-100 show the effectiveness of the proposed tcil method, which outperforms existing sota methods by 2% in terms of final accuracy on cifar-100 and 3% on imagenet-100.",,2023-04-11,,"['yuzhao chen', 'zonghuan li', 'zhiyuan hu', 'nuno vasconcelos']",https://arxiv.org/pdf/2304.05547.pdf
835,2304.05548,distilling token-pruned pose transformer for 2d human pose estimation,cs.cv,"human pose estimation has seen widespread use of transformer models in recent years. pose transformers benefit from the self-attention map, which captures the correlation between human joint tokens and the image. however, training such models is computationally expensive. the recent token-pruned pose transformer (ppt) solves this problem by pruning the background tokens of the image, which are usually less informative. however, although it improves efficiency, ppt inevitably leads to worse performance than tokenpose due to the pruning of tokens. to overcome this problem, we present a novel method called distilling pruned-token transformer for human pose estimation (dppt). our method leverages the output of a pre-trained tokenpose to supervise the learning process of ppt. we also establish connections between the internal structure of pose transformers and ppt, such as attention maps and joint features. our experimental results on the mpii datasets show that our dppt can significantly improve pck compared to previous ppt models while still reducing computational complexity.",,2023-04-11,,['feixiang ren'],https://arxiv.org/pdf/2304.05548.pdf
836,2304.05552,dynamicdet: a unified dynamic architecture for object detection,cs.cv cs.ai,"dynamic neural network is an emerging research topic in deep learning. with adaptive inference, dynamic models can achieve remarkable accuracy and computational efficiency. however, it is challenging to design a powerful dynamic detector, because of no suitable dynamic architecture and exiting criterion for object detection. to tackle these difficulties, we propose a dynamic framework for object detection, named dynamicdet. firstly, we carefully design a dynamic architecture based on the nature of the object detection task. then, we propose an adaptive router to analyze the multi-scale information and to decide the inference route automatically. we also present a novel optimization strategy with an exiting criterion based on the detection losses for our dynamic detectors. last, we present a variable-speed inference strategy, which helps to realize a wide range of accuracy-speed trade-offs with only one dynamic detector. extensive experiments conducted on the coco benchmark demonstrate that the proposed dynamicdet achieves new state-of-the-art accuracy-speed trade-offs. for instance, with comparable accuracy, the inference speed of our dynamic detector dy-yolov7-w6 surpasses yolov7-e6 by 12%, yolov7-d6 by 17%, and yolov7-e6e by 39%. the code is available at https://github.com/vdigpku/dynamicdet.",,2023-04-11,,"['zhihao lin', 'yongtao wang', 'jinhe zhang', 'xiaojie chu']",https://arxiv.org/pdf/2304.05552.pdf
837,2304.05554,learning transferable pedestrian representation from multimodal   information supervision,cs.cv cs.ai,"recent researches on unsupervised person re-identification~(reid) have demonstrated that pre-training on unlabeled person images achieves superior performance on downstream reid tasks than pre-training on imagenet. however, those pre-trained methods are specifically designed for reid and suffer flexible adaption to other pedestrian analysis tasks. in this paper, we propose val-pat, a novel framework that learns transferable representations to enhance various pedestrian analysis tasks with multimodal information. to train our framework, we introduce three learning objectives, \emph{i.e.,} self-supervised contrastive learning, image-text contrastive learning and multi-attribute classification. the self-supervised contrastive learning facilitates the learning of the intrinsic pedestrian properties, while the image-text contrastive learning guides the model to focus on the appearance information of pedestrians.meanwhile, multi-attribute classification encourages the model to recognize attributes to excavate fine-grained pedestrian information. we first perform pre-training on luperson-ta dataset, where each image contains text and attribute annotations, and then transfer the learned representations to various downstream tasks, including person reid, person attribute recognition and text-based person search. extensive experiments demonstrate that our framework facilitates the learning of general pedestrian representations and thus leads to promising results on various pedestrian analysis tasks.",,2023-04-11,,"['liping bao', 'longhui wei', 'xiaoyu qiu', 'wengang zhou', 'houqiang li', 'qi tian']",https://arxiv.org/pdf/2304.05554.pdf
838,2304.05556,an end-to-end network for upright adjustment of panoramic images,cs.cv,"nowadays, panoramic images can be easily obtained by panoramic cameras. however, when the panoramic camera orientation is tilted, a non-upright panoramic image will be captured. existing upright adjustment models focus on how to estimate more accurate camera orientation, and attribute image reconstruction to offline or post-processing tasks. to this end, we propose an online end-to-end network for upright adjustment. our network is designed to reconstruct the image while finding the angle. our network consists of three modules: orientation estimation, lut online generation, and upright reconstruction. direction estimation estimates the tilt angle of the panoramic image. then, a converter block with upsampling function is designed to generate angle to lut. this module can output corresponding online lut for different input angles. finally, a lightweight generative adversarial network (gan) aims to generate upright images from shallow features. the experimental results show that in terms of angles, we have improved the accuracy of small angle errors. in terms of image reconstruction, in image reconstruction, we have achieved the first real-time online upright reconstruction of panoramic images using deep learning networks.",,2023-04-11,,"['heyu chen', 'jianfeng li', 'shigang li']",https://arxiv.org/pdf/2304.05556.pdf
839,2304.05564,neural invertible variable-degree optical aberrations correction,cs.cv eess.iv,"optical aberrations of optical systems cause significant degradation of imaging quality. aberration correction by sophisticated lens designs and special glass materials generally incurs high cost of manufacturing and the increase in the weight of optical systems, thus recent work has shifted to aberration correction with deep learning-based post-processing. though real-world optical aberrations vary in degree, existing methods cannot eliminate variable-degree aberrations well, especially for the severe degrees of degradation. also, previous methods use a single feed-forward neural network and suffer from information loss in the output. to address the issues, we propose a novel aberration correction method with an invertible architecture by leveraging its information-lossless property. within the architecture, we develop conditional invertible blocks to allow the processing of aberrations with variable degrees. our method is evaluated on both a synthetic dataset from physics-based imaging simulation and a real captured dataset. quantitative and qualitative experimental results demonstrate that our method outperforms compared methods in correcting variable-degree optical aberrations.",10.1364/oe.485258,2023-04-11,,"['shuang cui', 'bingnan wang', 'quan zheng']",https://arxiv.org/pdf/2304.05564.pdf
840,2304.05565,a predictive model using machine learning algorithm in identifying   students probability on passing semestral course,cs.lg cs.cv cs.cy,"this study aims to determine a predictive model to learn students probability to pass their courses taken at the earliest stage of the semester. to successfully discover a good predictive model with high acceptability, accurate, and precision rate which delivers a useful outcome for decision making in education systems, in improving the processes of conveying knowledge and uplifting students academic performance, the proponent applies and strictly followed the crisp-dm (cross-industry standard process for data mining) methodology. this study employs classification for data mining techniques, and decision tree for algorithm. with the utilization of the newly discovered predictive model, the prediction of students probabilities to pass the current courses they take gives 0.7619 accuracy, 0.8333 precision, 0.8823 recall, and 0.8571 f1 score, which shows that the model used in the prediction is reliable, accurate, and recommendable. considering the indicators and the results, it can be noted that the prediction model used in this study is highly acceptable. the data mining techniques provides effective and efficient innovative tools in analyzing and predicting student performances. the model used in this study will greatly affect the way educators understand and identify the weakness of their students in the class, the way they improved the effectiveness of their learning processes gearing to their students, bring down academic failure rates, and help institution administrators modify their learning system outcomes. further study for the inclusion of some students demographic information, vast amount of data within the dataset, automated and manual process of predictive criteria indicators where the students can regulate to which criteria, they must improve more for them to pass their courses taken at the end of the semester as early as midterm period are highly needed.",10.25147/ijcsr.2017.001.1.135,2023-04-11,,['anabella c. doctor'],https://arxiv.org/pdf/2304.05565.pdf
841,2304.05571,sgl: structure guidance learning for camera localization,cs.cv,"camera localization is a classical computer vision task that serves various artificial intelligence and robotics applications. with the rapid developments of deep neural networks (dnns), end-to-end visual localization methods are prosperous in recent years. in this work, we focus on the scene coordinate prediction ones and propose a network architecture named as structure guidance learning (sgl) which utilizes the receptive branch and the structure branch to extract both high-level and low-level features to estimate the 3d coordinates. we design a confidence strategy to refine and filter the predicted 3d observations, which enables us to estimate the camera poses by employing the perspective-n-point (pnp) with ransac. in the training part, we design the bundle adjustment trainer to help the network fit the scenes better. comparisons with some state-of-the-art (sota) methods and sufficient ablation experiments confirm the validity of our proposed architecture.",,2023-04-11,,"['xudong zhang', 'shuang gao', 'xiaohu nan', 'haikuan ning', 'yuchen yang', 'yishan ping', 'jixiang wan', 'shuzhou dong', 'jijunnan li', 'yandong guo']",https://arxiv.org/pdf/2304.05571.pdf
842,2304.05578,does informativeness matter? active learning for educational dialogue   act classification,cs.cl cs.ai cs.lg,"dialogue acts (das) can be used to explain what expert tutors do and what students know during the tutoring process. most empirical studies adopt the random sampling method to obtain sentence samples for manual annotation of das, which are then used to train da classifiers. however, these studies have paid little attention to sample informativeness, which can reflect the information quantity of the selected samples and inform the extent to which a classifier can learn patterns. notably, the informativeness level may vary among the samples and the classifier might only need a small amount of low informative samples to learn the patterns. random sampling may overlook sample informativeness, which consumes human labelling costs and contributes less to training the classifiers. as an alternative, researchers suggest employing statistical sampling methods of active learning (al) to identify the informative samples for training the classifiers. however, the use of al methods in educational da classification tasks is under-explored. in this paper, we examine the informativeness of annotated sentence samples. then, the study investigates how the al methods can select informative samples to support da classifiers in the al sampling process. the results reveal that most annotated sentences present low informativeness in the training dataset and the patterns of these sentences can be easily captured by the da classifier. we also demonstrate how al methods can reduce the cost of manual annotation in the al sampling process.",,2023-04-11,,"['wei tan', 'jionghao lin', 'david lang', 'guanliang chen', 'dragan gasevic', 'lan du', 'wray buntine']",https://arxiv.org/pdf/2304.05578.pdf
843,2304.05590,zero-knowledge proof-based practical federated learning on blockchain,cs.cr,"since the concern of privacy leakage extremely discourages user participation in sharing data, federated learning has gradually become a promising technique for both academia and industry for achieving collaborative learning without leaking information about the local data. unfortunately, most federated learning solutions cannot efficiently verify the execution of each participant's local machine learning model and protect the privacy of user data, simultaneously. in this article, we first propose a zero-knowledge proof-based federated learning (zkp-fl) scheme on blockchain. it leverages zero-knowledge proof for both the computation of local data and the aggregation of local model parameters, aiming to verify the computation process without requiring the plaintext of the local data. we further propose a practical zkp-fl (pzkp-fl) scheme to support fraction and non-linear operations. specifically, we explore a fraction-integer mapping function, and use taylor expansion to efficiently handle non-linear operations while maintaining the accuracy of the federated learning model. we also analyze the security of pzkp-fl. performance analysis demonstrates that the whole running time of the pzkp-fl scheme is approximately less than one minute in parallel execution.",,2023-04-11,,"['zhibo xing', 'zijian zhang', 'meng li', 'jiamou liu', 'liehuang zhu', 'giovanni russello', 'muhammad rizwan asghar']",https://arxiv.org/pdf/2304.05590.pdf
844,2304.05592,learned multiphysics inversion with differentiable programming and   machine learning,cs.ms cs.dc cs.lg physics.comp-ph physics.geo-ph,"we present the seismic laboratory for imaging and modeling/monitoring (slim) open-source software framework for computational geophysics and, more generally, inverse problems involving the wave-equation (e.g., seismic and medical ultrasound), regularization with learned priors, and learned neural surrogates for multiphase flow simulations. by integrating multiple layers of abstraction, our software is designed to be both readable and scalable. this allows researchers to easily formulate their problems in an abstract fashion while exploiting the latest developments in high-performance computing. we illustrate and demonstrate our design principles and their benefits by means of building a scalable prototype for permeability inversion from time-lapse crosswell seismic data, which aside from coupling of wave physics and multiphase flow, involves machine learning.",,2023-04-11,,"['mathias louboutin', 'ziyi yin', 'rafael orozco', 'thomas j. grady', 'ali siahkoohi', 'gabrio rizzuti', 'philipp a. witte', 'olav m√∏yner', 'gerard j. gorman', 'felix j. herrmann']",https://arxiv.org/pdf/2304.05592.pdf
845,2304.05600,"looking similar, sounding different: leveraging counterfactual   cross-modal pairs for audiovisual representation learning",cs.sd cs.cv cs.lg cs.mm eess.as,"audiovisual representation learning typically relies on the correspondence between sight and sound. however, there are often multiple audio tracks that can correspond with a visual scene. consider, for example, different conversations on the same crowded street. the effect of such counterfactual pairs on audiovisual representation learning has not been previously explored. to investigate this, we use dubbed versions of movies to augment cross-modal contrastive learning. our approach learns to represent alternate audio tracks, differing only in speech content, similarly to the same video. our results show that dub-augmented training improves performance on a range of auditory and audiovisual tasks, without significantly affecting linguistic task performance overall. we additionally compare this approach to a strong baseline where we remove speech before pretraining, and find that dub-augmented training is more effective, including for paralinguistic and audiovisual tasks where speech removal leads to worse performance. these findings highlight the importance of considering speech variation when learning scene-level audiovisual correspondences and suggest that dubbed audio can be a useful augmentation technique for training audiovisual models toward more robust performance.",,2023-04-12,,"['nikhil singh', 'chih-wei wu', 'iroro orife', 'mahdi kalayeh']",https://arxiv.org/pdf/2304.05600.pdf
846,2304.05613,chatgpt beyond english: towards a comprehensive evaluation of large   language models in multilingual learning,cs.cl cs.ai,"over the last few years, large language models (llms) have emerged as the most important breakthroughs in natural language processing (nlp) that fundamentally transform research and developments in the field. chatgpt represents one of the most exciting llm systems developed recently to showcase impressive skills for language generation and highly attract public attention. among various exciting applications discovered for chatgpt in english, the model can process and generate texts for multiple languages due to its multilingual training data. given the broad adoption of chatgpt for english in different problems and areas, a natural question is whether chatgpt can also be applied effectively for other languages or it is necessary to develop more language-specific technologies. the answer to this question requires a thorough evaluation of chatgpt over multiple tasks with diverse languages and large datasets (i.e., beyond reported anecdotes), which is still missing or limited in current research. our work aims to fill this gap for the evaluation of chatgpt and similar llms to provide more comprehensive information for multilingual nlp applications. while this work will be an ongoing effort to include additional experiments in the future, our current paper evaluates chatgpt on 7 different tasks, covering 37 diverse languages with high, medium, low, and extremely low resources. we also focus on the zero-shot learning setting for chatgpt to improve reproducibility and better simulate the interactions of general users. compared to the performance of previous models, our extensive experimental results demonstrate a worse performance of chatgpt for different nlp tasks and languages, calling for further research to develop better models and understanding for multilingual learning.",,2023-04-12,,"['viet dac lai', 'nghia trung ngo', 'amir pouran ben veyseh', 'hieu man', 'franck dernoncourt', 'trung bui', 'thien huu nguyen']",https://arxiv.org/pdf/2304.05613.pdf
847,2304.05615,deep stable multi-interest learning for out-of-distribution sequential   recommendation,cs.ir cs.ai,"recently, multi-interest models, which extract interests of a user as multiple representation vectors, have shown promising performances for sequential recommendation. however, none of existing multi-interest recommendation models consider the out-of-distribution (ood) generalization problem, in which interest distribution may change. considering multiple interests of a user are usually highly correlated, the model has chance to learn spurious correlations between noisy interests and target items. once the data distribution changes, the correlations among interests may also change, and the spurious correlations will mislead the model to make wrong predictions. to tackle with above ood generalization problem, we propose a novel multi-interest network, named deep stable multi-interest learning (desmil), which attempts to de-correlate the extracted interests in the model, and thus spurious correlations can be eliminated. desmil applies an attentive module to extract multiple interests, and then selects the most important one for making final predictions. meanwhile, desmil incorporates a weighted correlation estimation loss based on hilbert-schmidt independence criterion (hsic), with which training samples are weighted, to minimize the correlations among extracted interests. extensive experiments have been conducted under both ood and random settings, and up to 36.8% and 21.7% relative improvements are achieved respectively.",,2023-04-12,,"['qiang liu', 'zhaocheng liu', 'zhenxi zhu', 'shu wu', 'liang wang']",https://arxiv.org/pdf/2304.05615.pdf
848,2304.05619,nutritionverse-3d: a 3d food model dataset for nutritional intake   estimation,cs.cv,"77% of adults over 50 want to age in place today, presenting a major challenge to ensuring adequate nutritional intake. it has been reported that one in four older adults that are 65 years or older are malnourished and given the direct link between malnutrition and decreased quality of life, there have been numerous studies conducted on how to efficiently track nutritional intake of food. recent advancements in machine learning and computer vision show promise of automated nutrition tracking methods of food, but require a large high-quality dataset in order to accurately identify the nutrients from the food on the plate. unlike existing datasets, a collection of 3d models with nutritional information allow for view synthesis to create an infinite number of 2d images for any given viewpoint/camera angle along with the associated nutritional information. in this paper, we develop a methodology for collecting high-quality 3d models for food items with a particular focus on speed and consistency, and introduce nutritionverse-3d, a large-scale high-quality high-resolution dataset of 105 3d food models, in conjunction with their associated weight, food name, and nutritional value. these models allow for large quantity food intake scenes, diverse and customizable scene layout, and an infinite number of camera settings and lighting conditions. nutritionverse-3d is publicly available as a part of an open initiative to accelerate machine learning for nutrition sensing.",,2023-04-12,,"['chi-en amy tai', 'matthew keller', 'mattie kerrigan', 'yuhao chen', 'saeejith nair', 'pengcheng xi', 'alexander wong']",https://arxiv.org/pdf/2304.05619.pdf
849,2304.05623,a multi-institutional open-source benchmark dataset for breast cancer   clinical decision support using synthetic correlated diffusion imaging data,eess.iv cs.cv q-bio.qm,"recently, a new form of magnetic resonance imaging (mri) called synthetic correlated diffusion (cdi$^s$) imaging was introduced and showed considerable promise for clinical decision support for cancers such as prostate cancer when compared to current gold-standard mri techniques. however, the efficacy for cdi$^s$ for other forms of cancers such as breast cancer has not been as well-explored nor have cdi$^s$ data been previously made publicly available. motivated to advance efforts in the development of computer-aided clinical decision support for breast cancer using cdi$^s$, we introduce cancer-net bca, a multi-institutional open-source benchmark dataset of volumetric cdi$^s$ imaging data of breast cancer patients. cancer-net bca contains cdi$^s$ volumetric images from a pre-treatment cohort of 253 patients across ten institutions, along with detailed annotation metadata (the lesion type, genetic subtype, longest diameter on the mri (mrld), the scarff-bloom-richardson (sbr) grade, and the post-treatment breast cancer pathologic complete response (pcr) to neoadjuvant chemotherapy). we further examine the demographic and tumour diversity of the cancer-net bca dataset to gain deeper insights into potential biases. cancer-net bca is publicly available as a part of a global open-source initiative dedicated to accelerating advancement in machine learning to aid clinicians in the fight against cancer.",,2023-04-12,,"['chi-en amy tai', 'hayden gunraj', 'alexander wong']",https://arxiv.org/pdf/2304.05623.pdf
850,2304.05632,multi-agent policy reciprocity with theoretical guarantee,cs.ai cs.lg,"modern multi-agent reinforcement learning (rl) algorithms hold great potential for solving a variety of real-world problems. however, they do not fully exploit cross-agent knowledge to reduce sample complexity and improve performance. although transfer rl supports knowledge sharing, it is hyperparameter sensitive and complex. to solve this problem, we propose a novel multi-agent policy reciprocity (pr) framework, where each agent can fully exploit cross-agent policies even in mismatched states. we then define an adjacency space for mismatched states and design a plug-and-play module for value iteration, which enables agents to infer more precise returns. to improve the scalability of pr, deep pr is proposed for continuous control tasks. moreover, theoretical analysis shows that agents can asymptotically reach consensus through individual perceived rewards and converge to an optimal value function, which implies the stability and effectiveness of pr, respectively. experimental results on discrete and continuous environments demonstrate that pr outperforms various existing rl and transfer rl methods.",,2023-04-12,,"['haozhi wang', 'yinchuan li', 'qing wang', 'yunfeng shao', 'jianye hao']",https://arxiv.org/pdf/2304.05632.pdf
851,2304.05635,unifying and personalizing weakly-supervised federated medical image   segmentation via adaptive representation and aggregation,eess.iv cs.cv,"federated learning (fl) enables multiple sites to collaboratively train powerful deep models without compromising data privacy and security. the statistical heterogeneity (e.g., non-iid data and domain shifts) is a primary obstacle in fl, impairing the generalization performance of the global model. weakly supervised segmentation, which uses sparsely-grained (i.e., point-, bounding box-, scribble-, block-wise) supervision, is increasingly being paid attention to due to its great potential of reducing annotation costs. however, there may exist label heterogeneity, i.e., different annotation forms across sites. in this paper, we propose a novel personalized fl framework for medical image segmentation, named fedicra, which uniformly leverages heterogeneous weak supervision via adaptive contrastive representation and aggregation. concretely, to facilitate personalized modeling and to avoid confusion, a channel selection based site contrastive representation module is employed to adaptively cluster intra-site embeddings and separate inter-site ones. to effectively integrate the common knowledge from the global model with the unique knowledge from each local model, an adaptive aggregation module is applied for updating and initializing local models at the element level. additionally, a weakly supervised objective function that leverages a multiscale tree energy loss and a gated crf loss is employed to generate more precise pseudo-labels and further boost the segmentation performance. through extensive experiments on two distinct medical image segmentation tasks of different modalities, the proposed fedicra demonstrates overwhelming performance over other state-of-the-art personalized fl methods. its performance even approaches that of fully supervised training on centralized data. our code and data are available at https://github.com/llmir/fedicra.",,2023-04-12,,"['li lin', 'jiewei wu', 'yixiang liu', 'kenneth k. y. wong', 'xiaoying tang']",https://arxiv.org/pdf/2304.05635.pdf
852,2304.05637,dosm: demand-prediction based online service management for vehicular   edge computing networks,cs.ni,"in this work, we investigate an online service management problem in vehicular edge computing networks. to satisfy the varying service demands of mobile vehicles, a service management framework is required to make decisions on the service lifecycle to maintain good network performance. we describe the service lifecycle consists of creating an instance of a given service (\textit{scale-out}), moving an instance to a different edge node (\textit{migration}), and/or termination of an underutilized instance (\textit{scale-in}). in this paper, we propose an efficient online algorithm to perform service management in each time slot, where performance quality in the current time slot, the service demand in future time slots, and the minimal observed delay by vehicles and the minimal migration delay are considered while making the decisions on service lifecycle. here, the future service demand is computed from a gated recurrent unit (gru)-based prediction model, and the network performance quality is estimated using a deep reinforcement learning (drl) model which has the ability to interact with the vehicular environment in real-time. the choice of optimal edge location to deploy a service instance at different times is based on our proposed optimization formulations. simulation experiments using real-world vehicle trajectories are carried out to evaluate the performance of our proposed demand-prediction based online service management (dosm) framework against different state-of-the-art solutions using several performance metrics.",,2023-04-12,,"['anum talpur', 'mohan gurusamy']",https://arxiv.org/pdf/2304.05637.pdf
853,2304.05638,self optimisation and automatic code generation by evolutionary   algorithms in plc based controlling processes,cs.ne cs.lg,"the digital transformation of automation places new demands on data acquisition and processing in industrial processes. logical relationships between acquired data and cyclic process sequences must be correctly interpreted and evaluated. to solve this problem, a novel approach based on evolutionary algorithms is proposed to self optimise the system logic of complex processes. based on the genetic results, a programme code for the system implementation is derived by decoding the solution. this is achieved by a flexible system structure with an upstream, intermediate and downstream unit. in the intermediate unit, a directed learning process interacts with a system replica and an evaluation function in a closed loop. the code generation strategy is represented by redundancy and priority, sequencing and performance derivation. the presented approach is evaluated on an industrial liquid station process subject to a multi-objective optimisation problem.",,2023-04-12,,"['marlon l√∂ppenberg', 'andreas schwung']",https://arxiv.org/pdf/2304.05638.pdf
854,2304.05640,instance-aware domain generalization for face anti-spoofing,cs.cv,"face anti-spoofing (fas) based on domain generalization (dg) has been recently studied to improve the generalization on unseen scenarios. previous methods typically rely on domain labels to align the distribution of each domain for learning domain-invariant representations. however, artificial domain labels are coarse-grained and subjective, which cannot reflect real domain distributions accurately. besides, such domain-aware methods focus on domain-level alignment, which is not fine-grained enough to ensure that learned representations are insensitive to domain styles. to address these issues, we propose a novel perspective for dg fas that aligns features on the instance level without the need for domain labels. specifically, instance-aware domain generalization framework is proposed to learn the generalizable feature by weakening the features' sensitivity to instance-specific styles. concretely, we propose asymmetric instance adaptive whitening to adaptively eliminate the style-sensitive feature correlation, boosting the generalization. moreover, dynamic kernel generator and categorical style assembly are proposed to first extract the instance-specific features and then generate the style-diversified features with large style shifts, respectively, further facilitating the learning of style-insensitive features. extensive experiments and analysis demonstrate the superiority of our method over state-of-the-art competitors. code will be publicly available at https://github.com/qianyuzqy/iadg.",,2023-04-12,,"['qianyu zhou', 'ke-yue zhang', 'taiping yao', 'xuequan lu', 'ran yi', 'shouhong ding', 'lizhuang ma']",https://arxiv.org/pdf/2304.05640.pdf
855,2304.05644,generative adversarial networks-driven cyber threat intelligence   detection framework for securing internet of things,cs.cr,"while the benefits of 6g-enabled internet of things (iot) are numerous, providing high-speed, low-latency communication that brings new opportunities for innovation and forms the foundation for continued growth in the iot industry, it is also important to consider the security challenges and risks associated with the technology. in this paper, we propose a two-stage intrusion detection framework for securing iots, which is based on two detectors. in the first stage, we propose an adversarial training approach using generative adversarial networks (gan) to help the first detector train on robust features by supplying it with adversarial examples as validation sets. consequently, the classifier would perform very well against adversarial attacks. then, we propose a deep learning (dl) model for the second detector to identify intrusions. we evaluated the proposed approach's efficiency in terms of detection accuracy and robustness against adversarial attacks. experiment results with a new cyber security dataset demonstrate the effectiveness of the proposed methodology in detecting both intrusions and persistent adversarial examples with a weighted avg of 96%, 95%, 95%, and 95% for precision, recall, f1-score, and accuracy, respectively.",,2023-04-12,,"['mohamed amine ferrag', 'djallel hamouda', 'merouane debbah', 'leandros maglaras', 'abderrahmane lakas']",https://arxiv.org/pdf/2304.05644.pdf
856,2304.05653,clip surgery for better explainability with enhancement in   open-vocabulary tasks,cs.cv,"contrastive language-image pre-training (clip) is a powerful multimodal large vision model that has demonstrated significant benefits for downstream tasks, including many zero-shot learning and text-guided vision tasks. however, we notice some severe problems regarding the model's explainability, which undermines its credibility and impedes related tasks. specifically, we find clip prefers the background regions than the foregrounds according to the predicted similarity map, which contradicts human understanding. besides, there are obvious noisy activations on the visualization results at irrelevant positions. to address these two issues, we conduct in-depth analyses and reveal the reasons with new findings and evidences. based on these insights, we propose the clip surgery, a method that enables surgery-like modifications for the inference architecture and features, for better explainability and enhancement in multiple open-vocabulary tasks. the proposed method has significantly improved the explainability of clip for both convolutional networks and vision transformers, surpassing existing methods by large margins. besides, our approach also demonstrates remarkable improvements in open-vocabulary segmentation and multi-label recognition tasks. for examples, the map improvement on nus-wide multi-label recognition is 4.41% without any additional training, and our clip surgery surpasses the state-of-the-art method by 8.74% at miou on cityscapes open-vocabulary semantic segmentation. furthermore, our method benefits other tasks including multimodal visualization and interactive segmentation like segment anything model (sam). the code is available at https://github.com/xmed-lab/clip_surgery",,2023-04-12,,"['yi li', 'hualiang wang', 'yiqun duan', 'xiaomeng li']",https://arxiv.org/pdf/2304.05653.pdf
857,2304.05655,localisation of regularised and multiview support vector machine   learning,math.fa cs.lg,"we prove a few representer theorems for a localised version of the regularised and multiview support vector machine learning problem introduced by h.q.~minh, l.~bazzani, and v.~murino, \textit{journal of machine learning research}, \textbf{17}(2016) 1--72, that involves operator valued positive semidefinite kernels and their reproducing kernel hilbert spaces. the results concern general cases when convex or nonconvex loss functions and finite or infinite dimensional input spaces are considered. we show that the general framework allows infinite dimensional input spaces and nonconvex loss functions for some special cases, in particular in case the loss functions are g\^ateaux differentiable. detailed calculations are provided for the exponential least squares loss functions that leads to partially nonlinear problems.",,2023-04-12,,"['aurelian gheondea', 'cankat tilki']",https://arxiv.org/pdf/2304.05655.pdf
858,2304.05659,riformer: keep your vision backbone effective while removing token mixer,cs.cv cs.ai,"this paper studies how to keep a vision backbone effective while removing token mixers in its basic building blocks. token mixers, as self-attention for vision transformers (vits), are intended to perform information communication between different spatial tokens but suffer from considerable computational cost and latency. however, directly removing them will lead to an incomplete model structure prior, and thus brings a significant accuracy drop. to this end, we first develop an repidentityformer base on the re-parameterizing idea, to study the token mixer free model architecture. and we then explore the improved learning paradigm to break the limitation of simple token mixer free backbone, and summarize the empirical practice into 5 guidelines. equipped with the proposed optimization strategy, we are able to build an extremely simple vision backbone with encouraging performance, while enjoying the high efficiency during inference. extensive experiments and ablative analysis also demonstrate that the inductive bias of network architecture, can be incorporated into simple network structure with appropriate optimization strategy. we hope this work can serve as a starting point for the exploration of optimization-driven efficient network design. project page: https://techmonsterwang.github.io/riformer/.",,2023-04-12,,"['jiahao wang', 'songyang zhang', 'yong liu', 'taiqiang wu', 'yujiu yang', 'xihui liu', 'kai chen', 'ping luo', 'dahua lin']",https://arxiv.org/pdf/2304.05659.pdf
859,2304.05673,precise localization of corneal reflections in eye images using deep   learning trained on synthetic data,cs.cv cs.ai,"we present a deep learning method for accurately localizing the center of a single corneal reflection (cr) in an eye image. unlike previous approaches, we use a convolutional neural network (cnn) that was trained solely using simulated data. using only simulated data has the benefit of completely sidestepping the time-consuming process of manual annotation that is required for supervised training on real eye images. to systematically evaluate the accuracy of our method, we first tested it on images with simulated crs placed on different backgrounds and embedded in varying levels of noise. second, we tested the method on high-quality videos captured from real eyes. our method outperformed state-of-the-art algorithmic methods on real eye images with a 35% reduction in terms of spatial precision, and performed on par with state-of-the-art on simulated images in terms of spatial accuracy.we conclude that our method provides a precise method for cr center localization and provides a solution to the data availability problem which is one of the important common roadblocks in the development of deep learning models for gaze estimation. due to the superior cr center localization and ease of application, our method has the potential to improve the accuracy and precision of cr-based eye trackers",,2023-04-12,,"['sean anthony byrne', 'marcus nystr√∂m', 'virmarie maquiling', 'enkelejda kasneci', 'diederick c. niehorster']",https://arxiv.org/pdf/2304.05673.pdf
860,2304.05678,real-time trajectory-based social group detection,cs.cv,"social group detection is a crucial aspect of various robotic applications, including robot navigation and human-robot interactions. to date, a range of model-based techniques have been employed to address this challenge, such as the f-formation and trajectory similarity frameworks. however, these approaches often fail to provide reliable results in crowded and dynamic scenarios. recent advancements in this area have mainly focused on learning-based methods, such as deep neural networks that use visual content or human pose. although visual content-based methods have demonstrated promising performance on large-scale datasets, their computational complexity poses a significant barrier to their practical use in real-time applications. to address these issues, we propose a simple and efficient framework for social group detection. our approach explores the impact of motion trajectory on social grouping and utilizes a novel, reliable, and fast data-driven method. we formulate the individuals in a scene as a graph, where the nodes are represented by lstm-encoded trajectories and the edges are defined by the distances between each pair of tracks. our framework employs a modified graph transformer module and graph clustering losses to detect social groups. our experiments on the popular jrdbact dataset reveal noticeable improvements in performance, with relative improvements ranging from 2% to 11%. furthermore, our framework is significantly faster, with up to 12x faster inference times compared to state-of-the-art methods under the same computation resources. these results demonstrate that our proposed method is suitable for real-time robotic applications.",,2023-04-12,,"['simindokht jahangard', 'munawar hayat', 'hamid rezatofighi']",https://arxiv.org/pdf/2304.05678.pdf
861,2304.05685,multisensor fusion-based digital twin in additive manufacturing for   in-situ quality monitoring and defect correction,eess.iv cs.sy eess.sp eess.sy,"early detection and correction of defects are critical in additive manufacturing (am) to avoid build failures. in this paper, we present a multisensor fusion-based digital twin for in-situ quality monitoring and defect correction in a robotic laser direct energy deposition process. multisensor fusion sources consist of an acoustic sensor, an infrared thermal camera, a coaxial vision camera, and a laser line scanner. the key novelty and contribution of this work are to develop a spatiotemporal data fusion method that synchronizes and registers the multisensor features within the part's 3d volume. the fused dataset can be used to predict location-specific quality using machine learning. on-the-fly identification of regions requiring material addition or removal is feasible. robot toolpath and auto-tuned process parameters are generated for defecting correction. in contrast to traditional single-sensor-based monitoring, multisensor fusion allows for a more in-depth understanding of underlying process physics, such as pore formation and laser-material interactions. the proposed methods pave the way for self-adaptation am with higher efficiency, less waste, and cleaner production.",,2023-04-12,,"['lequn chen', 'xiling yao', 'kui liu', 'chaolin tan', 'seung ki moon']",https://arxiv.org/pdf/2304.05685.pdf
862,2304.05691,vers: fully distributed coded computing system with distributed encoding,cs.dc,"coded computing has proved to be useful in distributed computing. we have observed that almost all coded computing systems studied so far consider a setup of one master and some workers. however, recently emerging technologies such as blockchain, internet of things, and federated learning introduce new requirements for coded computing systems. in these systems, data is generated in a distributed manner, so central encoding/decoding by a master is not feasible and scalable. this paper presents a fully distributed coded computing system that consists of $k\in\mathbb{n}$ data owners and $n\in\mathbb{n}$ workers, where data owners employ workers to do some computations on their data, as specified by a target function $f$ of degree $d\in\mathbb{n}$. as there is no central encoder, workers perform encoding themselves, prior to computation phase. the challenge in this system is the presence of adversarial data owners that do not know the data of honest data owners but cause discrepancies by sending different data to different workers, which is detrimental to local encodings in workers. there are at most $\beta\in\mathbb{n}$ adversarial data owners, and each sends at most $v\in\mathbb{n}$ different versions of data. since the adversaries and their possibly colluded behavior are not known to workers and honest data owners, workers compute tags of their received data, in addition to their main computational task, and send them to data owners to help them in decoding. we introduce a tag function that allows data owners to partition workers into sets that previously had received the same data from all data owners. then, we characterize the fundamental limit of the system, $t^*$, which is the minimum number of workers whose work can be used to correctly calculate the desired function of data of honest data owners. we show that $t^*=v^{\beta}d(k-1)+1$, and present converse and achievable proofs.",,2023-04-12,,"['nastaran abadi khooshemehr', 'mohammad ali maddah-ali']",https://arxiv.org/pdf/2304.05691.pdf
863,2304.05693,a persistent-excitation-free method for system disturbance estimation   using concurrent learning,eess.sy cs.sy,"observer-based methods are widely used to estimate the disturbances of different dynamic systems. however, a drawback of the conventional disturbance observers is that they all assume persistent excitation (pe) of the systems. as a result, they may lead to poor estimation precision when pe is not ensured, for instance, when the disturbance gain of the system is close to the singularity. in this paper, we propose a novel disturbance observer based on concurrent learning (cl) with time-variant history stacks, which ensures high estimation precision even in pe-free cases. the disturbance observer is designed in both continuous and discrete time. the estimation errors of the proposed method are proved to converge to a bounded set using the lyapunov method. a history-sample-selection procedure is proposed to reduce the estimation error caused by the accumulation of old history samples. a simulation study on epidemic control shows that the proposed method produces higher estimation precision than the conventional disturbance observer when pe is not satisfied. this justifies the correctness of the proposed cl-based disturbance observer and verifies its applicability to solving practical problems.",,2023-04-12,,"['zengjie zhang', 'fangzhou liu', 'tong liu', 'jianbin qiu', 'martin buss']",https://arxiv.org/pdf/2304.05693.pdf
864,2304.05703,human-robot skill transfer with enhanced compliance via dynamic movement   primitives,cs.ro cs.ai,"finding an efficient way to adapt robot trajectory is a priority to improve overall performance of robots. one approach for trajectory planning is through transferring human-like skills to robots by learning from demonstrations (lfd). the human demonstration is considered the target motion to mimic. however, human motion is typically optimal for human embodiment but not for robots because of the differences between human biomechanics and robot dynamics. the dynamic movement primitives (dmp) framework is a viable solution for this limitation of lfd, but it requires tuning the second-order dynamics in the formulation. our contribution is introducing a systematic method to extract the dynamic features from human demonstration to auto-tune the parameters in the dmp framework. in addition to its use with lfd, another utility of the proposed method is that it can readily be used in conjunction with reinforcement learning (rl) for robot training. in this way, the extracted features facilitate the transfer of human skills by allowing the robot to explore the possible trajectories more efficiently and increasing robot compliance significantly. we introduced a methodology to extract the dynamic features from multiple trajectories based on the optimization of human-likeness and similarity in the parametric space. our method was implemented into an actual human-robot setup to extract human dynamic features and used to regenerate the robot trajectories following both lfd and rl with dmp. it resulted in a stable performance of the robot, maintaining a high degree of human-likeness based on accumulated distance error as good as the best heuristic tuning.",,2023-04-12,,"['jayden hong', 'zengjie zhang', 'amir m. soufi enayati', 'homayoun najjaran']",https://arxiv.org/pdf/2304.05703.pdf
865,2304.05724,universal polarization transformations: spatial programming of   polarization scattering matrices using a deep learning-designed diffractive   polarization transformer,physics.optics cs.cv,"we demonstrate universal polarization transformers based on an engineered diffractive volume, which can synthesize a large set of arbitrarily-selected, complex-valued polarization scattering matrices between the polarization states at different positions within its input and output field-of-views (fovs). this framework comprises 2d arrays of linear polarizers with diverse angles, which are positioned between isotropic diffractive layers, each containing tens of thousands of diffractive features with optimizable transmission coefficients. we demonstrate that, after its deep learning-based training, this diffractive polarization transformer could successfully implement n_i x n_o = 10,000 different spatially-encoded polarization scattering matrices with negligible error within a single diffractive volume, where n_i and n_o represent the number of pixels in the input and output fovs, respectively. we experimentally validated this universal polarization transformation framework in the terahertz part of the spectrum by fabricating wire-grid polarizers and integrating them with 3d-printed diffractive layers to form a physical polarization transformer operating at 0.75 mm wavelength. through this set-up, we demonstrated an all-optical polarization permutation operation of spatially-varying polarization fields, and simultaneously implemented distinct spatially-encoded polarization scattering matrices between the input and output fovs of a compact diffractive processor that axially spans 200 wavelengths. this framework opens up new avenues for developing novel optical devices for universal polarization control, and may find various applications in, e.g., remote sensing, medical imaging, security, material inspection and machine vision.",,2023-04-12,,"['yuhang li', 'jingxi li', 'yifan zhao', 'tianyi gan', 'jingtian hu', 'mona jarrahi', 'aydogan ozcan']",https://arxiv.org/pdf/2304.05724.pdf
866,2304.05727,preemptively pruning clever-hans strategies in deep neural networks,cs.lg cs.ai cs.cv,"explainable ai has become a popular tool for validating machine learning models. mismatches between the explained model's decision strategy and the user's domain knowledge (e.g. clever hans effects) have also been recognized as a starting point for improving faulty models. however, it is less clear what to do when the user and the explanation agree. in this paper, we demonstrate that acceptance of explanations by the user is not a guarantee for a ml model to function well, in particular, some clever hans effects may remain undetected. such hidden flaws of the model can nevertheless be mitigated, and we demonstrate this by contributing a new method, explanation-guided exposure minimization (egem), that premptively prunes variations in the ml model that have not been the subject of positive explanation feedback. experiments on natural image data demonstrate that our approach leads to models that strongly reduce their reliance on hidden clever hans strategies, and consequently achieve higher accuracy on new data.",,2023-04-12,,"['lorenz linhardt', 'klaus-robert m√ºller', 'gr√©goire montavon']",https://arxiv.org/pdf/2304.05727.pdf
867,2304.05729,dynamic graph representation learning with neural networks: a survey,cs.lg,"in recent years, dynamic graph (dg) representations have been increasingly used for modeling dynamic systems due to their ability to integrate both topological and temporal information in a compact representation. dynamic graphs allow to efficiently handle applications such as social network prediction, recommender systems, traffic forecasting or electroencephalography analysis, that can not be adressed using standard numeric representations. as a direct consequence of the emergence of dynamic graph representations, dynamic graph learning has emerged as a new machine learning problem, combining challenges from both sequential/temporal data processing and static graph learning. in this research area, dynamic graph neural network (dgnn) has became the state of the art approach and plethora of models have been proposed in the very recent years. this paper aims at providing a review of problems and models related to dynamic graph learning. the various dynamic graph supervised learning settings are analysed and discussed. we identify the similarities and differences between existing models with respect to the way time information is modeled. finally, general guidelines for a dgnn designer when faced with a dynamic graph learning problem are provided.",,2023-04-12,,"['leshanshui yang', 's√©bastien adam', 'cl√©ment chatelain']",https://arxiv.org/pdf/2304.05729.pdf
868,2304.05734,few-shot class-incremental learning for cross-domain disease   classification,cs.cv cs.lg,"the ability to incrementally learn new classes from limited samples is crucial to the development of artificial intelligence systems for real clinical application. although existing incremental learning techniques have attempted to address this issue, they still struggle with only few labeled data, particularly when the samples are from varied domains. in this paper, we explore the cross-domain few-shot incremental learning (cdfscil) problem. cdfscil requires models to learn new classes from very few labeled samples incrementally, and the new classes may be vastly different from the target space. to counteract this difficulty, we propose a cross-domain enhancement constraint and cross-domain data augmentation method. experiments on medmnist show that the classification performance of this method is better than other similar incremental learning methods.",,2023-04-12,,"['hao yang', 'weijian huang', 'jiarun liu', 'cheng li', 'shanshan wang']",https://arxiv.org/pdf/2304.05734.pdf
869,2304.05754,self-supervised learning with cluster-aware-dino for high-performance   robust speaker verification,cs.sd eess.as,"automatic speaker verification task has made great achievements using deep learning approaches with the large-scale manually annotated dataset. however, it's very difficult and expensive to collect a large amount of well-labeled data for system building. in this paper, we propose a novel and advanced self-supervised learning framework which can construct a high performance speaker verification system without using any labeled data. to avoid the impact of false negative pairs, we adopt the self-distillation with no labels (dino) framework as the initial model, which can be trained without exploiting negative pairs. then, we introduce a cluster-aware training strategy for dino to improve the diversity of data. in the iteration learning stage, due to a mass of unreliable labels from clustering, the quality of pseudo labels is important for the system training. this motivates us to propose dynamic loss-gate and label correction (dlg-lc) methods to alleviate the performance degradation caused by unreliable labels. more specifically, we model the loss distribution with gmm and obtain the loss-gate threshold dynamically to distinguish the reliable and unreliable labels. besides, we adopt the model predictions to correct the unreliable label, for better utilizing the unreliable data rather than dropping them directly. moreover, we extend the dlg-lc to multi-modality to further improve the performance. the experiments are performed on the commonly used voxceleb dataset. compared to the best-known self-supervised speaker verification system, our proposed method obtain 22.17%, 27.94% and 25.56% relative eer improvement on vox-o, vox-e and vox-h test sets, even with fewer iterations, smaller models, and simpler clustering methods. more importantly, the newly proposed system even achieves comparable results with the fully supervised system, but without using any human labeled data.",,2023-04-12,,"['bing han', 'zhengyang chen', 'yanmin qian']",https://arxiv.org/pdf/2304.05754.pdf
870,2304.05755,aladin-nst: self-supervised disentangled representation learning of   artistic style through neural style transfer,cs.cv,"representation learning aims to discover individual salient features of a domain in a compact and descriptive form that strongly identifies the unique characteristics of a given sample respective to its domain. existing works in visual style representation literature have tried to disentangle style from content during training explicitly. a complete separation between these has yet to be fully achieved. our paper aims to learn a representation of visual artistic style more strongly disentangled from the semantic content depicted in an image. we use neural style transfer (nst) to measure and drive the learning signal and achieve state-of-the-art representation learning on explicitly disentangled metrics. we show that strongly addressing the disentanglement of style and content leads to large gains in style-specific metrics, encoding far less semantic information and achieving state-of-the-art accuracy in downstream multimodal applications.",,2023-04-12,,"['dan ruta', 'gemma canet tarres', 'alex black', 'andrew gilbert', 'john collomosse']",https://arxiv.org/pdf/2304.05755.pdf
871,2304.05772,an image quality assessment dataset for portraits,cs.cv,"year after year, the demand for ever-better smartphone photos continues to grow, in particular in the domain of portrait photography. manufacturers thus use perceptual quality criteria throughout the development of smartphone cameras. this costly procedure can be partially replaced by automated learning-based methods for image quality assessment (iqa). due to its subjective nature, it is necessary to estimate and guarantee the consistency of the iqa process, a characteristic lacking in the mean opinion scores (mos) widely used for crowdsourcing iqa. in addition, existing blind iqa (biqa) datasets pay little attention to the difficulty of cross-content assessment, which may degrade the quality of annotations. this paper introduces piq23, a portrait-specific iqa dataset of 5116 images of 50 predefined scenarios acquired by 100 smartphones, covering a high variety of brands, models, and use cases. the dataset includes individuals of various genders and ethnicities who have given explicit and informed consent for their photographs to be used in public research. it is annotated by pairwise comparisons (pwc) collected from over 30 image quality experts for three image attributes: face detail preservation, face target exposure, and overall image quality. an in-depth statistical analysis of these annotations allows us to evaluate their consistency over piq23. finally, we show through an extensive comparison with existing baselines that semantic information (image context) can be used to improve iqa predictions. the dataset along with the proposed statistical analysis and biqa algorithms are available: https://github.com/dxomark-research/piq2023",,2023-04-12,,"['nicolas chahine', 'ana-stefania calarasanu', 'davide garcia-civiero', 'theo cayla', 'sira ferradans', 'jean ponce']",https://arxiv.org/pdf/2304.05772.pdf
872,2304.05822,data-driven response regime exploration and identification for dynamical   systems,eess.sy cs.ai cs.sy math.ds,"data-driven response regime exploration and identification (dr$^2$ei) is a novel and fully data-driven method for identifying and classifying response regimes of a dynamical system without requiring human intervention. this approach is a valuable tool for exploring and discovering response regimes in complex dynamical systems, especially when the governing equations and the number of response regimes are unknown, and the system is expensive to sample. additionally, the method is useful for order reduction, as it can be used to identify the most dominant response regimes of a given dynamical system. dr$^2$ei utilizes unsupervised learning algorithms to transform the system's response into an embedding space that facilitates regime classification. an active sequential sampling approach based on gaussian process regression (gpr) is used to efficiently sample the parameter space, quantify uncertainty, and provide optimal trade-offs between exploration and exploitation. the performance of the dr$^2$ei method was evaluated by analyzing three established dynamical systems: the mathematical pendulum, the lorenz system, and the duffing oscillator. the method was shown to effectively identify a variety of response regimes with both similar and distinct topological features and frequency content, demonstrating its versatility in capturing a wide range of behaviors. while it may not be possible to guarantee that all possible regimes will be identified, the method provides an automated and efficient means for exploring the parameter space of a dynamical system and identifying its underlying ""sufficiently dominant"" response regimes without prior knowledge of the system's equations or behavior.",,2023-04-06,,['maor farid'],https://arxiv.org/pdf/2304.05822.pdf
873,2304.05824,fedtrip: a resource-efficient federated learning method with triplet   regularization,cs.dc,"in the federated learning scenario, geographically distributed clients collaboratively train a global model. data heterogeneity among clients significantly results in inconsistent model updates, which evidently slow down model convergence. to alleviate this issue, many methods employ regularization terms to narrow the discrepancy between client-side local models and the server-side global model. however, these methods impose limitations on the ability to explore superior local models and ignore the valuable information in historical models. besides, although the up-to-date representation method simultaneously concerns the global and historical local models, it suffers from unbearable computation cost. to accelerate convergence with low resource consumption, we innovatively propose a model regularization method named fedtrip, which is designed to restrict global-local divergence and decrease current-historical correlation for alleviating the negative effects derived from data heterogeneity. fedtrip helps the current local model to be close to the global model while keeping away from historical local models, which contributes to guaranteeing the consistency of local updates among clients and efficiently exploring superior local models with negligible additional computation cost on attaching operations. empirically, we demonstrate the superiority of fedtrip via extensive evaluations. to achieve the target accuracy, fedtrip outperforms the state-of-the-art baselines in terms of significantly reducing the total overhead of client-server communication and local computation.",,2023-04-12,,"['xujing li', 'min liu', 'sheng sun', 'yuwei wang', 'hui jiang', 'xuefeng jiang']",https://arxiv.org/pdf/2304.05824.pdf
874,2304.05832,few shot semantic segmentation: a review of methodologies and open   challenges,cs.cv cs.ai,"semantic segmentation assigns category labels to each pixel in an image, enabling breakthroughs in fields such as autonomous driving and robotics. deep neural networks have achieved high accuracies in semantic segmentation but require large training datasets. some domains have difficulties building such datasets due to rarity, privacy concerns, and the need for skilled annotators. few-shot learning (fsl) has emerged as a new research stream that allows models to learn new tasks from a few samples. this contribution provides an overview of fsl in semantic segmentation (fss), proposes a new taxonomy, and describes current limitations and outlooks.",,2023-04-12,,"['nico catalano', 'matteo matteucci']",https://arxiv.org/pdf/2304.05832.pdf
875,2304.05836,a game-theoretic framework for federated learning,cs.lg cs.ai cs.cr cs.gt,"in federated learning, benign participants aim to optimize a global model collaboratively. however, the risk of \textit{privacy leakage} cannot be ignored in the presence of \textit{semi-honest} adversaries. existing research has focused either on designing protection mechanisms or on inventing attacking mechanisms. while the battle between defenders and attackers seems never-ending, we are concerned with one critical question: is it possible to prevent potential attacks in advance? to address this, we propose the first game-theoretic framework that considers both fl defenders and attackers in terms of their respective payoffs, which include computational costs, fl model utilities, and privacy leakage risks. we name this game the federated learning security game (flsg), in which neither defenders nor attackers are aware of all participants' payoffs.   to handle the \textit{incomplete information} inherent in this situation, we propose associating the flsg with an \textit{oracle} that has two primary responsibilities. first, the oracle provides lower and upper bounds of the payoffs for the players. second, the oracle acts as a correlation device, privately providing suggested actions to each player. with this novel framework, we analyze the optimal strategies of defenders and attackers. furthermore, we derive and demonstrate conditions under which the attacker, as a rational decision-maker, should always follow the oracle's suggestion \textit{not to attack}.",,2023-04-11,,"['xiaojin zhang', 'lixin fan', 'siwei wang', 'wenjie li', 'kai chen', 'qiang yang']",https://arxiv.org/pdf/2304.05836.pdf
876,2304.05839,optimal interpretability-performance trade-off of classification trees   with black-box reinforcement learning,cs.lg cs.ai,"interpretability of ai models allows for user safety checks to build trust in these models. in particular, decision trees (dts) provide a global view on the learned model and clearly outlines the role of the features that are critical to classify a given data. however, interpretability is hindered if the dt is too large. to learn compact trees, a reinforcement learning (rl) framework has been recently proposed to explore the space of dts. a given supervised classification task is modeled as a markov decision problem (mdp) and then augmented with additional actions that gather information about the features, equivalent to building a dt. by appropriately penalizing these actions, the rl agent learns to optimally trade-off size and performance of a dt. however, to do so, this rl agent has to solve a partially observable mdp. the main contribution of this paper is to prove that it is sufficient to solve a fully observable problem to learn a dt optimizing the interpretability-performance trade-off. as such any planning or rl algorithm can be used. we demonstrate the effectiveness of this approach on a set of classical supervised classification datasets and compare our approach with other interpretability-performance optimizing methods.",,2023-04-11,,"['hector kohler', 'riad akrour', 'philippe preux']",https://arxiv.org/pdf/2304.05839.pdf
877,2304.05845,rethinking dense retrieval's few-shot ability,cs.cl,"few-shot dense retrieval (dr) aims to effectively generalize to novel search scenarios by learning a few samples. despite its importance, there is little study on specialized datasets and standardized evaluation protocols. as a result, current methods often resort to random sampling from supervised datasets to create ""few-data"" setups and employ inconsistent training strategies during evaluations, which poses a challenge in accurately comparing recent progress. in this paper, we propose a customized fewdr dataset and a unified evaluation benchmark. specifically, fewdr employs class-wise sampling to establish a standardized ""few-shot"" setting with finely-defined classes, reducing variability in multiple sampling rounds. moreover, the dataset is disjointed into base and novel classes, allowing dr models to be continuously trained on ample data from base classes and a few samples in novel classes. this benchmark eliminates the risk of novel class leakage, providing a reliable estimation of the dr model's few-shot ability. our extensive empirical results reveal that current state-of-the-art dr models still face challenges in the standard few-shot scene. our code and data will be open-sourced at https://github.com/openmatch/ance-tele.",,2023-04-12,,"['si sun', 'yida lu', 'shi yu', 'xiangyang li', 'zhonghua li', 'zhao cao', 'zhiyuan liu', 'deiming ye', 'jie bao']",https://arxiv.org/pdf/2304.05845.pdf
878,2304.05864,scale-equivariant deep learning for 3d data,cs.cv cs.lg,"the ability of convolutional neural networks (cnns) to recognize objects regardless of their position in the image is due to the translation-equivariance of the convolutional operation. group-equivariant cnns transfer this equivariance to other transformations of the input. dealing appropriately with objects and object parts of different scale is challenging, and scale can vary for multiple reasons such as the underlying object size or the resolution of the imaging modality. in this paper, we propose a scale-equivariant convolutional network layer for three-dimensional data that guarantees scale-equivariance in 3d cnns. scale-equivariance lifts the burden of having to learn each possible scale separately, allowing the neural network to focus on higher-level learning goals, which leads to better results and better data-efficiency. we provide an overview of the theoretical foundations and scientific work on scale-equivariant neural networks in the two-dimensional domain. we then transfer the concepts from 2d to the three-dimensional space and create a scale-equivariant convolutional layer for 3d data. using the proposed scale-equivariant layer, we create a scale-equivariant u-net for medical image segmentation and compare it with a non-scale-equivariant baseline method. our experiments demonstrate the effectiveness of the proposed method in achieving scale-equivariance for 3d medical image analysis. we publish our code at https://github.com/wimmerth/scale-equivariant-3d-convnet for further research and application.",,2023-04-12,,"['thomas wimmer', 'vladimir golkov', 'hoai nam dang', 'moritz zaiss', 'andreas maier', 'daniel cremers']",https://arxiv.org/pdf/2304.05864.pdf
879,2304.05868,mesh2tex: generating mesh textures from image queries,cs.cv,"remarkable advances have been achieved recently in learning neural representations that characterize object geometry, while generating textured objects suitable for downstream applications and 3d rendering remains at an early stage. in particular, reconstructing textured geometry from images of real objects is a significant challenge -- reconstructed geometry is often inexact, making realistic texturing a significant challenge. we present mesh2tex, which learns a realistic object texture manifold from uncorrelated collections of 3d object geometry and photorealistic rgb images, by leveraging a hybrid mesh-neural-field texture representation. our texture representation enables compact encoding of high-resolution textures as a neural field in the barycentric coordinate system of the mesh faces. the learned texture manifold enables effective navigation to generate an object texture for a given 3d object geometry that matches to an input rgb image, which maintains robustness even under challenging real-world scenarios where the mesh geometry approximates an inexact match to the underlying geometry in the rgb image. mesh2tex can effectively generate realistic object textures for an object mesh to match real images observations towards digitization of real environments, significantly improving over previous state of the art.",,2023-04-12,,"['alexey bokhovkin', 'shubham tulsiani', 'angela dai']",https://arxiv.org/pdf/2304.05868.pdf
880,2304.05871,edge-cloud collaborative learning with federated and centralized   features,cs.lg cs.ir,"federated learning (fl) is a popular way of edge computing that doesn't compromise users' privacy. current fl paradigms assume that data only resides on the edge, while cloud servers only perform model averaging. however, in real-life situations such as recommender systems, the cloud server has the ability to store historical and interactive features. in this paper, our proposed edge-cloud collaborative knowledge transfer framework (ecct) bridges the gap between the edge and cloud, enabling bi-directional knowledge transfer between both, sharing feature embeddings and prediction logits. ecct consolidates various benefits, including enhancing personalization, enabling model heterogeneity, tolerating training asynchronization, and relieving communication burdens. extensive experiments on public and industrial datasets demonstrate ecct's effectiveness and potential for use in academia and industry.",10.1145/3539618.3591976,2023-04-12,,"['zexi li', 'qunwei li', 'yi zhou', 'wenliang zhong', 'guannan zhang', 'chao wu']",https://arxiv.org/pdf/2304.05871.pdf
881,2304.05872,learning to communicate and collaborate in a competitive multi-agent   setup to clean the ocean from macroplastics,cs.ai cs.lg cs.ma,"finding a balance between collaboration and competition is crucial for artificial agents in many real-world applications. we investigate this using a multi-agent reinforcement learning (marl) setup on the back of a high-impact problem. the accumulation and yearly growth of plastic in the ocean cause irreparable damage to many aspects of oceanic health and the marina system. to prevent further damage, we need to find ways to reduce macroplastics from known plastic patches in the ocean. here we propose a graph neural network (gnn) based communication mechanism that increases the agents' observation space. in our custom environment, agents control a plastic collecting vessel. the communication mechanism enables agents to develop a communication protocol using a binary signal. while the goal of the agent collective is to clean up as much as possible, agents are rewarded for the individual amount of macroplastics collected. hence agents have to learn to communicate effectively while maintaining high individual performance. we compare our proposed communication mechanism with a multi-agent baseline without the ability to communicate. results show communication enables collaboration and increases collective performance significantly. this means agents have learned the importance of communication and found a balance between collaboration and competition.",,2023-04-12,,['philipp dominic siedler'],https://arxiv.org/pdf/2304.05872.pdf
882,2304.05879,fetmrqc: automated quality control for fetal brain mri,eess.iv cs.lg,"quality control (qc) has long been considered essential to guarantee the reliability of neuroimaging studies. it is particularly important for fetal brain mri, where large and unpredictable fetal motion can lead to substantial artifacts in the acquired images. existing methods for fetal brain quality assessment operate at the \textit{slice} level, and fail to get a comprehensive picture of the quality of an image, that can only be achieved by looking at the \textit{entire} brain volume. in this work, we propose fetmrqc, a machine learning framework for automated image quality assessment tailored to fetal brain mri, which extracts an ensemble of quality metrics that are then used to predict experts' ratings. based on the manual ratings of more than 1000 low-resolution stacks acquired across two different institutions, we show that, compared with existing quality metrics, fetmrqc is able to generalize out-of-domain, while being interpretable and data efficient. we also release a novel manual quality rating tool designed to facilitate and optimize quality rating of fetal brain images.   our tool, along with all the code to generate, train and evaluate the model will be released upon acceptance of the paper.",,2023-04-12,,"['thomas sanchez', 'oscar esteban', 'yvan gomez', 'elisenda eixarch', 'meritxell bach cuadra']",https://arxiv.org/pdf/2304.05879.pdf
883,2304.05889,representation learning with multi-step inverse kinematics: an efficient   and optimal approach to rich-observation rl,cs.lg cs.ai,"we study the design of sample-efficient algorithms for reinforcement learning in the presence of rich, high-dimensional observations, formalized via the block mdp problem. existing algorithms suffer from either 1) computational intractability, 2) strong statistical assumptions that are not necessarily satisfied in practice, or 3) suboptimal sample complexity. we address these issues by providing the first computationally efficient algorithm that attains rate-optimal sample complexity with respect to the desired accuracy level, with minimal statistical assumptions. our algorithm, musik, combines systematic exploration with representation learning based on multi-step inverse kinematics, a learning objective in which the aim is to predict the learner's own action from the current observation and observations in the (potentially distant) future. musik is simple and flexible, and can efficiently take advantage of general-purpose function approximation. our analysis leverages several new techniques tailored to non-optimistic exploration algorithms, which we anticipate will find broader use.",,2023-04-12,,"['zakaria mhammedi', 'dylan j. foster', 'alexander rakhlin']",https://arxiv.org/pdf/2304.05889.pdf
884,2304.05894,dynamic mixed membership stochastic block model for weighted labeled   networks,cs.lg cs.ir cs.si,"most real-world networks evolve over time. existing literature proposes models for dynamic networks that are either unlabeled or assumed to have a single membership structure. on the other hand, a new family of mixed membership stochastic block models (mmsbm) allows to model static labeled networks under the assumption of mixed-membership clustering. in this work, we propose to extend this later class of models to infer dynamic labeled networks under a mixed membership assumption. our approach takes the form of a temporal prior on the model's parameters. it relies on the single assumption that dynamics are not abrupt. we show that our method significantly differs from existing approaches, and allows to model more complex systems --dynamic labeled networks. we demonstrate the robustness of our method with several experiments on both synthetic and real-world datasets. a key interest of our approach is that it needs very few training data to yield good results. the performance gain under challenging conditions broadens the variety of possible applications of automated learning tools --as in social sciences, which comprise many fields where small datasets are a major obstacle to the introduction of machine learning methods.",10.1145/3539618.3591675,2023-04-12,,"['ga√´l poux-m√©dard', 'julien velcin', 'sabine loudcher']",https://arxiv.org/pdf/2304.05894.pdf
885,2304.05895,towards understanding how data augmentation works with imbalanced data,cs.lg,"data augmentation forms the cornerstone of many modern machine learning training pipelines; yet, the mechanisms by which it works are not clearly understood. much of the research on data augmentation (da) has focused on improving existing techniques, examining its regularization effects in the context of neural network over-fitting, or investigating its impact on features. here, we undertake a holistic examination of the effect of da on three different classifiers, convolutional neural networks, support vector machines, and logistic regression models, which are commonly used in supervised classification of imbalanced data. we support our examination with testing on three image and five tabular datasets. our research indicates that da, when applied to imbalanced data, produces substantial changes in model weights, support vectors and feature selection; even though it may only yield relatively modest changes to global metrics, such as balanced accuracy or f1 measure. we hypothesize that da works by facilitating variances in data, so that machine learning models can associate changes in the data with labels. by diversifying the range of feature amplitudes that a model must recognize to predict a label, da improves a model's capacity to generalize when learning with imbalanced data.",,2023-04-12,,"['damien a. dablain', 'nitesh v. chawla']",https://arxiv.org/pdf/2304.05895.pdf
886,2304.05899,cancer-net bca-s: breast cancer grade prediction using volumetric deep   radiomic features from synthetic correlated diffusion imaging,cs.cv,"the prevalence of breast cancer continues to grow, affecting about 300,000 females in the united states in 2023. however, there are different levels of severity of breast cancer requiring different treatment strategies, and hence, grading breast cancer has become a vital component of breast cancer diagnosis and treatment planning. specifically, the gold-standard scarff-bloom-richardson (sbr) grade has been shown to consistently indicate a patient's response to chemotherapy. unfortunately, the current method to determine the sbr grade requires removal of some cancer cells from the patient which can lead to stress and discomfort along with costly expenses. in this paper, we study the efficacy of deep learning for breast cancer grading based on synthetic correlated diffusion (cdi$^s$) imaging, a new magnetic resonance imaging (mri) modality and found that it achieves better performance on sbr grade prediction compared to those learnt using gold-standard imaging modalities. hence, we introduce cancer-net bca-s, a volumetric deep radiomics approach for predicting sbr grade based on volumetric cdi$^s$ data. given the promising results, this proposed method to identify the severity of the cancer would allow for better treatment decisions without the need for a biopsy. cancer-net bca-s has been made publicly available as part of a global open-source initiative for advancing machine learning for cancer care.",,2023-04-12,,"['chi-en amy tai', 'hayden gunraj', 'alexander wong']",https://arxiv.org/pdf/2304.05899.pdf
887,2304.05901,automated computed tomography and magnetic resonance imaging   segmentation using deep learning: a beginner's guide,eess.iv cs.cv,"medical image segmentation is an increasingly popular area of research in medical imaging processing and analysis. however, many researchers who are new to the field struggle with basic concepts. this tutorial paper aims to provide an overview of the fundamental concepts of medical imaging, with a focus on magnetic resonance and computerized tomography. we will also discuss deep learning algorithms, tools, and frameworks used for segmentation tasks, and suggest best practices for method development and image analysis. our tutorial includes sample tasks using public data, and accompanying code is available on github (https://github.com/miclab-unicamp/medical-imagingtutorial). by sharing our insights gained from years of experience in the field and learning from relevant literature, we hope to assist researchers in overcoming the initial challenges they may encounter in this exciting and important area of research.",,2023-04-12,,"['diedre carmo', 'gustavo pinheiro', 'l√≠via rodrigues', 'thays abreu', 'roberto lotufo', 'let√≠cia rittner']",https://arxiv.org/pdf/2304.05901.pdf
888,2304.05919,hard patches mining for masked image modeling,cs.cv,"masked image modeling (mim) has attracted much research attention due to its promising potential for learning scalable visual representations. in typical approaches, models usually focus on predicting specific contents of masked patches, and their performances are highly related to pre-defined mask strategies. intuitively, this procedure can be considered as training a student (the model) on solving given problems (predict masked patches). however, we argue that the model should not only focus on solving given problems, but also stand in the shoes of a teacher to produce a more challenging problem by itself. to this end, we propose hard patches mining (hpm), a brand-new framework for mim pre-training. we observe that the reconstruction loss can naturally be the metric of the difficulty of the pre-training task. therefore, we introduce an auxiliary loss predictor, predicting patch-wise losses first and deciding where to mask next. it adopts a relative relationship learning strategy to prevent overfitting to exact reconstruction loss values. experiments under various settings demonstrate the effectiveness of hpm in constructing masked images. furthermore, we empirically find that solely introducing the loss prediction objective leads to powerful representations, verifying the efficacy of the ability to be aware of where is hard to reconstruct.",,2023-04-12,,"['haochen wang', 'kaiyou song', 'junsong fan', 'yuxi wang', 'jin xie', 'zhaoxiang zhang']",https://arxiv.org/pdf/2304.05919.pdf
889,2304.05930,med-vt: multiscale encoder-decoder video transformer with application to   object segmentation,cs.cv,"multiscale video transformers have been explored in a wide variety of vision tasks. to date, however, the multiscale processing has been confined to the encoder or decoder alone. we present a unified multiscale encoder-decoder transformer that is focused on dense prediction tasks in videos. multiscale representation at both encoder and decoder yields key benefits of implicit extraction of spatiotemporal features (i.e. without reliance on input optical flow) as well as temporal consistency at encoding and coarseto-fine detection for high-level (e.g. object) semantics to guide precise localization at decoding. moreover, we propose a transductive learning scheme through many-to-many label propagation to provide temporally consistent predictions. we showcase our multiscale encoder-decoder video transformer (med-vt) on automatic video object segmentation (avos) and actor/action segmentation, where we outperform state-of-the-art approaches on multiple benchmarks using only raw images, without using optical flow.",,2023-04-12,,"['rezaul karim', 'he zhao', 'richard p. wildes', 'mennatullah siam']",https://arxiv.org/pdf/2304.05930.pdf
890,2304.05934,asl citizen: a community-sourced dataset for advancing isolated sign   language recognition,cs.cv cs.cl,"sign languages are used as a primary language by approximately 70 million d/deaf people world-wide. however, most communication technologies operate in spoken and written languages, creating inequities in access. to help tackle this problem, we release asl citizen, the largest isolated sign language recognition (islr) dataset to date, collected with consent and containing 83,912 videos for 2,731 distinct signs filmed by 52 signers in a variety of environments. we propose that this dataset be used for sign language dictionary retrieval for american sign language (asl), where a user demonstrates a sign to their own webcam with the aim of retrieving matching signs from a dictionary. we show that training supervised machine learning classifiers with our dataset greatly advances the state-of-the-art on metrics relevant for dictionary retrieval, achieving, for instance, 62% accuracy and a recall-at-10 of 90%, evaluated entirely on videos of users who are not present in the training or validation sets. an accessible pdf of this article is available at https://aashakadesai.github.io/research/asl_dataset__arxiv_.pdf",,2023-04-12,,"['aashaka desai', 'lauren berger', 'fyodor o. minakov', 'vanessa milan', 'chinmay singh', 'kriston pumphrey', 'richard e. ladner', 'hal daum√©', 'alex x. lu', 'naomi caselli', 'danielle bragg']",https://arxiv.org/pdf/2304.05934.pdf
891,2304.05944,constructing a searchable knowledge repository for fair climate data,cs.dl,"the development of a knowledge repository for climate science data is a multidisciplinary effort between the domain experts (climate scientists), data engineers whos skills include design and building a knowledge repository, and machine learning researchers who provide expertise on data preparation tasks such as gap filling and advise on different machine learning models that can exploit this data. one of the main goals of the ca20108 cost action is to develop a knowledge portal that is fully compliant with the fair principles for scientific data management. in the first year, a bespoke knowledge portal was developed to capture metadata for fair datasets. its purpose was to provide detailed metadata descriptions for shareable \micro data using the wmo standard. while storing network, site and sensor metadata locally, the system passes the actual data to zenodo, receives back the doi and thus, creates a permanent link between the knowledge portal and the storage platform zenodo. while the user searches the knowledge portal (metadata), results provide both detailed descriptions and links to data on the zenodo platform.",,2023-04-12,,"['mark roantree', 'branislava lalic', 'stevan savic', 'dragan milosevic', 'michael scriney']",https://arxiv.org/pdf/2304.05944.pdf
892,2304.05949,cmos + stochastic nanomagnets: heterogeneous computers for probabilistic   inference and learning,cond-mat.mes-hall cs.ai cs.et cs.lg,"with the slowing down of moore's law, augmenting complementary-metal-oxide semiconductor (cmos) transistors with emerging nanotechnologies (x) is becoming increasingly important. in this paper, we demonstrate how stochastic magnetic tunnel junction (smtj)-based probabilistic bits, or p-bits, can be combined with versatile field programmable gate arrays (fpga) to design an energy-efficient, heterogeneous cmos + x (x = smtj) prototype. our heterogeneous computer successfully performs probabilistic inference and asynchronous boltzmann learning despite device-to-device variations in smtjs. a comprehensive comparison using a cmos predictive process design kit (pdk) reveals that digital cmos-based p-bits emulating high-quality randomness use over 10,000 transistors with the energy per generated random number being roughly two orders of magnitude greater than the smtj-based p-bits that dissipate only 2 fj. scaled and integrated versions of our approach can significantly advance probabilistic computing and its applications in various domains, including probabilistic machine learning, optimization, and quantum simulation.",,2023-04-12,,"['keito kobayashi', 'nihal singh', 'qixuan cao', 'kemal selcuk', 'tianrui hu', 'shaila niazi', 'navid anjum aadit', 'shun kanai', 'hideo ohno', 'shunsuke fukami', 'kerem y. camsari']",https://arxiv.org/pdf/2304.05949.pdf
893,2304.05959,uav obstacle avoidance by human-in-the-loop reinforcement in arbitrary   3d environment,cs.ro cs.ai,"this paper focuses on the continuous control of the unmanned aerial vehicle (uav) based on a deep reinforcement learning method for a large-scale 3d complex environment. the purpose is to make the uav reach any target point from a certain starting point, and the flying height and speed are variable during navigation. in this work, we propose a deep reinforcement learning (drl)-based method combined with human-in-the-loop, which allows the uav to avoid obstacles automatically during flying. we design multiple reward functions based on the relevant domain knowledge to guide uav navigation. the role of human-in-the-loop is to dynamically change the reward function of the uav in different situations to suit the obstacle avoidance of the uav better. we verify the success rate and average step size on urban, rural, and forest scenarios, and the experimental results show that the proposed method can reduce the training convergence time and improve the efficiency and accuracy of navigation tasks. the code is available on the website https://github.com/monnalo/uav_navigation.",,2023-04-06,,"['xuyang li', 'jianwu fang', 'kai du', 'kuizhi mei', 'jianru xue']",https://arxiv.org/pdf/2304.05959.pdf
894,2304.05961,spectraldiff: hyperspectral image classification with spectral-spatial   diffusion models,cs.cv,"hyperspectral image (hsi) classification is an important topic in the field of remote sensing, and has a wide range of applications in earth science. hsis contain hundreds of continuous bands, which are characterized by high dimension and high correlation between adjacent bands. the high dimension and redundancy of hsi data bring great difficulties to hsi classification. in recent years, a large number of hsi feature extraction and classification methods based on deep learning have been proposed. however, their ability to model the global relationships among samples in both spatial and spectral domains is still limited. in order to solve this problem, an hsi classification method with spectral-spatial diffusion models is proposed. the proposed method realizes the reconstruction of spectral-spatial distribution of the training samples with the forward and reverse spectral-spatial diffusion process, thus modeling the global spatial-spectral relationship between samples. then, we use the spectral-spatial denoising network of the reverse process to extract the unsupervised diffusion features. features extracted by the spectral-spatial diffusion models can achieve cross-sample perception from the reconstructed distribution of the training samples, thus obtaining better classification performance. experiments on three public hsi datasets show that the proposed method can achieve better performance than the state-of-the-art methods. the source code and the pre-trained spectral-spatial diffusion model will be publicly available at https://github.com/chenning0115/spectraldiff.",,2023-04-12,,"['ning chen', 'jun yue', 'leyuan fang', 'shaobo xia']",https://arxiv.org/pdf/2304.05961.pdf
895,2304.05967,angler: helping machine translation practitioners prioritize model   improvements,cs.hc cs.ai cs.cl cs.lg,"machine learning (ml) models can fail in unexpected ways in the real world, but not all model failures are equal. with finite time and resources, ml practitioners are forced to prioritize their model debugging and improvement efforts. through interviews with 13 ml practitioners at apple, we found that practitioners construct small targeted test sets to estimate an error's nature, scope, and impact on users. we built on this insight in a case study with machine translation models, and developed angler, an interactive visual analytics tool to help practitioners prioritize model improvements. in a user study with 7 machine translation experts, we used angler to understand prioritization practices when the input space is infinite, and obtaining reliable signals of model quality is expensive. our study revealed that participants could form more interesting and user-focused hypotheses for prioritization by analyzing quantitative summary statistics and qualitatively assessing data by reading sentences.",10.1145/3544548.3580790,2023-04-12,,"['samantha robertson', 'zijie j. wang', 'dominik moritz', 'mary beth kery', 'fred hohman']",https://arxiv.org/pdf/2304.05967.pdf
896,2304.05976,bayesian causal inference in doubly gaussian dag-probit models,stat.me cs.ai stat.ml,"we consider modeling a binary response variable together with a set of covariates for two groups under observational data. the grouping variable can be the confounding variable (the common cause of treatment and outcome), gender, case/control, ethnicity, etc. given the covariates and a binary latent variable, the goal is to construct two directed acyclic graphs (dags), while sharing some common parameters. the set of nodes, which represent the variables, are the same for both groups but the directed edges between nodes, which represent the causal relationships between the variables, can be potentially different. for each group, we also estimate the effect size for each node. we assume that each group follows a gaussian distribution under its dag. given the parent nodes, the joint distribution of dag is conditionally independent due to the markov property of dags. we introduce the concept of gaussian dag-probit model under two groups and hence doubly gaussian dag-probit model. to estimate the skeleton of the dags and the model parameters, we took samples from the posterior distribution of doubly gaussian dag-probit model via mcmc method. we validated the proposed method using a comprehensive simulation experiment and applied it on two real datasets. furthermore, we validated the results of the real data analysis using well-known experimental studies to show the value of the proposed grouping variable in the causality domain.",,2023-04-12,,"['rasool tahmasbi', 'keyvan tahmasbi']",https://arxiv.org/pdf/2304.05976.pdf
897,2304.05979,navistar: socially aware robot navigation with hybrid spatio-temporal   graph transformer and preference learning,cs.ro,"developing robotic technologies for use in human society requires ensuring the safety of robots' navigation behaviors while adhering to pedestrians' expectations and social norms. however, maintaining real-time communication between robots and pedestrians to avoid collisions can be challenging. to address these challenges, we propose a novel socially-aware navigation benchmark called navistar, which utilizes a hybrid spatio-temporal graph transformer (star) to understand interactions in human-rich environments fusing potential crowd multi-modal information. we leverage off-policy reinforcement learning algorithm with preference learning to train a policy and a reward function network with supervisor guidance. additionally, we design a social score function to evaluate the overall performance of social navigation. to compare, we train and test our algorithm and other state-of-the-art methods in both simulator and real-world scenarios independently. our results show that navistar outperforms previous methods with outstanding performance\footnote{the source code and experiment videos of this work are available at: https://sites.google.com/view/san-navistar",,2023-04-12,,"['weizheng wang', 'ruiqi wang', 'le mao', 'byung-cheol min']",https://arxiv.org/pdf/2304.05979.pdf
898,2304.05985,kubeedge-sedna v0.3: towards next-generation automatically customized ai   engineering scheme,cs.dc cs.ai,"the scale of the global edge ai market continues to grow. the current technical challenges that hinder the large-scale replication of edge ai are mainly small samples on the edge and heterogeneity of edge data. in addition, edge ai customers often have requirements for data security compliance and offline autonomy of edge ai services. based on the lifelong learning method in the academic world, we formally define the problem of edge-cloud collaborative lifelong learning for the first time, and release the industry's first open-source edge-cloud collaborative lifelong learning. edge-cloud collaborative lifelong learning adapts to data heterogeneity at different edge locations through (1) multi-task transfer learning to achieve accurate prediction of ""thousands of people and thousands of faces""; (2) incremental processing of unknown tasks, the more systems learn and the smarter systems are with small samples, gradually realize ai engineering and automation; (3) use the cloud-side knowledge base to remember new situational knowledge to avoid catastrophic forgetting; (4) the edge-cloud collaborative architecture enables data security compliance and edge ai services to be offline autonomy while applying cloud resources. this work hopes to help fundamentally solve the above-mentioned challenges of edge-cloud collaborative machine learning.",,2023-03-08,,['zimu zheng'],https://arxiv.org/pdf/2304.05985.pdf
899,2304.05986,auditing icu readmission rates in an clinical database: an analysis of   risk factors and clinical outcomes,cs.lg,"this study presents a machine learning (ml) pipeline for clinical data classification in the context of a 30-day readmission problem, along with a fairness audit on subgroups based on sensitive attributes. a range of ml models are used for classification and the fairness audit is conducted on the model predictions. the fairness audit uncovers disparities in equal opportunity, predictive parity, false positive rate parity, and false negative rate parity criteria on the mimic iii dataset based on attributes such as gender, ethnicity, language, and insurance group. the results identify disparities in the model's performance across different groups and highlights the need for better fairness and bias mitigation strategies. the study suggests the need for collaborative efforts among researchers, policymakers, and practitioners to address bias and fairness in artificial intelligence (ai) systems.",,2023-04-12,,['shaina raza'],https://arxiv.org/pdf/2304.05986.pdf
900,2304.05989,object-agnostic affordance categorization via unsupervised learning of   graph embeddings,cs.ai cs.cv cs.lg,"acquiring knowledge about object interactions and affordances can facilitate scene understanding and human-robot collaboration tasks. as humans tend to use objects in many different ways depending on the scene and the objects' availability, learning object affordances in everyday-life scenarios is a challenging task, particularly in the presence of an open set of interactions and objects. we address the problem of affordance categorization for class-agnostic objects with an open set of interactions; we achieve this by learning similarities between object interactions in an unsupervised way and thus inducing clusters of object affordances. a novel depth-informed qualitative spatial representation is proposed for the construction of activity graphs (ags), which abstract from the continuous representation of spatio-temporal interactions in rgb-d videos. these ags are clustered to obtain groups of objects with similar affordances. our experiments in a real-world scenario demonstrate that our method learns to create object affordance clusters with a high v-measure even in cluttered scenes. the proposed approach handles object occlusions by capturing effectively possible interactions and without imposing any object or scene constraints.",,2023-03-30,,"['alexia toumpa', 'anthony g. cohn']",https://arxiv.org/pdf/2304.05989.pdf
901,2304.05995,applenet: visual attention parameterized prompt learning for few-shot   remote sensing image generalization using clip,cs.cv,"in recent years, the success of large-scale vision-language models (vlms) such as clip has led to their increased usage in various computer vision tasks. these models enable zero-shot inference through carefully crafted instructional text prompts without task-specific supervision. however, the potential of vlms for generalization tasks in remote sensing (rs) has not been fully realized. to address this research gap, we propose a novel image-conditioned prompt learning strategy called the visual attention parameterized prompts learning network (applenet). applenet emphasizes the importance of multi-scale feature learning in rs scene classification and disentangles visual style and content primitives for domain generalization tasks. to achieve this, applenet combines visual content features obtained from different layers of the vision encoder and style properties obtained from feature statistics of domain-specific batches. an attention-driven injection module is further introduced to generate visual tokens from this information. we also introduce an anti-correlation regularizer to ensure discrimination among the token embeddings, as this visual information is combined with the textual tokens. to validate applenet, we curated four available rs benchmarks and introduced experimental protocols and datasets for three domain generalization tasks. our results consistently outperform the relevant literature and code is available at https://github.com/mainaksingha01/applenet",,2023-04-12,,"['mainak singha', 'ankit jha', 'bhupendra solanki', 'shirsha bose', 'biplab banerjee']",https://arxiv.org/pdf/2304.05995.pdf
902,2304.06007,gpr-net: geometric prototypical network for point cloud few-shot   learning,cs.cv,"in the realm of 3d-computer vision applications, point cloud few-shot learning plays a critical role. however, it poses an arduous challenge due to the sparsity, irregularity, and unordered nature of the data. current methods rely on complex local geometric extraction techniques such as convolution, graph, and attention mechanisms, along with extensive data-driven pre-training tasks. these approaches contradict the fundamental goal of few-shot learning, which is to facilitate efficient learning. to address this issue, we propose gpr-net (geometric prototypical network), a lightweight and computationally efficient geometric prototypical network that captures the intrinsic topology of point clouds and achieves superior performance. our proposed method, igi++ (intrinsic geometry interpreter++) employs vector-based hand-crafted intrinsic geometry interpreters and laplace vectors to extract and evaluate point cloud morphology, resulting in improved representations for fsl (few-shot learning). additionally, laplace vectors enable the extraction of valuable features from point clouds with fewer points. to tackle the distribution drift challenge in few-shot metric learning, we leverage hyperbolic space and demonstrate that our approach handles intra and inter-class variance better than existing point cloud few-shot learning methods. experimental results on the modelnet40 dataset show that gpr-net outperforms state-of-the-art methods in few-shot learning on point clouds, achieving utmost computational efficiency that is $170\times$ better than all existing works. the code is publicly available at https://github.com/tejasanvekar/gpr-net.",,2023-04-12,,"['tejas anvekar', 'dena bazazian']",https://arxiv.org/pdf/2304.06007.pdf
903,2304.06011,bi-level latent variable model for sample-efficient multi-agent   reinforcement learning,cs.lg cs.ma,"despite their potential in real-world applications, multi-agent reinforcement learning (marl) algorithms often suffer from high sample complexity. to address this issue, we present a novel model-based marl algorithm, bill (bi-level latent variable model-based learning), that learns a bi-level latent variable model from high-dimensional inputs. at the top level, the model learns latent representations of the global state, which encode global information relevant to behavior learning. at the bottom level, it learns latent representations for each agent, given the global latent representations from the top level. the model generates latent trajectories to use for policy learning. we evaluate our algorithm on complex multi-agent tasks in the challenging smac and flatland environments. our algorithm outperforms state-of-the-art model-free and model-based baselines in sample efficiency, including on two extremely challenging super hard smac maps.",,2023-04-12,,"['aravind venugopal', 'stephanie milani', 'fei fang', 'balaraman ravindran']",https://arxiv.org/pdf/2304.06011.pdf
904,2304.06016,pd-adsv: an automated diagnosing system using voice signals and hard   voting ensemble method for parkinson's disease,cs.sd cs.lg eess.as eess.sp,"parkinson's disease (pd) is the most widespread movement condition and the second most common neurodegenerative disorder, following alzheimer's. movement symptoms and imaging techniques are the most popular ways to diagnose this disease. however, they are not accurate and fast and may only be accessible to a few people. this study provides an autonomous system, i.e., pd-adsv, for diagnosing pd based on voice signals, which uses four machine learning classifiers and the hard voting ensemble method to achieve the highest accuracy. pd-adsv is developed using python and the gradio web framework.",,2023-04-11,,"['paria ghaheri', 'ahmadreza shateri', 'hamid nasiri']",https://arxiv.org/pdf/2304.06016.pdf
905,2304.06017,exploiting logic locking for a neural trojan attack on machine learning   accelerators,cs.cr cs.ai cs.ar,"logic locking has been proposed to safeguard intellectual property (ip) during chip fabrication. logic locking techniques protect hardware ip by making a subset of combinational modules in a design dependent on a secret key that is withheld from untrusted parties. if an incorrect secret key is used, a set of deterministic errors is produced in locked modules, restricting unauthorized use. a common target for logic locking is neural accelerators, especially as machine-learning-as-a-service becomes more prevalent. in this work, we explore how logic locking can be used to compromise the security of a neural accelerator it protects. specifically, we show how the deterministic errors caused by incorrect keys can be harnessed to produce neural-trojan-style backdoors. to do so, we first outline a motivational attack scenario where a carefully chosen incorrect key, which we call a trojan key, produces misclassifications for an attacker-specified input class in a locked accelerator. we then develop a theoretically-robust attack methodology to automatically identify trojan keys. to evaluate this attack, we launch it on several locked accelerators. in our largest benchmark accelerator, our attack identified a trojan key that caused a 74\% decrease in classification accuracy for attacker-specified trigger inputs, while degrading accuracy by only 1.7\% for other inputs on average.",,2023-04-12,,"['hongye xu', 'dongfang liu', 'cory merkel', 'michael zuzack']",https://arxiv.org/pdf/2304.06017.pdf
906,2304.06027,continual diffusion: continual customization of text-to-image diffusion   with c-lora,cs.cv cs.ai cs.lg,"recent works demonstrate a remarkable ability to customize text-to-image diffusion models while only providing a few example images. what happens if you try to customize such models using multiple, fine-grained concepts in a sequential (i.e., continual) manner? in our work, we show that recent state-of-the-art customization of text-to-image models suffer from catastrophic forgetting when new concepts arrive sequentially. specifically, when adding a new concept, the ability to generate high quality images of past, similar concepts degrade. to circumvent this forgetting, we propose a new method, c-lora, composed of a continually self-regularized low-rank adaptation in cross attention layers of the popular stable diffusion model. furthermore, we use customization prompts which do not include the word of the customized object (i.e., ""person"" for a human face dataset) and are initialized as completely random embeddings. importantly, our method induces only marginal additional parameter costs and requires no storage of user data for replay. we show that c-lora not only outperforms several baselines for our proposed setting of text-to-image continual customization, which we refer to as continual diffusion, but that we achieve a new state-of-the-art in the well-established rehearsal-free continual learning setting for image classification. the high achieving performance of c-lora in two separate domains positions it as a compelling solution for a wide range of applications, and we believe it has significant potential for practical impact.",,2023-04-12,,"['james seale smith', 'yen-chang hsu', 'lingyu zhang', 'ting hua', 'zsolt kira', 'yilin shen', 'hongxia jin']",https://arxiv.org/pdf/2304.06027.pdf
907,2304.06028,reclip: resource-efficient clip by training with small images,cs.cv,"we present reclip (resource-efficient clip), a simple method that minimizes computational resource footprint for clip (contrastive language image pretraining). inspired by the notion of coarse-to-fine in computer vision, we leverage small images to learn from large-scale language supervision efficiently, and finetune the model with high-resolution data in the end. since the complexity of the vision transformer heavily depends on input image size, our approach significantly reduces the training resource requirements both in theory and in practice. using the same batch size and training epoch, reclip achieves highly competitive zero-shot classification and image text retrieval accuracy with 6 to 8$\times$ less computational resources and 7 to 9$\times$ fewer flops than the baseline. compared to the state-of-the-art contrastive learning methods, reclip demonstrates 5 to 59$\times$ training resource savings while maintaining highly competitive zero-shot classification and retrieval performance. we hope this work will pave the path for the broader research community to explore language supervised pretraining in more resource-friendly settings.",,2023-04-12,,"['runze li', 'dahun kim', 'bir bhanu', 'weicheng kuo']",https://arxiv.org/pdf/2304.06028.pdf
908,2304.06031,fairness: from the ethical principle to the practice of machine learning   development as an ongoing agreement with stakeholders,cs.cy cs.ai cs.lg,"this paper clarifies why bias cannot be completely mitigated in machine learning (ml) and proposes an end-to-end methodology to translate the ethical principle of justice and fairness into the practice of ml development as an ongoing agreement with stakeholders. the pro-ethical iterative process presented in the paper aims to challenge asymmetric power dynamics in the fairness decision making within ml design and support ml development teams to identify, mitigate and monitor bias at each step of ml systems development. the process also provides guidance on how to explain the always imperfect trade-offs in terms of bias to users.",,2023-03-22,,"['georgina curto', 'flavio comim']",https://arxiv.org/pdf/2304.06031.pdf
909,2304.06033,quantifying the impact of data characteristics on the transferability of   sleep stage scoring models,eess.sp cs.lg,"deep learning models for scoring sleep stages based on single-channel eeg have been proposed as a promising method for remote sleep monitoring. however, applying these models to new datasets, particularly from wearable devices, raises two questions. first, when annotations on a target dataset are unavailable, which different data characteristics affect the sleep stage scoring performance the most and by how much? second, when annotations are available, which dataset should be used as the source of transfer learning to optimize performance? in this paper, we propose a novel method for computationally quantifying the impact of different data characteristics on the transferability of deep learning models. quantification is accomplished by training and evaluating two models with significant architectural differences, tinysleepnet and u-time, under various transfer configurations in which the source and target datasets have different recording channels, recording environments, and subject conditions. for the first question, the environment had the highest impact on sleep stage scoring performance, with performance degrading by over 14% when sleep annotations were unavailable. for the second question, the most useful transfer sources for tinysleepnet and the u-time models were mass-ss1 and isruc-sg1, containing a high percentage of n1 (the rarest sleep stage) relative to the others. the frontal and central eegs were preferred for tinysleepnet. the proposed approach enables full utilization of existing sleep datasets for training and planning model transfer to maximize the sleep stage scoring performance on a target problem when sleep annotations are limited or unavailable, supporting the realization of remote sleep monitoring.",,2023-03-28,,"['akara supratak', 'peter haddawy']",https://arxiv.org/pdf/2304.06033.pdf
910,2304.06036,upper limb movement execution classification using   electroencephalography for brain computer interface,eess.sp cs.hc,"an accurate classification of upper limb movements using electroencephalography (eeg) signals is gaining significant importance in recent years due to the prevalence of brain-computer interfaces. the upper limbs in the human body are crucial since different skeletal segments combine to make a range of motion that helps us in our trivial daily tasks. decoding eeg-based upper limb movements can be of great help to people with spinal cord injury (sci) or other neuro-muscular diseases such as amyotrophic lateral sclerosis (als), primary lateral sclerosis, and periodic paralysis. this can manifest in a loss of sensory and motor function, which could make a person reliant on others to provide care in day-to-day activities. we can detect and classify upper limb movement activities, whether they be executed or imagined using an eeg-based brain-computer interface (bci). toward this goal, we focus our attention on decoding movement execution (me) of the upper limb in this study. for this purpose, we utilize a publicly available eeg dataset that contains eeg signal recordings from fifteen subjects acquired using a 61-channel eeg device. we propose a method to classify four me classes for different subjects using spectrograms of the eeg data through pre-trained deep learning (dl) models. our proposed method of using eeg spectrograms for the classification of me has shown significant results, where the highest average classification accuracy (for four me classes) obtained is 87.36%, with one subject achieving the best classification accuracy of 97.03%.",,2023-04-01,,"['saadat ullah khan', 'muhammad majid', 'syed muhammad anwar']",https://arxiv.org/pdf/2304.06036.pdf
911,2304.06037,quantitative trading using deep q learning,q-fin.tr cs.lg q-fin.gn,"reinforcement learning (rl) is a branch of machine learning that has been used in a variety of applications such as robotics, game playing, and autonomous systems. in recent years, there has been growing interest in applying rl to quantitative trading, where the goal is to make profitable trades in financial markets. this paper explores the use of rl in quantitative trading and presents a case study of a rl-based trading algorithm. the results show that rl can be a powerful tool for quantitative trading, and that it has the potential to outperform traditional trading algorithms. the use of reinforcement learning in quantitative trading represents a promising area of research that can potentially lead to the development of more sophisticated and effective trading systems. future work could explore the use of alternative reinforcement learning algorithms, incorporate additional data sources, and test the system on different asset classes. overall, our research demonstrates the potential of using reinforcement learning in quantitative trading and highlights the importance of continued research and development in this area. by developing more sophisticated and effective trading systems, we can potentially improve the efficiency of financial markets and generate greater returns for investors.",,2023-04-03,,['soumyadip sarkar'],https://arxiv.org/pdf/2304.06037.pdf
912,2304.06043,a deep learning approach towards generating high-fidelity diverse   synthetic battery datasets,cs.lg,"recent surge in the number of electric vehicles have created a need to develop inexpensive energy-dense battery storage systems. many countries across the planet have put in place concrete measures to reduce and subsequently limit the number of vehicles powered by fossil fuels. lithium-ion based batteries are presently dominating the electric automotive sector. energy research efforts are also focussed on accurate computation of state-of-charge of such batteries to provide reliable vehicle range estimates. although such estimation algorithms provide precise estimates, all such techniques available in literature presume availability of superior quality battery datasets. in reality, gaining access to proprietary battery usage datasets is very tough for battery scientists. moreover, open access datasets lack the diverse battery charge/discharge patterns needed to build generalized models. curating battery measurement data is time consuming and needs expensive equipment. to surmount such limited data scenarios, we introduce few deep learning-based methods to synthesize high-fidelity battery datasets, these augmented synthetic datasets will help battery researchers build better estimation models in the presence of limited data. we have released the code and dataset used in the present approach to generate synthetic data. the battery data augmentation techniques introduced here will alleviate limited battery dataset challenges.",10.1109/tia.2023.3265359,2023-04-09,,"['janamejaya channegowda', 'vageesh maiya', 'chaitanya lingaraj']",https://arxiv.org/pdf/2304.06043.pdf
913,2304.06048,rels-dqn: a robust and efficient local search framework for   combinatorial optimization,cs.lg cs.ai,"combinatorial optimization (co) aims to efficiently find the best solution to np-hard problems ranging from statistical physics to social media marketing. a wide range of co applications can benefit from local search methods because they allow reversible action over greedy policies. deep q-learning (dqn) using message-passing neural networks (mpnn) has shown promise in replicating the local search behavior and obtaining comparable results to the local search algorithms. however, the over-smoothing and the information loss during the iterations of message passing limit its robustness across applications, and the large message vectors result in memory inefficiency. our paper introduces rels-dqn, a lightweight dqn framework that exhibits the local search behavior while providing practical scalability. using the rels-dqn model trained on one application, it can generalize to various applications by providing solution values higher than or equal to both the local search algorithms and the existing dqn models while remaining efficient in runtime and memory.",,2023-04-11,,"['yuanhang shao', 'tonmoy dey', 'nikola vuckovic', 'luke van popering', 'alan kuhnle']",https://arxiv.org/pdf/2304.06048.pdf
914,2304.06051,open-transmind: a new baseline and benchmark for 1st foundation model   challenge of intelligent transportation,cs.cv cs.ai cs.lg,"with the continuous improvement of computing power and deep learning algorithms in recent years, the foundation model has grown in popularity. because of its powerful capabilities and excellent performance, this technology is being adopted and applied by an increasing number of industries. in the intelligent transportation industry, artificial intelligence faces the following typical challenges: few shots, poor generalization, and a lack of multi-modal techniques. foundation model technology can significantly alleviate the aforementioned issues. to address these, we designed the 1st foundation model challenge, with the goal of increasing the popularity of foundation model technology in traffic scenarios and promoting the rapid development of the intelligent transportation industry. the challenge is divided into two tracks: all-in-one and cross-modal image retrieval. furthermore, we provide a new baseline and benchmark for the two tracks, called open-transmind. according to our knowledge, open-transmind is the first open-source transportation foundation model with multi-task and multi-modal capabilities. simultaneously, open-transmind can achieve state-of-the-art performance on detection, classification, and segmentation datasets of traffic scenarios. our source code is available at https://github.com/traffic-x/open-transmind.",,2023-04-12,,"['yifeng shi', 'feng lv', 'xinliang wang', 'chunlong xia', 'shaojie li', 'shujie yang', 'teng xi', 'gang zhang']",https://arxiv.org/pdf/2304.06051.pdf
915,2304.06052,confident object detection via conformal prediction and conformal risk   control: an application to railway signaling,cs.lg,"deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. in this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. we test several conformal approaches and introduce a new method based on conformal risk control. our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds.",,2023-04-12,,"['l√©o and√©ol', 'thomas fel', 'florence de grancey', 'luca mossina']",https://arxiv.org/pdf/2304.06052.pdf
916,2304.06054,landslide susceptibility prediction modeling based on self-screening   deep learning model,cs.lg physics.geo-ph,"landslide susceptibility prediction has always been an important and challenging content. however, there are some uncertain problems to be solved in susceptibility modeling, such as the error of landslide samples and the complex nonlinear relationship between environmental factors. a self-screening graph convolutional network and long short-term memory network (sgcn-lstm) is proposed int this paper to overcome the above problems in landslide susceptibility prediction. the sgcn-lstm model has the advantages of wide width and good learning ability. the landslide samples with large errors outside the set threshold interval are eliminated by self-screening network, and the nonlinear relationship between environmental factors can be extracted from both spatial nodes and time series, so as to better simulate the nonlinear relationship between environmental factors. the sgcn-lstm model was applied to landslide susceptibility prediction in anyuan county, jiangxi province, china, and compared with cascade-parallel long short-term memory and conditional random fields (cplstm-crf), random forest (rf), support vector machine (svm), stochastic gradient descent (sgd) and logistic regression (lr) models.the landslide prediction experiment in anyuan county showed that the total accuracy and auc of sgcn-lstm model were the highest among the six models, and the total accuracy reached 92.38 %, which was 5.88%, 12.44%, 19.65%, 19.92% and 20.34% higher than those of cplstm-crf, rf, svm, sgd and lr models, respectively. the auc value reached 0.9782, which was 0.0305,0.0532,0.1875,0.1909 and 0.1829 higher than the other five models, respectively. in conclusion, compared with some existing traditional machine learning, the sgcn-lstm model proposed in this paper has higher landslide prediction accuracy and better robustness, and has a good application prospect in the lsp field.",,2023-04-12,,"['li zhu', 'lekai liu', 'changshi yu']",https://arxiv.org/pdf/2304.06054.pdf
917,2304.06055,exploiting symmetry and heuristic demonstrations in off-policy   reinforcement learning for robotic manipulation,cs.ro cs.ai,"reinforcement learning demonstrates significant potential in automatically building control policies in numerous domains, but shows low efficiency when applied to robot manipulation tasks due to the curse of dimensionality. to facilitate the learning of such tasks, prior knowledge or heuristics that incorporate inherent simplification can effectively improve the learning performance. this paper aims to define and incorporate the natural symmetry present in physical robotic environments. then, sample-efficient policies are trained by exploiting the expert demonstrations in symmetrical environments through an amalgamation of reinforcement and behavior cloning, which gives the off-policy learning process a diverse yet compact initiation. furthermore, it presents a rigorous framework for a recent concept and explores its scope for robot manipulation tasks. the proposed method is validated via two point-to-point reaching tasks of an industrial arm, with and without an obstacle, in a simulation experiment study. a pid controller, which tracks the linear joint-space trajectories with hard-coded temporal logic to produce interim midpoints, is used to generate demonstrations in the study. the results of the study present the effect of the number of demonstrations and quantify the magnitude of behavior cloning to exemplify the possible improvement of model-free reinforcement learning in common manipulation tasks. a comparison study between the proposed method and a traditional off-policy reinforcement learning algorithm indicates its advantage in learning performance and potential value for applications.",,2023-04-12,,"['amir m. soufi enayati', 'zengjie zhang', 'kashish gupta', 'homayoun najjaran']",https://arxiv.org/pdf/2304.06055.pdf
918,2304.06056,exploiting intrinsic stochasticity of real-time simulation to facilitate   robust reinforcement learning for robot manipulation,cs.ro cs.ai,"simulation is essential to reinforcement learning (rl) before implementation in the real world, especially for safety-critical applications like robot manipulation. conventionally, rl agents are sensitive to the discrepancies between the simulation and the real world, known as the sim-to-real gap. the application of domain randomization, a technique used to fill this gap, is limited to the imposition of heuristic-randomized models. we investigate the properties of intrinsic stochasticity of real-time simulation (rt-is) of off-the-shelf simulation software and its potential to improve the robustness of rl methods and the performance of domain randomization. firstly, we conduct analytical studies to measure the correlation of rt-is with the occupation of the computer hardware and validate its comparability with the natural stochasticity of a physical robot. then, we apply the rt-is feature in the training of an rl agent. the simulation and physical experiment results verify the feasibility and applicability of rt-is to robust rl agent design for robot manipulation tasks. the rt-is-powered robust rl agent outperforms conventional rl agents on robots with modeling uncertainties. it requires fewer heuristic randomization and achieves better generalizability than the conventional domain-randomization-powered agents. our findings provide a new perspective on the sim-to-real problem in practical applications like robot manipulation tasks.",,2023-04-12,,"['ram dershan', 'amir m. soufi enayati', 'zengjie zhang', 'dean richert', 'homayoun najjaran']",https://arxiv.org/pdf/2304.06056.pdf
919,2304.06059,efficient deep learning models for privacy-preserving people counting on   low-resolution infrared arrays,cs.cv cs.lg,"ultra-low-resolution infrared (ir) array sensors offer a low-cost, energy-efficient, and privacy-preserving solution for people counting, with applications such as occupancy monitoring. previous work has shown that deep learning (dl) can yield superior performance on this task. however, the literature was missing an extensive comparative analysis of various efficient dl architectures for ir array-based people counting, that considers not only their accuracy, but also the cost of deploying them on memory- and energy-constrained internet of things (iot) edge nodes. in this work, we address this need by comparing 6 different dl architectures on a novel dataset composed of ir images collected from a commercial 8x8 array, which we made openly available. with a wide architectural exploration of each model type, we obtain a rich set of pareto-optimal solutions, spanning cross-validated balanced accuracy scores in the 55.70-82.70% range. when deployed on a commercial microcontroller (mcu) by stmicroelectronics, the stm32l4a6zg, these models occupy 0.41-9.28kb of memory, and require 1.10-7.74ms per inference, while consuming 17.18-120.43 $\mu$j of energy. our models are significantly more accurate than a previous deterministic method (up to +39.9%), while being up to 3.53x faster and more energy efficient. further, our models' accuracy is comparable to state-of-the-art dl solutions on similar resolution sensors, despite a much lower complexity. all our models enable continuous, real-time inference on a mcu-based iot node, with years of autonomous operation without battery recharging.",10.1109/jiot.2023.3263290,2023-04-12,,"['chen xie', 'francesco daghero', 'yukai chen', 'marco castellano', 'luca gandolfi', 'andrea calimera', 'enrico macii', 'massimo poncino', 'daniele jahier pagliari']",https://arxiv.org/pdf/2304.06059.pdf
920,2304.06094,energy-guided entropic neural optimal transport,cs.lg stat.ml,"energy-based models (ebms) are known in the machine learning community for the decades. since the seminal works devoted to ebms dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). in contrast, the realm of optimal transport (ot) and, in particular, neural ot solvers is much less explored and limited by few recent works (excluding wgan based approaches which utilize ot as a loss function and do not model ot maps themselves). in our work, we bridge the gap between ebms and entropy-regularized ot. we present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. we validate the applicability of our method on toy 2d scenarios as well as standard unpaired image-to-image translation problems. for the sake of simplicity, we choose simple short- and long- run ebms as a backbone of our energy-guided entropic ot method, leaving the application of more sophisticated ebms for future research.",,2023-04-12,,"['petr mokrov', 'alexander korotin', 'evgeny burnaev']",https://arxiv.org/pdf/2304.06094.pdf
921,2304.06099,fast emulation of cosmological density fields based on dimensionality   reduction and supervised machine-learning,astro-ph.co astro-ph.im cs.lg,"n-body simulations are the most powerful method to study the non-linear evolution of large-scale structure. however, they require large amounts of computational resources, making unfeasible their direct adoption in scenarios that require broad explorations of parameter spaces. in this work, we show that it is possible to perform fast dark matter density field emulations with competitive accuracy using simple machine-learning approaches. we build an emulator based on dimensionality reduction and machine learning regression combining simple principal component analysis and supervised learning methods. for the estimations with a single free parameter, we train on the dark matter density parameter, $\omega_m$, while for emulations with two free parameters, we train on a range of $\omega_m$ and redshift. the method first adopts a projection of a grid of simulations on a given basis; then, a machine learning regression is trained on this projected grid. finally, new density cubes for different cosmological parameters can be estimated without relying directly on new n-body simulations by predicting and de-projecting the basis coefficients. we show that the proposed emulator can generate density cubes at non-linear cosmological scales with density distributions within a few percent compared to the corresponding n-body simulations. the method enables gains of three orders of magnitude in cpu run times compared to performing a full n-body simulation while reproducing the power spectrum and bispectrum within $\sim 1\%$ and $\sim 3\%$, respectively, for the single free parameter emulation and $\sim 5\%$ and $\sim 15\%$ for two free parameters. this can significantly accelerate the generation of density cubes for a wide variety of cosmological models, opening the doors to previously unfeasible applications, such as parameter and model inferences at full survey scales as the esa/nasa euclid mission.",,2023-04-12,,"['miguel concei√ß√£o', 'alberto krone-martins', 'antonio da silva', '√°ngeles molin√©']",https://arxiv.org/pdf/2304.06099.pdf
922,2304.06102,an analysis of how covid-19 shaped the realm of online gaming and lesson   delivery,cs.cy,"the covid-19 pandemic has forced schools and universities to adapt to remote learning, and online gaming has emerged as a tool for education. educational games can make learning fun and engaging, help students develop important skills like problem-solving and collaboration, and reach students who are struggling with traditional learning methods. while there are concerns about the potential drawbacks of online gaming in education, its benefits are clear. as the pandemic continues to disrupt education, online gaming is likely to become an increasingly important tool for teachers and students alike.",,2023-04-12,,"['yingwei cheng', 'nicholas milikich']",https://arxiv.org/pdf/2304.06102.pdf
923,2304.06103,$e(3) \times so(3)$-equivariant networks for spherical deconvolution in   diffusion mri,eess.iv cs.cv,"we present roto-translation equivariant spherical deconvolution (rt-esd), an $e(3)\times so(3)$ equivariant framework for sparse deconvolution of volumes where each voxel contains a spherical signal. such 6d data naturally arises in diffusion mri (dmri), a medical imaging modality widely used to measure microstructure and structural connectivity. as each dmri voxel is typically a mixture of various overlapping structures, there is a need for blind deconvolution to recover crossing anatomical structures such as white matter tracts. existing dmri work takes either an iterative or deep learning approach to sparse spherical deconvolution, yet it typically does not account for relationships between neighboring measurements. this work constructs equivariant deep learning layers which respect to symmetries of spatial rotations, reflections, and translations, alongside the symmetries of voxelwise spherical rotations. as a result, rt-esd improves on previous work across several tasks including fiber recovery on the disco dataset, deconvolution-derived partial volume estimation on real-world \textit{in vivo} human brain dmri, and improved downstream reconstruction of fiber tractograms on the tractometer dataset. our implementation is available at https://github.com/axelelaldi/e3so3_conv",,2023-04-12,,"['axel elaldi', 'guido gerig', 'neel dey']",https://arxiv.org/pdf/2304.06103.pdf
924,2304.06125,assessment framework for deepfake detection in real-world situations,cs.cv eess.iv,"detecting digital face manipulation in images and video has attracted extensive attention due to the potential risk to public trust. to counteract the malicious usage of such techniques, deep learning-based deepfake detection methods have been employed and have exhibited remarkable performance. however, the performance of such detectors is often assessed on related benchmarks that hardly reflect real-world situations. for example, the impact of various image and video processing operations and typical workflow distortions on detection accuracy has not been systematically measured. in this paper, a more reliable assessment framework is proposed to evaluate the performance of learning-based deepfake detectors in more realistic settings. to the best of our acknowledgment, it is the first systematic assessment approach for deepfake detectors that not only reports the general performance under real-world conditions but also quantitatively measures their robustness toward different processing operations. to demonstrate the effectiveness and usage of the framework, extensive experiments and detailed analysis of three popular deepfake detection methods are further presented in this paper. in addition, a stochastic degradation-based data augmentation method driven by realistic processing operations is designed, which significantly improves the robustness of deepfake detectors.",,2023-04-12,,"['yuhang lu', 'touradj ebrahimi']",https://arxiv.org/pdf/2304.06125.pdf
925,2304.06131,universeg: universal medical image segmentation,cs.cv cs.lg,"while deep learning models have become the predominant method for medical image segmentation, they are typically not capable of generalizing to unseen segmentation tasks involving new anatomies, image modalities, or labels. given a new segmentation task, researchers generally have to train or fine-tune models, which is time-consuming and poses a substantial barrier for clinical researchers, who often lack the resources and expertise to train neural networks. we present universeg, a method for solving unseen medical segmentation tasks without additional training. given a query image and example set of image-label pairs that define a new segmentation task, universeg employs a new cross-block mechanism to produce accurate segmentation maps without the need for additional training. to achieve generalization to new tasks, we have gathered and standardized a collection of 53 open-access medical segmentation datasets with over 22,000 scans, which we refer to as megamedical. we used this collection to train universeg on a diverse set of anatomies and imaging modalities. we demonstrate that universeg substantially outperforms several related methods on unseen tasks, and thoroughly analyze and draw insights about important aspects of the proposed system. the universeg source code and model weights are freely available at https://universeg.csail.mit.edu",,2023-04-12,,"['victor ion butoi', 'jose javier gonzalez ortiz', 'tianyu ma', 'mert r. sabuncu', 'john guttag', 'adrian v. dalca']",https://arxiv.org/pdf/2304.06131.pdf
926,2304.06133,towards evaluating explanations of vision transformers for medical   imaging,cs.cv cs.lg,"as deep learning models increasingly find applications in critical domains such as medical imaging, the need for transparent and trustworthy decision-making becomes paramount. many explainability methods provide insights into how these models make predictions by attributing importance to input features. as vision transformer (vit) becomes a promising alternative to convolutional neural networks for image classification, its interpretability remains an open research question. this paper investigates the performance of various interpretation methods on a vit applied to classify chest x-ray images. we introduce the notion of evaluating faithfulness, sensitivity, and complexity of vit explanations. the obtained results indicate that layerwise relevance propagation for transformers outperforms local interpretable model-agnostic explanations and attention visualization, providing a more accurate and reliable representation of what a vit has actually learned. our findings provide insights into the applicability of vit explanations in medical imaging and highlight the importance of using appropriate evaluation criteria for comparing them.",,2023-04-12,,"['piotr komorowski', 'hubert baniecki', 'przemys≈Çaw biecek']",https://arxiv.org/pdf/2304.06133.pdf
927,2304.06148,detection of fake generated scientific abstracts,cs.cl,"the widespread adoption of large language models and publicly available chatgpt has marked a significant turning point in the integration of artificial intelligence into people's everyday lives. the academic community has taken notice of these technological advancements and has expressed concerns regarding the difficulty of discriminating between what is real and what is artificially generated. thus, researchers have been working on developing effective systems to identify machine-generated text. in this study, we utilize the gpt-3 model to generate scientific paper abstracts through artificial intelligence and explore various text representation methods when combined with machine learning models with the aim of identifying machine-written text. we analyze the models' performance and address several research questions that rise during the analysis of the results. by conducting this research, we shed light on the capabilities and limitations of artificial intelligence generated text.",,2023-04-12,,"['panagiotis c. theocharopoulos', 'panagiotis anagnostou', 'anastasia tsoukala', 'spiros v. georgakopoulos', 'sotiris k. tasoulis', 'vassilis p. plagianakos']",https://arxiv.org/pdf/2304.06148.pdf
928,2304.06152,distributed gesture controlled systems for human-machine interface,eess.iv cs.hc cs.sy eess.sy,"this paper presents the design flow of an iot human machine touchless interface. the device uses embedded computing in conjunction with the leap motion controller to provide an accurate and intuitive touchless interface. its main function is to augment current touchscreen devices in public spaces through a combination of computer vision technology, event driven programming, and machine learning. especially following the covid 19 pandemic, this technology is important for hygiene and sanitation purposes for public devices such as airports, food, and atm kiosks where hundreds or even thousands of people may touch these devices in a single day. a prototype of the touchless interface was designed with a leap motion controller housed on a windows pc exchanging information with a raspberry pi microcontroller via internet connection.",10.1109/eit53891.2022.9813764,2023-04-12,,"['hans johnson', 'jafar saniie']",https://arxiv.org/pdf/2304.06152.pdf
929,2304.06160,learning robust and correct controllers from signal temporal logic   specifications using barriernet,eess.sy cs.lg cs.sy,"in this paper, we consider the problem of learning a neural network controller for a system required to satisfy a signal temporal logic (stl) specification. we exploit stl quantitative semantics to define a notion of robust satisfaction. guaranteeing the correctness of a neural network controller, i.e., ensuring the satisfaction of the specification by the controlled system, is a difficult problem that received a lot of attention recently. we provide a general procedure to construct a set of trainable high order control barrier functions (hocbfs) enforcing the satisfaction of formulas in a fragment of stl. we use the barriernet, implemented by a differentiable quadratic program (dqp) with hocbf constraints, as the last layer of the neural network controller, to guarantee the satisfaction of the stl formulas. we train the hocbfs together with other neural network parameters to further improve the robustness of the controller. simulation results demonstrate that our approach ensures satisfaction and outperforms existing algorithms.",,2023-04-12,,"['wenliang liu', 'wei xiao', 'calin belta']",https://arxiv.org/pdf/2304.06160.pdf
930,2304.06169,neural network algorithm for intercepting targets moving along known   trajectories by a dubins' car,math.oc cs.ai,"the task of intercepting a target moving along a rectilinear or circular trajectory by a dubins' car is formulated as a time-optimal control problem with an arbitrary direction of the car's velocity at the interception moment. to solve this problem and to synthesize interception trajectories, neural network methods of unsupervised learning based on the deep deterministic policy gradient algorithm are used. the analysis of the obtained control laws and interception trajectories in comparison with the analytical solutions of the interception problem is performed. the mathematical modeling for the parameters of the target movement that the neural network had not seen before during training is carried out. model experiments are conducted to test the stability of the neural solution. the effectiveness of using neural network methods for the synthesis of interception trajectories for given classes of target movements is shown.",10.25728/arcras.2023.21.74.001,2023-04-12,,"['ivan nasonov', 'andrey galyaev', 'andrey medvedev']",https://arxiv.org/pdf/2304.06169.pdf
931,2304.06177,visual based tomato size measurement system for an indoor farming   environment,cs.cv cs.ai,"as technology progresses, smart automated systems will serve an increasingly important role in the agricultural industry. current existing vision systems for yield estimation face difficulties in occlusion and scalability as they utilize a camera system that is large and expensive, which are unsuitable for orchard environments. to overcome these problems, this paper presents a size measurement method combining a machine learning model and depth images captured from three low cost rgbd cameras to detect and measure the height and width of tomatoes. the performance of the presented system is evaluated on a lab environment with real tomato fruits and fake leaves to simulate occlusion in the real farm environment. to improve accuracy by addressing fruit occlusion, our three-camera system was able to achieve a height measurement accuracy of 0.9114 and a width accuracy of 0.9443.",,2023-04-12,,"['andy kweon', 'vishnu hu', 'jong yoon lim', 'trevor gee', 'edmond liu', 'henry williams', 'bruce a. macdonald', 'mahla nejati', 'inkyu sa', 'ho seok ahn']",https://arxiv.org/pdf/2304.06177.pdf
932,2304.06184,lingo : visually debiasing natural language instructions to support task   diversity,cs.hc cs.cl,"cross-task generalization is a significant outcome that defines mastery in natural language understanding. humans show a remarkable aptitude for this, and can solve many different types of tasks, given definitions in the form of textual instructions and a small set of examples. recent work with pre-trained language models mimics this learning style: users can define and exemplify a task for the model to attempt as a series of natural language prompts or instructions. while prompting approaches have led to higher cross-task generalization compared to traditional supervised learning, analyzing 'bias' in the task instructions given to the model is a difficult problem, and has thus been relatively unexplored. for instance, are we truly modeling a task, or are we modeling a user's instructions? to help investigate this, we develop lingo, a novel visual analytics interface that supports an effective, task-driven workflow to (1) help identify bias in natural language task instructions, (2) alter (or create) task instructions to reduce bias, and (3) evaluate pre-trained model performance on debiased task instructions. to robustly evaluate lingo, we conduct a user study with both novice and expert instruction creators, over a dataset of 1,616 linguistic tasks and their natural language instructions, spanning 55 different languages. for both user groups, lingo promotes the creation of more difficult tasks for pre-trained models, that contain higher linguistic diversity and lower instruction bias. we additionally discuss how the insights learned in developing and evaluating lingo can aid in the design of future dashboards that aim to minimize the effort involved in prompt creation across multiple domains.",,2023-04-12,,"['anjana arunkumar', 'shubham sharma', 'rakhi agrawal', 'sriram chandrasekaran', 'chris bryan']",https://arxiv.org/pdf/2304.06184.pdf
933,2304.06193,learning over all contracting and lipschitz closed-loops for   partially-observed nonlinear systems,eess.sy cs.lg cs.sy math.oc,"this paper presents a policy parameterization for learning-based control on nonlinear, partially-observed dynamical systems. the parameterization is based on a nonlinear version of the youla parameterization and the recently proposed recurrent equilibrium network (ren) class of models. we prove that the resulting youla-ren parameterization automatically satisfies stability (contraction) and user-tunable robustness (lipschitz) conditions on the closed-loop system. this means it can be used for safe learning-based control with no additional constraints or projections required to enforce stability or robustness. we test the new policy class in simulation on two reinforcement learning tasks: 1) magnetic suspension, and 2) inverting a rotary-arm pendulum. we find that the youla-ren performs similarly to existing learning-based and optimal control methods while also ensuring stability and exhibiting improved robustness to adversarial disturbances.",,2023-04-12,,"['nicholas h. barbara', 'ruigang wang', 'ian r. manchester']",https://arxiv.org/pdf/2304.06193.pdf
934,2304.06194,silk -- simple learned keypoints,cs.cv,"keypoint detection & descriptors are foundational tech-nologies for computer vision tasks like image matching, 3d reconstruction and visual odometry. hand-engineered methods like harris corners, sift, and hog descriptors have been used for decades; more recently, there has been a trend to introduce learning in an attempt to improve keypoint detectors. on inspection however, the results are difficult to interpret; recent learning-based methods employ a vast diversity of experimental setups and design choices: empirical results are often reported using different backbones, protocols, datasets, types of supervisions or tasks. since these differences are often coupled together, it raises a natural question on what makes a good learned keypoint detector. in this work, we revisit the design of existing keypoint detectors by deconstructing their methodologies and identifying the key components. we re-design each component from first-principle and propose simple learned keypoints (silk) that is fully-differentiable, lightweight, and flexible. despite its simplicity, silk advances new state-of-the-art on detection repeatability and homography estimation tasks on hpatches and 3d point-cloud registration task on scannet, and achieves competitive performance to state-of-the-art on camera pose estimation in 2022 image matching challenge and scannet.",,2023-04-12,,"['pierre gleize', 'weiyao wang', 'matt feiszli']",https://arxiv.org/pdf/2304.06194.pdf
935,2304.06197,surfsup: learning fluid simulation for novel surfaces,cs.lg physics.flu-dyn,"modeling the mechanics of fluid in complex scenes is vital to applications in design, graphics, and robotics. learning-based methods provide fast and differentiable fluid simulators, however most prior work is unable to accurately model how fluids interact with genuinely novel surfaces not seen during training. we introduce surfsup, a framework that represents objects implicitly using signed distance functions (sdfs), rather than an explicit representation of meshes or particles. this continuous representation of geometry enables more accurate simulation of fluid-object interactions over long time periods while simultaneously making computation more efficient. moreover, surfsup trained on simple shape primitives generalizes considerably out-of-distribution, even to complex real-world scenes and objects. finally, we show we can invert our model to design simple objects to manipulate fluid flow.",,2023-04-12,,"['arjun mani', 'ishaan preetam chandratreya', 'elliot creager', 'carl vondrick', 'richard zemel']",https://arxiv.org/pdf/2304.06197.pdf
936,2304.06203,leafai: query generator for clinical cohort discovery rivaling a human   programmer,cs.cl,"objective: identifying study-eligible patients within clinical databases is a critical step in clinical research. however, accurate query design typically requires extensive technical and biomedical expertise. we sought to create a system capable of generating data model-agnostic queries while also providing novel logical reasoning capabilities for complex clinical trial eligibility criteria.   materials and methods: the task of query creation from eligibility criteria requires solving several text-processing problems, including named entity recognition and relation extraction, sequence-to-sequence transformation, normalization, and reasoning. we incorporated hybrid deep learning and rule-based modules for these, as well as a knowledge base of the unified medical language system (umls) and linked ontologies. to enable data-model agnostic query creation, we introduce a novel method for tagging database schema elements using umls concepts. to evaluate our system, called leafai, we compared the capability of leafai to a human database programmer to identify patients who had been enrolled in 8 clinical trials conducted at our institution. we measured performance by the number of actual enrolled patients matched by generated queries.   results: leafai matched a mean 43% of enrolled patients with 27,225 eligible across 8 clinical trials, compared to 27% matched and 14,587 eligible in queries by a human database programmer. the human programmer spent 26 total hours crafting queries compared to several minutes by leafai.   conclusions: our work contributes a state-of-the-art data model-agnostic query generation system capable of conditional reasoning using a knowledge base. we demonstrate that leafai can rival a human programmer in finding patients eligible for clinical trials.",,2023-04-12,,"['nicholas j dobbins', 'bin han', 'weipeng zhou', 'kristine lan', 'h. nina kim', 'robert harrington', 'ozlem uzuner', 'meliha yetisgen']",https://arxiv.org/pdf/2304.06203.pdf
937,2304.06211,boosting video object segmentation via space-time correspondence   learning,cs.cv,"current top-leading solutions for video object segmentation (vos) typically follow a matching-based regime: for each query frame, the segmentation mask is inferred according to its correspondence to previously processed and the first annotated frames. they simply exploit the supervisory signals from the groundtruth masks for learning mask prediction only, without posing any constraint on the space-time correspondence matching, which, however, is the fundamental building block of such regime. to alleviate this crucial yet commonly ignored issue, we devise a correspondence-aware training framework, which boosts matching-based vos solutions by explicitly encouraging robust correspondence matching during network learning. through comprehensively exploring the intrinsic coherence in videos on pixel and object levels, our algorithm reinforces the standard, fully supervised training of mask segmentation with label-free, contrastive correspondence learning. without neither requiring extra annotation cost during training, nor causing speed delay during deployment, nor incurring architectural modification, our algorithm provides solid performance gains on four widely used benchmarks, i.e., davis2016&2017, and youtube-vos2018&2019, on the top of famous matching-based vos solutions.",,2023-04-12,,"['yurong zhang', 'liulei li', 'wenguan wang', 'rong xie', 'li song', 'wenjun zhang']",https://arxiv.org/pdf/2304.06211.pdf
938,2304.06227,quasi real-time autonomous satellite detection and orbit estimation,astro-ph.im cs.ro,"a method of near real-time detection and tracking of resident space objects (rsos) using a convolutional neural network (cnn) and linear quadratic estimator (lqe) is proposed. advances in machine learning architecture allow the use of low-power/cost embedded devices to perform complex classification tasks. in order to reduce the costs of tracking systems, a low-cost embedded device will be used to run a cnn detection model for rsos in unresolved images captured by a gray-scale camera and small telescope. detection results computed in near real-time are then passed to an lqe to compute tracking updates for the telescope mount, resulting in a fully autonomous method of optical rso detection and tracking. keywords: space domain awareness, neural networks, real-time, object detection, embedded systems.",,2023-04-12,,"['jarred jordan', 'daniel posada', 'matthew gillette', 'david zuehlke', 'troy henderson']",https://arxiv.org/pdf/2304.06227.pdf
939,2304.06233,situational-aware multi-graph convolutional recurrent network (sa-mgcrn)   for travel demand forecasting during wildfires,cs.lg,"real-time forecasting of travel demand during wildfire evacuations is crucial for emergency managers and transportation planners to make timely and better-informed decisions. however, few studies focus on accurate travel demand forecasting in large-scale emergency evacuations. therefore, this study develops and tests a new methodological framework for modeling trip generation in wildfire evacuations by using (a) large-scale gps data generated by mobile devices and (b) state-of-the-art ai technologies. the proposed methodology aims at forecasting evacuation trips and other types of trips. based on the travel demand inferred from the gps data, we develop a new deep learning model, i.e., situational-aware multi-graph convolutional recurrent network (sa-mgcrn), along with a model updating scheme to achieve real-time forecasting of travel demand during wildfire evacuations. the proposed methodological framework is tested in this study for a real-world case study: the 2019 kincade fire in sonoma county, ca. the results show that sa-mgcrn significantly outperforms all the selected state-of-the-art benchmarks in terms of prediction performance. our finding suggests that the most important model components of sa-mgcrn are evacuation order/warning information, proximity to fire, and population change, which are consistent with behavioral theories and empirical findings.",,2023-04-12,,"['xiaojian zhang', 'xilei zhao', 'yiming xu', 'ruggiero lovreglio', 'daniel nilsson']",https://arxiv.org/pdf/2304.06233.pdf
940,2304.06234,physics-informed radial basis network (pirbn): a local approximation   neural network for solving nonlinear pdes,cs.lg,"our recent intensive study has found that physics-informed neural networks (pinn) tend to be local approximators after training. this observation leads to this novel physics-informed radial basis network (pirbn), which can maintain the local property throughout the entire training process. compared to deep neural networks, a pirbn comprises of only one hidden layer and a radial basis ""activation"" function. under appropriate conditions, we demonstrated that the training of pirbns using gradient descendent methods can converge to gaussian processes. besides, we studied the training dynamics of pirbn via the neural tangent kernel (ntk) theory. in addition, comprehensive investigations regarding the initialisation strategies of pirbn were conducted. based on numerical examples, pirbn has been demonstrated to be more effective and efficient than pinn in solving pdes with high-frequency features and ill-posed computational domains. moreover, the existing pinn numerical techniques, such as adaptive learning, decomposition and different types of loss functions, are applicable to pirbn. the programs that can regenerate all numerical results can be found at https://github.com/jinshuaibai/pirbn.",,2023-04-12,,"['jinshuai bai', 'gui-rong liu', 'ashish gupta', 'laith alzubaidi', 'xi-qiao feng', 'yuantong gu']",https://arxiv.org/pdf/2304.06234.pdf
941,2304.06237,an arrhythmia classification-guided segmentation model for   electrocardiogram delineation,cs.lg eess.sp,"accurate delineation of key waveforms in an ecg is a critical initial step in extracting relevant features to support the diagnosis and treatment of heart conditions. although deep learning based methods using a segmentation model to locate p, qrs and t waves have shown promising results, their ability to handle signals exhibiting arrhythmia remains unclear. in this study, we propose a novel approach that leverages a deep learning model to accurately delineate signals with a wide range of arrhythmia. our approach involves training a segmentation model using a hybrid loss function that combines segmentation with the task of arrhythmia classification. in addition, we use a diverse training set containing various arrhythmia types, enabling our model to handle a wide range of challenging cases. experimental results show that our model accurately delineates signals with a broad range of abnormal rhythm types, and the combined training with classification guidance can effectively reduce false positive p wave predictions, particularly during atrial fibrillation and atrial flutter. furthermore, our proposed method shows competitive performance with previous delineation algorithms on the lobachevsky university database (ludb).",,2023-04-12,,"['chankyu joung', 'mijin kim', 'taejin paik', 'seong-ho kong', 'seung-young oh', 'won kyeong jeon', 'jae-hu jeon', 'joong-sik hong', 'wan-joong kim', 'woong kook', 'myung-jin cha', 'otto van koert']",https://arxiv.org/pdf/2304.06237.pdf
942,2304.06247,shapeclipper: scalable 3d shape learning from single-view images via   geometric and clip-based consistency,cs.cv,"we present shapeclipper, a novel method that reconstructs 3d object shapes from real-world single-view rgb images. instead of relying on laborious 3d, multi-view or camera pose annotation, shapeclipper learns shape reconstruction from a set of single-view segmented images. the key idea is to facilitate shape learning via clip-based shape consistency, where we encourage objects with similar clip encodings to share similar shapes. we also leverage off-the-shelf normals as an additional geometric constraint so the model can learn better bottom-up reasoning of detailed surface geometry. these two novel consistency constraints, when used to regularize our model, improve its ability to learn both global shape structure and local geometric details. we evaluate our method over three challenging real-world datasets, pix3d, pascal3d+, and openimages, where we achieve superior performance over state-of-the-art methods.",,2023-04-12,,"['zixuan huang', 'varun jampani', 'anh thai', 'yuanzhen li', 'stefan stojanov', 'james m. rehg']",https://arxiv.org/pdf/2304.06247.pdf
943,2304.06253,enhancing model learning and interpretation using multiple molecular   graph representations for compound property and activity prediction,q-bio.bm cs.lg q-bio.mn,"graph neural networks (gnns) demonstrate great performance in compound property and activity prediction due to their capability to efficiently learn complex molecular graph structures. however, two main limitations persist including compound representation and model interpretability. while atom-level molecular graph representations are commonly used because of their ability to capture natural topology, they may not fully express important substructures or functional groups which significantly influence molecular properties. consequently, recent research proposes alternative representations employing reduction techniques to integrate higher-level information and leverages both representations for model learning. however, there is still a lack of study about different molecular graph representations on model learning and interpretation. interpretability is also crucial for drug discovery as it can offer chemical insights and inspiration for optimization. numerous studies attempt to include model interpretation to explain the rationale behind predictions, but most of them focus solely on individual prediction with little analysis of the interpretation on different molecular graph representations. this research introduces multiple molecular graph representations that incorporate higher-level information and investigates their effects on model learning and interpretation from diverse perspectives. the results indicate that combining atom graph representation with reduced molecular graph representation can yield promising model performance. furthermore, the interpretation results can provide significant features and potential substructures consistently aligning with background knowledge. these multiple molecular graph representations and interpretation analysis can bolster model comprehension and facilitate relevant applications in drug discovery.",,2023-04-13,,"['apakorn kengkanna', 'masahito ohue']",https://arxiv.org/pdf/2304.06253.pdf
944,2304.06254,fair grading algorithms for randomized exams,stat.ml cs.gt,"this paper studies grading algorithms for randomized exams. in a randomized exam, each student is asked a small number of random questions from a large question bank. the predominant grading rule is simple averaging, i.e., calculating grades by averaging scores on the questions each student is asked, which is fair ex-ante, over the randomized questions, but not fair ex-post, on the realized questions. the fair grading problem is to estimate the average grade of each student on the full question bank. the maximum-likelihood estimator for the bradley-terry-luce model on the bipartite student-question graph is shown to be consistent with high probability when the number of questions asked to each student is at least the cubed-logarithm of the number of students. in an empirical study on exam data and in simulations, our algorithm based on the maximum-likelihood estimator significantly outperforms simple averaging in prediction accuracy and ex-post fairness even with a small class and exam size.",,2023-04-13,,"['jiale chen', 'jason hartline', 'onno zoeter']",https://arxiv.org/pdf/2304.06254.pdf
945,2304.06258,mprotonet: a case-based interpretable model for brain tumor   classification with 3d multi-parametric magnetic resonance imaging,cs.cv cs.lg eess.iv,"recent applications of deep convolutional neural networks in medical imaging raise concerns about their interpretability. while most explainable deep learning applications use post hoc methods (such as gradcam) to generate feature attribution maps, there is a new type of case-based reasoning models, namely protopnet and its variants, which identify prototypes during training and compare input image patches with those prototypes. we propose the first medical prototype network (mprotonet) to extend protopnet to brain tumor classification with 3d multi-parametric magnetic resonance imaging (mpmri) data. to address different requirements between 2d natural images and 3d mpmris especially in terms of localizing attention regions, a new attention module with soft masking and online-cam loss is introduced. soft masking helps sharpen attention maps, while online-cam loss directly utilizes image-level labels when training the attention module. mprotonet achieves statistically significant improvements in interpretability metrics of both correctness and localization coherence (with a best activation precision of $0.713\pm0.058$) without human-annotated labels during training, when compared with gradcam and several protopnet variants. the source code is available at https://github.com/aywi/mprotonet.",,2023-04-13,,"['yuanyuan wei', 'roger tam', 'xiaoying tang']",https://arxiv.org/pdf/2304.06258.pdf
946,2304.06270,gamifying math education using object detection,cs.cv,"manipulatives used in the right way help improve mathematical concepts leading to better learning outcomes. in this paper, we present a phygital (physical + digital) curriculum inspired teaching system for kids aged 5-8 to learn geometry using shape tile manipulatives. combining smaller shapes to form larger ones is an important skill kids learn early on which requires shape tiles to be placed close to each other in the play area. this introduces a challenge of oriented object detection for densely packed objects with arbitrary orientations. leveraging simulated data for neural network training and light-weight mobile architectures, we enable our system to understand user interactions and provide real-time audiovisual feedback. experimental results show that our network runs real-time with high precision/recall on consumer devices, thereby providing a consistent and enjoyable learning experience.",,2023-04-13,,"['yueqiu sun', 'rohitkrishna nambiar', 'vivek vidyasagaran']",https://arxiv.org/pdf/2304.06270.pdf
947,2304.06275,noisy correspondence learning with meta similarity correction,cs.cv cs.mm,"despite the success of multimodal learning in cross-modal retrieval task, the remarkable progress relies on the correct correspondence among multimedia data. however, collecting such ideal data is expensive and time-consuming. in practice, most widely used datasets are harvested from the internet and inevitably contain mismatched pairs. training on such noisy correspondence datasets causes performance degradation because the cross-modal retrieval methods can wrongly enforce the mismatched data to be similar. to tackle this problem, we propose a meta similarity correction network (mscn) to provide reliable similarity scores. we view a binary classification task as the meta-process that encourages the mscn to learn discrimination from positive and negative meta-data. to further alleviate the influence of noise, we design an effective data purification strategy using meta-data as prior knowledge to remove the noisy samples. extensive experiments are conducted to demonstrate the strengths of our method in both synthetic and real-world noises, including flickr30k, ms-coco, and conceptual captions.",,2023-04-13,,"['haochen han', 'kaiyao miao', 'qinghua zheng', 'minnan luo']",https://arxiv.org/pdf/2304.06275.pdf
948,2304.06277,optimizing multi-domain performance with active learning-based   improvement strategies,cs.lg cs.ai cs.cv,"improving performance in multiple domains is a challenging task, and often requires significant amounts of data to train and test models. active learning techniques provide a promising solution by enabling models to select the most informative samples for labeling, thus reducing the amount of labeled data required to achieve high performance. in this paper, we present an active learning-based framework for improving performance across multiple domains. our approach consists of two stages: first, we use an initial set of labeled data to train a base model, and then we iteratively select the most informative samples for labeling to refine the model. we evaluate our approach on several multi-domain datasets, including image classification, sentiment analysis, and object recognition. our experiments demonstrate that our approach consistently outperforms baseline methods and achieves state-of-the-art performance on several datasets. we also show that our method is highly efficient, requiring significantly fewer labeled samples than other active learning-based methods. overall, our approach provides a practical and effective solution for improving performance across multiple domains using active learning techniques.",,2023-04-13,,"['anand gokul mahalingam', 'aayush shah', 'akshay gulati', 'royston mascarenhas', 'rakshitha panduranga']",https://arxiv.org/pdf/2304.06277.pdf
949,2304.06281,model-based dynamic shielding for safe and efficient multi-agent   reinforcement learning,cs.lg cs.ai cs.ma cs.ro,"multi-agent reinforcement learning (marl) discovers policies that maximize reward but do not have safety guarantees during the learning and deployment phases. although shielding with linear temporal logic (ltl) is a promising formal method to ensure safety in single-agent reinforcement learning (rl), it results in conservative behaviors when scaling to multi-agent scenarios. additionally, it poses computational challenges for synthesizing shields in complex multi-agent environments. this work introduces model-based dynamic shielding (mbds) to support marl algorithm design. our algorithm synthesizes distributive shields, which are reactive systems running in parallel with each marl agent, to monitor and rectify unsafe behaviors. the shields can dynamically split, merge, and recompute based on agents' states. this design enables efficient synthesis of shields to monitor agents in complex environments without coordination overheads. we also propose an algorithm to synthesize shields without prior knowledge of the dynamics model. the proposed algorithm obtains an approximate world model by interacting with the environment during the early stage of exploration, making our mbds enjoy formal safety guarantees with high probability. we demonstrate in simulations that our framework can surpass existing baselines in terms of safety guarantees and learning performance.",,2023-04-13,,"['wenli xiao', 'yiwei lyu', 'john dolan']",https://arxiv.org/pdf/2304.06281.pdf
950,2304.06286,converting ecg signals to images for efficient image-text retrieval via   encoding,eess.sp cs.cv,"automated interpretation of electrocardiograms (ecg) has garnered significant attention with the advancements in machine learning methodologies. despite the growing interest in automated ecg interpretation using machine learning, most current studies focus solely on classification or regression tasks and overlook a crucial aspect of clinical cardio-disease diagnosis: the diagnostic report generated by experienced human clinicians. in this paper, we introduce a novel approach to ecg interpretation, leveraging recent breakthroughs in large language models (llms) and vision-transformer (vit) models. rather than treating ecg diagnosis as a classification or regression task, we propose an alternative method of automatically identifying the most similar clinical cases based on the input ecg data. also, since interpreting ecg as images are more affordable and accessible, we process ecg as encoded images and adopt a vision-language learning paradigm to jointly learn vision-language alignment between encoded ecg images and ecg diagnosis reports. encoding ecg into images can result in an efficient ecg retrieval system, which will be highly practical and useful in clinical applications. more importantly, our findings could serve as a crucial resource for providing diagnostic services in regions where only paper-printed ecg images are accessible due to past underdevelopment.",,2023-04-13,,"['jielin qiu', 'jiacheng zhu', 'shiqi liu', 'william han', 'jingqi zhang', 'chaojing duan', 'michael rosenberg', 'emerson liu', 'douglas weber', 'ding zhao']",https://arxiv.org/pdf/2304.06286.pdf
951,2304.06287,nerfvs: neural radiance fields for free view synthesis via geometry   scaffolds,cs.cv cs.ai,"we present nerfvs, a novel neural radiance fields (nerf) based method to enable free navigation in a room. nerf achieves impressive performance in rendering images for novel views similar to the input views while suffering for novel views that are significantly different from the training views. to address this issue, we utilize the holistic priors, including pseudo depth maps and view coverage information, from neural reconstruction to guide the learning of implicit neural representations of 3d indoor scenes. concretely, an off-the-shelf neural reconstruction method is leveraged to generate a geometry scaffold. then, two loss functions based on the holistic priors are proposed to improve the learning of nerf: 1) a robust depth loss that can tolerate the error of the pseudo depth map to guide the geometry learning of nerf; 2) a variance loss to regularize the variance of implicit neural representations to reduce the geometry and color ambiguity in the learning procedure. these two loss functions are modulated during nerf optimization according to the view coverage information to reduce the negative influence brought by the view coverage imbalance. extensive results demonstrate that our nerfvs outperforms state-of-the-art view synthesis methods quantitatively and qualitatively on indoor scenes, achieving high-fidelity free navigation results.",,2023-04-13,,"['chen yang', 'peihao li', 'zanwei zhou', 'shanxin yuan', 'bingbing liu', 'xiaokang yang', 'weichao qiu', 'wei shen']",https://arxiv.org/pdf/2304.06287.pdf
952,2304.06306,efficient multimodal fusion via interactive prompting,cs.cv,"large-scale pre-training has brought unimodal fields such as computer vision and natural language processing to a new era. following this trend, the size of multi-modal learning models constantly increases, leading to an urgent need to reduce the massive computational cost of finetuning these models for downstream tasks. in this paper, we propose an efficient and flexible multimodal fusion method, namely pmf, tailored for fusing unimodally pre-trained transformers. specifically, we first present a modular multimodal fusion framework that exhibits high flexibility and facilitates mutual interactions among different modalities. in addition, we disentangle vanilla prompts into three types in order to learn different optimizing objectives for multimodal learning. it is also worth noting that we propose to add prompt vectors only on the deep layers of the unimodal transformers, thus significantly reducing the training memory usage. experiment results show that our proposed method achieves comparable performance to several other multimodal finetuning methods with less than 3% trainable parameters and up to 66% saving of training memory usage.",,2023-04-13,,"['yaowei li', 'ruijie quan', 'linchao zhu', 'yi yang']",https://arxiv.org/pdf/2304.06306.pdf
953,2304.06309,out-of-distribution few-shot learning for edge devices without model   fine-tuning,cs.cv,"few-shot learning (fsl) via customization of a deep learning network with limited data has emerged as a promising technique to achieve personalized user experiences on edge devices. however, existing fsl methods primarily assume independent and identically distributed (iid) data and utilize either computational backpropagation updates for each task or a common model with task-specific prototypes. unfortunately, the former solution is infeasible for edge devices that lack on-device backpropagation capabilities, while the latter often struggles with limited generalization ability, especially for out-of-distribution (ood) data. this paper proposes a lightweight, plug-and-play fsl module called task-aware normalization (tano) that enables efficient and task-aware adaptation of a deep neural network without backpropagation. tano covers the properties of multiple user groups by coordinating the updates of several groups of the normalization statistics during meta-training and automatically identifies the appropriate normalization group for a downstream few-shot task. consequently, tano provides stable but task-specific estimations of the normalization statistics to close the distribution gaps and achieve efficient model adaptation. results on both intra-domain and out-of-domain generalization experiments demonstrate that tano outperforms recent methods in terms of accuracy, inference speed, and model size. moreover, tano achieves promising results on widely-used fsl benchmarks and data from real applications.",,2023-04-13,,"['xinyun zhang', 'lanqing hong']",https://arxiv.org/pdf/2304.06309.pdf
954,2304.06326,understanding overfitting in adversarial training in kernel regression,stat.ml cs.lg math.st stat.th,"adversarial training and data augmentation with noise are widely adopted techniques to enhance the performance of neural networks. this paper investigates adversarial training and data augmentation with noise in the context of regularized regression in a reproducing kernel hilbert space (rkhs). we establish the limiting formula for these techniques as the attack and noise size, as well as the regularization parameter, tend to zero. based on this limiting formula, we analyze specific scenarios and demonstrate that, without appropriate regularization, these two methods may have larger generalization error and lipschitz constant than standard kernel regression. however, by selecting the appropriate regularization parameter, these two methods can outperform standard kernel regression and achieve smaller generalization error and lipschitz constant. these findings support the empirical observations that adversarial training can lead to overfitting, and appropriate regularization methods, such as early stopping, can alleviate this issue.",,2023-04-13,,"['teng zhang', 'kang li']",https://arxiv.org/pdf/2304.06326.pdf
955,2304.06327,an automotive case study on the limits of approximation for object   detection,cs.ar,"the accuracy of camera-based object detection (cbod) built upon deep learning is often evaluated against the real objects in frames only. however, such simplistic evaluation ignores the fact that many unimportant objects are small, distant, or background, and hence, their misdetections have less impact than those for closer, larger, and foreground objects in domains such as autonomous driving. moreover, sporadic misdetections are irrelevant since confidence on detections is typically averaged across consecutive frames, and detection devices (e.g. cameras, lidars) are often redundant, thus providing fault tolerance.   this paper exploits such intrinsic fault tolerance of the cbod process, and assesses in an automotive case study to what extent cbod can tolerate approximation coming from multiple sources such as lower precision arithmetic, approximate arithmetic units, and even random faults due to, for instance, low voltage operation. we show that the accuracy impact of those sources of approximation is within 1% of the baseline even when considering the three approximate domains simultaneously, and hence, multiple sources of approximation can be exploited to build highly efficient accelerators for cbod in cars.",10.1016/j.sysarc.2023.102872,2023-04-13,,"['mart√≠ caro', 'hamid tabani', 'jaume abella', 'francesc moll', 'enric morancho', 'ramon canal', 'josep altet', 'antonio calomarde', 'francisco j. cazorla', 'antonio rubio', 'pau fontova', 'jordi fornt']",https://arxiv.org/pdf/2304.06327.pdf
956,2304.06335,deep learning-based fall detection algorithm using ensemble model of   coarse-fine cnn and gru networks,cs.lg eess.sp,"falls are the public health issue for the elderly all over the world since the fall-induced injuries are associated with a large amount of healthcare cost. falls can cause serious injuries, even leading to death if the elderly suffers a ""long-lie"". hence, a reliable fall detection (fd) system is required to provide an emergency alarm for first aid. due to the advances in wearable device technology and artificial intelligence, some fall detection systems have been developed using machine learning and deep learning methods to analyze the signal collected from accelerometer and gyroscopes. in order to achieve better fall detection performance, an ensemble model that combines a coarse-fine convolutional neural network and gated recurrent unit is proposed in this study. the parallel structure design used in this model restores the different grains of spatial characteristics and capture temporal dependencies for feature representation. this study applies the fallalld public dataset to validate the reliability of the proposed model, which achieves a recall, precision, and f-score of 92.54%, 96.13%, and 94.26%, respectively. the results demonstrate the reliability of the proposed ensemble model in discriminating falls from daily living activities and its superior performance compared to the state-of-the-art convolutional neural network long short-term memory (cnn-lstm) for fd.",,2023-04-13,,"['chien-pin liu', 'ju-hsuan li', 'en-ping chu', 'chia-yeh hsieh', 'kai-chun liu', 'chia-tai chan', 'yu tsao']",https://arxiv.org/pdf/2304.06335.pdf
957,2304.06336,attributed multi-order graph convolutional network for heterogeneous   graphs,cs.lg cs.ai,"heterogeneous graph neural networks aim to discover discriminative node embeddings and relations from multi-relational networks.one challenge of heterogeneous graph learning is the design of learnable meta-paths, which significantly influences the quality of learned embeddings.thus, in this paper, we propose an attributed multi-order graph convolutional network (amogcn), which automatically studies meta-paths containing multi-hop neighbors from an adaptive aggregation of multi-order adjacency matrices. the proposed model first builds different orders of adjacency matrices from manually designed node connections. after that, an intact multi-order adjacency matrix is attached from the automatic fusion of various orders of adjacency matrices. this process is supervised by the node semantic information, which is extracted from the node homophily evaluated by attributes. eventually, we utilize a one-layer simplifying graph convolutional network with the learned multi-order adjacency matrix, which is equivalent to the cross-hop node information propagation with multi-layer graph neural networks. substantial experiments reveal that amogcn gains superior semi-supervised classification performance compared with state-of-the-art competitors.",,2023-04-13,,"['zhaoliang chen', 'zhihao wu', 'luying zhong', 'claudia plant', 'shiping wang', 'wenzhong guo']",https://arxiv.org/pdf/2304.06336.pdf
958,2304.06342,rosi: recovering 3d shape interiors from few articulation images,cs.cv cs.gr,"the dominant majority of 3d models that appear in gaming, vr/ar, and those we use to train geometric deep learning algorithms are incomplete, since they are modeled as surface meshes and missing their interior structures. we present a learning framework to recover the shape interiors (rosi) of existing 3d models with only their exteriors from multi-view and multi-articulation images. given a set of rgb images that capture a target 3d object in different articulated poses, possibly from only few views, our method infers the interior planes that are observable in the input images. our neural architecture is trained in a category-agnostic manner and it consists of a motion-aware multi-view analysis phase including pose, depth, and motion estimations, followed by interior plane detection in images and 3d space, and finally multi-view plane fusion. in addition, our method also predicts part articulations and is able to realize and even extrapolate the captured motions on the target 3d object. we evaluate our method by quantitative and qualitative comparisons to baselines and alternative solutions, as well as testing on untrained object categories and real image inputs to assess its generalization capabilities.",,2023-04-13,,"['akshay gadi patil', 'yiming qian', 'shan yang', 'brian jackson', 'eric bennett', 'hao zhang']",https://arxiv.org/pdf/2304.06342.pdf
959,2304.06345,asr: attention-alike structural re-parameterization,cs.cv cs.ai,"the structural re-parameterization (srp) technique is a novel deep learning technique that achieves interconversion between different network architectures through equivalent parameter transformations. this technique enables the mitigation of the extra costs for performance improvement during training, such as parameter size and inference time, through these transformations during inference, and therefore srp has great potential for industrial and practical applications. the existing srp methods have successfully considered many commonly used architectures, such as normalizations, pooling methods, multi-branch convolution. however, the widely used self-attention modules cannot be directly implemented by srp due to these modules usually act on the backbone network in a multiplicative manner and the modules' output is input-dependent during inference, which limits the application scenarios of srp. in this paper, we conduct extensive experiments from a statistical perspective and discover an interesting phenomenon stripe observation, which reveals that channel attention values quickly approach some constant vectors during training. this observation inspires us to propose a simple-yet-effective attention-alike structural re-parameterization (asr) that allows us to achieve srp for a given network while enjoying the effectiveness of the self-attention mechanism. extensive experiments conducted on several standard benchmarks demonstrate the effectiveness of asr in generally improving the performance of existing backbone networks, self-attention modules, and srp methods without any elaborated model crafting. we also analyze the limitations and provide experimental or theoretical evidence for the strong robustness of the proposed asr.",,2023-04-13,,"['shanshan zhong', 'zhongzhan huang', 'wushao wen', 'jinghui qin', 'liang lin']",https://arxiv.org/pdf/2304.06345.pdf
960,2304.06349,neural state-space models: empirical evaluation of uncertainty   quantification,cs.lg cs.sy eess.sy,"effective quantification of uncertainty is an essential and still missing step towards a greater adoption of deep-learning approaches in different applications, including mission-critical ones. in particular, investigations on the predictive uncertainty of deep-learning models describing non-linear dynamical systems are very limited to date. this paper is aimed at filling this gap and presents preliminary results on uncertainty quantification for system identification with neural state-space models. we frame the learning problem in a bayesian probabilistic setting and obtain posterior distributions for the neural network's weights and outputs through approximate inference techniques. based on the posterior, we construct credible intervals on the outputs and define a surprise index which can effectively diagnose usage of the model in a potentially dangerous out-of-distribution regime, where predictions cannot be trusted.",,2023-04-13,,"['marco forgione', 'dario piga']",https://arxiv.org/pdf/2304.06349.pdf
961,2304.06358,deep metric multi-view hashing for multimedia retrieval,cs.cv cs.mm,"learning the hash representation of multi-view heterogeneous data is an important task in multimedia retrieval. however, existing methods fail to effectively fuse the multi-view features and utilize the metric information provided by the dissimilar samples, leading to limited retrieval precision. current methods utilize weighted sum or concatenation to fuse the multi-view features. we argue that these fusion methods cannot capture the interaction among different views. furthermore, these methods ignored the information provided by the dissimilar samples. we propose a novel deep metric multi-view hashing (dmmvh) method to address the mentioned problems. extensive empirical evidence is presented to show that gate-based fusion is better than typical methods. we introduce deep metric learning to the multi-view hashing problems, which can utilize metric information of dissimilar samples. on the mir-flickr25k, ms coco, and nus-wide, our method outperforms the current state-of-the-art methods by a large margin (up to 15.28 mean average precision (map) improvement).",,2023-04-13,,"['jian zhu', 'zhangmin huang', 'xiaohu ruan', 'yu cui', 'yongli cheng', 'lingfang zeng']",https://arxiv.org/pdf/2304.06358.pdf
962,2304.06370,robust multiview multimodal driver monitoring system using masked   multi-head self-attention,cs.cv,"driver monitoring systems (dmss) are crucial for safe hand-over actions in level-2+ self-driving vehicles. state-of-the-art dmss leverage multiple sensors mounted at different locations to monitor the driver and the vehicle's interior scene and employ decision-level fusion to integrate these heterogenous data. however, this fusion method may not fully utilize the complementarity of different data sources and may overlook their relative importance. to address these limitations, we propose a novel multiview multimodal driver monitoring system based on feature-level fusion through multi-head self-attention (mhsa). we demonstrate its effectiveness by comparing it against four alternative fusion strategies (sum, conv, se, and aff). we also present a novel gpu-friendly supervised contrastive learning framework sumoco to learn better representations. furthermore, we fine-grained the test split of the dad dataset to enable the multi-class recognition of drivers' activities. experiments on this enhanced database demonstrate that 1) the proposed mhsa-based fusion method (auc-roc: 97.0\%) outperforms all baselines and previous approaches, and 2) training mhsa with patch masking can improve its robustness against modality/view collapses. the code and annotations are publicly available.",,2023-04-13,,"['yiming ma', 'victor sanchez', 'soodeh nikan', 'devesh upadhyay', 'bhushan atote', 'tanaya guha']",https://arxiv.org/pdf/2304.06370.pdf
963,2304.06372,contact models in robotics: a comparative analysis,cs.ro,"physics simulation is ubiquitous in robotics. whether in model-based approaches (e.g., trajectory optimization), or model-free algorithms (e.g., reinforcement learning), physics simulators are a central component of modern control pipelines in robotics. over the past decades, several robotic simulators have been developed, each with dedicated contact modeling assumptions and algorithmic solutions. in this article, we survey the main contact models and the associated numerical methods commonly used in robotics for simulating advanced robot motions involving contact interactions. in particular, we recall the physical laws underlying contacts and friction (i.e., signorini condition, coulomb's law, and the maximum dissipation principle), and how they are transcribed in current simulators. for each physics engine, we expose their inherent physical relaxations along with their limitations due to the numerical techniques employed. based on our study, we propose theoretically grounded quantitative criteria on which we build benchmarks assessing both the physical and computational aspects of simulation. we support our work with an open-source and efficient c++ implementation of the existing algorithmic variations. our results demonstrate that some approximations or algorithms commonly used in robotics can severely widen the reality gap and impact target applications. we hope this work will help motivate the development of new contact models, contact solvers, and robotic simulators in general, at the root of recent progress in motion generation in robotics.",,2023-04-13,,"['quentin le lidec', 'wilson jallet', 'louis montaut', 'ivan laptev', 'cordelia schmid', 'justin carpentier']",https://arxiv.org/pdf/2304.06372.pdf
964,2304.06375,towards hypergraph cognitive networks as feature-rich models of   knowledge,cs.cl cs.ai,"semantic networks provide a useful tool to understand how related concepts are retrieved from memory. however, most current network approaches use pairwise links to represent memory recall patterns. pairwise connections neglect higher-order associations, i.e. relationships between more than two concepts at a time. these higher-order interactions might covariate with (and thus contain information about) how similar concepts are along psycholinguistic dimensions like arousal, valence, familiarity, gender and others. we overcome these limits by introducing feature-rich cognitive hypergraphs as quantitative models of human memory where: (i) concepts recalled together can all engage in hyperlinks involving also more than two concepts at once (cognitive hypergraph aspect), and (ii) each concept is endowed with a vector of psycholinguistic features (feature-rich aspect). we build hypergraphs from word association data and use evaluation methods from machine learning features to predict concept concreteness. since concepts with similar concreteness tend to cluster together in human memory, we expect to be able to leverage this structure. using word association data from the small world of words dataset, we compared a pairwise network and a hypergraph with n=3586 concepts/nodes. interpretable artificial intelligence models trained on (1) psycholinguistic features only, (2) pairwise-based feature aggregations, and on (3) hypergraph-based aggregations show significant differences between pairwise and hypergraph links. specifically, our results show that higher-order and feature-rich hypergraph models contain richer information than pairwise networks leading to improved prediction of word concreteness. the relation with previous studies about conceptual clustering and compartmentalisation in associative knowledge and human memory are discussed.",,2023-04-13,,"['salvatore citraro', 'simon de deyne', 'massimo stella', 'giulio rossetti']",https://arxiv.org/pdf/2304.06375.pdf
965,2304.06378,generalizable deep learning method for suppressing unseen and multiple   mri artifacts using meta-learning,eess.iv cs.cv,"magnetic resonance (mr) images suffer from various types of artifacts due to motion, spatial resolution, and under-sampling. conventional deep learning methods deal with removing a specific type of artifact, leading to separately trained models for each artifact type that lack the shared knowledge generalizable across artifacts. moreover, training a model for each type and amount of artifact is a tedious process that consumes more training time and storage of models. on the other hand, the shared knowledge learned by jointly training the model on multiple artifacts might be inadequate to generalize under deviations in the types and amounts of artifacts. model-agnostic meta-learning (maml), a nested bi-level optimization framework is a promising technique to learn common knowledge across artifacts in the outer level of optimization, and artifact-specific restoration in the inner level. we propose curriculum-maml (cmaml), a learning process that integrates maml with curriculum learning to impart the knowledge of variable artifact complexity to adaptively learn restoration of multiple artifacts during training. comparative studies against stochastic gradient descent and maml, using two cardiac datasets reveal that cmaml exhibits (i) better generalization with improved psnr for 83% of unseen types and amounts of artifacts and improved ssim in all cases, and (ii) better artifact suppression in 4 out of 5 cases of composite artifacts (scans with multiple artifacts).",,2023-04-13,,"['arun palla', 'sriprabha ramanarayanan', 'keerthi ram', 'mohanasankar sivaprakasam']",https://arxiv.org/pdf/2304.06378.pdf
966,2304.06384,multi-subset approach to early sepsis prediction,cs.lg,"sepsis is a life-threatening organ malfunction caused by the host's inability to fight infection, which can lead to death without proper and immediate treatment. therefore, early diagnosis and medical treatment of sepsis in critically ill populations at high risk for sepsis and sepsis-associated mortality are vital to providing the patient with rapid therapy. studies show that advancing sepsis detection by 6 hours leads to earlier administration of antibiotics, which is associated with improved mortality. however, clinical scores like sequential organ failure assessment (sofa) are not applicable for early prediction, while machine learning algorithms can help capture the progressing pattern for early prediction. therefore, we aim to develop a machine learning algorithm that predicts sepsis onset 6 hours before it is suspected clinically. although some machine learning algorithms have been applied to sepsis prediction, many of them did not consider the fact that six hours is not a small gap. to overcome this big gap challenge, we explore a multi-subset approach in which the likelihood of sepsis occurring earlier than 6 hours is output from a previous subset and feed to the target subset as additional features. moreover, we use the hourly sampled data like vital signs in an observation window to derive a temporal change trend to further assist, which however is often ignored by previous studies. our empirical study shows that both the multi-subset approach to alleviating the 6-hour gap and the added temporal trend features can help improve the performance of sepsis-related early prediction.",,2023-04-13,,"['kevin ewig', 'xiangwen lin', 'tucker stewart', 'katherine stern', ""grant o'keefe"", 'ankur teredesai', 'juhua hu']",https://arxiv.org/pdf/2304.06384.pdf
967,2304.06385,transhp: image classification with hierarchical prompting,cs.cv,"this paper explores a hierarchical prompting mechanism for the hierarchical image classification (hic) task. different from prior hic methods, our hierarchical prompting is the first to explicitly inject ancestor-class information as a tokenized hint that benefits the descendant-class discrimination. we think it well imitates human visual recognition, i.e., humans may use the ancestor class as a prompt to draw focus on the subtle differences among descendant classes. we model this prompting mechanism into a transformer with hierarchical prompting (transhp). transhp consists of three steps: 1) learning a set of prompt tokens to represent the coarse (ancestor) classes, 2) on-the-fly predicting the coarse class of the input image at an intermediate block, and 3) injecting the prompt token of the predicted coarse class into the intermediate feature. though the parameters of transhp maintain the same for all input images, the injected coarse-class prompt conditions (modifies) the subsequent feature extraction and encourages a dynamic focus on relatively subtle differences among the descendant classes. extensive experiments show that transhp improves image classification on accuracy (e.g., improving vit-b/16 by +2.83% imagenet classification accuracy), training data efficiency (e.g., +12.69% improvement under 10% imagenet training data), and model explainability. moreover, transhp also performs favorably against prior hic methods, showing that transhp well exploits the hierarchical information.",,2023-04-13,,"['wenhao wang', 'yifan sun', 'wei li', 'yi yang']",https://arxiv.org/pdf/2304.06385.pdf
968,2304.06401,why existing multimodal crowd counting datasets can lead to unfulfilled   expectations in real-world applications,cs.cv,"more information leads to better decisions and predictions, right? confirming this hypothesis, several studies concluded that the simultaneous use of optical and thermal images leads to better predictions in crowd counting. however, the way multimodal models extract enriched features from both modalities is not yet fully understood. since the use of multimodal data usually increases the complexity, inference time, and memory requirements of the models, it is relevant to examine the differences and advantages of multimodal compared to monomodal models. in this work, all available multimodal datasets for crowd counting are used to investigate the differences between monomodal and multimodal models. to do so, we designed a monomodal architecture that considers the current state of research on monomodal crowd counting. in addition, several multimodal architectures have been developed using different multimodal learning strategies. the key components of the monomodal architecture are also used in the multimodal architectures to be able to answer whether multimodal models perform better in crowd counting in general. surprisingly, no general answer to this question can be derived from the existing datasets. we found that the existing datasets hold a bias toward thermal images. this was determined by analyzing the relationship between the brightness of optical images and crowd count as well as examining the annotations made for each dataset. since answering this question is important for future real-world applications of crowd counting, this paper establishes criteria for a potential dataset suitable for answering whether multimodal models perform better in crowd counting in general.",,2023-04-13,,"['martin thi√üen', 'elke hergenr√∂ther']",https://arxiv.org/pdf/2304.06401.pdf
969,2304.06403,leveraging triplet loss for unsupervised action segmentation,cs.cv cs.ai,"in this paper, we propose a novel fully unsupervised framework that learns action representations suitable for the action segmentation task from the single input video itself, without requiring any training data. our method is a deep metric learning approach rooted in a shallow network with a triplet loss operating on similarity distributions and a novel triplet selection strategy that effectively models temporal and semantic priors to discover actions in the new representational space. under these circumstances, we successfully recover temporal boundaries in the learned action representations with higher quality compared with existing unsupervised approaches. the proposed method is evaluated on two widely used benchmark datasets for the action segmentation task and it achieves competitive performance by applying a generic clustering algorithm on the learned representations.",,2023-04-13,,"['e. bueno-benito', 'b. tura', 'm. dimiccoli']",https://arxiv.org/pdf/2304.06403.pdf
970,2304.06411,meta-auxiliary learning for adaptive human pose prediction,cs.cv cs.ai cs.hc,"predicting high-fidelity future human poses, from a historically observed sequence, is decisive for intelligent robots to interact with humans. deep end-to-end learning approaches, which typically train a generic pre-trained model on external datasets and then directly apply it to all test samples, emerge as the dominant solution to solve this issue. despite encouraging progress, they remain non-optimal, as the unique properties (e.g., motion style, rhythm) of a specific sequence cannot be adapted. more generally, at test-time, once encountering unseen motion categories (out-of-distribution), the predicted poses tend to be unreliable. motivated by this observation, we propose a novel test-time adaptation framework that leverages two self-supervised auxiliary tasks to help the primary forecasting network adapt to the test sequence. in the testing phase, our model can adjust the model parameters by several gradient updates to improve the generation quality. however, due to catastrophic forgetting, both auxiliary tasks typically tend to the low ability to automatically present the desired positive incentives for the final prediction performance. for this reason, we also propose a meta-auxiliary learning scheme for better adaptation. in terms of general setup, our approach obtains higher accuracy, and under two new experimental designs for out-of-distribution data (unseen subjects and categories), achieves significant improvements.",,2023-04-13,,"['qiongjie cui', 'huaijiang sun', 'jianfeng lu', 'bin li', 'weiqing li']",https://arxiv.org/pdf/2304.06411.pdf
971,2304.06412,quantifying and explaining machine learning uncertainty in predictive   process monitoring: an operations research perspective,cs.lg cs.ai math.oc stat.ml,"this paper introduces a comprehensive, multi-stage machine learning methodology that effectively integrates information systems and artificial intelligence to enhance decision-making processes within the domain of operations research. the proposed framework adeptly addresses common limitations of existing solutions, such as the neglect of data-driven estimation for vital production parameters, exclusive generation of point forecasts without considering model uncertainty, and lacking explanations regarding the sources of such uncertainty. our approach employs quantile regression forests for generating interval predictions, alongside both local and global variants of shapley additive explanations for the examined predictive process monitoring problem. the practical applicability of the proposed methodology is substantiated through a real-world production planning case study, emphasizing the potential of prescriptive analytics in refining decision-making procedures. this paper accentuates the imperative of addressing these challenges to fully harness the extensive and rich data resources accessible for well-informed decision-making.",,2023-04-13,,"['nijat mehdiyev', 'maxim majlatow', 'peter fettke']",https://arxiv.org/pdf/2304.06412.pdf
972,2304.06427,in-distribution and out-of-distribution self-supervised ecg   representation learning for arrhythmia detection,cs.lg cs.ai eess.sp,"this paper presents a systematic investigation into the effectiveness of self-supervised learning (ssl) methods for electrocardiogram (ecg) arrhythmia detection. we begin by conducting a novel distribution analysis on three popular ecg-based arrhythmia datasets: ptb-xl, chapman, and ribeiro. to the best of our knowledge, our study is the first to quantify these distributions in this area. we then perform a comprehensive set of experiments using different augmentations and parameters to evaluate the effectiveness of various ssl methods, namely simcrl, byol, and swav, for ecg representation learning, where we observe the best performance achieved by swav. furthermore, our analysis shows that ssl methods achieve highly competitive results to those achieved by supervised state-of-the-art methods. to further assess the performance of these methods on both in-distribution (id) and out-of-distribution (ood) ecg data, we conduct cross-dataset training and testing experiments. our comprehensive experiments show almost identical results when comparing id and ood schemes, indicating that ssl techniques can learn highly effective representations that generalize well across different ood datasets. this finding can have major implications for ecg-based arrhythmia detection. lastly, to further analyze our results, we perform detailed per-disease studies on the performance of the ssl methods on the three datasets.",,2023-04-13,,"['sahar soltanieh', 'javad hashemi', 'ali etemad']",https://arxiv.org/pdf/2304.06427.pdf
973,2304.06441,fast and automatic floating point error analysis with chef-fp,math.na cs.ar cs.na cs.pf,"as we reach the limit of moore's law, researchers are exploring different paradigms to achieve unprecedented performance. approximate computing (ac), which relies on the ability of applications to tolerate some error in the results to trade-off accuracy for performance, has shown significant promise. despite the success of ac in domains such as machine learning, its acceptance in high-performance computing (hpc) is limited due to stringent requirements for accuracy. we need tools and techniques to identify regions of code that are amenable to approximations and their impact on the application output quality to guide developers to employ selective approximation. to this end, we propose chef-fp, a flexible, scalable, and easy-to-use source-code transformation tool based on automatic differentiation (ad) for analyzing approximation errors in hpc applications. chef-fp uses clad, an efficient ad tool built as a plugin to the clang compiler and based on the llvm compiler infrastructure, as a backend and utilizes its ad abilities to evaluate approximation errors in c++ code. chef-fp works at the source by injecting error estimation code into the generated adjoints. this enables the error-estimation code to undergo compiler optimizations resulting in improved analysis time and reduced memory usage. we also provide theoretical and architectural augmentations to source code transformation-based ad tools to perform fp error analysis. this paper primarily focuses on analyzing errors introduced by mixed-precision ac techniques. we also show the applicability of our tool in estimating other kinds of errors by evaluating our tool on codes that use approximate functions. moreover, we demonstrate the speedups chef-fp achieved during analysis time compared to the existing state-of-the-art tool due to its ability to generate and insert approximation error estimate code directly into the derivative source.",,2023-04-13,,"['garima singh', 'baidyanath kundu', 'harshitha menon', 'alexander penev', 'david j. lange', 'vassil vassilev']",https://arxiv.org/pdf/2304.06441.pdf
974,2304.06446,spectformer: frequency and attention is what you need in a vision   transformer,cs.cv cs.ai cs.cl cs.lg,"vision transformers have been applied successfully for image recognition tasks. there have been either multi-headed self-attention based (vit \cite{dosovitskiy2020image}, deit, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (fnet\cite{lee2021fnet}, gfnet\cite{rao2021global}, afno\cite{guibas2021efficient}). we hypothesize that both spectral and multi-headed attention plays a major role. we investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. we thus propose the novel spectformer architecture for transformers that combines spectral and multi-headed attention layers. we believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. for instance, it improves the top-1 accuracy by 2\% on imagenet compared to both gfnet-h and lit. spectformer-s reaches 84.25\% top-1 accuracy on imagenet-1k (state of the art for small version). further, spectformer-l achieves 85.7\% that is the state of the art for the comparable base version of the transformers. we further ensure that we obtain reasonable results in other scenarios such as transfer learning on standard datasets such as cifar-10, cifar-100, oxford-iiit-flower, and standford car datasets. we then investigate its use in downstream tasks such of object detection and instance segmentation on the ms-coco dataset and observe that spectformer shows consistent performance that is comparable to the best backbones and can be further optimized and improved. hence, we believe that combined spectral and attention layers are what are needed for vision transformers.",,2023-04-13,,"['badri n. patro', 'vinay p. namboodiri', 'vijay srinivas agneeswaran']",https://arxiv.org/pdf/2304.06446.pdf
975,2304.06459,masakhane-afrisenti at semeval-2023 task 12: sentiment analysis using   afro-centric language models and adapters for low-resource african languages,cs.cl cs.ai,"afrisenti-semeval shared task 12 of semeval-2023. the task aims to perform monolingual sentiment classification (sub-task a) for 12 african languages, multilingual sentiment classification (sub-task b), and zero-shot sentiment classification (task c). for sub-task a, we conducted experiments using classical machine learning classifiers, afro-centric language models, and language-specific models. for task b, we fine-tuned multilingual pre-trained language models that support many of the languages in the task. for task c, we used we make use of a parameter-efficient adapter approach that leverages monolingual texts in the target language for effective zero-shot transfer. our findings suggest that using pre-trained afro-centric language models improves performance for low-resource african languages. we also ran experiments using adapters for zero-shot tasks, and the results suggest that we can obtain promising results by using adapters with a limited amount of resources.",,2023-04-13,,"['israel abebe azime', 'sana sabah al-azzawi', 'atnafu lambebo tonja', 'iyanuoluwa shode', 'jesujoba alabi', 'ayodele awokoya', 'mardiyyah oduwole', 'tosin adewumi', 'samuel fanijo', 'oyinkansola awosan', 'oreen yousuf']",https://arxiv.org/pdf/2304.06459.pdf
976,2304.06461,multi-mode online knowledge distillation for self-supervised visual   representation learning,cs.cv,"self-supervised learning (ssl) has made remarkable progress in visual representation learning. some studies combine ssl with knowledge distillation (ssl-kd) to boost the representation learning performance of small models. in this study, we propose a multi-mode online knowledge distillation method (mokd) to boost self-supervised visual representation learning. different from existing ssl-kd methods that transfer knowledge from a static pre-trained teacher to a student, in mokd, two different models learn collaboratively in a self-supervised manner. specifically, mokd consists of two distillation modes: self-distillation and cross-distillation modes. among them, self-distillation performs self-supervised learning for each model independently, while cross-distillation realizes knowledge interaction between different models. in cross-distillation, a cross-attention feature search strategy is proposed to enhance the semantic feature alignment between different models. as a result, the two models can absorb knowledge from each other to boost their representation learning performance. extensive experimental results on different backbones and datasets demonstrate that two heterogeneous models can benefit from mokd and outperform their independently trained baseline. in addition, mokd also outperforms existing ssl-kd methods for both the student and teacher models.",,2023-04-13,,"['kaiyou song', 'jin xie', 'shan zhang', 'zimeng luo']",https://arxiv.org/pdf/2304.06461.pdf
977,2304.06469,analysing fairness of privacy-utility mobility models,cs.lg cs.ai cs.cr cs.cy,"preserving the individuals' privacy in sharing spatial-temporal datasets is critical to prevent re-identification attacks based on unique trajectories. existing privacy techniques tend to propose ideal privacy-utility tradeoffs, however, largely ignore the fairness implications of mobility models and whether such techniques perform equally for different groups of users. the quantification between fairness and privacy-aware models is still unclear and there barely exists any defined sets of metrics for measuring fairness in the spatial-temporal context. in this work, we define a set of fairness metrics designed explicitly for human mobility, based on structural similarity and entropy of the trajectories. under these definitions, we examine the fairness of two state-of-the-art privacy-preserving models that rely on gan and representation learning to reduce the re-identification rate of users for data sharing. our results show that while both models guarantee group fairness in terms of demographic parity, they violate individual fairness criteria, indicating that users with highly similar trajectories receive disparate privacy gain. we conclude that the tension between the re-identification task and individual fairness needs to be considered for future spatial-temporal data analysis and modelling to achieve a privacy-preserving fairness-aware setting.",,2023-04-10,,"['yuting zhan', 'hamed haddadi', 'afra mashhadi']",https://arxiv.org/pdf/2304.06469.pdf
978,2304.06471,two heads are better than one: a bio-inspired method for improving   classification on eeg-et data,eess.sp cs.hc cs.lg,"classifying eeg data is integral to the performance of brain computer interfaces (bci) and their applications. however, external noise often obstructs eeg data due to its biological nature and complex data collection process. especially when dealing with classification tasks, standard eeg preprocessing approaches extract relevant events and features from the entire dataset. however, these approaches treat all relevant cognitive events equally and overlook the dynamic nature of the brain over time. in contrast, we are inspired by neuroscience studies to use a novel approach that integrates feature selection and time segmentation of eeg data. when tested on the eegeyenet dataset, our proposed method significantly increases the performance of machine learning classifiers while reducing their respective computational complexity.",,2023-03-25,,"['eric modesitt', 'ruiqi yang', 'qi liu']",https://arxiv.org/pdf/2304.06471.pdf
979,2304.06474,attention-based learning for sleep apnea and limb movement detection   using wi-fi csi signals,eess.sp cs.lg,"wi-fi channel state information (csi) has become a promising solution for non-invasive breathing and body motion monitoring during sleep. sleep disorders of apnea and periodic limb movement disorder (plmd) are often unconscious and fatal. the existing researches detect abnormal sleep disorders in impractically controlled environments. moreover, it leads to compelling challenges to classify complex macro- and micro-scales of sleep movements as well as entangled similar waveforms of cases of apnea and plmd. in this paper, we propose the attention-based learning for sleep apnea and limb movement detection (alesal) system that can jointly detect sleep apnea and plmd under different sleep postures across a variety of patients. alesal contains antenna-pair and time attention mechanisms for mitigating the impact of modest antenna pairs and emphasizing the duration of interest, respectively. performance results show that our proposed alesal system can achieve a weighted f1-score of 84.33, outperforming the other existing non-attention based methods of support vector machine and deep multilayer perceptron.",,2023-03-26,,"['chi-che chang', 'an-hung hsiao', 'li-hsiang shen', 'kai-ten feng', 'chia-yu chen']",https://arxiv.org/pdf/2304.06474.pdf
980,2304.06489,domain adaptation for inertial measurement unit-based human activity   recognition: a survey,eess.sp cs.ai cs.lg,"machine learning-based wearable human activity recognition (whar) models enable the development of various smart and connected community applications such as sleep pattern monitoring, medication reminders, cognitive health assessment, sports analytics, etc. however, the widespread adoption of these whar models is impeded by their degraded performance in the presence of data distribution heterogeneities caused by the sensor placement at different body positions, inherent biases and heterogeneities across devices, and personal and environmental diversities. various traditional machine learning algorithms and transfer learning techniques have been proposed in the literature to address the underpinning challenges of handling such data heterogeneities. domain adaptation is one such transfer learning techniques that has gained significant popularity in recent literature. in this paper, we survey the recent progress of domain adaptation techniques in the inertial measurement unit (imu)-based human activity recognition area, discuss potential future directions.",,2023-04-06,,"['avijoy chakma', 'abu zaher md faridee', 'indrajeet ghosh', 'nirmalya roy']",https://arxiv.org/pdf/2304.06489.pdf
981,2304.06490,a new paradigm for device-free indoor localization: deep learning with   error vector spectrum in wi-fi systems,eess.sp cs.lg,"the demand for device-free indoor localization using commercial wi-fi devices has rapidly increased in various fields due to its convenience and versatile applications. however, random frequency offset (rfo) in wireless channels poses challenges to the accuracy of indoor localization when using fluctuating channel state information (csi). to mitigate the rfo problem, an error vector spectrum (evs) is conceived thanks to its higher resolution of signal and robustness to rfo. to address these challenges, this paper proposed a novel error vector assisted learning (eval) for device-free indoor localization. the proposed eval scheme employs deep neural networks to classify the location of a person in the indoor environment by extracting ample channel features from the physical layer signals. we conducted realistic experiments based on openwifi project to extract both evs and csi to examine the performance of different device-free localization techniques. experimental results show that our proposed eval scheme outperforms conventional machine learning methods and benchmarks utilizing either csi amplitude or phase information. compared to most existing csi-based localization schemes, a new paradigm with higher positioning accuracy by adopting evs is revealed by our proposed eval system.",,2023-03-25,,"['wen liu', 'an-hung hsiao', 'li-hsiang shen', 'kai-ten feng']",https://arxiv.org/pdf/2304.06490.pdf
982,2304.06495,an embedding for eeg signals learned using a triplet loss,eess.sp cs.lg,"neurophysiological time series recordings like the electroencephalogram (eeg) or local field potentials are obtained from multiple sensors. they can be decoded by machine learning models in order to estimate the ongoing brain state of a patient or healthy user. in a brain-computer interface (bci), this decoded brain state information can be used with minimal time delay to either control an application, e.g., for communication or for rehabilitation after stroke, or to passively monitor the ongoing brain state of the subject, e.g., in a demanding work environment. a specific challenge in such decoding tasks is posed by the small dataset sizes in bci compared to other domains of machine learning like computer vision or natural language processing. a possibility to tackle classification or regression problems in bci despite small training data sets is through transfer learning, which utilizes data from other sessions, subjects or even datasets to train a model. in this exploratory study, we propose novel domain-specific embeddings for neurophysiological data. our approach is based on metric learning and builds upon the recently proposed ladder loss. using embeddings allowed us to benefit, both from the good generalisation abilities and robustness of deep learning and from the fast training of classical machine learning models for subject-specific calibration. in offline analyses using eeg data of 14 subjects, we tested the embeddings' feasibility and compared their efficiency with state-of-the-art deep learning models and conventional machine learning pipelines. in summary, we propose the use of metric learning to obtain pre-trained embeddings of eeg-bci data as a means to incorporate domain knowledge and to reach competitive performance on novel subjects with minimal calibration requirements.",,2023-03-23,,"['pierre guetschel', 'th√©odore papadopoulo', 'michael tangermann']",https://arxiv.org/pdf/2304.06495.pdf
983,2304.06496,eegmatch: learning with incomplete labels for semi-supervised eeg-based   cross-subject emotion recognition,eess.sp cs.hc cs.lg,"electroencephalography (eeg) is an objective tool for emotion recognition and shows promising performance. however, the label scarcity problem is a main challenge in this field, which limits the wide application of eeg-based emotion recognition. in this paper, we propose a novel semi-supervised learning framework (eegmatch) to leverage both labeled and unlabeled eeg data. first, an eeg-mixup based data augmentation method is developed to generate more valid samples for model learning. second, a semi-supervised two-step pairwise learning method is proposed to bridge prototype-wise and instance-wise pairwise learning, where the prototype-wise pairwise learning measures the global relationship between eeg data and the prototypical representation of each emotion class and the instance-wise pairwise learning captures the local intrinsic relationship among eeg data. third, a semi-supervised multi-domain adaptation is introduced to align the data representation among multiple domains (labeled source domain, unlabeled source domain, and target domain), where the distribution mismatch is alleviated. extensive experiments are conducted on two benchmark databases (seed and seed-iv) under a cross-subject leave-one-subject-out cross-validation evaluation protocol. the results show the proposed eegmatch performs better than the state-of-the-art methods under different incomplete label conditions (with 6.89% improvement on seed and 1.44% improvement on seed-iv), which demonstrates the effectiveness of the proposed eegmatch in dealing with the label scarcity problem in emotion recognition using eeg signals. the source code is available at https://github.com/kazabana/eegmatch.",,2023-03-27,,"['rushuang zhou', 'weishan ye', 'zhiguo zhang', 'yanyang luo', 'li zhang', 'linling li', 'gan huang', 'yining dong', 'yuan-ting zhang', 'zhen liang']",https://arxiv.org/pdf/2304.06496.pdf
984,2304.06508,"philosophical foundations of geoai: exploring sustainability, diversity,   and bias in geoai and spatial data science",cs.cy cs.ai cs.lg,"this chapter presents some of the fundamental assumptions and principles that could form the philosophical foundation of geoai and spatial data science. instead of reviewing the well-established characteristics of spatial data (analysis), including interaction, neighborhoods, and autocorrelation, the chapter highlights themes such as sustainability, bias in training data, diversity in schema knowledge, and the (potential lack of) neutrality of geoai systems from a unifying ethical perspective. reflecting on our profession's ethical implications will assist us in conducting potentially disruptive research more responsibly, identifying pitfalls in designing, training, and deploying geoai-based systems, and developing a shared understanding of the benefits but also potential dangers of artificial intelligence and machine learning research across academic fields, all while sharing our unique (geo)spatial perspective with others.",,2023-03-27,,['krzysztof janowicz'],https://arxiv.org/pdf/2304.06508.pdf
985,2304.06513,passive radio frequency-based 3d indoor positioning system via ensemble   learning,eess.sp cs.ai cs.sy eess.sy,"passive radio frequency (prf)-based indoor positioning systems (ips) have attracted researchers' attention due to their low price, easy and customizable configuration, and non-invasive design. this paper proposes a prf-based three-dimensional (3d) indoor positioning system (pips), which is able to use signals of opportunity (soop) for positioning and also capture a scenario signature. pips passively monitors soops containing scenario signatures through a single receiver. moreover, pips leverages the dynamic data driven applications system (dddas) framework to devise and customize the sampling frequency, enabling the system to use the most impacted frequency band as the rated frequency band. various regression methods within three ensemble learning strategies are used to train and predict the receiver position. the prf spectrum of 60 positions is collected in the experimental scenario, and three criteria are applied to evaluate the performance of pips. experimental results show that the proposed pips possesses the advantages of high accuracy, configurability, and robustness.",,2023-03-25,,"['liangqi yuan', 'houlin chen', 'robert ewing', 'jia li']",https://arxiv.org/pdf/2304.06513.pdf
986,2304.06514,ml-enabled outdoor user positioning in 5g nr systems via uplink srs   channel estimates,eess.sp cs.lg,"cellular user positioning is a promising service provided by fifth generation new radio (5g nr) networks. besides, machine learning (ml) techniques are foreseen to become an integrated part of 5g nr systems improving radio performance and reducing complexity. in this paper, we investigate ml techniques for positioning using 5g nr fingerprints consisting of uplink channel estimates from the physical layer channel. we show that it is possible to use sounding reference signals (srs) channel fingerprints to provide sufficient data to infer user position. furthermore, we show that small fully-connected moderately deep neural networks, even when applied to very sparse srs data, can achieve successful outdoor user positioning with meter-level accuracy in a commercial 5g environment.",,2023-04-12,,"['andre r√°th', 'dino pjaniƒá', 'bo bernhardsson', 'fredrik tufvesson']",https://arxiv.org/pdf/2304.06514.pdf
987,2304.06519,secure federated learning for cognitive radio sensing,eess.sp cs.ai cs.lg cs.sy eess.sy,"this paper considers reliable and secure spectrum sensing (ss) based on federated learning (fl) in the cognitive radio (cr) environment. motivation, architectures, and algorithms of fl in ss are discussed. security and privacy threats on these algorithms are overviewed, along with possible countermeasures to such attacks. some illustrative examples are also provided, with design recommendations for fl-based ss in future crs.",10.1109/mcom.001.2200465,2023-03-23,,"['malgorzata wasilewska', 'hanna bogucka', 'h. vincent poor']",https://arxiv.org/pdf/2304.06519.pdf
988,2304.06520,an efficient transfer learning-based approach for apple leaf disease   classification,cs.cv cs.ai cs.lg,"correct identification and categorization of plant diseases are crucial for ensuring the safety of the global food supply and the overall financial success of stakeholders. in this regard, a wide range of solutions has been made available by introducing deep learning-based classification systems for different staple crops. despite being one of the most important commercial crops in many parts of the globe, research proposing a smart solution for automatically classifying apple leaf diseases remains relatively unexplored. this study presents a technique for identifying apple leaf diseases based on transfer learning. the system extracts features using a pretrained efficientnetv2s architecture and passes to a classifier block for effective prediction. the class imbalance issues are tackled by utilizing runtime data augmentation. the effect of various hyperparameters, such as input resolution, learning rate, number of epochs, etc., has been investigated carefully. the competence of the proposed pipeline has been evaluated on the apple leaf disease subset from the publicly available `plantvillage' dataset, where it achieved an accuracy of 99.21%, outperforming the existing works.",,2023-04-10,,"['md. hamjajul ashmafee', 'tasnim ahmed', 'sabbir ahmed', 'md. bakhtiar hasan', 'mst nura jahan', 'a. b. m. ashikur rahman']",https://arxiv.org/pdf/2304.06520.pdf
989,2304.06521,multi-contact force-sensing guitar for training and therapy,eess.sp cs.hc physics.ed-ph,"hand injuries from repetitive high-strain and physical overload can hamper or even end a musician's career. to help musicians develop safer playing habits, we developed a multiplecontact force-sensing array that can substitute as a guitar fretboard. the system consists of 72 individual force sensing modules, each containing a flexure and a photointerrupter that measures the corresponding deflection when forces are applied. the system is capable of measuring forces between 0-25 n applied anywhere within the first 12 frets at a rate of 20 hz with an average accuracy of 0.4 n and a resolution of 0.1 n. accompanied with a gui, the resulting prototype was received positively as a useful tool for learning and injury prevention by novice and expert musicians.",,2023-02-25,,"['zhiyi ren', 'chun-cheng hsu', 'can kocabalkanli', 'khanh nguyen', 'iulian i. iordachita', 'serap bastepe-gray', 'nathan scott']",https://arxiv.org/pdf/2304.06521.pdf
990,2304.06551,decentralized federated learning methods for reducing communication cost   and energy consumption in uav networks,cs.lg cs.ni,"unmanned aerial vehicles (uav) or drones play many roles in a modern smart city such as the delivery of goods, mapping real-time road traffic and monitoring pollution. the ability of drones to perform these functions often requires the support of machine learning technology. however, traditional machine learning models for drones encounter data privacy problems, communication costs and energy limitations. federated learning, an emerging distributed machine learning approach, is an excellent solution to address these issues. federated learning (fl) allows drones to train local models without transmitting raw data. however, existing fl requires a central server to aggregate the trained model parameters of the uav. a failure of the central server can significantly impact the overall training. in this paper, we propose two aggregation methods: commutative fl and alternate fl, based on the existing architecture of decentralised federated learning for uav networks (dfl-un) by adding a unique aggregation method of decentralised fl. those two methods can effectively control energy consumption and communication cost by controlling the number of local training epochs, local communication, and global communication. the simulation results of the proposed training methods are also presented to verify the feasibility and efficiency of the architecture compared with two benchmark methods (e.g. standard machine learning training and standard single aggregation server training). the simulation results show that the proposed methods outperform the benchmark methods in terms of operational stability, energy consumption and communication cost.",,2023-04-13,,"['deng pan', 'mohammad ali khoshkholghi', 'toktam mahmoodi']",https://arxiv.org/pdf/2304.06551.pdf
991,2304.06560,real-time wheel detection and rim classification in automotive   production,cs.cv,"this paper proposes a novel approach to real-time automatic rim detection, classification, and inspection by combining traditional computer vision and deep learning techniques. at the end of every automotive assembly line, a quality control process is carried out to identify any potential defects in the produced cars. common yet hazardous defects are related, for example, to incorrectly mounted rims. routine inspections are mostly conducted by human workers that are negatively affected by factors such as fatigue or distraction. we have designed a new prototype to validate whether all four wheels on a single car match in size and type. additionally, we present three comprehensive open-source databases, cwd1500, wheel22, and rb600, for wheel, rim, and bolt detection, as well as rim classification, which are free-to-use for scientific purposes.",,2023-04-13,,"['roman stanek', 'tomas kerepecky', 'adam novozamsky', 'filip sroubek', 'barbara zitova', 'jan flusser']",https://arxiv.org/pdf/2304.06560.pdf
992,2304.06566,nerd: neural field-based demosaicking,cs.cv eess.iv,"we introduce nerd, a new demosaicking method for generating full-color images from bayer patterns. our approach leverages advancements in neural fields to perform demosaicking by representing an image as a coordinate-based neural network with sine activation functions. the inputs to the network are spatial coordinates and a low-resolution bayer pattern, while the outputs are the corresponding rgb values. an encoder network, which is a blend of resnet and u-net, enhances the implicit neural representation of the image to improve its quality and ensure spatial consistency through prior learning. our experimental results demonstrate that nerd outperforms traditional and state-of-the-art cnn-based methods and significantly closes the gap to transformer-based methods.",,2023-04-13,,"['tomas kerepecky', 'filip sroubek', 'adam novozamsky', 'jan flusser']",https://arxiv.org/pdf/2304.06566.pdf
993,2304.06567,deep reinforcement learning applied to an assembly sequence planning   problem with user preferences,cs.lg,"deep reinforcement learning (drl) has demonstrated its potential in solving complex manufacturing decision-making problems, especially in a context where the system learns over time with actual operation in the absence of training data. one interesting and challenging application for such methods is the assembly sequence planning (asp) problem. in this paper, we propose an approach to the implementation of drl methods in asp. the proposed approach introduces in the rl environment parametric actions to improve training time and sample efficiency and uses two different reward signals: (1) user's preferences and (2) total assembly time duration. the user's preferences signal addresses the difficulties and non-ergonomic properties of the assembly faced by the human and the total assembly time signal enforces the optimization of the assembly. three of the most powerful deep rl methods were studied, advantage actor-critic (a2c), deep q-learning (dqn), and rainbow, in two different scenarios: a stochastic and a deterministic one. finally, the performance of the drl algorithms was compared to tabular q-learnings performance. after 10,000 episodes, the system achieved near optimal behaviour for the algorithms tabular q-learning, a2c, and rainbow. though, for more complex scenarios, the algorithm tabular q-learning is expected to underperform in comparison to the other 2 algorithms. the results support the potential for the application of deep reinforcement learning in assembly sequence planning problems with human interaction.",10.1007/s00170-022-09877-8,2023-04-13,,"['miguel neves', 'pedro neto']",https://arxiv.org/pdf/2304.06567.pdf
994,2304.06569,counterfactuals: an r package for counterfactual explanation methods,stat.ml cs.lg stat.co,"counterfactual explanation methods provide information on how feature values of individual observations must be changed to obtain a desired prediction. despite the increasing amount of proposed methods in research, only a few implementations exist whose interfaces and requirements vary widely. in this work, we introduce the counterfactuals r package, which provides a modular and unified r6-based interface for counterfactual explanation methods. we implemented three existing counterfactual explanation methods and propose some optional methodological extensions to generalize these methods to different scenarios and to make them more comparable. we explain the structure and workflow of the package using real use cases and show how to integrate additional counterfactual explanation methods into the package. in addition, we compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior.",,2023-04-13,,"['susanne dandl', 'andreas hofheinz', 'martin binder', 'bernd bischl', 'giuseppe casalicchio']",https://arxiv.org/pdf/2304.06569.pdf
995,2304.06574,bayes classifier cannot be learned from noisy responses with unknown   noise rates,stat.ml cs.lg,"training a classifier with noisy labels typically requires the learner to specify the distribution of label noise, which is often unknown in practice. although there have been some recent attempts to relax that requirement, we show that the bayes decision rule is unidentified in most classification problems with noisy labels. this suggests it is generally not possible to bypass/relax the requirement. in the special cases in which the bayes decision rule is identified, we develop a simple algorithm to learn the bayes decision rule, that does not require knowledge of the noise distribution.",,2023-04-13,,"['soham bakshi', 'subha maity']",https://arxiv.org/pdf/2304.06574.pdf
996,2304.06575,adversarial examples from dimensional invariance,cs.lg cs.cv cs.na math.na,"adversarial examples have been found for various deep as well as shallow learning models, and have at various times been suggested to be either fixable model-specific bugs, or else inherent dataset feature, or both. we present theoretical and empirical results to show that adversarial examples are approximate discontinuities resulting from models that specify approximately bijective maps $f: \bbb r^n \to \bbb r^m; n \neq m$ over their inputs, and this discontinuity follows from the topological invariance of dimension.",,2023-04-13,,['benjamin l. badger'],https://arxiv.org/pdf/2304.06575.pdf
997,2304.06591,brain structure ages -- a new biomarker for multi-disease classification,cs.cv,"age is an important variable to describe the expected brain's anatomy status across the normal aging trajectory. the deviation from that normative aging trajectory may provide some insights into neurological diseases. in neuroimaging, predicted brain age is widely used to analyze different diseases. however, using only the brain age gap information (\ie the difference between the chronological age and the estimated age) can be not enough informative for disease classification problems. in this paper, we propose to extend the notion of global brain age by estimating brain structure ages using structural magnetic resonance imaging. to this end, an ensemble of deep learning models is first used to estimate a 3d aging map (\ie voxel-wise age estimation). then, a 3d segmentation mask is used to obtain the final brain structure ages. this biomarker can be used in several situations. first, it enables to accurately estimate the brain age for the purpose of anomaly detection at the population level. in this situation, our approach outperforms several state-of-the-art methods. second, brain structure ages can be used to compute the deviation from the normal aging process of each brain structure. this feature can be used in a multi-disease classification task for an accurate differential diagnosis at the subject level. finally, the brain structure age deviations of individuals can be visualized, providing some insights about brain abnormality and helping clinicians in real medical contexts.",,2023-04-13,,"['huy-dung nguyen', 'micha√´l cl√©ment', 'boris mansencal', 'pierrick coup√©']",https://arxiv.org/pdf/2304.06591.pdf
998,2304.06596,beyond submodularity: a unified framework of randomized set selection   with group fairness constraints,cs.lg cs.ai cs.cy cs.ds,"machine learning algorithms play an important role in a variety of important decision-making processes, including targeted advertisement displays, home loan approvals, and criminal behavior predictions. given the far-reaching impact of these algorithms, it is crucial that they operate fairly, free from bias or prejudice towards certain groups in the population. ensuring impartiality in these algorithms is essential for promoting equality and avoiding discrimination. to this end we introduce a unified framework for randomized subset selection that incorporates group fairness constraints. our problem involves a global utility function and a set of group utility functions for each group, here a group refers to a group of individuals (e.g., people) sharing the same attributes (e.g., gender). our aim is to generate a distribution across feasible subsets, specifying the selection probability of each feasible set, to maximize the global utility function while meeting a predetermined quota for each group utility function in expectation. note that there may not necessarily be any direct connections between the global utility function and each group utility function. we demonstrate that this framework unifies and generalizes many significant applications in machine learning and operations research. our algorithmic results either improves the best known result or provide the first approximation algorithms for new applications.",,2023-04-13,,"['shaojie tang', 'jing yuan']",https://arxiv.org/pdf/2304.06596.pdf
999,2304.06597,"""what it wants me to say"": bridging the abstraction gap between end-user   programmers and code-generating large language models",cs.hc,"code-generating large language models translate natural language into code. however, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. for non-expert end-user programmers, learning this is the challenge of abstraction matching. we examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the users natural language query to python code using the codex generator, executes the code, and shows the result. we propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. in a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. we find that the grounded approach improves end-users' understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.",10.1145/3544548.3580817,2023-04-13,,"['michael xieyang liu', 'advait sarkar', 'carina negreanu', 'ben zorn', 'jack williams', 'neil toronto', 'andrew d. gordon']",https://arxiv.org/pdf/2304.06597.pdf
1000,2304.06600,lossless adaptation of pretrained vision models for robotic manipulation,cs.lg cs.cv cs.ro,"recent works have shown that large models pretrained on common visual learning tasks can provide useful representations for a wide range of specialized perception problems, as well as a variety of robotic manipulation tasks. while prior work on robotic manipulation has predominantly used frozen pretrained features, we demonstrate that in robotics this approach can fail to reach optimal performance, and that fine-tuning of the full model can lead to significantly better results. unfortunately, fine-tuning disrupts the pretrained visual representation, and causes representational drift towards the fine-tuned task thus leading to a loss of the versatility of the original model. we introduce ""lossless adaptation"" to address this shortcoming of classical fine-tuning. we demonstrate that appropriate placement of our parameter efficient adapters can significantly reduce the performance gap between frozen pretrained representations and full end-to-end fine-tuning without changes to the original representation and thus preserving original capabilities of the pretrained model. we perform a comprehensive investigation across three major model architectures (vits, nfnets, and resnets), supervised (imagenet-1k classification) and self-supervised pretrained weights (clip, byol, visual mae) in 3 task domains and 35 individual tasks, and demonstrate that our claims are strongly validated in various settings.",,2023-04-13,,"['mohit sharma', 'claudio fantacci', 'yuxiang zhou', 'skanda koppula', 'nicolas heess', 'jon scholz', 'yusuf aytar']",https://arxiv.org/pdf/2304.06600.pdf
1001,2304.06619,class-incremental learning of plant and disease detection: growing   branches with knowledge distillation,cs.cv,"this paper investigates the problem of class-incremental object detection for agricultural applications where a model needs to learn new plant species and diseases incrementally without forgetting the previously learned ones. we adapt two public datasets to include new categories over time, simulating a more realistic and dynamic scenario. we then compare three class-incremental learning methods that leverage different forms of knowledge distillation to mitigate catastrophic forgetting. our experiments show that all three methods suffer from catastrophic forgetting, but the recent dynamic y-kd approach, which additionally uses a dynamic architecture that grows new branches to learn new tasks, outperforms ilod and faster-ilod in most scenarios both on new and old classes.   these results highlight the challenges and opportunities of continual object detection for agricultural applications. in particular, the large intra-class and small inter-class variability that is typical of plant images exacerbate the difficulty of learning new categories without interfering with previous knowledge. we publicly release our code to encourage future work.",,2023-04-13,,['mathieu pag√© fortin'],https://arxiv.org/pdf/2304.06619.pdf
1002,2304.06623,exploring the state of the art in legal qa systems,cs.cl,"answering questions related to the legal domain is a complex task, primarily due to the intricate nature and diverse range of legal document systems. providing an accurate answer to a legal query typically necessitates specialized knowledge in the relevant domain, which makes this task all the more challenging, even for human experts. qa (question answering systems) are designed to generate answers to questions asked in human languages. they use natural language processing to understand questions and search through information to find relevant answers. qa has various practical applications, including customer service, education, research, and cross-lingual communication. however, they face challenges such as improving natural language understanding and handling complex and ambiguous questions. answering questions related to the legal domain is a complex task, primarily due to the intricate nature and diverse range of legal document systems. providing an accurate answer to a legal query typically necessitates specialized knowledge in the relevant domain, which makes this task all the more challenging, even for human experts. at this time, there is a lack of surveys that discuss legal question answering. to address this problem, we provide a comprehensive survey that reviews 14 benchmark datasets for question-answering in the legal field as well as presents a comprehensive review of the state-of-the-art legal question answering deep learning models. we cover the different architectures and techniques used in these studies and the performance and limitations of these models. moreover, we have established a public github repository where we regularly upload the most recent articles, open data, and source code. the repository is available at: \url{https://github.com/abdoelsayed2016/legal-question-answering-review}.",,2023-04-13,,"['abdelrahman abdallah', 'bhawna piryani', 'adam jatowt']",https://arxiv.org/pdf/2304.06623.pdf
1003,2304.06626,hebbian fast plasticity and working memory,q-bio.nc cs.ne,"theories and models of working memory (wm) were at least since the mid-1990s dominated by the persistent activity hypothesis. the past decade has seen rising concerns about the shortcomings of sustained activity as the mechanism for short-term maintenance of wm information in the light of accumulating experimental evidence for so-called activity-silent wm and the fundamental difficulty in explaining robust multi-item wm. in consequence, alternative theories are now explored mostly in the direction of fast synaptic plasticity as the underlying mechanism.the question of non-hebbian vs hebbian synaptic plasticity emerges naturally in this context. in this review we focus on fast hebbian plasticity and trace the origins of wm theories and models building on this form of associative learning.",,2023-04-13,,"['anders lansner', 'florian fiebig', 'pawel herman']",https://arxiv.org/pdf/2304.06626.pdf
1004,2304.06627,cosda: continual source-free domain adaptation,cs.lg cs.cv,"without access to the source data, source-free domain adaptation (sfda) transfers knowledge from a source-domain trained model to target domains. recently, sfda has gained popularity due to the need to protect the data privacy of the source domain, but it suffers from catastrophic forgetting on the source domain due to the lack of data. to systematically investigate the mechanism of catastrophic forgetting, we first reimplement previous sfda approaches within a unified framework and evaluate them on four benchmarks. we observe that there is a trade-off between adaptation gain and forgetting loss, which motivates us to design a consistency regularization to mitigate forgetting. in particular, we propose a continual source-free domain adaptation approach named cosda, which employs a dual-speed optimized teacher-student model pair and is equipped with consistency learning capability. our experiments demonstrate that cosda outperforms state-of-the-art approaches in continuous adaptation. notably, our cosda can also be integrated with other sfda methods to alleviate forgetting.",,2023-04-13,,"['haozhe feng', 'zhaorui yang', 'hesun chen', 'tianyu pang', 'chao du', 'minfeng zhu', 'wei chen', 'shuicheng yan']",https://arxiv.org/pdf/2304.06627.pdf
1005,2304.06652,protodiv: prototype-guided division of consistent pseudo-bags for   whole-slide image classification,cs.cv,"due to the limitations of inadequate whole-slide image (wsi) samples with weak labels, pseudo-bag-based multiple instance learning (mil) appears as a vibrant prospect in wsi classification. however, the pseudo-bag dividing scheme, often crucial for classification performance, is still an open topic worth exploring. therefore, this paper proposes a novel scheme, protodiv, using a bag prototype to guide the division of wsi pseudo-bags. rather than designing complex network architecture, this scheme takes a plugin-and-play approach to safely augment wsi data for effective training while preserving sample consistency. furthermore, we specially devise an attention-based prototype that could be optimized dynamically in training to adapt to a classification task. we apply our protodiv scheme on seven baseline models, and then carry out a group of comparison experiments on two public wsi datasets. experiments confirm our protodiv could usually bring obvious performance improvements to wsi classification.",,2023-04-13,,"['rui yang', 'pei liu', 'luping ji']",https://arxiv.org/pdf/2304.06652.pdf
1006,2304.06662,deep learning in breast cancer imaging: a decade of progress and future   directions,eess.iv cs.cv,"breast cancer has reached the highest incidence rate worldwide among all malignancies since 2020. breast imaging plays a significant role in early diagnosis and intervention to improve the outcome of breast cancer patients. in the past decade, deep learning has shown remarkable progress in breast cancer imaging analysis, holding great promise in interpreting the rich information and complex context of breast imaging modalities. considering the rapid improvement in the deep learning technology and the increasing severity of breast cancer, it is critical to summarize past progress and identify future challenges to be addressed. in this paper, we provide an extensive survey of deep learning-based breast cancer imaging research, covering studies on mammogram, ultrasound, magnetic resonance imaging, and digital pathology images over the past decade. the major deep learning methods, publicly available datasets, and applications on imaging-based screening, diagnosis, treatment response prediction, and prognosis are described in detail. drawn from the findings of this survey, we present a comprehensive discussion of the challenges and potential avenues for future research in deep learning-based breast cancer imaging.",,2023-04-13,,"['luyang luo', 'xi wang', 'yi lin', 'xiaoqi ma', 'andong tan', 'ronald chan', 'vince vardhanabhuti', 'winnie cw chu', 'kwang-ting cheng', 'hao chen']",https://arxiv.org/pdf/2304.06662.pdf
1007,2304.06667,d-svm over networked systems with non-ideal linking conditions,eess.sy cs.lg cs.sy math.ds math.oc,"this paper considers distributed optimization algorithms, with application in binary classification via distributed support-vector-machines (d-svm) over multi-agent networks subject to some link nonlinearities. the agents solve a consensus-constraint distributed optimization cooperatively via continuous-time dynamics, while the links are subject to strongly sign-preserving odd nonlinear conditions. logarithmic quantization and clipping (saturation) are two examples of such nonlinearities. in contrast to existing literature that mostly considers ideal links and perfect information exchange over linear channels, we show how general sector-bounded models affect the convergence to the optimizer (i.e., the svm classifier) over dynamic balanced directed networks. in general, any odd sector-bounded nonlinear mapping can be applied to our dynamics. the main challenge is to show that the proposed system dynamics always have one zero eigenvalue (associated with the consensus) and the other eigenvalues all have negative real parts. this is done by recalling arguments from matrix perturbation theory. then, the solution is shown to converge to the agreement state under certain conditions. for example, the gradient tracking (gt) step size is tighter than the linear case by factors related to the upper/lower sector bounds. to the best of our knowledge, no existing work in distributed optimization and learning literature considers non-ideal link conditions.",,2023-04-13,,"['mohammadreza doostmohammadian', 'alireza aghasi', 'houman zarrabi']",https://arxiv.org/pdf/2304.06667.pdf
1008,2304.06670,do deep neural networks have an inbuilt occam's razor?,cs.lg cs.ai stat.ml,"the remarkable performance of overparameterized deep neural networks (dnns) must arise from an interplay between network architecture, training algorithms, and structure in the data. to disentangle these three components, we apply a bayesian picture, based on the functions expressed by a dnn, to supervised learning. the prior over functions is determined by the network, and is varied by exploiting a transition between ordered and chaotic regimes. for boolean function classification, we approximate the likelihood using the error spectrum of functions on data. when combined with the prior, this accurately predicts the posterior, measured for dnns trained with stochastic gradient descent. this analysis reveals that structured data, combined with an intrinsic occam's razor-like inductive bias towards (kolmogorov) simple functions that is strong enough to counteract the exponential growth of the number of functions with complexity, is a key to the success of dnns.",,2023-04-13,,"['chris mingard', 'henry rees', 'guillermo valle-p√©rez', 'ard a. louis']",https://arxiv.org/pdf/2304.06670.pdf
1009,2304.06672,lsfsl: leveraging shape information in few-shot learning,cs.cv cs.ai,"few-shot learning (fsl) techniques seek to learn the underlying patterns in data using fewer samples, analogous to how humans learn from limited experience. in this limited-data scenario, the challenges associated with deep neural networks, such as shortcut learning and texture bias behaviors, are further exacerbated. moreover, the significance of addressing shortcut learning is not yet fully explored in the few-shot setup. to address these issues, we propose lsfsl, which enforces the model to learn more generalizable features utilizing the implicit prior information present in the data. through comprehensive analyses, we demonstrate that lsfsl-trained models are less vulnerable to alteration in color schemes, statistical correlations, and adversarial perturbations leveraging the global semantics in the data. our findings highlight the potential of incorporating relevant priors in few-shot approaches to increase robustness and generalization.",,2023-04-13,,"['deepan chakravarthi padmanabhan', 'shruthi gowda', 'elahe arani', 'bahram zonooz']",https://arxiv.org/pdf/2304.06672.pdf
1010,2304.06686,okridge: scalable optimal k-sparse ridge regression for learning   dynamical systems,cs.lg stat.ml,"we consider an important problem in scientific discovery, identifying sparse governing equations for nonlinear dynamical systems. this involves solving sparse ridge regression problems to provable optimality in order to determine which terms drive the underlying dynamics. we propose a fast algorithm, okridge, for sparse ridge regression, using a novel lower bound calculation involving, first, a saddle point formulation, and from there, either solving (i) a linear system or (ii) using an admm-based approach, where the proximal operators can be efficiently evaluated by solving another linear system and an isotonic regression problem. we also propose a method to warm-start our solver, which leverages a beam search. experimentally, our methods attain provable optimality with run times that are orders of magnitude faster than those of the existing mip formulations solved by the commercial solver gurobi.",,2023-04-13,,"['jiachang liu', 'sam rosen', 'chudi zhong', 'cynthia rudin']",https://arxiv.org/pdf/2304.06686.pdf
1011,2304.06692,reduce api debugging overhead via knowledge prepositioning,cs.se,"openapi indicates a behavior where producers offer application programming interfaces (apis) to help end-users access their data, resources, and services. generally, api has many parameters that need to be entered. however, it is challenging for users to understand and document these parameters correctly. this paper develops an api workbench to help users learn and debug apis. based on this workbench, much exploratory work has been proposed to reduce the overhead of learning and debugging apis. we explore the knowledge, such as parameter characteristics (e.g., enumerability) and constraints (e.g., maximum/minimum value), from the massive api call logs to narrow the range of parameter values. then, we propose a fine-grained approach to enrich the api documentation by extracting dependency knowledge between apis. finally, we present a learning-based prediction method to predict api execution results before the api is called, significantly reducing user debugging cycles. the experiments evaluated on the online system show that this work's approach substantially improves the user experience of debugging openapis.",10.1145/3543873.3587311,2023-03-23,,"['shujun wang', 'yongqiang tian', 'dengcheng he']",https://arxiv.org/pdf/2304.06692.pdf
1012,2304.06701,learning personalized decision support policies,cs.lg cs.ai cs.cy cs.hc,"individual human decision-makers may benefit from different forms of support to improve decision outcomes. however, a key question is which form of support will lead to accurate decisions at a low cost. in this work, we propose learning a decision support policy that, for a given input, chooses which form of support, if any, to provide. we consider decision-makers for whom we have no prior information and formalize learning their respective policies as a multi-objective optimization problem that trades off accuracy and cost. using techniques from stochastic contextual bandits, we propose $\texttt{thread}$, an online algorithm to personalize a decision support policy for each decision-maker, and devise a hyper-parameter tuning strategy to identify a cost-performance trade-off using simulated human behavior. we provide computational experiments to demonstrate the benefits of $\texttt{thread}$ compared to offline baselines. we then introduce $\texttt{modiste}$, an interactive tool that provides $\texttt{thread}$ with an interface. we conduct human subject experiments to show how $\texttt{modiste}$ learns policies personalized to each decision-maker and discuss the nuances of learning decision support policies online for real users.",,2023-04-13,,"['umang bhatt', 'valerie chen', 'katherine m. collins', 'parameswaran kamalaruban', 'emma kallina', 'adrian weller', 'ameet talwalkar']",https://arxiv.org/pdf/2304.06701.pdf
1013,2304.06704,how will it drape like? capturing fabric mechanics from depth images,cs.cv cs.ai cs.cg cs.gr stat.ml,"we propose a method to estimate the mechanical parameters of fabrics using a casual capture setup with a depth camera. our approach enables to create mechanically-correct digital representations of real-world textile materials, which is a fundamental step for many interactive design and engineering applications. as opposed to existing capture methods, which typically require expensive setups, video sequences, or manual intervention, our solution can capture at scale, is agnostic to the optical appearance of the textile, and facilitates fabric arrangement by non-expert operators. to this end, we propose a sim-to-real strategy to train a learning-based framework that can take as input one or multiple images and outputs a full set of mechanical parameters. thanks to carefully designed data augmentation and transfer learning protocols, our solution generalizes to real images despite being trained only on synthetic data, hence successfully closing the sim-to-real loop.key in our work is to demonstrate that evaluating the regression accuracy based on the similarity at parameter space leads to an inaccurate distances that do not match the human perception. to overcome this, we propose a novel metric for fabric drape similarity that operates on the image domain instead on the parameter space, allowing us to evaluate our estimation within the context of a similarity rank. we show that out metric correlates with human judgments about the perception of drape similarity, and that our model predictions produce perceptually accurate results compared to the ground truth parameters.",10.1111/cgf.14750,2023-04-13,,"['carlos rodriguez-pardo', 'melania prieto-martin', 'dan casas', 'elena garces']",https://arxiv.org/pdf/2304.06704.pdf
1014,2304.06708,verbs in action: improving verb understanding in video-language models,cs.cv cs.ai cs.cl,"understanding verbs is crucial to modelling how people and objects interact with each other and the environment through space and time. recently, state-of-the-art video-language models based on clip have been shown to have limited verb understanding and to rely extensively on nouns, restricting their performance in real-world video applications that require action and temporal understanding. in this work, we improve verb understanding for clip-based video-language models by proposing a new verb-focused contrastive (vfc) framework. this consists of two main components: (1) leveraging pretrained large language models (llms) to create hard negatives for cross-modal contrastive learning, together with a calibration strategy to balance the occurrence of concepts in positive and negative pairs; and (2) enforcing a fine-grained, verb phrase alignment loss. our method achieves state-of-the-art results for zero-shot performance on three downstream tasks that focus on verb understanding: video-text matching, video question-answering and video classification. to the best of our knowledge, this is the first work which proposes a method to alleviate the verb understanding problem, and does not simply highlight it.",,2023-04-13,,"['liliane momeni', 'mathilde caron', 'arsha nagrani', 'andrew zisserman', 'cordelia schmid']",https://arxiv.org/pdf/2304.06708.pdf
1015,2304.06711,diffusionrig: learning personalized priors for facial appearance editing,cs.cv cs.gr,"we address the problem of learning person-specific facial priors from a small number (e.g., 20) of portrait photos of the same person. this enables us to edit this specific person's facial appearance, such as expression and lighting, while preserving their identity and high-frequency facial details. key to our approach, which we dub diffusionrig, is a diffusion model conditioned on, or ""rigged by,"" crude 3d face models estimated from single in-the-wild images by an off-the-shelf estimator. on a high level, diffusionrig learns to map simplistic renderings of 3d face models to realistic photos of a given person. specifically, diffusionrig is trained in two stages: it first learns generic facial priors from a large-scale face dataset and then person-specific priors from a small portrait photo collection of the person of interest. by learning the cgi-to-photo mapping with such personalized priors, diffusionrig can ""rig"" the lighting, facial expression, head pose, etc. of a portrait photo, conditioned only on coarse 3d models while preserving this person's identity and other high-frequency characteristics. qualitative and quantitative experiments show that diffusionrig outperforms existing approaches in both identity preservation and photorealism. please see the project website: https://diffusionrig.github.io for the supplemental material, video, code, and data.",,2023-04-13,,"['zheng ding', 'xuaner zhang', 'zhihao xia', 'lars jebe', 'zhuowen tu', 'xiuming zhang']",https://arxiv.org/pdf/2304.06711.pdf
1016,2304.06714,single-stage diffusion nerf: a unified approach to 3d generation and   reconstruction,cs.cv,"3d-aware image synthesis encompasses a variety of tasks, such as scene generation and novel view synthesis from images. despite numerous task-specific methods, developing a comprehensive model remains challenging. in this paper, we present ssdnerf, a unified approach that employs an expressive diffusion model to learn a generalizable prior of neural radiance fields (nerf) from multi-view images of diverse objects. previous studies have used two-stage approaches that rely on pretrained nerfs as real data to train diffusion models. in contrast, we propose a new single-stage training paradigm with an end-to-end objective that jointly optimizes a nerf auto-decoder and a latent diffusion model, enabling simultaneous 3d reconstruction and prior learning, even from sparsely available views. at test time, we can directly sample the diffusion prior for unconditional generation, or combine it with arbitrary observations of unseen objects for nerf reconstruction. ssdnerf demonstrates robust results comparable to or better than leading task-specific methods in unconditional generation and single/sparse-view 3d reconstruction.",,2023-04-13,,"['hansheng chen', 'jiatao gu', 'anpei chen', 'wei tian', 'zhuowen tu', 'lingjie liu', 'hao su']",https://arxiv.org/pdf/2304.06714.pdf
1017,2304.06715,evaluating the robustness of interpretability methods through   explanation invariance and equivariance,cs.lg cs.ai cs.cg,"interpretability methods are valuable only if their explanations faithfully describe the explained model. in this work, we consider neural networks whose predictions are invariant under a specific symmetry group. this includes popular architectures, ranging from convolutional to graph neural networks. any explanation that faithfully explains this type of model needs to be in agreement with this invariance property. we formalize this intuition through the notion of explanation invariance and equivariance by leveraging the formalism from geometric deep learning. through this rigorous formalism, we derive (1) two metrics to measure the robustness of any interpretability method with respect to the model symmetry group; (2) theoretical robustness guarantees for some popular interpretability methods and (3) a systematic approach to increase the invariance of any interpretability method with respect to a symmetry group. by empirically measuring our metrics for explanations of models associated with various modalities and symmetry groups, we derive a set of 5 guidelines to allow users and developers of interpretability methods to produce robust explanations.",,2023-04-13,,"['jonathan crabb√©', 'mihaela van der schaar']",https://arxiv.org/pdf/2304.06715.pdf
1018,2304.06716,stu-net: scalable and transferable medical image segmentation models   empowered by large-scale supervised pre-training,cs.cv,"large-scale models pre-trained on large-scale datasets have profoundly advanced the development of deep learning. however, the state-of-the-art models for medical image segmentation are still small-scale, with their parameters only in the tens of millions. further scaling them up to higher orders of magnitude is rarely explored. an overarching goal of exploring large-scale models is to train them on large-scale medical segmentation datasets for better transfer capacities. in this work, we design a series of scalable and transferable u-net (stu-net) models, with parameter sizes ranging from 14 million to 1.4 billion. notably, the 1.4b stu-net is the largest medical image segmentation model to date. our stu-net is based on nnu-net framework due to its popularity and impressive performance. we first refine the default convolutional blocks in nnu-net to make them scalable. then, we empirically evaluate different scaling combinations of network depth and width, discovering that it is optimal to scale model depth and width together. we train our scalable stu-net models on a large-scale totalsegmentator dataset and find that increasing model size brings a stronger performance gain. this observation reveals that a large model is promising in medical image segmentation. furthermore, we evaluate the transferability of our model on 14 downstream datasets for direct inference and 3 datasets for further fine-tuning, covering various modalities and segmentation targets. we observe good performance of our pre-trained model in both direct inference and fine-tuning. the code and pre-trained models are available at https://github.com/ziyan-huang/stu-net.",,2023-04-13,,"['ziyan huang', 'haoyu wang', 'zhongying deng', 'jin ye', 'yanzhou su', 'hui sun', 'junjun he', 'yun gu', 'lixu gu', 'shaoting zhang', 'yu qiao']",https://arxiv.org/pdf/2304.06716.pdf
1019,2304.06718,segment everything everywhere all at once,cs.cv,"despite the growing demand for interactive ai systems, there have been few comprehensive studies on human-ai interaction in visual understanding e.g. segmentation. inspired by the development of prompt-based universal interfaces for llms, this paper presents seem, a promptable, interactive model for segmenting everything everywhere all at once in an image. seem has four desiderata: i) versatility: by introducing a versatile prompting engine for different types of prompts, including points, boxes, scribbles, masks, texts, and referred regions of another image; ii) compositionality: by learning a joint visual-semantic space for visual and textual prompts to compose queries on the fly for inference as shown in fig 1; iii)interactivity: by incorporating learnable memory prompts to retain dialog history information via mask-guided cross-attention; and iv) semantic-awareness: by using a text encoder to encode text queries and mask labels for open-vocabulary segmentation.",,2023-04-13,,"['xueyan zou', 'jianwei yang', 'hao zhang', 'feng li', 'linjie li', 'jianfeng gao', 'yong jae lee']",https://arxiv.org/pdf/2304.06718.pdf
